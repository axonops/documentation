{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to AxonOps Documentation \u00b6 Introduction \u00b6 AxonOps is an operational management tool built for Apache Cassandra (https://cassandra.apache.org). Features \u00b6 Inventory information overview Dashboarding metrics , logs , and healthchecks Highly efficient metrics collection and storage from the agents Integrates with ChatOps and alerting tools - Slack and PagerDuty etc for notifications and alerts Domain aware functionalities, including Cassandra repairs and backups schedulers. Components \u00b6 AxonOps has four main components: axon-server - The main server of axonops that collect metrics, logs, events and more. axon-dash - The UI to interact with axon-server (dash for AxonOps Dashboards). axon-agents - An to small agent binary deployed onto the managed nodes. Elasticsearch - A distributed search engine which stores all of the collected data.","title":"Introduction"},{"location":"#welcome-to-axonops-documentation","text":"","title":"Welcome to AxonOps Documentation"},{"location":"#introduction","text":"AxonOps is an operational management tool built for Apache Cassandra (https://cassandra.apache.org).","title":"Introduction"},{"location":"#features","text":"Inventory information overview Dashboarding metrics , logs , and healthchecks Highly efficient metrics collection and storage from the agents Integrates with ChatOps and alerting tools - Slack and PagerDuty etc for notifications and alerts Domain aware functionalities, including Cassandra repairs and backups schedulers.","title":"Features"},{"location":"#components","text":"AxonOps has four main components: axon-server - The main server of axonops that collect metrics, logs, events and more. axon-dash - The UI to interact with axon-server (dash for AxonOps Dashboards). axon-agents - An to small agent binary deployed onto the managed nodes. Elasticsearch - A distributed search engine which stores all of the collected data.","title":"Components"},{"location":"cluster/cluster-overview/","text":"Cluster Overview is the home page and provides an overview of your cluster health, including OS , Cassandra and JVM details. The informations are automatically extracted by the AxonOps agent and pushed to AxonOps server. There is no need to configure anything on the agent or the server side for this information to be populated in the Cluster Overview dashboard. On the Axonops application menu, select Cluster Overview . You can select a node to view some details on the OS , Cassandra or the JVM . Infomy OS Details \u00b6 Operating System Details section shows general information including: General Information CPU Memory Swap Disk volumes Infomy Cassandra Details \u00b6 Cassandra Details view shows the details from cassandra.yaml loaded into Cassandra. There is a search field available near the top to filter the parameters. Infomy JVM Details \u00b6 JVM Details section shows the general information about the JVM, including the version and some configurations such as the heap and Garbage Collection settings. Infomy","title":"Overview"},{"location":"cluster/cluster-overview/#os-details","text":"Operating System Details section shows general information including: General Information CPU Memory Swap Disk volumes Infomy","title":"OS Details"},{"location":"cluster/cluster-overview/#cassandra-details","text":"Cassandra Details view shows the details from cassandra.yaml loaded into Cassandra. There is a search field available near the top to filter the parameters. Infomy","title":"Cassandra Details"},{"location":"cluster/cluster-overview/#jvm-details","text":"JVM Details section shows the general information about the JVM, including the version and some configurations such as the heap and Garbage Collection settings. Infomy","title":"JVM Details"},{"location":"configuration/agent-configuration/","text":"Configuring AxonOps Agent \u00b6 Work in progress","title":"Configuring AxonOps Agent"},{"location":"configuration/agent-configuration/#configuring-axonops-agent","text":"Work in progress","title":"Configuring AxonOps Agent"},{"location":"configuration/axondash/","text":"Configuring AxonOps Agent \u00b6 Work in progress","title":"Configuring AxonOps Agent"},{"location":"configuration/axondash/#configuring-axonops-agent","text":"Work in progress","title":"Configuring AxonOps Agent"},{"location":"configuration/server-configuration/","text":"Configuring AxonOps Server \u00b6 Work in progress","title":"Configuring AxonOps Server"},{"location":"configuration/server-configuration/#configuring-axonops-server","text":"Work in progress","title":"Configuring AxonOps Server"},{"location":"how-to/backup-restore-notifications/","text":"Setup Backup - Restore Notications \u00b6 On the Axonops application menu, click Operations -> Backups -> Setup and select Notifications tab. Notification Severities. \u00b6 Notification Severities. For each notifications severity Info Warning Error you can either use the slider to use the default routing or use the icon to customize the notification integrations. Notice: not available when default routing selected Infomy Customize Notifications. \u00b6 To customize notifications click on select the integrations that you require and click Close . Infomy Noticed: The Warning Integration were customized. You can remove these by clicking the . If you want to remove default routing groups from a severity and create custom groups , use the slider bar to remove default routing click the and follow this steps If you do not require any notifications ensure the default routing is off and delete any previously created custom notification. Infomy","title":"Setup Backup - Restore Notications"},{"location":"how-to/backup-restore-notifications/#setup-backup-restore-notications","text":"On the Axonops application menu, click Operations -> Backups -> Setup and select Notifications tab.","title":"Setup Backup - Restore Notications"},{"location":"how-to/backup-restore-notifications/#notification-severities","text":"Notification Severities. For each notifications severity Info Warning Error you can either use the slider to use the default routing or use the icon to customize the notification integrations. Notice: not available when default routing selected Infomy","title":"Notification Severities."},{"location":"how-to/backup-restore-notifications/#customize-notifications","text":"To customize notifications click on select the integrations that you require and click Close . Infomy Noticed: The Warning Integration were customized. You can remove these by clicking the . If you want to remove default routing groups from a severity and create custom groups , use the slider bar to remove default routing click the and follow this steps If you do not require any notifications ensure the default routing is off and delete any previously created custom notification. Infomy","title":"Customize Notifications."},{"location":"how-to/default-routing/","text":"Setup Default Routing \u00b6 Deafult Routing. Allows you to set up the channels though which alerts & notifications will be received and the specific groups that will receive the alerts & notifications Setup Default Routing \u00b6 On the Axonops application menu, select Alert & Notifications -> Integration and select Default Routing tab. Alert & Notification types can be set up Infomy Info Warning Error Info \u00b6 To Setup Default Routing For Info click On Select the desired group(s) from the dropdown menu for the desired integrations(s) and click` to confirm selections Infomy The group should now appear in the Info Info box on the Default Routing Tab Infomy Warning - Error \u00b6 Repeat these steps to setup the Default Routing for Warning Error Edit Default Routing \u00b6 To Edit Default Routing click on the icon on either Add or Remove existing integrations using the dropdown menus. Delete Default Routing \u00b6 To Remove a group click on the Delete icon Infomy","title":"Setup Default Routing"},{"location":"how-to/default-routing/#setup-default-routing","text":"Deafult Routing. Allows you to set up the channels though which alerts & notifications will be received and the specific groups that will receive the alerts & notifications","title":"Setup Default Routing"},{"location":"how-to/default-routing/#setup-default-routing_1","text":"On the Axonops application menu, select Alert & Notifications -> Integration and select Default Routing tab. Alert & Notification types can be set up Infomy Info Warning Error","title":"Setup Default Routing"},{"location":"how-to/default-routing/#info","text":"To Setup Default Routing For Info click On Select the desired group(s) from the dropdown menu for the desired integrations(s) and click` to confirm selections Infomy The group should now appear in the Info Info box on the Default Routing Tab Infomy","title":"Info"},{"location":"how-to/default-routing/#warning-error","text":"Repeat these steps to setup the Default Routing for Warning Error","title":"Warning - Error"},{"location":"how-to/default-routing/#edit-default-routing","text":"To Edit Default Routing click on the icon on either Add or Remove existing integrations using the dropdown menus.","title":"Edit Default Routing"},{"location":"how-to/default-routing/#delete-default-routing","text":"To Remove a group click on the Delete icon Infomy","title":"Delete Default Routing"},{"location":"how-to/reuse-host-id/","text":"Re-using an existing Host ID \u00b6 Each agent connected to the AxonOps server is assigned a unique host ID that is used internally to associate metrics and events with the node. If a Cassandra host dies and is replaced by another one with the same IP and token range then normally a new host ID will be generated and the replacement server will appear as a new machine in AxonOps. In this situation it is possible to re-use the same host ID so AxonOps sees the replacement server as the same as the original one. You can find the host ID of a node in the AxonOps GUI by going to Cluster Overview and selecting a node. In Graph View the host ID is shown next to the hostname in the details panel and in List View it is shown as Agent ID at the top of the details popup. If the old server's filesystem is still accessible you can also find the host ID stored in /var/lib/axonops/hostId . Follow these steps to start up a replacement server using the old host ID: Install axon-agent on the replacement server Stop axon-agent if it is running then delete these files if they exist: /var/lib/axonops/hostId , /var/lib/axonops/local.db Create a new file at /var/lib/axonops/hostId containing the host ID you wish to use Start axon-agent","title":"Re-use an existing host ID"},{"location":"how-to/reuse-host-id/#re-using-an-existing-host-id","text":"Each agent connected to the AxonOps server is assigned a unique host ID that is used internally to associate metrics and events with the node. If a Cassandra host dies and is replaced by another one with the same IP and token range then normally a new host ID will be generated and the replacement server will appear as a new machine in AxonOps. In this situation it is possible to re-use the same host ID so AxonOps sees the replacement server as the same as the original one. You can find the host ID of a node in the AxonOps GUI by going to Cluster Overview and selecting a node. In Graph View the host ID is shown next to the hostname in the details panel and in List View it is shown as Agent ID at the top of the details popup. If the old server's filesystem is still accessible you can also find the host ID stored in /var/lib/axonops/hostId . Follow these steps to start up a replacement server using the old host ID: Install axon-agent on the replacement server Stop axon-agent if it is running then delete these files if they exist: /var/lib/axonops/hostId , /var/lib/axonops/local.db Create a new file at /var/lib/axonops/hostId containing the host ID you wish to use Start axon-agent","title":"Re-using an existing Host ID"},{"location":"how-to/setup-alert-rules/","text":"Setup alert rules \u00b6 Insert Alert Rules Credentials \u00b6 On the Axonops application menu, click Dashboards and select required Dashboard. eg. System Hover over the desired Chart click on the button. Infomy Complete The Fields In Form \u00b6 Below the chart click on the alert tab. Infomy A form will appear Infomy Complete Alert settings in Comparator Warning value or Critical value or Both and the Duration ==> (how often to check) In Infomy Annotations \u00b6 In the Summary box you can include free text & type one or many of the following $labels $labels : - cluster - dc - hostname - org - rack - type - keyspace $value : In the Description box you can include free along with one or many of the above $labels Example CPU usage per DC Alerts usage on {{ $labels.hostname }} and cluster {{$labels.cluster}} Infomy Integrations \u00b6 Using the slider bar you can select any Integrations . Then click on the Info , Warning , Error icons, to select the group(s) of Integrations for the alert. Infomy Not selecting integrations If you do not select any specific Integrations the Alert will automatically follow the Global Dashboard Routing or if this has not been setup the Default Routing Integrations. Edit Alert Rule \u00b6 On the Axonops application menu, click Alerts & Notifications and click Active. Select the Alert Rules tab and click Infomy Delete Alert Rule(s) \u00b6 To Delete An Alert Either... On the Axonops application menu, click Dashboards and select required Dashboard. eg. System Hover over the desired Chart click on the button. Below the chart click on the alert tab and click on the of the alert rule you want to remove. OR... On the Axonops application menu, click Alerts & Notifications and click Active. Select the Alert Rules tab and click Infomy","title":"Setup Alert Rules"},{"location":"how-to/setup-alert-rules/#setup-alert-rules","text":"","title":"Setup alert rules"},{"location":"how-to/setup-alert-rules/#insert-alert-rules-credentials","text":"On the Axonops application menu, click Dashboards and select required Dashboard. eg. System Hover over the desired Chart click on the button. Infomy","title":"Insert Alert Rules Credentials"},{"location":"how-to/setup-alert-rules/#complete-the-fields-in-form","text":"Below the chart click on the alert tab. Infomy A form will appear Infomy Complete Alert settings in Comparator Warning value or Critical value or Both and the Duration ==> (how often to check) In Infomy","title":"Complete The Fields In Form"},{"location":"how-to/setup-alert-rules/#annotations","text":"In the Summary box you can include free text & type one or many of the following $labels $labels : - cluster - dc - hostname - org - rack - type - keyspace $value : In the Description box you can include free along with one or many of the above $labels Example CPU usage per DC Alerts usage on {{ $labels.hostname }} and cluster {{$labels.cluster}} Infomy","title":"Annotations"},{"location":"how-to/setup-alert-rules/#integrations","text":"Using the slider bar you can select any Integrations . Then click on the Info , Warning , Error icons, to select the group(s) of Integrations for the alert. Infomy Not selecting integrations If you do not select any specific Integrations the Alert will automatically follow the Global Dashboard Routing or if this has not been setup the Default Routing Integrations.","title":"Integrations"},{"location":"how-to/setup-alert-rules/#edit-alert-rule","text":"On the Axonops application menu, click Alerts & Notifications and click Active. Select the Alert Rules tab and click Infomy","title":"Edit Alert Rule"},{"location":"how-to/setup-alert-rules/#delete-alert-rules","text":"To Delete An Alert Either... On the Axonops application menu, click Dashboards and select required Dashboard. eg. System Hover over the desired Chart click on the button. Below the chart click on the alert tab and click on the of the alert rule you want to remove. OR... On the Axonops application menu, click Alerts & Notifications and click Active. Select the Alert Rules tab and click Infomy","title":"Delete Alert Rule(s)"},{"location":"how-to/setup-dashboards-global-integrations/","text":"Setup Dashboards Global Integrations \u00b6 On the Axonops application menu, click Alerts & Notifications -> Active and select Dashboards Global Routing tab. Notification Severities. \u00b6 Notification Severities. For each notifications severity Info Warning Error you can either use the slider to use the default routing or use the icon to customize the notification integrations. Notice: not available when default routing selected Infomy Customize Notifications. \u00b6 To customize notifications click on select the integrations that you require and click Close . Infomy Noticed: The Warning Integration were customized. You can remove these by clicking the . If you want to remove default routing groups from a severity and create custom groups , use the slider bar to remove default routing click the and follow this steps If you do not require any notifications ensure the default routing is off and delete any previously created custom notification. Infomy","title":"Setup Dashboards Global Integrations"},{"location":"how-to/setup-dashboards-global-integrations/#setup-dashboards-global-integrations","text":"On the Axonops application menu, click Alerts & Notifications -> Active and select Dashboards Global Routing tab.","title":"Setup Dashboards Global Integrations"},{"location":"how-to/setup-dashboards-global-integrations/#notification-severities","text":"Notification Severities. For each notifications severity Info Warning Error you can either use the slider to use the default routing or use the icon to customize the notification integrations. Notice: not available when default routing selected Infomy","title":"Notification Severities."},{"location":"how-to/setup-dashboards-global-integrations/#customize-notifications","text":"To customize notifications click on select the integrations that you require and click Close . Infomy Noticed: The Warning Integration were customized. You can remove these by clicking the . If you want to remove default routing groups from a severity and create custom groups , use the slider bar to remove default routing click the and follow this steps If you do not require any notifications ensure the default routing is off and delete any previously created custom notification. Infomy","title":"Customize Notifications."},{"location":"how-to/setup-log-collection/","text":"AxonOps dashboards provides a comprehensive set of charts with an embedded view for logs and events. The goal is to correlate metrics with logs/events as you can zoom in the logs histogram or metrics charts to drill down both results. Log and event view is located in the bottom part of that page that you can expand/collapse with the horizontal splitter. The setup for log collection is accessible via Settings > logs Infomy newlineregex is used by the log collector to handle multilines logs. Default newlineregex for Cassandra should be ok unless you've customized it.","title":"Setup Log Collection"},{"location":"how-to/setup-servicechecks/","text":"Setup Service Checks \u00b6 Add Service Checks \u00b6 On the Axonops application menu, click Service Checks and select Setup tab. Infomy Create Services \u00b6 Below there few examples copy and Paste inside. and click save { \"shellchecks\" : [ { \"name\" : \"check_elastic\" , \"shell\" : \"/bin/bash\" , \"script\" : \"if [ 'ps auxwww | grep elastic | wc -l' -lt 1 ] then exit 2 else exit 0 fi\" , \"interval\" : \"5m\" , \"timeout\" : \"1m\" } ], \"httpchecks\" : [], \"tcpchecks\" : [ { \"name\" : \"elastic_tcp_endpoint_check\" , \"interval\" : \"5s\" , \"timeout\" : \"1m\" , \"tcp\" : \"localhost:9200\" } ] } Example: Infomy Delete Services \u00b6 To Delete a service copy and Paste inside. and click save { \"shellchecks\" : [], \"httpchecks\" : [], \"tcpchecks\" : [] } Example: Infomy","title":"Setup Service Checks"},{"location":"how-to/setup-servicechecks/#setup-service-checks","text":"","title":"Setup Service Checks"},{"location":"how-to/setup-servicechecks/#add-service-checks","text":"On the Axonops application menu, click Service Checks and select Setup tab. Infomy","title":"Add Service Checks"},{"location":"how-to/setup-servicechecks/#create-services","text":"Below there few examples copy and Paste inside. and click save { \"shellchecks\" : [ { \"name\" : \"check_elastic\" , \"shell\" : \"/bin/bash\" , \"script\" : \"if [ 'ps auxwww | grep elastic | wc -l' -lt 1 ] then exit 2 else exit 0 fi\" , \"interval\" : \"5m\" , \"timeout\" : \"1m\" } ], \"httpchecks\" : [], \"tcpchecks\" : [ { \"name\" : \"elastic_tcp_endpoint_check\" , \"interval\" : \"5s\" , \"timeout\" : \"1m\" , \"tcp\" : \"localhost:9200\" } ] } Example: Infomy","title":"Create Services"},{"location":"how-to/setup-servicechecks/#delete-services","text":"To Delete a service copy and Paste inside. and click save { \"shellchecks\" : [], \"httpchecks\" : [], \"tcpchecks\" : [] } Example: Infomy","title":"Delete Services"},{"location":"installation/axon-agent/install/","text":"axon-agent installation \u00b6 There 2 elements to the AxonOps agent. The first is the axon-agent, which is a native application for Linux running as a standalone daemon process. The second is the Java agent which is added to the Java process. Two components communicate with each other using the Unix domain socket. The reason for this approach are the following requirements we have on the agent process. No JMX Metrics must push metrics from Cassandra all the way to the AxonOps server - never pull. AxonOps Java agent will push the metrics to the AxonOps native agent, which in turn pushes them to the AxonOps server. Scraping a large volume of metrics against the JMX is slow. We also wanted to avoid exposing an HTTP endpoint within Cassandra like the Prometheus JMX exporter does. The messaging between native agent and Java agent are bi-directional - i.e. AxonOps server sends control messages to Cassandra for operations such as repair and backups without the use of JMX. This section describes how to install and configure both the native agent and Java agent. CentOS / RedHat \u00b6 sudo tee /etc/yum.repos.d/axonops-yum.repo << EOL [axonops-yum] name=axonops-yum baseurl=https://packages.axonops.com/yum/ enabled=1 repo_gpgcheck=0 gpgcheck=0 EOL sudo yum install axon-agent Debian / Ubuntu \u00b6 curl https://packages.axonops.com/apt/repo-signing-key.gpg | sudo apt-key add - echo \"deb https://packages.axonops.com/apt axonops-apt main\" | sudo tee /etc/apt/sources.list.d/axonops-apt.list sudo apt-get update sudo apt-get install axon-agent Package details \u00b6 Configuration: /etc/axonops/axon-agent.yml Binary: usr/share/axonops/axon-agent Logs : /var/log/axonops/axon-agent.log Systemd service: /usr/lib/systemd/system/axon-agent.service certificate file used for it's OpenTSDB endpoint when SSL is active: /etc/axonops/agent.crt key file used for it's OpenTSDB endpoint when SSL is active: /etc/axonops/agent.key Configuration \u00b6 Make sure axon-agent configuration points to the correct axon-server address and your organisation name is specified: axon-server : hosts : \"axon-server_endpoint\" # Specify axon-server IP axon-server.mycompany.com axon-agent : org : \"my-company-test\" # Specify your organisation name type : \"cassandra\" NTP : host : \"ntp.mycompany.com\" # Specify you NTP server IP address or hostname Start axon-agent \u00b6 systemctl daemon-reload systemctl start axon-agent systemctl status axon-agent This will start the axon-agent process as the axonops user, which was created during the package installation. Note that you will have to refresh axon-dash page to show the newly connected node. Next Steps \u00b6 To complete your agent installation you will need to follow the steps in the link below: cassandra","title":"axon-agent installation"},{"location":"installation/axon-agent/install/#axon-agent-installation","text":"There 2 elements to the AxonOps agent. The first is the axon-agent, which is a native application for Linux running as a standalone daemon process. The second is the Java agent which is added to the Java process. Two components communicate with each other using the Unix domain socket. The reason for this approach are the following requirements we have on the agent process. No JMX Metrics must push metrics from Cassandra all the way to the AxonOps server - never pull. AxonOps Java agent will push the metrics to the AxonOps native agent, which in turn pushes them to the AxonOps server. Scraping a large volume of metrics against the JMX is slow. We also wanted to avoid exposing an HTTP endpoint within Cassandra like the Prometheus JMX exporter does. The messaging between native agent and Java agent are bi-directional - i.e. AxonOps server sends control messages to Cassandra for operations such as repair and backups without the use of JMX. This section describes how to install and configure both the native agent and Java agent.","title":"axon-agent installation"},{"location":"installation/axon-agent/install/#centos-redhat","text":"sudo tee /etc/yum.repos.d/axonops-yum.repo << EOL [axonops-yum] name=axonops-yum baseurl=https://packages.axonops.com/yum/ enabled=1 repo_gpgcheck=0 gpgcheck=0 EOL sudo yum install axon-agent","title":"CentOS / RedHat"},{"location":"installation/axon-agent/install/#debian-ubuntu","text":"curl https://packages.axonops.com/apt/repo-signing-key.gpg | sudo apt-key add - echo \"deb https://packages.axonops.com/apt axonops-apt main\" | sudo tee /etc/apt/sources.list.d/axonops-apt.list sudo apt-get update sudo apt-get install axon-agent","title":"Debian / Ubuntu"},{"location":"installation/axon-agent/install/#package-details","text":"Configuration: /etc/axonops/axon-agent.yml Binary: usr/share/axonops/axon-agent Logs : /var/log/axonops/axon-agent.log Systemd service: /usr/lib/systemd/system/axon-agent.service certificate file used for it's OpenTSDB endpoint when SSL is active: /etc/axonops/agent.crt key file used for it's OpenTSDB endpoint when SSL is active: /etc/axonops/agent.key","title":"Package details"},{"location":"installation/axon-agent/install/#configuration","text":"Make sure axon-agent configuration points to the correct axon-server address and your organisation name is specified: axon-server : hosts : \"axon-server_endpoint\" # Specify axon-server IP axon-server.mycompany.com axon-agent : org : \"my-company-test\" # Specify your organisation name type : \"cassandra\" NTP : host : \"ntp.mycompany.com\" # Specify you NTP server IP address or hostname","title":"Configuration"},{"location":"installation/axon-agent/install/#start-axon-agent","text":"systemctl daemon-reload systemctl start axon-agent systemctl status axon-agent This will start the axon-agent process as the axonops user, which was created during the package installation. Note that you will have to refresh axon-dash page to show the newly connected node.","title":"Start axon-agent"},{"location":"installation/axon-agent/install/#next-steps","text":"To complete your agent installation you will need to follow the steps in the link below: cassandra","title":"Next Steps"},{"location":"installation/axon-dash/install/","text":"AxonOps GUI installation \u00b6 AxonOps GUI service is installed as a separate service to AxonOps Server. The GUI service (axon-dash) can be co-hosted on the same server as the AxonOps Server process, or they can be running on 2 separate servers. This section describes the installation process for the GUI service. Step 1 - Installation \u00b6 CentOS / RedHat \u00b6 sudo tee /etc/yum.repos.d/axonops-yum.repo << EOL [axonops-yum] name=axonops-yum baseurl=https://packages.axonops.com/yum/ enabled=1 repo_gpgcheck=0 gpgcheck=0 EOL sudo yum install axon-dash Debian / Ubuntu \u00b6 curl https://packages.axonops.com/apt/repo-signing-key.gpg | sudo apt-key add - echo \"deb https://packages.axonops.com/apt axonops-apt main\" | sudo tee /etc/apt/sources.list.d/axonops-apt.list sudo apt-get update sudo apt-get install axon-dash Step 2 - Configuration \u00b6 Change axon-dash configuration to specify axon-server listening address. /etc/axonops/axon-dash.yml axon-dash : # The listening address of axon-dash host : 0.0.0.0 port : 3000 line_charts_max_results : 256 axon-server : public_endpoints : \"http://axon-server.public:8080, https://axon-server.public\" # Public HTTP endpoint to axon-server API. This can be a list with comma separator. http://127.0.0.1 or http://locahost are always wrong. context_path : \"\" # example: \"/gui\" axon-server default listening port is 8080 Step 3 - axon-server configuration update \u00b6 Update axon-server configuration by setting the correct axon-dash host and port : /etc/axonops/axon-server.yml host : 0.0.0.0 # axon-server listening address port : 8080 # axon-server listening port elastic_host : http://localhost # Elasticsearch endpoint elastic_port : 9200 # Elasticsearch port axon-dash : # This must point to axon-dash address host : 127.0.0.1 port : 3000 https : false alerting : # How long to wait before sending a notification again if it has already # been sent successfully for an alert. (Usually ~3h or more). notification_interval : 3h retention : events : 8w # logs and events retention. Must be expressed in weeks (w) metrics : high_resolution : 14d # High frequency metrics. Must be expressed in days (d) med_resolution : 12w # Must be expressed in weeks (w) low_resolution : 12M # Must be expressed in months (M) super_low_resolution : 2y # Must be expressed in years (y) backups : # Those are use as defaults but can be overridden from the UI local : 10d remote : 30d Step 4 - Restart axon-server after updating it's configuration \u00b6 sudo systemctl restart axon-server Step 5 - Start axon-dash \u00b6 sudo systemctl daemon-reload sudo systemctl start axon-dash sudo systemctl status axon-dash This will start the axon-dash process as the axonops user, which was created during the package installation. The default listening address is 0.0.0.0:3000 . Package details \u00b6 Configuration: /etc/axonops/axon-dash.yml Binary: /usr/share/axonops/axon-dash Logs: /var/log/axonops/axon-dash.log Systemd service: /usr/lib/systemd/system/axon-dash.service Copyright : /usr/share/doc/axonops/axon-dash/copyright Licenses : /usr/share/axonops/licenses/axon-dash/ Step 6 - Installing agents \u00b6 Now axon-dash is installed, you can start installing cassandra-agent","title":"AxonOps GUI Server"},{"location":"installation/axon-dash/install/#axonops-gui-installation","text":"AxonOps GUI service is installed as a separate service to AxonOps Server. The GUI service (axon-dash) can be co-hosted on the same server as the AxonOps Server process, or they can be running on 2 separate servers. This section describes the installation process for the GUI service.","title":"AxonOps GUI installation"},{"location":"installation/axon-dash/install/#step-1-installation","text":"","title":"Step 1 - Installation"},{"location":"installation/axon-dash/install/#centos-redhat","text":"sudo tee /etc/yum.repos.d/axonops-yum.repo << EOL [axonops-yum] name=axonops-yum baseurl=https://packages.axonops.com/yum/ enabled=1 repo_gpgcheck=0 gpgcheck=0 EOL sudo yum install axon-dash","title":"CentOS / RedHat"},{"location":"installation/axon-dash/install/#debian-ubuntu","text":"curl https://packages.axonops.com/apt/repo-signing-key.gpg | sudo apt-key add - echo \"deb https://packages.axonops.com/apt axonops-apt main\" | sudo tee /etc/apt/sources.list.d/axonops-apt.list sudo apt-get update sudo apt-get install axon-dash","title":"Debian / Ubuntu"},{"location":"installation/axon-dash/install/#step-2-configuration","text":"Change axon-dash configuration to specify axon-server listening address. /etc/axonops/axon-dash.yml axon-dash : # The listening address of axon-dash host : 0.0.0.0 port : 3000 line_charts_max_results : 256 axon-server : public_endpoints : \"http://axon-server.public:8080, https://axon-server.public\" # Public HTTP endpoint to axon-server API. This can be a list with comma separator. http://127.0.0.1 or http://locahost are always wrong. context_path : \"\" # example: \"/gui\" axon-server default listening port is 8080","title":"Step 2 - Configuration"},{"location":"installation/axon-dash/install/#step-3-axon-server-configuration-update","text":"Update axon-server configuration by setting the correct axon-dash host and port : /etc/axonops/axon-server.yml host : 0.0.0.0 # axon-server listening address port : 8080 # axon-server listening port elastic_host : http://localhost # Elasticsearch endpoint elastic_port : 9200 # Elasticsearch port axon-dash : # This must point to axon-dash address host : 127.0.0.1 port : 3000 https : false alerting : # How long to wait before sending a notification again if it has already # been sent successfully for an alert. (Usually ~3h or more). notification_interval : 3h retention : events : 8w # logs and events retention. Must be expressed in weeks (w) metrics : high_resolution : 14d # High frequency metrics. Must be expressed in days (d) med_resolution : 12w # Must be expressed in weeks (w) low_resolution : 12M # Must be expressed in months (M) super_low_resolution : 2y # Must be expressed in years (y) backups : # Those are use as defaults but can be overridden from the UI local : 10d remote : 30d","title":"Step 3 - axon-server configuration update"},{"location":"installation/axon-dash/install/#step-4-restart-axon-server-after-updating-its-configuration","text":"sudo systemctl restart axon-server","title":"Step 4 - Restart axon-server after updating it's configuration"},{"location":"installation/axon-dash/install/#step-5-start-axon-dash","text":"sudo systemctl daemon-reload sudo systemctl start axon-dash sudo systemctl status axon-dash This will start the axon-dash process as the axonops user, which was created during the package installation. The default listening address is 0.0.0.0:3000 .","title":"Step 5 - Start axon-dash"},{"location":"installation/axon-dash/install/#package-details","text":"Configuration: /etc/axonops/axon-dash.yml Binary: /usr/share/axonops/axon-dash Logs: /var/log/axonops/axon-dash.log Systemd service: /usr/lib/systemd/system/axon-dash.service Copyright : /usr/share/doc/axonops/axon-dash/copyright Licenses : /usr/share/axonops/licenses/axon-dash/","title":"Package details"},{"location":"installation/axon-dash/install/#step-6-installing-agents","text":"Now axon-dash is installed, you can start installing cassandra-agent","title":"Step 6 - Installing agents"},{"location":"installation/axon-server/centos/","text":"axon-server installation (CentOS / RedHat) \u00b6 Step 1 - Prerequisites \u00b6 Elasticsearch stores all of the collected data by axon-server. Let's install Java 8 and Elasticsearch first. Installing JDK \u00b6 Elasticsearch supports either OpenJDK or Oracle JDK. Since Oracle has changed the licensing model as of January 2019 we suggest using OpenJDK. Run the following commands for OpenJDK: sudo yum install java-1.8.0-openjdk-devel Run the following commands for Oracle JDK: wget -c --header \"Cookie: oraclelicense=accept-securebackup-cookie\" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm sudo rpm -i jdk-8u131-linux-x64.rpm Increase the bulk queue size of Elasticsearch by running the following command: Elastic 7+: \u00b6 sudo echo 'thread_pool.write.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml Elastic 6.x: \u00b6 sudo echo 'thread_pool.bulk.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml Increase the default heap size of elasticsearch by editing /etc/elasticsearch/jvm.options . From: -Xms1g -Xmx1g To: -Xms8g -Xmx8g This will set the minimum and maximum heap size to 8 GB. Set Xmx and Xms to no more than 50% of your physical RAM. Elasticsearch requires memory for purposes other than the JVM heap and it is important to leave space for this. Set the following index codec by running the following command: sudo echo 'index.codec: best_compression' >> /etc/elasticsearch/elasticsearch.yml Elasticsearch uses a mmapfs directory by default to store its indices. The default operating system limits on mmap counts is likely to be too low, which may result in out of memory exceptions. You can increase the limits by running the following command: sudo sysctl -w vm.max_map_count = 262144 Also, Elasticsearch needs max file descriptors system settings at least to 65536. echo 'elasticsearch - nofile 65536' | sudo tee --append /etc/security/limits.conf > /dev/null And set LimitNOFILE=65536 in /etc/systemd/system/elasticsearch.services Start Elasticsearch \u00b6 sudo systemctl start elasticsearch.service After a short period of time, you can verify that your Elasticsearch node is running by sending an HTTP request to port 9200 on localhost: curl -X GET \"localhost:9200/\" Step 2 - axon-server \u00b6 sudo tee /etc/yum.repos.d/axonops-yum.repo << EOL [axonops-yum] name=axonops-yum baseurl=https://packages.axonops.com/yum/ enabled=1 repo_gpgcheck=0 gpgcheck=0 EOL sudo yum install axon-server Step 3 - axon-server configurations \u00b6 Make sure elastic_host and elastic_port are corresponding to your Elasticsearch instance. /etc/axonops/axon-server.yml host : 0.0.0.0 # axon-server listening address (used by axon-dash and axon-agent) (env variable: AXONSERVER_HOST) port : 8080 # axon-server HTTP API listening port (used by axon-dash) (AXONSERVER_PORT) elastic_hosts : # Elasticsearch endpoint (env variable:ELASTIC_HOSTS, comma separated list) -http://localhost #integrations_proxy: # proxy endpoint for integrations. (INTEGRATIONS_PROXY) # For better performance on large clusters, you can use a CQL store for the metrics. # To opt-in for CQL metrics storage, just specify at least one CQL host. # We do recommend to specify a NetworkTopologyStrategy for cql_keyspace_replication #cql_hosts: # (CQL_HOSTS, comma separated list) # - 192.168.0.10:9042 # - 192.168.0.11:9042 #cql_username: \"cassandra\" # (CQL_USERNAME) #cql_password: \"cassandra\" # (CQL_PASSWORD) #cql_local_dc: datacenter1 # (CQL_LOCAL_DC) #cql_ssl: false # (CQL_SSL) #cql_skip_verify: false # (CQL_SSL_SKIP_VERIFY) #cql_ca_file: /path/to/ca_file # (CQL_CA_FILE) #cql_cert_file: /path/to/cert_file # (CQL_CERT_FILE) #cql_key_file: /path/to/key_file # (CQL_KEY_FILE) #cql_proto_version: 4 # (CQL_PROTO_VERSION) #cql_max_concurrent_reads: 1000 # (CQL_MAX_CONCURRENT_READS) #cql_batch_size: 1 # (CQL_BATCH_SIZE) #cql_page_size: 10 # (CQL_PAGE_SIZE) #cql_autocreate_tables: true # (CQL_AUTO_CREATE_TABLES) this will tell axon-server to automatically create the metrics tables (true is recommended) #cql_keyspace_replication: \"{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\" # (CQL_KS_REPLICATION) keyspace replication for the metrics tables #cql_retrypolicy_numretries: 3 # (CQL_RETRY_POLICY_NUM_RETRIES) #cql_retrypolicy_min: 1s # (CQL_RETRY_POLICY_MIN) #cql_retrypolicy_max: 10s # (CQL_RETRY_POLICY_MAX) #cql_reconnectionpolicy_maxretries: 10 # (CQL_RECONNECTION_POLICY_MAX_RETRIES) #cql_reconnectionpolicy_initialinterval: 1s # (CQL_RECONNECTION_POLICY_INITIAL_INTERVAL) #cql_reconnectionpolicy_maxinterval: 10s # (CQL_RECONNECTION_POLICY_MAX_INTERVAL) #cql_metrics_cache_max_size_mb: 100 #MB # (CQL_METRICS_CACHE_MAX_SIZE_MB) #cql_read_consistency: \"LOCAL_ONE\" # (CQL_READ_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_write_consistency: \"LOCAL_ONE\" # (CQL_WRITE_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_lvl1_compaction_window_size: 12 # (CQL_LVL1_COMPACTION_WINDOW_SIZE) #cql_lvl2_compaction_window_size: 1 # (CQL_LVL2_COMPACTION_WINDOW_SIZE) #cql_lvl3_compaction_window_size: 1 # (CQL_LVL3_COMPACTION_WINDOW_SIZE) #cql_lvl4_compaction_window_size: 10 # (CQL_LVL4_COMPACTION_WINDOW_SIZE) #cql_lvl5_compaction_window_size: 120 # (CQL_LVL5_COMPACTION_WINDOW_SIZE) axon-dash : # This must point to axon-dash address host : 127.0.0.1 port : 3000 https : false alerting : # How long to wait before sending a notification again if it has already # been sent successfully for an alert. (Usually ~3h or more). notification_interval : 3h retention : events : 8w # logs and events retention. Must be expressed in weeks (w) metrics : high_resolution : 14d # High frequency metrics. Must be expressed in days (d) med_resolution : 12w # Must be expressed in weeks (w) low_resolution : 12M # Must be expressed in months (M) super_low_resolution : 2y # Must be expressed in years (y) backups : # Those are use as defaults but can be overridden from the UI local : 10d remote : 30d For better performances on large clusters (100+ nodes), you can use a CQL store for the metrics such as Cassandra , Scylla or Elassandra . To opt-in for CQL metrics storage, just specify at least one CQL host with axon-server configuration. Step 4 - Start the server \u00b6 sudo systemctl daemon-reload sudo systemctl start axon-server sudo systemctl status axon-server This will start the axon-server process as the axonops user, which was created during the package installation. The default listening address is 0.0.0.0:8080 . Package details \u00b6 Configuration: /etc/axonops/axon-server.yml Binary: /usr/share/axonops/axon-server Logs: /var/log/axonops/axon-server.log Systemd service: /usr/lib/systemd/system/axon-server.service Copyright : /usr/share/doc/axonops/axon-server/copyright Licenses : /usr/share/axonops/licenses/axon-server/ Step 5 - Installing axon-dash \u00b6 Now axon-server is installed, you can start installing the GUI for it: axon-dash","title":"Installing on Centos/Redhat"},{"location":"installation/axon-server/centos/#axon-server-installation-centos-redhat","text":"","title":"axon-server installation (CentOS / RedHat)"},{"location":"installation/axon-server/centos/#step-1-prerequisites","text":"Elasticsearch stores all of the collected data by axon-server. Let's install Java 8 and Elasticsearch first.","title":"Step 1 - Prerequisites"},{"location":"installation/axon-server/centos/#installing-jdk","text":"Elasticsearch supports either OpenJDK or Oracle JDK. Since Oracle has changed the licensing model as of January 2019 we suggest using OpenJDK. Run the following commands for OpenJDK: sudo yum install java-1.8.0-openjdk-devel Run the following commands for Oracle JDK: wget -c --header \"Cookie: oraclelicense=accept-securebackup-cookie\" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm sudo rpm -i jdk-8u131-linux-x64.rpm Increase the bulk queue size of Elasticsearch by running the following command:","title":"Installing JDK"},{"location":"installation/axon-server/centos/#elastic-7","text":"sudo echo 'thread_pool.write.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml","title":"Elastic 7+:"},{"location":"installation/axon-server/centos/#elastic-6x","text":"sudo echo 'thread_pool.bulk.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml Increase the default heap size of elasticsearch by editing /etc/elasticsearch/jvm.options . From: -Xms1g -Xmx1g To: -Xms8g -Xmx8g This will set the minimum and maximum heap size to 8 GB. Set Xmx and Xms to no more than 50% of your physical RAM. Elasticsearch requires memory for purposes other than the JVM heap and it is important to leave space for this. Set the following index codec by running the following command: sudo echo 'index.codec: best_compression' >> /etc/elasticsearch/elasticsearch.yml Elasticsearch uses a mmapfs directory by default to store its indices. The default operating system limits on mmap counts is likely to be too low, which may result in out of memory exceptions. You can increase the limits by running the following command: sudo sysctl -w vm.max_map_count = 262144 Also, Elasticsearch needs max file descriptors system settings at least to 65536. echo 'elasticsearch - nofile 65536' | sudo tee --append /etc/security/limits.conf > /dev/null And set LimitNOFILE=65536 in /etc/systemd/system/elasticsearch.services","title":"Elastic 6.x:"},{"location":"installation/axon-server/centos/#start-elasticsearch","text":"sudo systemctl start elasticsearch.service After a short period of time, you can verify that your Elasticsearch node is running by sending an HTTP request to port 9200 on localhost: curl -X GET \"localhost:9200/\"","title":"Start Elasticsearch"},{"location":"installation/axon-server/centos/#step-2-axon-server","text":"sudo tee /etc/yum.repos.d/axonops-yum.repo << EOL [axonops-yum] name=axonops-yum baseurl=https://packages.axonops.com/yum/ enabled=1 repo_gpgcheck=0 gpgcheck=0 EOL sudo yum install axon-server","title":"Step 2 - axon-server"},{"location":"installation/axon-server/centos/#step-3-axon-server-configurations","text":"Make sure elastic_host and elastic_port are corresponding to your Elasticsearch instance. /etc/axonops/axon-server.yml host : 0.0.0.0 # axon-server listening address (used by axon-dash and axon-agent) (env variable: AXONSERVER_HOST) port : 8080 # axon-server HTTP API listening port (used by axon-dash) (AXONSERVER_PORT) elastic_hosts : # Elasticsearch endpoint (env variable:ELASTIC_HOSTS, comma separated list) -http://localhost #integrations_proxy: # proxy endpoint for integrations. (INTEGRATIONS_PROXY) # For better performance on large clusters, you can use a CQL store for the metrics. # To opt-in for CQL metrics storage, just specify at least one CQL host. # We do recommend to specify a NetworkTopologyStrategy for cql_keyspace_replication #cql_hosts: # (CQL_HOSTS, comma separated list) # - 192.168.0.10:9042 # - 192.168.0.11:9042 #cql_username: \"cassandra\" # (CQL_USERNAME) #cql_password: \"cassandra\" # (CQL_PASSWORD) #cql_local_dc: datacenter1 # (CQL_LOCAL_DC) #cql_ssl: false # (CQL_SSL) #cql_skip_verify: false # (CQL_SSL_SKIP_VERIFY) #cql_ca_file: /path/to/ca_file # (CQL_CA_FILE) #cql_cert_file: /path/to/cert_file # (CQL_CERT_FILE) #cql_key_file: /path/to/key_file # (CQL_KEY_FILE) #cql_proto_version: 4 # (CQL_PROTO_VERSION) #cql_max_concurrent_reads: 1000 # (CQL_MAX_CONCURRENT_READS) #cql_batch_size: 1 # (CQL_BATCH_SIZE) #cql_page_size: 10 # (CQL_PAGE_SIZE) #cql_autocreate_tables: true # (CQL_AUTO_CREATE_TABLES) this will tell axon-server to automatically create the metrics tables (true is recommended) #cql_keyspace_replication: \"{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\" # (CQL_KS_REPLICATION) keyspace replication for the metrics tables #cql_retrypolicy_numretries: 3 # (CQL_RETRY_POLICY_NUM_RETRIES) #cql_retrypolicy_min: 1s # (CQL_RETRY_POLICY_MIN) #cql_retrypolicy_max: 10s # (CQL_RETRY_POLICY_MAX) #cql_reconnectionpolicy_maxretries: 10 # (CQL_RECONNECTION_POLICY_MAX_RETRIES) #cql_reconnectionpolicy_initialinterval: 1s # (CQL_RECONNECTION_POLICY_INITIAL_INTERVAL) #cql_reconnectionpolicy_maxinterval: 10s # (CQL_RECONNECTION_POLICY_MAX_INTERVAL) #cql_metrics_cache_max_size_mb: 100 #MB # (CQL_METRICS_CACHE_MAX_SIZE_MB) #cql_read_consistency: \"LOCAL_ONE\" # (CQL_READ_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_write_consistency: \"LOCAL_ONE\" # (CQL_WRITE_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_lvl1_compaction_window_size: 12 # (CQL_LVL1_COMPACTION_WINDOW_SIZE) #cql_lvl2_compaction_window_size: 1 # (CQL_LVL2_COMPACTION_WINDOW_SIZE) #cql_lvl3_compaction_window_size: 1 # (CQL_LVL3_COMPACTION_WINDOW_SIZE) #cql_lvl4_compaction_window_size: 10 # (CQL_LVL4_COMPACTION_WINDOW_SIZE) #cql_lvl5_compaction_window_size: 120 # (CQL_LVL5_COMPACTION_WINDOW_SIZE) axon-dash : # This must point to axon-dash address host : 127.0.0.1 port : 3000 https : false alerting : # How long to wait before sending a notification again if it has already # been sent successfully for an alert. (Usually ~3h or more). notification_interval : 3h retention : events : 8w # logs and events retention. Must be expressed in weeks (w) metrics : high_resolution : 14d # High frequency metrics. Must be expressed in days (d) med_resolution : 12w # Must be expressed in weeks (w) low_resolution : 12M # Must be expressed in months (M) super_low_resolution : 2y # Must be expressed in years (y) backups : # Those are use as defaults but can be overridden from the UI local : 10d remote : 30d For better performances on large clusters (100+ nodes), you can use a CQL store for the metrics such as Cassandra , Scylla or Elassandra . To opt-in for CQL metrics storage, just specify at least one CQL host with axon-server configuration.","title":"Step 3 - axon-server configurations"},{"location":"installation/axon-server/centos/#step-4-start-the-server","text":"sudo systemctl daemon-reload sudo systemctl start axon-server sudo systemctl status axon-server This will start the axon-server process as the axonops user, which was created during the package installation. The default listening address is 0.0.0.0:8080 .","title":"Step 4 - Start the server"},{"location":"installation/axon-server/centos/#package-details","text":"Configuration: /etc/axonops/axon-server.yml Binary: /usr/share/axonops/axon-server Logs: /var/log/axonops/axon-server.log Systemd service: /usr/lib/systemd/system/axon-server.service Copyright : /usr/share/doc/axonops/axon-server/copyright Licenses : /usr/share/axonops/licenses/axon-server/","title":"Package details"},{"location":"installation/axon-server/centos/#step-5-installing-axon-dash","text":"Now axon-server is installed, you can start installing the GUI for it: axon-dash","title":"Step 5 - Installing axon-dash"},{"location":"installation/axon-server/elastic/","text":"Increase the bulk queue size of Elasticsearch by running the following command: Elastic 7+: \u00b6 sudo echo 'thread_pool.write.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml Elastic 6.x: \u00b6 sudo echo 'thread_pool.bulk.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml Increase the default heap size of elasticsearch by editing /etc/elasticsearch/jvm.options . From: -Xms1g -Xmx1g To: -Xms8g -Xmx8g This will set the minimum and maximum heap size to 8 GB. Set Xmx and Xms to no more than 50% of your physical RAM. Elasticsearch requires memory for purposes other than the JVM heap and it is important to leave space for this. Set the following index codec by running the following command: sudo echo 'index.codec: best_compression' >> /etc/elasticsearch/elasticsearch.yml Elasticsearch uses a mmapfs directory by default to store its indices. The default operating system limits on mmap counts is likely to be too low, which may result in out of memory exceptions. You can increase the limits by running the following command: sudo sysctl -w vm.max_map_count = 262144 Also, Elasticsearch needs max file descriptors system settings at least to 65536. echo 'elasticsearch - nofile 65536' | sudo tee --append /etc/security/limits.conf > /dev/null And set LimitNOFILE=65536 in /etc/systemd/system/elasticsearch.services Start Elasticsearch \u00b6 sudo systemctl start elasticsearch.service After a short period of time, you can verify that your Elasticsearch node is running by sending an HTTP request to port 9200 on localhost: curl -X GET \"localhost:9200/\"","title":"Elastic"},{"location":"installation/axon-server/elastic/#elastic-7","text":"sudo echo 'thread_pool.write.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml","title":"Elastic 7+:"},{"location":"installation/axon-server/elastic/#elastic-6x","text":"sudo echo 'thread_pool.bulk.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml Increase the default heap size of elasticsearch by editing /etc/elasticsearch/jvm.options . From: -Xms1g -Xmx1g To: -Xms8g -Xmx8g This will set the minimum and maximum heap size to 8 GB. Set Xmx and Xms to no more than 50% of your physical RAM. Elasticsearch requires memory for purposes other than the JVM heap and it is important to leave space for this. Set the following index codec by running the following command: sudo echo 'index.codec: best_compression' >> /etc/elasticsearch/elasticsearch.yml Elasticsearch uses a mmapfs directory by default to store its indices. The default operating system limits on mmap counts is likely to be too low, which may result in out of memory exceptions. You can increase the limits by running the following command: sudo sysctl -w vm.max_map_count = 262144 Also, Elasticsearch needs max file descriptors system settings at least to 65536. echo 'elasticsearch - nofile 65536' | sudo tee --append /etc/security/limits.conf > /dev/null And set LimitNOFILE=65536 in /etc/systemd/system/elasticsearch.services","title":"Elastic 6.x:"},{"location":"installation/axon-server/elastic/#start-elasticsearch","text":"sudo systemctl start elasticsearch.service After a short period of time, you can verify that your Elasticsearch node is running by sending an HTTP request to port 9200 on localhost: curl -X GET \"localhost:9200/\"","title":"Start Elasticsearch"},{"location":"installation/axon-server/install/","text":"Step 3 - axon-server configurations \u00b6 Make sure elastic_host and elastic_port are corresponding to your Elasticsearch instance. /etc/axonops/axon-server.yml host : 0.0.0.0 # axon-server listening address (used by axon-dash and axon-agent) (env variable: AXONSERVER_HOST) port : 8080 # axon-server HTTP API listening port (used by axon-dash) (AXONSERVER_PORT) elastic_hosts : # Elasticsearch endpoint (env variable:ELASTIC_HOSTS, comma separated list) -http://localhost #integrations_proxy: # proxy endpoint for integrations. (INTEGRATIONS_PROXY) # For better performance on large clusters, you can use a CQL store for the metrics. # To opt-in for CQL metrics storage, just specify at least one CQL host. # We do recommend to specify a NetworkTopologyStrategy for cql_keyspace_replication #cql_hosts: # (CQL_HOSTS, comma separated list) # - 192.168.0.10:9042 # - 192.168.0.11:9042 #cql_username: \"cassandra\" # (CQL_USERNAME) #cql_password: \"cassandra\" # (CQL_PASSWORD) #cql_local_dc: datacenter1 # (CQL_LOCAL_DC) #cql_ssl: false # (CQL_SSL) #cql_skip_verify: false # (CQL_SSL_SKIP_VERIFY) #cql_ca_file: /path/to/ca_file # (CQL_CA_FILE) #cql_cert_file: /path/to/cert_file # (CQL_CERT_FILE) #cql_key_file: /path/to/key_file # (CQL_KEY_FILE) #cql_proto_version: 4 # (CQL_PROTO_VERSION) #cql_max_concurrent_reads: 1000 # (CQL_MAX_CONCURRENT_READS) #cql_batch_size: 1 # (CQL_BATCH_SIZE) #cql_page_size: 10 # (CQL_PAGE_SIZE) #cql_autocreate_tables: true # (CQL_AUTO_CREATE_TABLES) this will tell axon-server to automatically create the metrics tables (true is recommended) #cql_keyspace_replication: \"{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\" # (CQL_KS_REPLICATION) keyspace replication for the metrics tables #cql_retrypolicy_numretries: 3 # (CQL_RETRY_POLICY_NUM_RETRIES) #cql_retrypolicy_min: 1s # (CQL_RETRY_POLICY_MIN) #cql_retrypolicy_max: 10s # (CQL_RETRY_POLICY_MAX) #cql_reconnectionpolicy_maxretries: 10 # (CQL_RECONNECTION_POLICY_MAX_RETRIES) #cql_reconnectionpolicy_initialinterval: 1s # (CQL_RECONNECTION_POLICY_INITIAL_INTERVAL) #cql_reconnectionpolicy_maxinterval: 10s # (CQL_RECONNECTION_POLICY_MAX_INTERVAL) #cql_metrics_cache_max_size_mb: 100 #MB # (CQL_METRICS_CACHE_MAX_SIZE_MB) #cql_read_consistency: \"LOCAL_ONE\" # (CQL_READ_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_write_consistency: \"LOCAL_ONE\" # (CQL_WRITE_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_lvl1_compaction_window_size: 12 # (CQL_LVL1_COMPACTION_WINDOW_SIZE) #cql_lvl2_compaction_window_size: 1 # (CQL_LVL2_COMPACTION_WINDOW_SIZE) #cql_lvl3_compaction_window_size: 1 # (CQL_LVL3_COMPACTION_WINDOW_SIZE) #cql_lvl4_compaction_window_size: 10 # (CQL_LVL4_COMPACTION_WINDOW_SIZE) #cql_lvl5_compaction_window_size: 120 # (CQL_LVL5_COMPACTION_WINDOW_SIZE) axon-dash : # This must point to axon-dash address host : 127.0.0.1 port : 3000 https : false alerting : # How long to wait before sending a notification again if it has already # been sent successfully for an alert. (Usually ~3h or more). notification_interval : 3h retention : events : 8w # logs and events retention. Must be expressed in weeks (w) metrics : high_resolution : 14d # High frequency metrics. Must be expressed in days (d) med_resolution : 12w # Must be expressed in weeks (w) low_resolution : 12M # Must be expressed in months (M) super_low_resolution : 2y # Must be expressed in years (y) backups : # Those are use as defaults but can be overridden from the UI local : 10d remote : 30d For better performances on large clusters (100+ nodes), you can use a CQL store for the metrics such as Cassandra , Scylla or Elassandra . To opt-in for CQL metrics storage, just specify at least one CQL host with axon-server configuration. Step 4 - Start the server \u00b6 sudo systemctl daemon-reload sudo systemctl start axon-server sudo systemctl status axon-server This will start the axon-server process as the axonops user, which was created during the package installation. The default listening address is 0.0.0.0:8080 . Package details \u00b6 Configuration: /etc/axonops/axon-server.yml Binary: /usr/share/axonops/axon-server Logs: /var/log/axonops/axon-server.log Systemd service: /usr/lib/systemd/system/axon-server.service Copyright : /usr/share/doc/axonops/axon-server/copyright Licenses : /usr/share/axonops/licenses/axon-server/ Step 5 - Installing axon-dash \u00b6 Now axon-server is installed, you can start installing the GUI for it: axon-dash","title":"Install"},{"location":"installation/axon-server/install/#step-3-axon-server-configurations","text":"Make sure elastic_host and elastic_port are corresponding to your Elasticsearch instance. /etc/axonops/axon-server.yml host : 0.0.0.0 # axon-server listening address (used by axon-dash and axon-agent) (env variable: AXONSERVER_HOST) port : 8080 # axon-server HTTP API listening port (used by axon-dash) (AXONSERVER_PORT) elastic_hosts : # Elasticsearch endpoint (env variable:ELASTIC_HOSTS, comma separated list) -http://localhost #integrations_proxy: # proxy endpoint for integrations. (INTEGRATIONS_PROXY) # For better performance on large clusters, you can use a CQL store for the metrics. # To opt-in for CQL metrics storage, just specify at least one CQL host. # We do recommend to specify a NetworkTopologyStrategy for cql_keyspace_replication #cql_hosts: # (CQL_HOSTS, comma separated list) # - 192.168.0.10:9042 # - 192.168.0.11:9042 #cql_username: \"cassandra\" # (CQL_USERNAME) #cql_password: \"cassandra\" # (CQL_PASSWORD) #cql_local_dc: datacenter1 # (CQL_LOCAL_DC) #cql_ssl: false # (CQL_SSL) #cql_skip_verify: false # (CQL_SSL_SKIP_VERIFY) #cql_ca_file: /path/to/ca_file # (CQL_CA_FILE) #cql_cert_file: /path/to/cert_file # (CQL_CERT_FILE) #cql_key_file: /path/to/key_file # (CQL_KEY_FILE) #cql_proto_version: 4 # (CQL_PROTO_VERSION) #cql_max_concurrent_reads: 1000 # (CQL_MAX_CONCURRENT_READS) #cql_batch_size: 1 # (CQL_BATCH_SIZE) #cql_page_size: 10 # (CQL_PAGE_SIZE) #cql_autocreate_tables: true # (CQL_AUTO_CREATE_TABLES) this will tell axon-server to automatically create the metrics tables (true is recommended) #cql_keyspace_replication: \"{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\" # (CQL_KS_REPLICATION) keyspace replication for the metrics tables #cql_retrypolicy_numretries: 3 # (CQL_RETRY_POLICY_NUM_RETRIES) #cql_retrypolicy_min: 1s # (CQL_RETRY_POLICY_MIN) #cql_retrypolicy_max: 10s # (CQL_RETRY_POLICY_MAX) #cql_reconnectionpolicy_maxretries: 10 # (CQL_RECONNECTION_POLICY_MAX_RETRIES) #cql_reconnectionpolicy_initialinterval: 1s # (CQL_RECONNECTION_POLICY_INITIAL_INTERVAL) #cql_reconnectionpolicy_maxinterval: 10s # (CQL_RECONNECTION_POLICY_MAX_INTERVAL) #cql_metrics_cache_max_size_mb: 100 #MB # (CQL_METRICS_CACHE_MAX_SIZE_MB) #cql_read_consistency: \"LOCAL_ONE\" # (CQL_READ_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_write_consistency: \"LOCAL_ONE\" # (CQL_WRITE_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_lvl1_compaction_window_size: 12 # (CQL_LVL1_COMPACTION_WINDOW_SIZE) #cql_lvl2_compaction_window_size: 1 # (CQL_LVL2_COMPACTION_WINDOW_SIZE) #cql_lvl3_compaction_window_size: 1 # (CQL_LVL3_COMPACTION_WINDOW_SIZE) #cql_lvl4_compaction_window_size: 10 # (CQL_LVL4_COMPACTION_WINDOW_SIZE) #cql_lvl5_compaction_window_size: 120 # (CQL_LVL5_COMPACTION_WINDOW_SIZE) axon-dash : # This must point to axon-dash address host : 127.0.0.1 port : 3000 https : false alerting : # How long to wait before sending a notification again if it has already # been sent successfully for an alert. (Usually ~3h or more). notification_interval : 3h retention : events : 8w # logs and events retention. Must be expressed in weeks (w) metrics : high_resolution : 14d # High frequency metrics. Must be expressed in days (d) med_resolution : 12w # Must be expressed in weeks (w) low_resolution : 12M # Must be expressed in months (M) super_low_resolution : 2y # Must be expressed in years (y) backups : # Those are use as defaults but can be overridden from the UI local : 10d remote : 30d For better performances on large clusters (100+ nodes), you can use a CQL store for the metrics such as Cassandra , Scylla or Elassandra . To opt-in for CQL metrics storage, just specify at least one CQL host with axon-server configuration.","title":"Step 3 - axon-server configurations"},{"location":"installation/axon-server/install/#step-4-start-the-server","text":"sudo systemctl daemon-reload sudo systemctl start axon-server sudo systemctl status axon-server This will start the axon-server process as the axonops user, which was created during the package installation. The default listening address is 0.0.0.0:8080 .","title":"Step 4 - Start the server"},{"location":"installation/axon-server/install/#package-details","text":"Configuration: /etc/axonops/axon-server.yml Binary: /usr/share/axonops/axon-server Logs: /var/log/axonops/axon-server.log Systemd service: /usr/lib/systemd/system/axon-server.service Copyright : /usr/share/doc/axonops/axon-server/copyright Licenses : /usr/share/axonops/licenses/axon-server/","title":"Package details"},{"location":"installation/axon-server/install/#step-5-installing-axon-dash","text":"Now axon-server is installed, you can start installing the GUI for it: axon-dash","title":"Step 5 - Installing axon-dash"},{"location":"installation/axon-server/ubuntu/","text":"axon-server installation (Debian / Ubuntu) \u00b6 Step 1 - Prerequisites \u00b6 Elasticsearch stores all of the collected data by axon-server. Let's install Java 8 and Elasticsearch first. Installing JDK \u00b6 Elasticsearch supports either OpenJDK or Oracle JDK. Since Oracle has changed the licensing model as of January 2019 we suggest using OpenJDK. Run the following commands for OpenJDK: sudo apt-get update sudo apt-get install default-jdk Run the following commands for Oracle JDK: sudo apt-get update sudo apt-get install dirmngr sudo cp /etc/apt/sources.list /etc/apt/sources.list_backup echo \"deb http://ppa.launchpad.net/webupd8team/java/ubuntu xenial main\" | sudo tee /etc/apt/sources.list.d/webupd8team-java.list sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys EEA14886 sudo apt-get update sudo apt-get install oracle-java8-installer Once you've accepted the license agreement the JDK will install. Installing Elasticsearch \u00b6 wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.1.deb sudo dpkg -i elasticsearch-6.6.1.deb Increase the bulk queue size of Elasticsearch by running the following command: Elastic 7+: \u00b6 sudo echo 'thread_pool.write.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml Elastic 6.x: \u00b6 sudo echo 'thread_pool.bulk.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml Increase the default heap size of elasticsearch by editing /etc/elasticsearch/jvm.options . From: -Xms1g -Xmx1g To: -Xms8g -Xmx8g This will set the minimum and maximum heap size to 8 GB. Set Xmx and Xms to no more than 50% of your physical RAM. Elasticsearch requires memory for purposes other than the JVM heap and it is important to leave space for this. Set the following index codec by running the following command: sudo echo 'index.codec: best_compression' >> /etc/elasticsearch/elasticsearch.yml Elasticsearch uses a mmapfs directory by default to store its indices. The default operating system limits on mmap counts is likely to be too low, which may result in out of memory exceptions. You can increase the limits by running the following command: sudo sysctl -w vm.max_map_count = 262144 Also, Elasticsearch needs max file descriptors system settings at least to 65536. echo 'elasticsearch - nofile 65536' | sudo tee --append /etc/security/limits.conf > /dev/null And set LimitNOFILE=65536 in /etc/systemd/system/elasticsearch.services Start Elasticsearch \u00b6 sudo systemctl start elasticsearch.service After a short period of time, you can verify that your Elasticsearch node is running by sending an HTTP request to port 9200 on localhost: curl -X GET \"localhost:9200/\" Step 2 - axon-server \u00b6 curl https://packages.axonops.com/apt/repo-signing-key.gpg | sudo apt-key add - echo \"deb https://packages.axonops.com/apt axonops-apt main\" | sudo tee /etc/apt/sources.list.d/axonops-apt.list sudo apt-get update sudo apt-get install axon-server Step 3 - axon-server configurations \u00b6 Make sure elastic_host and elastic_port are corresponding to your Elasticsearch instance. /etc/axonops/axon-server.yml host : 0.0.0.0 # axon-server listening address (used by axon-dash and axon-agent) (env variable: AXONSERVER_HOST) port : 8080 # axon-server HTTP API listening port (used by axon-dash) (AXONSERVER_PORT) elastic_hosts : # Elasticsearch endpoint (env variable:ELASTIC_HOSTS, comma separated list) -http://localhost #integrations_proxy: # proxy endpoint for integrations. (INTEGRATIONS_PROXY) # For better performance on large clusters, you can use a CQL store for the metrics. # To opt-in for CQL metrics storage, just specify at least one CQL host. # We do recommend to specify a NetworkTopologyStrategy for cql_keyspace_replication #cql_hosts: # (CQL_HOSTS, comma separated list) # - 192.168.0.10:9042 # - 192.168.0.11:9042 #cql_username: \"cassandra\" # (CQL_USERNAME) #cql_password: \"cassandra\" # (CQL_PASSWORD) #cql_local_dc: datacenter1 # (CQL_LOCAL_DC) #cql_ssl: false # (CQL_SSL) #cql_skip_verify: false # (CQL_SSL_SKIP_VERIFY) #cql_ca_file: /path/to/ca_file # (CQL_CA_FILE) #cql_cert_file: /path/to/cert_file # (CQL_CERT_FILE) #cql_key_file: /path/to/key_file # (CQL_KEY_FILE) #cql_proto_version: 4 # (CQL_PROTO_VERSION) #cql_max_concurrent_reads: 1000 # (CQL_MAX_CONCURRENT_READS) #cql_batch_size: 1 # (CQL_BATCH_SIZE) #cql_page_size: 10 # (CQL_PAGE_SIZE) #cql_autocreate_tables: true # (CQL_AUTO_CREATE_TABLES) this will tell axon-server to automatically create the metrics tables (true is recommended) #cql_keyspace_replication: \"{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\" # (CQL_KS_REPLICATION) keyspace replication for the metrics tables #cql_retrypolicy_numretries: 3 # (CQL_RETRY_POLICY_NUM_RETRIES) #cql_retrypolicy_min: 1s # (CQL_RETRY_POLICY_MIN) #cql_retrypolicy_max: 10s # (CQL_RETRY_POLICY_MAX) #cql_reconnectionpolicy_maxretries: 10 # (CQL_RECONNECTION_POLICY_MAX_RETRIES) #cql_reconnectionpolicy_initialinterval: 1s # (CQL_RECONNECTION_POLICY_INITIAL_INTERVAL) #cql_reconnectionpolicy_maxinterval: 10s # (CQL_RECONNECTION_POLICY_MAX_INTERVAL) #cql_metrics_cache_max_size_mb: 100 #MB # (CQL_METRICS_CACHE_MAX_SIZE_MB) #cql_read_consistency: \"LOCAL_ONE\" # (CQL_READ_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_write_consistency: \"LOCAL_ONE\" # (CQL_WRITE_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_lvl1_compaction_window_size: 12 # (CQL_LVL1_COMPACTION_WINDOW_SIZE) #cql_lvl2_compaction_window_size: 1 # (CQL_LVL2_COMPACTION_WINDOW_SIZE) #cql_lvl3_compaction_window_size: 1 # (CQL_LVL3_COMPACTION_WINDOW_SIZE) #cql_lvl4_compaction_window_size: 10 # (CQL_LVL4_COMPACTION_WINDOW_SIZE) #cql_lvl5_compaction_window_size: 120 # (CQL_LVL5_COMPACTION_WINDOW_SIZE) axon-dash : # This must point to axon-dash address host : 127.0.0.1 port : 3000 https : false alerting : # How long to wait before sending a notification again if it has already # been sent successfully for an alert. (Usually ~3h or more). notification_interval : 3h retention : events : 8w # logs and events retention. Must be expressed in weeks (w) metrics : high_resolution : 14d # High frequency metrics. Must be expressed in days (d) med_resolution : 12w # Must be expressed in weeks (w) low_resolution : 12M # Must be expressed in months (M) super_low_resolution : 2y # Must be expressed in years (y) backups : # Those are use as defaults but can be overridden from the UI local : 10d remote : 30d For better performances on large clusters (100+ nodes), you can use a CQL store for the metrics such as Cassandra , Scylla or Elassandra . To opt-in for CQL metrics storage, just specify at least one CQL host with axon-server configuration. Step 4 - Start the server \u00b6 sudo systemctl daemon-reload sudo systemctl start axon-server sudo systemctl status axon-server This will start the axon-server process as the axonops user, which was created during the package installation. The default listening address is 0.0.0.0:8080 . Package details \u00b6 Configuration: /etc/axonops/axon-server.yml Binary: /usr/share/axonops/axon-server Logs: /var/log/axonops/axon-server.log Systemd service: /usr/lib/systemd/system/axon-server.service Copyright : /usr/share/doc/axonops/axon-server/copyright Licenses : /usr/share/axonops/licenses/axon-server/ Step 5 - Installing axon-dash \u00b6 Now axon-server is installed, you can start installing the GUI for it: axon-dash","title":"Installing on Ubuntu/Debian"},{"location":"installation/axon-server/ubuntu/#axon-server-installation-debian-ubuntu","text":"","title":"axon-server installation (Debian / Ubuntu)"},{"location":"installation/axon-server/ubuntu/#step-1-prerequisites","text":"Elasticsearch stores all of the collected data by axon-server. Let's install Java 8 and Elasticsearch first.","title":"Step 1 - Prerequisites"},{"location":"installation/axon-server/ubuntu/#installing-jdk","text":"Elasticsearch supports either OpenJDK or Oracle JDK. Since Oracle has changed the licensing model as of January 2019 we suggest using OpenJDK. Run the following commands for OpenJDK: sudo apt-get update sudo apt-get install default-jdk Run the following commands for Oracle JDK: sudo apt-get update sudo apt-get install dirmngr sudo cp /etc/apt/sources.list /etc/apt/sources.list_backup echo \"deb http://ppa.launchpad.net/webupd8team/java/ubuntu xenial main\" | sudo tee /etc/apt/sources.list.d/webupd8team-java.list sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys EEA14886 sudo apt-get update sudo apt-get install oracle-java8-installer Once you've accepted the license agreement the JDK will install.","title":"Installing JDK"},{"location":"installation/axon-server/ubuntu/#installing-elasticsearch","text":"wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.1.deb sudo dpkg -i elasticsearch-6.6.1.deb Increase the bulk queue size of Elasticsearch by running the following command:","title":"Installing Elasticsearch"},{"location":"installation/axon-server/ubuntu/#elastic-7","text":"sudo echo 'thread_pool.write.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml","title":"Elastic 7+:"},{"location":"installation/axon-server/ubuntu/#elastic-6x","text":"sudo echo 'thread_pool.bulk.queue_size: 2000' >> /etc/elasticsearch/elasticsearch.yml Increase the default heap size of elasticsearch by editing /etc/elasticsearch/jvm.options . From: -Xms1g -Xmx1g To: -Xms8g -Xmx8g This will set the minimum and maximum heap size to 8 GB. Set Xmx and Xms to no more than 50% of your physical RAM. Elasticsearch requires memory for purposes other than the JVM heap and it is important to leave space for this. Set the following index codec by running the following command: sudo echo 'index.codec: best_compression' >> /etc/elasticsearch/elasticsearch.yml Elasticsearch uses a mmapfs directory by default to store its indices. The default operating system limits on mmap counts is likely to be too low, which may result in out of memory exceptions. You can increase the limits by running the following command: sudo sysctl -w vm.max_map_count = 262144 Also, Elasticsearch needs max file descriptors system settings at least to 65536. echo 'elasticsearch - nofile 65536' | sudo tee --append /etc/security/limits.conf > /dev/null And set LimitNOFILE=65536 in /etc/systemd/system/elasticsearch.services","title":"Elastic 6.x:"},{"location":"installation/axon-server/ubuntu/#start-elasticsearch","text":"sudo systemctl start elasticsearch.service After a short period of time, you can verify that your Elasticsearch node is running by sending an HTTP request to port 9200 on localhost: curl -X GET \"localhost:9200/\"","title":"Start Elasticsearch"},{"location":"installation/axon-server/ubuntu/#step-2-axon-server","text":"curl https://packages.axonops.com/apt/repo-signing-key.gpg | sudo apt-key add - echo \"deb https://packages.axonops.com/apt axonops-apt main\" | sudo tee /etc/apt/sources.list.d/axonops-apt.list sudo apt-get update sudo apt-get install axon-server","title":"Step 2 - axon-server"},{"location":"installation/axon-server/ubuntu/#step-3-axon-server-configurations","text":"Make sure elastic_host and elastic_port are corresponding to your Elasticsearch instance. /etc/axonops/axon-server.yml host : 0.0.0.0 # axon-server listening address (used by axon-dash and axon-agent) (env variable: AXONSERVER_HOST) port : 8080 # axon-server HTTP API listening port (used by axon-dash) (AXONSERVER_PORT) elastic_hosts : # Elasticsearch endpoint (env variable:ELASTIC_HOSTS, comma separated list) -http://localhost #integrations_proxy: # proxy endpoint for integrations. (INTEGRATIONS_PROXY) # For better performance on large clusters, you can use a CQL store for the metrics. # To opt-in for CQL metrics storage, just specify at least one CQL host. # We do recommend to specify a NetworkTopologyStrategy for cql_keyspace_replication #cql_hosts: # (CQL_HOSTS, comma separated list) # - 192.168.0.10:9042 # - 192.168.0.11:9042 #cql_username: \"cassandra\" # (CQL_USERNAME) #cql_password: \"cassandra\" # (CQL_PASSWORD) #cql_local_dc: datacenter1 # (CQL_LOCAL_DC) #cql_ssl: false # (CQL_SSL) #cql_skip_verify: false # (CQL_SSL_SKIP_VERIFY) #cql_ca_file: /path/to/ca_file # (CQL_CA_FILE) #cql_cert_file: /path/to/cert_file # (CQL_CERT_FILE) #cql_key_file: /path/to/key_file # (CQL_KEY_FILE) #cql_proto_version: 4 # (CQL_PROTO_VERSION) #cql_max_concurrent_reads: 1000 # (CQL_MAX_CONCURRENT_READS) #cql_batch_size: 1 # (CQL_BATCH_SIZE) #cql_page_size: 10 # (CQL_PAGE_SIZE) #cql_autocreate_tables: true # (CQL_AUTO_CREATE_TABLES) this will tell axon-server to automatically create the metrics tables (true is recommended) #cql_keyspace_replication: \"{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\" # (CQL_KS_REPLICATION) keyspace replication for the metrics tables #cql_retrypolicy_numretries: 3 # (CQL_RETRY_POLICY_NUM_RETRIES) #cql_retrypolicy_min: 1s # (CQL_RETRY_POLICY_MIN) #cql_retrypolicy_max: 10s # (CQL_RETRY_POLICY_MAX) #cql_reconnectionpolicy_maxretries: 10 # (CQL_RECONNECTION_POLICY_MAX_RETRIES) #cql_reconnectionpolicy_initialinterval: 1s # (CQL_RECONNECTION_POLICY_INITIAL_INTERVAL) #cql_reconnectionpolicy_maxinterval: 10s # (CQL_RECONNECTION_POLICY_MAX_INTERVAL) #cql_metrics_cache_max_size_mb: 100 #MB # (CQL_METRICS_CACHE_MAX_SIZE_MB) #cql_read_consistency: \"LOCAL_ONE\" # (CQL_READ_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_write_consistency: \"LOCAL_ONE\" # (CQL_WRITE_CONSISTENCY) #One of the following: ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE #cql_lvl1_compaction_window_size: 12 # (CQL_LVL1_COMPACTION_WINDOW_SIZE) #cql_lvl2_compaction_window_size: 1 # (CQL_LVL2_COMPACTION_WINDOW_SIZE) #cql_lvl3_compaction_window_size: 1 # (CQL_LVL3_COMPACTION_WINDOW_SIZE) #cql_lvl4_compaction_window_size: 10 # (CQL_LVL4_COMPACTION_WINDOW_SIZE) #cql_lvl5_compaction_window_size: 120 # (CQL_LVL5_COMPACTION_WINDOW_SIZE) axon-dash : # This must point to axon-dash address host : 127.0.0.1 port : 3000 https : false alerting : # How long to wait before sending a notification again if it has already # been sent successfully for an alert. (Usually ~3h or more). notification_interval : 3h retention : events : 8w # logs and events retention. Must be expressed in weeks (w) metrics : high_resolution : 14d # High frequency metrics. Must be expressed in days (d) med_resolution : 12w # Must be expressed in weeks (w) low_resolution : 12M # Must be expressed in months (M) super_low_resolution : 2y # Must be expressed in years (y) backups : # Those are use as defaults but can be overridden from the UI local : 10d remote : 30d For better performances on large clusters (100+ nodes), you can use a CQL store for the metrics such as Cassandra , Scylla or Elassandra . To opt-in for CQL metrics storage, just specify at least one CQL host with axon-server configuration.","title":"Step 3 - axon-server configurations"},{"location":"installation/axon-server/ubuntu/#step-4-start-the-server","text":"sudo systemctl daemon-reload sudo systemctl start axon-server sudo systemctl status axon-server This will start the axon-server process as the axonops user, which was created during the package installation. The default listening address is 0.0.0.0:8080 .","title":"Step 4 - Start the server"},{"location":"installation/axon-server/ubuntu/#package-details","text":"Configuration: /etc/axonops/axon-server.yml Binary: /usr/share/axonops/axon-server Logs: /var/log/axonops/axon-server.log Systemd service: /usr/lib/systemd/system/axon-server.service Copyright : /usr/share/doc/axonops/axon-server/copyright Licenses : /usr/share/axonops/licenses/axon-server/","title":"Package details"},{"location":"installation/axon-server/ubuntu/#step-5-installing-axon-dash","text":"Now axon-server is installed, you can start installing the GUI for it: axon-dash","title":"Step 5 - Installing axon-dash"},{"location":"installation/cassandra-agent/install/","text":"AxonOps Cassandra agent installation \u00b6 This agent will enable metrics, logs and events collection with adaptive repairs and backups for Cassandra. Available versions \u00b6 Apache Cassandra 3.0.x Apache Cassandra 3.11.x Step 1 - Installation \u00b6 Make sure that the {version} of your Cassandra and Cassandra agent are compatible from the compatibility matrix . CentOS / RedHat \u00b6 sudo tee /etc/yum.repos.d/axonops-yum.repo << EOL [axonops-yum] name=axonops-yum baseurl=https://packages.axonops.com/yum/ enabled=1 repo_gpgcheck=0 gpgcheck=0 EOL sudo yum install axon-cassandra { version } -agent Debian / Ubuntu \u00b6 curl https://packages.axonops.com/apt/repo-signing-key.gpg | sudo apt-key add - echo \"deb https://packages.axonops.com/apt axonops-apt main\" | sudo tee /etc/apt/sources.list.d/axonops-apt.list sudo apt-get update sudo apt-get install axon-cassandra { version } -agent Note: This will install AxonOps Cassandra agent and its dependency: axon-agent Step 2 - Agent Configuration \u00b6 Update the following highlighted lines from /etc/axonops/axon-agent.yml : axon-server : hosts : \"axon-server_endpoint\" # Specify axon-server IP axon-server.mycompany.com axon-agent : org : \"my-company-test\" # Specify your organisation name NTP : host : \"ntp.mycompany.com\" # Specify your NTP server IP address or hostname cassandra : tier0 : # metrics collected every 5 seconds metrics : jvm_ : - \"java.lang:*\" cas_ : - \"org.apache.cassandra.metrics:*\" - \"org.apache.cassandra.net:type=FailureDetector\" tier1 : frequency : 300 # metrics collected every 300 seconds (5m) metrics : cas_ : - \"org.apache.cassandra.metrics:name=EstimatedPartitionCount,*\" #tier2: # frequency: 3600 # 1h #tier3: # frequency: 86400 # 1d blacklist : # You can blacklist metrics based on MBean query pattern (regular expression) - \"org.apache.cassandra.metrics:type=ColumnFamily.*\" # duplication of table metrics - \"org.apache.cassandra.metrics:name=SnapshotsSize.*\" # Collecting SnapshotsSize metrics slows down collection free_text_blacklist : # You can blacklist metrics based on Regex pattern - \"org.apache.cassandra.metrics:type=ThreadPools,path=internal,scope=Repair#.*\" warningThresholdMillis : 100 # This will warn in logs when a MBean takes longer than the specified value. logFormat : \"%4$s %1$tY-%1$tm-%1$td %1$tH:%1$tM:%1$tS,%1$tL %5$s%6$s%n\" Note: the log format will only be used by AxonOps Cassandra agent Step 3 - Configure Cassandra \u00b6 Edit cassandra-env.sh usually located in your Cassandra install path such as /<Cassandra Installation Directory>/conf/cassandra-env.sh and append the following line at the end of the file: JVM_OPTS = \" $JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra{version}-agent.jar=/etc/axonops/axon-agent.yml\" example with Cassandra agent version 3.11 : JVM_OPTS = \" $JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.11-agent.jar=/etc/axonops/axon-agent.yml\" Make sure that this configuration will not get overridden by an automation tool. Step 4 - Add axonops user to Cassandra user group and Cassandra user to axonops group \u00b6 sudo usermod -aG <your_cassandra_group> axonops sudo usermod -aG axonops <your_cassandra_user> Step 5 - Start Cassandra \u00b6 Step 6 - Start axon-agent \u00b6 sudo service axon-agent start (Optional) Step 7 - Cassandra Remote Backups or Restore Prerequisites \u00b6 If you plan to use AxonOps remote backup functionality, axonops user will require read access on Cassandra data folder. As well if you plan to Restore data with AxonOps, axonops user will require write access to Cassandra data folder. We recommend to only provide temporary write access to axonops when required. Cassandra agent Package details \u00b6 Configuration: /etc/axonops/axon-agent.yml Binary: /usr/share/axonops/axon-cassandra{version}-agent.jar Version number: /usr/share/axonops/axon-cassandra{version}-agent.version Copyright : /usr/share/doc/axonops/axon-cassandra{version}-agent/copyright Licenses : /usr/share/axonops/licenses/axon-cassandra{version}-agent/ axon-agent Package details (dependency of Cassandra agent) \u00b6 Configuration: /etc/axonops/axon-agent.yml Binary: usr/share/axonops/axon-agent Logs : /var/log/axonops/axon-agent.log Systemd service: /usr/lib/systemd/system/axon-agent.service","title":"AxonOps Cassandra Agent"},{"location":"installation/cassandra-agent/install/#axonops-cassandra-agent-installation","text":"This agent will enable metrics, logs and events collection with adaptive repairs and backups for Cassandra.","title":"AxonOps Cassandra agent installation"},{"location":"installation/cassandra-agent/install/#available-versions","text":"Apache Cassandra 3.0.x Apache Cassandra 3.11.x","title":"Available versions"},{"location":"installation/cassandra-agent/install/#step-1-installation","text":"Make sure that the {version} of your Cassandra and Cassandra agent are compatible from the compatibility matrix .","title":"Step 1 - Installation"},{"location":"installation/cassandra-agent/install/#centos-redhat","text":"sudo tee /etc/yum.repos.d/axonops-yum.repo << EOL [axonops-yum] name=axonops-yum baseurl=https://packages.axonops.com/yum/ enabled=1 repo_gpgcheck=0 gpgcheck=0 EOL sudo yum install axon-cassandra { version } -agent","title":"CentOS / RedHat"},{"location":"installation/cassandra-agent/install/#debian-ubuntu","text":"curl https://packages.axonops.com/apt/repo-signing-key.gpg | sudo apt-key add - echo \"deb https://packages.axonops.com/apt axonops-apt main\" | sudo tee /etc/apt/sources.list.d/axonops-apt.list sudo apt-get update sudo apt-get install axon-cassandra { version } -agent Note: This will install AxonOps Cassandra agent and its dependency: axon-agent","title":"Debian / Ubuntu"},{"location":"installation/cassandra-agent/install/#step-2-agent-configuration","text":"Update the following highlighted lines from /etc/axonops/axon-agent.yml : axon-server : hosts : \"axon-server_endpoint\" # Specify axon-server IP axon-server.mycompany.com axon-agent : org : \"my-company-test\" # Specify your organisation name NTP : host : \"ntp.mycompany.com\" # Specify your NTP server IP address or hostname cassandra : tier0 : # metrics collected every 5 seconds metrics : jvm_ : - \"java.lang:*\" cas_ : - \"org.apache.cassandra.metrics:*\" - \"org.apache.cassandra.net:type=FailureDetector\" tier1 : frequency : 300 # metrics collected every 300 seconds (5m) metrics : cas_ : - \"org.apache.cassandra.metrics:name=EstimatedPartitionCount,*\" #tier2: # frequency: 3600 # 1h #tier3: # frequency: 86400 # 1d blacklist : # You can blacklist metrics based on MBean query pattern (regular expression) - \"org.apache.cassandra.metrics:type=ColumnFamily.*\" # duplication of table metrics - \"org.apache.cassandra.metrics:name=SnapshotsSize.*\" # Collecting SnapshotsSize metrics slows down collection free_text_blacklist : # You can blacklist metrics based on Regex pattern - \"org.apache.cassandra.metrics:type=ThreadPools,path=internal,scope=Repair#.*\" warningThresholdMillis : 100 # This will warn in logs when a MBean takes longer than the specified value. logFormat : \"%4$s %1$tY-%1$tm-%1$td %1$tH:%1$tM:%1$tS,%1$tL %5$s%6$s%n\" Note: the log format will only be used by AxonOps Cassandra agent","title":"Step 2 - Agent Configuration"},{"location":"installation/cassandra-agent/install/#step-3-configure-cassandra","text":"Edit cassandra-env.sh usually located in your Cassandra install path such as /<Cassandra Installation Directory>/conf/cassandra-env.sh and append the following line at the end of the file: JVM_OPTS = \" $JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra{version}-agent.jar=/etc/axonops/axon-agent.yml\" example with Cassandra agent version 3.11 : JVM_OPTS = \" $JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.11-agent.jar=/etc/axonops/axon-agent.yml\" Make sure that this configuration will not get overridden by an automation tool.","title":"Step 3 - Configure Cassandra"},{"location":"installation/cassandra-agent/install/#step-4-add-axonops-user-to-cassandra-user-group-and-cassandra-user-to-axonops-group","text":"sudo usermod -aG <your_cassandra_group> axonops sudo usermod -aG axonops <your_cassandra_user>","title":"Step 4 - Add axonops user to Cassandra user group and Cassandra user to axonops group"},{"location":"installation/cassandra-agent/install/#step-5-start-cassandra","text":"","title":"Step 5 - Start Cassandra"},{"location":"installation/cassandra-agent/install/#step-6-start-axon-agent","text":"sudo service axon-agent start","title":"Step 6 - Start axon-agent"},{"location":"installation/cassandra-agent/install/#optional-step-7-cassandra-remote-backups-or-restore-prerequisites","text":"If you plan to use AxonOps remote backup functionality, axonops user will require read access on Cassandra data folder. As well if you plan to Restore data with AxonOps, axonops user will require write access to Cassandra data folder. We recommend to only provide temporary write access to axonops when required.","title":"(Optional) Step 7 - Cassandra Remote Backups or Restore Prerequisites"},{"location":"installation/cassandra-agent/install/#cassandra-agent-package-details","text":"Configuration: /etc/axonops/axon-agent.yml Binary: /usr/share/axonops/axon-cassandra{version}-agent.jar Version number: /usr/share/axonops/axon-cassandra{version}-agent.version Copyright : /usr/share/doc/axonops/axon-cassandra{version}-agent/copyright Licenses : /usr/share/axonops/licenses/axon-cassandra{version}-agent/","title":"Cassandra agent Package details"},{"location":"installation/cassandra-agent/install/#axon-agent-package-details-dependency-of-cassandra-agent","text":"Configuration: /etc/axonops/axon-agent.yml Binary: usr/share/axonops/axon-agent Logs : /var/log/axonops/axon-agent.log Systemd service: /usr/lib/systemd/system/axon-agent.service","title":"axon-agent Package details (dependency of Cassandra agent)"},{"location":"installation/compat_matrix/compat_matrix/","text":"AxonOps Server \u00b6 Operating Systems Target Architecture RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04], Debian [10,11] x86_64 AxonOps GUI Server \u00b6 Operating Systems Target Architecture RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04], Debian [10,11] x86_64 AxonOps Cassandra Agent \u00b6 System AxonOps Cassandra Agent Version Operating Systems Target Architecture Cassandra 3.0.x 3.0 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04], Debian [10,11] x86_64 Cassandra 3.11.x 3.11 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04], Debian [10,11] x86_64 Cassandra 4.0.x 4.0 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04], Debian [10,11] x86_64","title":"Compatibility matrix"},{"location":"installation/compat_matrix/compat_matrix/#axonops-server","text":"Operating Systems Target Architecture RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04], Debian [10,11] x86_64","title":"AxonOps Server"},{"location":"installation/compat_matrix/compat_matrix/#axonops-gui-server","text":"Operating Systems Target Architecture RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04], Debian [10,11] x86_64","title":"AxonOps GUI Server"},{"location":"installation/compat_matrix/compat_matrix/#axonops-cassandra-agent","text":"System AxonOps Cassandra Agent Version Operating Systems Target Architecture Cassandra 3.0.x 3.0 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04], Debian [10,11] x86_64 Cassandra 3.11.x 3.11 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04], Debian [10,11] x86_64 Cassandra 4.0.x 4.0 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04], Debian [10,11] x86_64","title":"AxonOps Cassandra Agent"},{"location":"installation/dse-agent/install/","text":"axon-java-agent for DSE installation \u00b6 This agent will enable metrics collection from DSE and enable adaptive repairs and backups. Prerequisites \u00b6 DSE agent needs axon-agent to be installed and configured properly. If not installed already, please go to axon-agent installation page. Setup axon-agent for DSE \u00b6 You'll need the specify/update the following lines from axon-agent.yml located in /etc/axonops/axon-agent.yml : axon-server : hosts : \"axon-server_endpoint\" # Specify axon-server endpoint axon-agent : host : 0.0.0.0 # axon-agent listening address for it's OpenTSDB endpoint port : 9916 # axon-agent listening port for it's OpenTSDB endpoint org : \"your_organisation_name\" # Specify your organisation name standalone_mode : false type : \"dse\" #cluster_name: \"standalone\" # comment that line ssl : false # SSL flag for it's OpenTSDB endpoint Set standalone_mode to false Set type to dse Don't forget to comment or remove the cluster_name as it will be deduced from DSE configuration. Don't forget to specify axon-server host and port if that's not already specified. DSE agent installation \u00b6 Make sure the {version} of your DSE and DSE agent are compatible from the compatibility matrix . CentOS / RedHat installer \u00b6 sudo yum install <TODO> Debian / Ubuntu installer \u00b6 sudo apt-get install <TODO> Package details \u00b6 Configuration: /etc/axonops/axon-java-agent.yml Binary: usr/share/axonops/axon-dse{version}-agent-1.0.jar Version number: usr/share/axonops/axon-dse{version}-agent-1.0.version Configure DSE \u00b6 Edit cassandra-env.sh usually located in your dse install path such as /<path_to_DSE>/resources/cassandra/conf/cassandra-env.sh and add at the end of the file the following line: JVM_OPTS = \" $JVM_OPTS -javaagent:/usr/share/axonops/axon-dse{version}-agent-1.0.jar=/etc/axonops/axon-java-agent.yml\" example: JVM_OPTS = \" $JVM_OPTS -javaagent:/usr/share/axonops/axon-dse6.0.4-agent-1.0.jar=/etc/axonops/axon-java-agent.yml\" Start DSE \u00b6 All you need to do now is start DSE. Configuration defaults \u00b6 tier0 : # metrics collected every 5 seconds metrics : jvm_ : - \"java.lang:*\" cas_ : - \"org.apache.cassandra.metrics:*\" - \"org.apache.cassandra.net:type=FailureDetector\" - \"com.datastax.bdp:type=dsefs,*\" tier1 : frequency : 300 # metrics collected every 300 seconds (5m) metrics : cas_ : - \"org.apache.cassandra.metrics:name=EstimatedPartitionCount,*\" #tier2: # frequency: 3600 # 1h #tier3: # frequency: 86400 # 1d blacklist : # You can blacklist metrics based on MBean query pattern - \"org.apache.cassandra.metrics:type=ColumnFamily,*\" # dup of tables - \"org.apache.cassandra.metrics:name=SnapshotsSize,*\" # generally takes time free_text_blacklist : # You can blacklist metrics based on Regex pattern - \"org.apache.cassandra.metrics:type=ThreadPools,path=internal,scope=Repair#.*\" warningThresholdMillis : 100 # This will warn in logs when a MBean takes longer than the specified value. whitelisted_clients : # Whitelist for CQL connections - \"127.0.0.1\" - \"^*.*.*.*\"","title":"axon-java-agent for DSE installation"},{"location":"installation/dse-agent/install/#axon-java-agent-for-dse-installation","text":"This agent will enable metrics collection from DSE and enable adaptive repairs and backups.","title":"axon-java-agent for DSE installation"},{"location":"installation/dse-agent/install/#prerequisites","text":"DSE agent needs axon-agent to be installed and configured properly. If not installed already, please go to axon-agent installation page.","title":"Prerequisites"},{"location":"installation/dse-agent/install/#setup-axon-agent-for-dse","text":"You'll need the specify/update the following lines from axon-agent.yml located in /etc/axonops/axon-agent.yml : axon-server : hosts : \"axon-server_endpoint\" # Specify axon-server endpoint axon-agent : host : 0.0.0.0 # axon-agent listening address for it's OpenTSDB endpoint port : 9916 # axon-agent listening port for it's OpenTSDB endpoint org : \"your_organisation_name\" # Specify your organisation name standalone_mode : false type : \"dse\" #cluster_name: \"standalone\" # comment that line ssl : false # SSL flag for it's OpenTSDB endpoint Set standalone_mode to false Set type to dse Don't forget to comment or remove the cluster_name as it will be deduced from DSE configuration. Don't forget to specify axon-server host and port if that's not already specified.","title":"Setup axon-agent for DSE"},{"location":"installation/dse-agent/install/#dse-agent-installation","text":"Make sure the {version} of your DSE and DSE agent are compatible from the compatibility matrix .","title":"DSE agent installation"},{"location":"installation/dse-agent/install/#centos-redhat-installer","text":"sudo yum install <TODO>","title":"CentOS / RedHat installer"},{"location":"installation/dse-agent/install/#debian-ubuntu-installer","text":"sudo apt-get install <TODO>","title":"Debian / Ubuntu installer"},{"location":"installation/dse-agent/install/#package-details","text":"Configuration: /etc/axonops/axon-java-agent.yml Binary: usr/share/axonops/axon-dse{version}-agent-1.0.jar Version number: usr/share/axonops/axon-dse{version}-agent-1.0.version","title":"Package details"},{"location":"installation/dse-agent/install/#configure-dse","text":"Edit cassandra-env.sh usually located in your dse install path such as /<path_to_DSE>/resources/cassandra/conf/cassandra-env.sh and add at the end of the file the following line: JVM_OPTS = \" $JVM_OPTS -javaagent:/usr/share/axonops/axon-dse{version}-agent-1.0.jar=/etc/axonops/axon-java-agent.yml\" example: JVM_OPTS = \" $JVM_OPTS -javaagent:/usr/share/axonops/axon-dse6.0.4-agent-1.0.jar=/etc/axonops/axon-java-agent.yml\"","title":"Configure DSE"},{"location":"installation/dse-agent/install/#start-dse","text":"All you need to do now is start DSE.","title":"Start DSE"},{"location":"installation/dse-agent/install/#configuration-defaults","text":"tier0 : # metrics collected every 5 seconds metrics : jvm_ : - \"java.lang:*\" cas_ : - \"org.apache.cassandra.metrics:*\" - \"org.apache.cassandra.net:type=FailureDetector\" - \"com.datastax.bdp:type=dsefs,*\" tier1 : frequency : 300 # metrics collected every 300 seconds (5m) metrics : cas_ : - \"org.apache.cassandra.metrics:name=EstimatedPartitionCount,*\" #tier2: # frequency: 3600 # 1h #tier3: # frequency: 86400 # 1d blacklist : # You can blacklist metrics based on MBean query pattern - \"org.apache.cassandra.metrics:type=ColumnFamily,*\" # dup of tables - \"org.apache.cassandra.metrics:name=SnapshotsSize,*\" # generally takes time free_text_blacklist : # You can blacklist metrics based on Regex pattern - \"org.apache.cassandra.metrics:type=ThreadPools,path=internal,scope=Repair#.*\" warningThresholdMillis : 100 # This will warn in logs when a MBean takes longer than the specified value. whitelisted_clients : # Whitelist for CQL connections - \"127.0.0.1\" - \"^*.*.*.*\"","title":"Configuration defaults"},{"location":"installation/kubernetes/","text":"Running AxonOps on Kubernetes \u00b6 Introduction \u00b6 The following shows how to install AxonOps for monitoring cassandra. AxonOps requires ElasticSearch and the documentation below shows how to install both. If you already have ElasticSearch running, you can omit the installation and just ensure the AxonOps config points to it. AxonOps installation uses Helm Charts. Preparing the configuration \u00b6 Resources \u00b6 Cassandra Nodes ElasticSearch CPU ElasticSearch Memory AxonOps Server CPU AxonOps Server Memory <10 1000m 4Gi 500m 1Gi <50 1000m 4Gi 1000m 2Gi 100 2000m 16Gi 2000m 8Gi 200 4000m 32Gi 4000m 16Gi ElasticSearch \u00b6 The example below is a configuration file for the official ElasticSearch helm repository. See inline comments: --- clusterName : \"axonops-elastic\" replicas : 1 esConfig : elasticsearch.yml : | thread_pool.write.queue_size: 2000 roles : master : \"true\" ingest : \"true\" data : \"true\" remote_cluster_client : \"false\" ml : \"false\" # Adjust the memory and cpu requirements to your deployment # esJavaOpts : \"-Xms2g -Xmx2g\" resources : requests : cpu : \"750m\" memory : \"2Gi\" limits : cpu : \"1500m\" memory : \"4Gi\" volumeClaimTemplate : accessModes : [ \"ReadWriteOnce\" ] storageClassName : \"\" # adjust to your storageClass if you don't want to use default resources : requests : storage : 50Gi rbac : create : true AxonOps \u00b6 The default AxonOps installation does not expose the services outside of the cluster. We recommend that you use either a LoadBalancer service or an Ingress. Below you can find an example using Ingress to expose both the dashboard and the AxonOps server. axon-dash : config : axonServerUrl : http://axonops-axon-server:8080 image : pullPolicy : IfNotPresent repository : registry.axonops.com/axonops-public/axonops-docker/axon-dash tag : 1.0.13 ingress : enabled : true annotations : external-dns.alpha.kubernetes.io/hostname : axonops.mycompany.com hosts : - host : axonops.mycompany.com paths : - / tls : - hosts : - axonops.mycompany.com secretName : axon-dash-tls resources : limits : cpu : 500m memory : 512Mi requests : cpu : 25m memory : 64Mi # If you are using an existing ElasticSearch rather than installing it # as shown here then make sure you update the elasticHost URL below axon-server : elasticHost : http://axonops-elastic-master:9200 dashboardUrl : https://axonops.mycompany.com config : # Set up your organization name here org_name : demo image : pullPolicy : IfNotPresent repository : registry.axonops.com/axonops-public/axonops-docker/axon-server tag : 1.0.40 ingress : enabled : true annotations : external-dns.alpha.kubernetes.io/hostname : axonops-server.mycompany.com hosts : - host : axonops-server.mycompany.com paths : - / tls : - hosts : - axonops-server.mycompany.com secretName : axon-server-tls resources : limits : cpu : 1 memory : 1Gi requests : cpu : 100m memory : 256Mi serviceAccount : create : true Installing \u00b6 ElasticSearch \u00b6 Now you can install Elasticsearch referencing the configuration file created in the previous step: helm repo add elastic https://helm.elastic.co helm update helm upgrade -n axonops --install \\ --create-namespace \\ -f \"elasticsearch.yaml\" \\ elasticsearch elastic/elasticsearch AxonOps \u00b6 Finally install the AxonOps helm chart: helm upgrade -n axonops --install \\ --create-namespace \\ -f \"axonops.yaml\" \\ axonops oci://helm.axonops.com/axonops-public/axonops-helm/axonops","title":"Kubernetes"},{"location":"installation/kubernetes/#running-axonops-on-kubernetes","text":"","title":"Running AxonOps on Kubernetes"},{"location":"installation/kubernetes/#introduction","text":"The following shows how to install AxonOps for monitoring cassandra. AxonOps requires ElasticSearch and the documentation below shows how to install both. If you already have ElasticSearch running, you can omit the installation and just ensure the AxonOps config points to it. AxonOps installation uses Helm Charts.","title":"Introduction"},{"location":"installation/kubernetes/#preparing-the-configuration","text":"","title":"Preparing the configuration"},{"location":"installation/kubernetes/#resources","text":"Cassandra Nodes ElasticSearch CPU ElasticSearch Memory AxonOps Server CPU AxonOps Server Memory <10 1000m 4Gi 500m 1Gi <50 1000m 4Gi 1000m 2Gi 100 2000m 16Gi 2000m 8Gi 200 4000m 32Gi 4000m 16Gi","title":"Resources"},{"location":"installation/kubernetes/#elasticsearch","text":"The example below is a configuration file for the official ElasticSearch helm repository. See inline comments: --- clusterName : \"axonops-elastic\" replicas : 1 esConfig : elasticsearch.yml : | thread_pool.write.queue_size: 2000 roles : master : \"true\" ingest : \"true\" data : \"true\" remote_cluster_client : \"false\" ml : \"false\" # Adjust the memory and cpu requirements to your deployment # esJavaOpts : \"-Xms2g -Xmx2g\" resources : requests : cpu : \"750m\" memory : \"2Gi\" limits : cpu : \"1500m\" memory : \"4Gi\" volumeClaimTemplate : accessModes : [ \"ReadWriteOnce\" ] storageClassName : \"\" # adjust to your storageClass if you don't want to use default resources : requests : storage : 50Gi rbac : create : true","title":"ElasticSearch"},{"location":"installation/kubernetes/#axonops","text":"The default AxonOps installation does not expose the services outside of the cluster. We recommend that you use either a LoadBalancer service or an Ingress. Below you can find an example using Ingress to expose both the dashboard and the AxonOps server. axon-dash : config : axonServerUrl : http://axonops-axon-server:8080 image : pullPolicy : IfNotPresent repository : registry.axonops.com/axonops-public/axonops-docker/axon-dash tag : 1.0.13 ingress : enabled : true annotations : external-dns.alpha.kubernetes.io/hostname : axonops.mycompany.com hosts : - host : axonops.mycompany.com paths : - / tls : - hosts : - axonops.mycompany.com secretName : axon-dash-tls resources : limits : cpu : 500m memory : 512Mi requests : cpu : 25m memory : 64Mi # If you are using an existing ElasticSearch rather than installing it # as shown here then make sure you update the elasticHost URL below axon-server : elasticHost : http://axonops-elastic-master:9200 dashboardUrl : https://axonops.mycompany.com config : # Set up your organization name here org_name : demo image : pullPolicy : IfNotPresent repository : registry.axonops.com/axonops-public/axonops-docker/axon-server tag : 1.0.40 ingress : enabled : true annotations : external-dns.alpha.kubernetes.io/hostname : axonops-server.mycompany.com hosts : - host : axonops-server.mycompany.com paths : - / tls : - hosts : - axonops-server.mycompany.com secretName : axon-server-tls resources : limits : cpu : 1 memory : 1Gi requests : cpu : 100m memory : 256Mi serviceAccount : create : true","title":"AxonOps"},{"location":"installation/kubernetes/#installing","text":"","title":"Installing"},{"location":"installation/kubernetes/#elasticsearch_1","text":"Now you can install Elasticsearch referencing the configuration file created in the previous step: helm repo add elastic https://helm.elastic.co helm update helm upgrade -n axonops --install \\ --create-namespace \\ -f \"elasticsearch.yaml\" \\ elasticsearch elastic/elasticsearch","title":"ElasticSearch"},{"location":"installation/kubernetes/#axonops_1","text":"Finally install the AxonOps helm chart: helm upgrade -n axonops --install \\ --create-namespace \\ -f \"axonops.yaml\" \\ axonops oci://helm.axonops.com/axonops-public/axonops-helm/axonops","title":"AxonOps"},{"location":"installation/kubernetes/minikube/","text":"Cassandra with AxonOps on Kubernetes \u00b6 Introduction \u00b6 The following shows how to install AxonOps for monitoring cassandra. This process specifically requires the official cassandra helm repository . Using minikube \u00b6 The deployment should work fine on latest versions of minikube as long as you provide enough memory for it. minikube start --memory 8192 --cpus = 4 minikube addons enable storage-provisioner :warning: Make sure you use a recent version of minikube. Also check available drivers and select the most appropiate for your platform Helmfile \u00b6 Overview \u00b6 As this deployment contains multiple applications we recommend you use an automation system such as Ansible or Helmfile to put together the config. The example below uses helmfile. Install requirements \u00b6 You would need to install the following components: helm: https://helm.sh/docs/intro/install/ helmfile: https://github.com/roboll/helmfile/releases Alternatively you can consider using a dockerized version of them both such as https://hub.docker.com/r/chatwork/helmfile Config files \u00b6 The values below are set for running on a laptop with minikube , adjust accordingly for larger deployments. helmfile.yaml \u00b6 --- repositories : - name : axonops url : helm.axonops.com/axonops-public/axonops-helm/axonops oci : true - name : bitnami url : https://charts.bitnami.com/bitnami - name : ckotzbauer url : https://ckotzbauer.github.io/helm-charts releases : - name : axon-elastic namespace : {{ env \"NAMESPACE\" | default \"axonops\" }} chart : \"bitnami/elasticsearch\" version : '12.8.1' wait : true values : - fullnameOverride : axon-elastic - imageTag : \"7.8.0\" - data : replicas : 1 persistence : size : 1Gi enabled : true accessModes : [ \"ReadWriteOnce\" ] - curator : enabled : true - coordinating : replicas : 1 - master : replicas : 1 persistence : size : 1Gi enabled : true accessModes : [ \"ReadWriteOnce\" ] - name : axonops namespace : {{ env \"NAMESPACE\" | default \"axonops\" }} chart : \"digitalis/axonops\" wait : true values : - values.yaml - name : cassandra namespace : cassandra chart : \"digitalis/cassandra\" wait : true values : - values.yaml - name : cadvisor namespace : kube-system chart : ckotzbauer/cadvisor version : 1.2.0 values : - container : additionalArgs : - --housekeeping_interval=5s # kubernetes default args - --max_housekeeping_interval=10s - --event_storage_event_limit=default=0 - --event_storage_age_limit=default=0 - --disable_metrics=percpu,process,sched,tcp,udp # enable only diskIO, cpu, memory, network, disk - --docker_only - image : repository : gcr.io/cadvisor/cadvisor tag : v0.37.0 values.yaml \u00b6 --- persistence : enabled : true size : 2Gi accessMode : ReadWriteMany podSettings : terminationGracePeriodSeconds : 300 image : tag : 3.11.6 pullPolicy : IfNotPresent config : cluster_name : digitalis cluster_size : 2 dc_name : dc1 seed_size : 1 num_tokens : 256 max_heap_size : 512M heap_new_size : 512M endpoint_snitch : GossipingPropertyFileSnitch env : JVM_OPTS : \"-javaagent:/var/lib/axonops/axon-cassandra3.11-agent.jar=/etc/axonops/axon-agent.yml\" serviceAccount : create : true rules : - apiGroups : - \"\" resources : - nodes - nodes/metrics - pods verbs : - get - list - watch - nonResourceURLs : - /metrics verbs : - get extraVolumes : - name : axonops-agent-config configMap : name : axonops-agent - name : axonops-shared emptyDir : {} - name : axonops-logs emptyDir : {} extraVolumeMounts : - name : axonops-shared mountPath : /var/lib/axonops readOnly : false - name : axonops-agent-config mountPath : /etc/axonops readOnly : true - name : axonops-logs mountPath : /var/log/axonops extraContainers : - name : axonops-agent image : digitalisdocker/axon-agent:latest env : - name : AXON_AGENT_VERBOSITY value : \"1\" - name : AXON_AGENT_ARGS value : \"-v 1\" - name : DATA_FILE_DIRECTORY value : \"/var/lib/cassandra\" - name : CASSANDRA_POD_NAME valueFrom : fieldRef : fieldPath : metadata.name - name : CASSANDRA_POD_NAMESPACE valueFrom : fieldRef : fieldPath : metadata.namespace - name : CASSANDRA_NODE_NAME valueFrom : fieldRef : fieldPath : spec.nodeName - name : CASSANDRA_POD_IP valueFrom : fieldRef : apiVersion : v1 fieldPath : status.podIP volumeMounts : - name : axonops-agent-config mountPath : /etc/axonops readOnly : true - name : axonops-shared mountPath : /var/lib/axonops readOnly : false - name : axonops-logs mountPath : /var/log/axonops - name : data mountPath : /var/lib/cassandra axon-server : global : customer : minikube baseDomain : axonops.com elasticHost : http://axon-elastic-elasticsearch-master.axonops:9200 dashboardUrl : https://axonops.axonops.com image : repository : digitalisdocker/axon-server tag : latest pullPolicy : IfNotPresent config : extraConfig : cql_hosts : - cassandra-0.cassandra.cassandra.svc.cluster.local cql_username : \"cassandra\" cql_password : \"cassandra\" cql_local_dc : dc1 cql_proto_version : 4 cql_max_searchqueriesparallelism : 100 cql_batch_size : 100 cql_page_size : 100 cql_autocreate_tables : false cql_retrypolicy_numretries : 3 cql_retrypolicy_min : 2s cql_retrypolicy_max : 10s cql_reconnectionpolicy_maxretries : 10 cql_reconnectionpolicy_initialinterval : 1s cql_reconnectionpolicy_maxinterval : 10s cql_keyspace_replication : \"{ 'class': 'NetworkTopologyStrategy', 'dc1': 1 }\" cql_metrics_cache_max_size : 128 #MB cql_metrics_cache_max_items : 500000 axon-dash : replicaCount : 1 config : axonServerUrl : http://axonops-axon-server:8080 service : type : NodePort ingress : enabled : true annotations : nginx.ingress.kubernetes.io/ssl-redirect : \"true\" hosts : - hosts : axonops.axonops.com paths : - / image : repository : digitalisdocker/axon-dash tag : latest pullPolicy : IfNotPresent autoscaling : enabled : true resources : limits : cpu : 500m memory : 512Mi requests : cpu : 50m memory : 128Mi axon-agent.yml \u00b6 axon-server : hosts : \"axonops-axon-server.axonops\" # Specify axon-server IP axon-server.mycompany. port : 1888 axon-agent : org : \"digitalis\" human_readable_identifier : \"axon_agent_ip\" # one of the following: NTP : host : \"pool.ntp.org\" # Specify a NTP to determine a NTP offset cassandra : tier0 : # metrics collected every 5 seconds metrics : jvm_ : - \"java.lang:*\" cas_ : - \"org.apache.cassandra.metrics:*\" - \"org.apache.cassandra.net:type=FailureDetector\" tier1 : frequency : 300 # metrics collected every 300 seconds (5m) metrics : cas_ : - \"org.apache.cassandra.metrics:name=EstimatedPartitionCount,*\" blacklist : # You can blacklist metrics based on Regex pattern. Hit the agent on http://agentIP:9916/metricslist to list JMX metrics it is collecting - \"org.apache.cassandra.metrics:type=ColumnFamily.*\" # duplication of table metrics - \"org.apache.cassandra.metrics:.*scope=Repair#.*\" # ignore each repair instance metrics - \"org.apache.cassandra.metrics:.*name=SnapshotsSize.*\" # Collecting SnapshotsSize metrics slows down collection - \"org.apache.cassandra.metrics:.*Max.*\" - \"org.apache.cassandra.metrics:.*Min.*\" - \".*999thPercentile|.*50thPercentile|.*FifteenMinuteRate|.*FiveMinuteRate|.*MeanRate|.*Mean|.*OneMinuteRate|.*StdDev\" JMXOperationsBlacklist : - \"getThreadInfo\" - \"getDatacenter\" - \"getRack\" DMLEventsWhitelist : # You can whitelist keyspaces / tables (list of \"keyspace\" and/or \"keyspace.table\" to log DML queries. Data is not analysed. # - \"system_distributed\" DMLEventsBlacklist : # You can blacklist keyspaces / tables from the DMLEventsWhitelist (list of \"keyspace\" and/or \"keyspace.table\" to log DML queries. Data is not analysed. # - system_distributed.parent_repair_history logSuccessfulRepairs : false # set it to true if you want to log all the successful repair events. warningThresholdMillis : 200 # This will warn in logs when a MBean takes longer than the specified value. logFormat : \"%4$s %1$tY-%1$tm-%1$td %1$tH:%1$tM:%1$tS,%1$tL %5$s%6$s%n\" Start up \u00b6 Create Axon Agent configuration \u00b6 kubectl create ns cassandra kubectl create configmap axonops-agent --from-file = axon-agent.yml -n cassandra Run helmfile \u00b6 With locally installed helm and helmfile \u00b6 cd your/config/directory hemlfile sync With docker image \u00b6 docker run --rm \\ -v ~/.kube:/root/.kube \\ -v ${ PWD } /.helm:/root/.helm \\ -v ${ PWD } /helmfile.yaml:/helmfile.yaml \\ -v ${ PWD } /values.yaml:/values.yaml \\ --net = host chatwork/helmfile sync Access \u00b6 Minikube \u00b6 If you used minikube , identify the name of the service with kubectl get svc -n monitoring and launch it with minikube service axonops-axon-dash -n monitoring LoadBalancer \u00b6 Find the DNS entry for it: kubectl get svc -n monitoring -o wide Open your browser and copy and paste the URL. Troubleshooting \u00b6 Check the status of the pods: kubectl get pod -n monitoring kubectl get pod -n cassandra Any pod which is not on state Running check it out with kubectl describe -n NAMESPACE pod POD-NAME Storage \u00b6 One common problem is regarding storage. If you have enabled persistent storage you may see an error about persistent volume claims (not found, unclaimed, etc). If you're using minikube make sure you enable storage with minikube addons enable storage-provisioner Memory \u00b6 The second most common problem is not enough memory (OOMKilled). You will see this often if you're node does not have enough memory to run the containers or if the heap settings for Cassandra are not right. kubectl describe command will be showing Error 127 when this occurs. In the values.yaml file adjust the heap options to match your hardware: max_heap_size : 512M heap_new_size : 512M Minikube \u00b6 Review the way you have started up minikube and assign more memory if you can. Also check the available drivers and select the appropiate for your platform. On MacOS where I tested hyperkit or virtualbox are the best ones. minikube start --memory 10240 --cpus = 4 --driver = hyperkit Putting it all together \u00b6","title":"Cassandra with AxonOps on Kubernetes"},{"location":"installation/kubernetes/minikube/#cassandra-with-axonops-on-kubernetes","text":"","title":"Cassandra with AxonOps on Kubernetes"},{"location":"installation/kubernetes/minikube/#introduction","text":"The following shows how to install AxonOps for monitoring cassandra. This process specifically requires the official cassandra helm repository .","title":"Introduction"},{"location":"installation/kubernetes/minikube/#using-minikube","text":"The deployment should work fine on latest versions of minikube as long as you provide enough memory for it. minikube start --memory 8192 --cpus = 4 minikube addons enable storage-provisioner :warning: Make sure you use a recent version of minikube. Also check available drivers and select the most appropiate for your platform","title":"Using minikube"},{"location":"installation/kubernetes/minikube/#helmfile","text":"","title":"Helmfile"},{"location":"installation/kubernetes/minikube/#overview","text":"As this deployment contains multiple applications we recommend you use an automation system such as Ansible or Helmfile to put together the config. The example below uses helmfile.","title":"Overview"},{"location":"installation/kubernetes/minikube/#install-requirements","text":"You would need to install the following components: helm: https://helm.sh/docs/intro/install/ helmfile: https://github.com/roboll/helmfile/releases Alternatively you can consider using a dockerized version of them both such as https://hub.docker.com/r/chatwork/helmfile","title":"Install requirements"},{"location":"installation/kubernetes/minikube/#config-files","text":"The values below are set for running on a laptop with minikube , adjust accordingly for larger deployments.","title":"Config files"},{"location":"installation/kubernetes/minikube/#helmfileyaml","text":"--- repositories : - name : axonops url : helm.axonops.com/axonops-public/axonops-helm/axonops oci : true - name : bitnami url : https://charts.bitnami.com/bitnami - name : ckotzbauer url : https://ckotzbauer.github.io/helm-charts releases : - name : axon-elastic namespace : {{ env \"NAMESPACE\" | default \"axonops\" }} chart : \"bitnami/elasticsearch\" version : '12.8.1' wait : true values : - fullnameOverride : axon-elastic - imageTag : \"7.8.0\" - data : replicas : 1 persistence : size : 1Gi enabled : true accessModes : [ \"ReadWriteOnce\" ] - curator : enabled : true - coordinating : replicas : 1 - master : replicas : 1 persistence : size : 1Gi enabled : true accessModes : [ \"ReadWriteOnce\" ] - name : axonops namespace : {{ env \"NAMESPACE\" | default \"axonops\" }} chart : \"digitalis/axonops\" wait : true values : - values.yaml - name : cassandra namespace : cassandra chart : \"digitalis/cassandra\" wait : true values : - values.yaml - name : cadvisor namespace : kube-system chart : ckotzbauer/cadvisor version : 1.2.0 values : - container : additionalArgs : - --housekeeping_interval=5s # kubernetes default args - --max_housekeeping_interval=10s - --event_storage_event_limit=default=0 - --event_storage_age_limit=default=0 - --disable_metrics=percpu,process,sched,tcp,udp # enable only diskIO, cpu, memory, network, disk - --docker_only - image : repository : gcr.io/cadvisor/cadvisor tag : v0.37.0","title":"helmfile.yaml"},{"location":"installation/kubernetes/minikube/#valuesyaml","text":"--- persistence : enabled : true size : 2Gi accessMode : ReadWriteMany podSettings : terminationGracePeriodSeconds : 300 image : tag : 3.11.6 pullPolicy : IfNotPresent config : cluster_name : digitalis cluster_size : 2 dc_name : dc1 seed_size : 1 num_tokens : 256 max_heap_size : 512M heap_new_size : 512M endpoint_snitch : GossipingPropertyFileSnitch env : JVM_OPTS : \"-javaagent:/var/lib/axonops/axon-cassandra3.11-agent.jar=/etc/axonops/axon-agent.yml\" serviceAccount : create : true rules : - apiGroups : - \"\" resources : - nodes - nodes/metrics - pods verbs : - get - list - watch - nonResourceURLs : - /metrics verbs : - get extraVolumes : - name : axonops-agent-config configMap : name : axonops-agent - name : axonops-shared emptyDir : {} - name : axonops-logs emptyDir : {} extraVolumeMounts : - name : axonops-shared mountPath : /var/lib/axonops readOnly : false - name : axonops-agent-config mountPath : /etc/axonops readOnly : true - name : axonops-logs mountPath : /var/log/axonops extraContainers : - name : axonops-agent image : digitalisdocker/axon-agent:latest env : - name : AXON_AGENT_VERBOSITY value : \"1\" - name : AXON_AGENT_ARGS value : \"-v 1\" - name : DATA_FILE_DIRECTORY value : \"/var/lib/cassandra\" - name : CASSANDRA_POD_NAME valueFrom : fieldRef : fieldPath : metadata.name - name : CASSANDRA_POD_NAMESPACE valueFrom : fieldRef : fieldPath : metadata.namespace - name : CASSANDRA_NODE_NAME valueFrom : fieldRef : fieldPath : spec.nodeName - name : CASSANDRA_POD_IP valueFrom : fieldRef : apiVersion : v1 fieldPath : status.podIP volumeMounts : - name : axonops-agent-config mountPath : /etc/axonops readOnly : true - name : axonops-shared mountPath : /var/lib/axonops readOnly : false - name : axonops-logs mountPath : /var/log/axonops - name : data mountPath : /var/lib/cassandra axon-server : global : customer : minikube baseDomain : axonops.com elasticHost : http://axon-elastic-elasticsearch-master.axonops:9200 dashboardUrl : https://axonops.axonops.com image : repository : digitalisdocker/axon-server tag : latest pullPolicy : IfNotPresent config : extraConfig : cql_hosts : - cassandra-0.cassandra.cassandra.svc.cluster.local cql_username : \"cassandra\" cql_password : \"cassandra\" cql_local_dc : dc1 cql_proto_version : 4 cql_max_searchqueriesparallelism : 100 cql_batch_size : 100 cql_page_size : 100 cql_autocreate_tables : false cql_retrypolicy_numretries : 3 cql_retrypolicy_min : 2s cql_retrypolicy_max : 10s cql_reconnectionpolicy_maxretries : 10 cql_reconnectionpolicy_initialinterval : 1s cql_reconnectionpolicy_maxinterval : 10s cql_keyspace_replication : \"{ 'class': 'NetworkTopologyStrategy', 'dc1': 1 }\" cql_metrics_cache_max_size : 128 #MB cql_metrics_cache_max_items : 500000 axon-dash : replicaCount : 1 config : axonServerUrl : http://axonops-axon-server:8080 service : type : NodePort ingress : enabled : true annotations : nginx.ingress.kubernetes.io/ssl-redirect : \"true\" hosts : - hosts : axonops.axonops.com paths : - / image : repository : digitalisdocker/axon-dash tag : latest pullPolicy : IfNotPresent autoscaling : enabled : true resources : limits : cpu : 500m memory : 512Mi requests : cpu : 50m memory : 128Mi","title":"values.yaml"},{"location":"installation/kubernetes/minikube/#axon-agentyml","text":"axon-server : hosts : \"axonops-axon-server.axonops\" # Specify axon-server IP axon-server.mycompany. port : 1888 axon-agent : org : \"digitalis\" human_readable_identifier : \"axon_agent_ip\" # one of the following: NTP : host : \"pool.ntp.org\" # Specify a NTP to determine a NTP offset cassandra : tier0 : # metrics collected every 5 seconds metrics : jvm_ : - \"java.lang:*\" cas_ : - \"org.apache.cassandra.metrics:*\" - \"org.apache.cassandra.net:type=FailureDetector\" tier1 : frequency : 300 # metrics collected every 300 seconds (5m) metrics : cas_ : - \"org.apache.cassandra.metrics:name=EstimatedPartitionCount,*\" blacklist : # You can blacklist metrics based on Regex pattern. Hit the agent on http://agentIP:9916/metricslist to list JMX metrics it is collecting - \"org.apache.cassandra.metrics:type=ColumnFamily.*\" # duplication of table metrics - \"org.apache.cassandra.metrics:.*scope=Repair#.*\" # ignore each repair instance metrics - \"org.apache.cassandra.metrics:.*name=SnapshotsSize.*\" # Collecting SnapshotsSize metrics slows down collection - \"org.apache.cassandra.metrics:.*Max.*\" - \"org.apache.cassandra.metrics:.*Min.*\" - \".*999thPercentile|.*50thPercentile|.*FifteenMinuteRate|.*FiveMinuteRate|.*MeanRate|.*Mean|.*OneMinuteRate|.*StdDev\" JMXOperationsBlacklist : - \"getThreadInfo\" - \"getDatacenter\" - \"getRack\" DMLEventsWhitelist : # You can whitelist keyspaces / tables (list of \"keyspace\" and/or \"keyspace.table\" to log DML queries. Data is not analysed. # - \"system_distributed\" DMLEventsBlacklist : # You can blacklist keyspaces / tables from the DMLEventsWhitelist (list of \"keyspace\" and/or \"keyspace.table\" to log DML queries. Data is not analysed. # - system_distributed.parent_repair_history logSuccessfulRepairs : false # set it to true if you want to log all the successful repair events. warningThresholdMillis : 200 # This will warn in logs when a MBean takes longer than the specified value. logFormat : \"%4$s %1$tY-%1$tm-%1$td %1$tH:%1$tM:%1$tS,%1$tL %5$s%6$s%n\"","title":"axon-agent.yml"},{"location":"installation/kubernetes/minikube/#start-up","text":"","title":"Start up"},{"location":"installation/kubernetes/minikube/#create-axon-agent-configuration","text":"kubectl create ns cassandra kubectl create configmap axonops-agent --from-file = axon-agent.yml -n cassandra","title":"Create Axon Agent configuration"},{"location":"installation/kubernetes/minikube/#run-helmfile","text":"","title":"Run helmfile"},{"location":"installation/kubernetes/minikube/#with-locally-installed-helm-and-helmfile","text":"cd your/config/directory hemlfile sync","title":"With locally installed helm and helmfile"},{"location":"installation/kubernetes/minikube/#with-docker-image","text":"docker run --rm \\ -v ~/.kube:/root/.kube \\ -v ${ PWD } /.helm:/root/.helm \\ -v ${ PWD } /helmfile.yaml:/helmfile.yaml \\ -v ${ PWD } /values.yaml:/values.yaml \\ --net = host chatwork/helmfile sync","title":"With docker image"},{"location":"installation/kubernetes/minikube/#access","text":"","title":"Access"},{"location":"installation/kubernetes/minikube/#minikube","text":"If you used minikube , identify the name of the service with kubectl get svc -n monitoring and launch it with minikube service axonops-axon-dash -n monitoring","title":"Minikube"},{"location":"installation/kubernetes/minikube/#loadbalancer","text":"Find the DNS entry for it: kubectl get svc -n monitoring -o wide Open your browser and copy and paste the URL.","title":"LoadBalancer"},{"location":"installation/kubernetes/minikube/#troubleshooting","text":"Check the status of the pods: kubectl get pod -n monitoring kubectl get pod -n cassandra Any pod which is not on state Running check it out with kubectl describe -n NAMESPACE pod POD-NAME","title":"Troubleshooting"},{"location":"installation/kubernetes/minikube/#storage","text":"One common problem is regarding storage. If you have enabled persistent storage you may see an error about persistent volume claims (not found, unclaimed, etc). If you're using minikube make sure you enable storage with minikube addons enable storage-provisioner","title":"Storage"},{"location":"installation/kubernetes/minikube/#memory","text":"The second most common problem is not enough memory (OOMKilled). You will see this often if you're node does not have enough memory to run the containers or if the heap settings for Cassandra are not right. kubectl describe command will be showing Error 127 when this occurs. In the values.yaml file adjust the heap options to match your hardware: max_heap_size : 512M heap_new_size : 512M","title":"Memory"},{"location":"installation/kubernetes/minikube/#minikube_1","text":"Review the way you have started up minikube and assign more memory if you can. Also check the available drivers and select the appropiate for your platform. On MacOS where I tested hyperkit or virtualbox are the best ones. minikube start --memory 10240 --cpus = 4 --driver = hyperkit","title":"Minikube"},{"location":"installation/kubernetes/minikube/#putting-it-all-together","text":"","title":"Putting it all together"},{"location":"integrations/email-integration/","text":"Setup SMTP notifications \u00b6 On the Axonops application menu, select Settings -> Integrations . Click on the SMTP area. Infomy","title":"Email Integration"},{"location":"integrations/email-integration/#setup-smtp-notifications","text":"On the Axonops application menu, select Settings -> Integrations . Click on the SMTP area. Infomy","title":"Setup SMTP notifications"},{"location":"integrations/overview/","text":"AxonOps provide various integrations for the notifications. The functionality is accessible via Settings > Integrations The current integrations are: SMTP Pagerduty Slack ServiceNow Generic webhooks Infomy Routing \u00b6 AxonOps provide a rich routing mechanism for the notifications. The current routing options are: Global - this will route all the notifications Metrics - notifications about the alerts on metrics Backups - notifications about the backups / restore Service Checks - notifications about the service checks / healthchecks Nodes - notifications raised from the nodes Commands - notifications from generic tasks Repairs - notifications from Cassandra repairs Rolling Restart - notification from the rolling restart feature Each severity ( info, warning, error ) can be routed independently","title":"Overview"},{"location":"integrations/overview/#routing","text":"AxonOps provide a rich routing mechanism for the notifications. The current routing options are: Global - this will route all the notifications Metrics - notifications about the alerts on metrics Backups - notifications about the backups / restore Service Checks - notifications about the service checks / healthchecks Nodes - notifications raised from the nodes Commands - notifications from generic tasks Repairs - notifications from Cassandra repairs Rolling Restart - notification from the rolling restart feature Each severity ( info, warning, error ) can be routed independently","title":"Routing"},{"location":"integrations/pagerduy-integration/","text":"Setup Pagerduty \u00b6 Create Pagerduty Routing Key \u00b6 Using these steps . Please note down the pagerduty routing key Insert Pagerduty Routing Key \u00b6 On the Axonops application menu, select Settings -> Integrations . Click on the Pagerduty area. Infomy","title":"PagerDuty Integration"},{"location":"integrations/pagerduy-integration/#setup-pagerduty","text":"","title":"Setup Pagerduty"},{"location":"integrations/pagerduy-integration/#create-pagerduty-routing-key","text":"Using these steps . Please note down the pagerduty routing key","title":"Create Pagerduty Routing Key"},{"location":"integrations/pagerduy-integration/#insert-pagerduty-routing-key","text":"On the Axonops application menu, select Settings -> Integrations . Click on the Pagerduty area. Infomy","title":"Insert Pagerduty Routing Key"},{"location":"integrations/servicenow-integration/","text":"Navigate to Settings > Integrations and click on ServiceNow Once you have gather your instance name , username and password from ServiceNow, you can validate the form: If you want to see the detailed description of a notification, you'll need to add the description field from ServiceNow incidents templates.","title":"ServiceNow"},{"location":"integrations/slack-integration/","text":"Setup Slack \u00b6 Create Slack Incoming Webhooks \u00b6 Go to Slack Application On the side menu click In search box type Incoming Webhook s From the App directory click Install on Incoming WebHooks App . Infomy Click Add Configuration Infomy In Post to Channel Box select an option from the choose a channel dropdown menu . Click Add Incoming WebHooks Integration Infomy Copy and make a note of the WebHook URL that appears in the Setup Instructions . Infomy Creating the Slack integration on axon-server \u00b6 On the Axonops application menu, select Settings -> Integrations . Click on the Slack area. Infomy Infomy","title":"Slack Integration"},{"location":"integrations/slack-integration/#setup-slack","text":"","title":"Setup Slack"},{"location":"integrations/slack-integration/#create-slack-incoming-webhooks","text":"Go to Slack Application On the side menu click In search box type Incoming Webhook s From the App directory click Install on Incoming WebHooks App . Infomy Click Add Configuration Infomy In Post to Channel Box select an option from the choose a channel dropdown menu . Click Add Incoming WebHooks Integration Infomy Copy and make a note of the WebHook URL that appears in the Setup Instructions . Infomy","title":"Create Slack Incoming Webhooks"},{"location":"integrations/slack-integration/#creating-the-slack-integration-on-axon-server","text":"On the Axonops application menu, select Settings -> Integrations . Click on the Slack area. Infomy Infomy","title":"Creating the Slack integration on axon-server"},{"location":"monitoring/overview/","text":"When monitoring enterprise service there are 3 categories of how the service is performing that we generally capture and monitor. These are; Performance metrics Events (logs) Service availability Performance Metrics \u00b6 Performance metrics in Cassandra is highly extensive and there is a large number that can be captured to understand how Cassandra is performing. Another key metrics that also must be captured in order to effectively understand the performance of a database is the system resource utilisations. AxonOps agent captures both Cassandra and OS metrics and pushes them to the AxonOps server. Events \u00b6 Cassandra event logs are, by default, written to log files. There are important information in the log files that allows SRE's and DevOps engineers to identify issues when they occur. AxonOps agent captures the logs and pushes them to the AxonOps server. These logs are visible within AxonOps dashboard allowing quick access to them without having to log in to the individual servers. Service Availability \u00b6 Checking the momentary service availability and dashboards gives confidence that all services are running correctly as expected. Example service checks that allow engineers to gain confidence in the service availability are: System process Network open ports - e.g. CQL and storage ports Database availability - e.g. can execute CQL query AxonOps Monitoring \u00b6 AxonOps implements all three types of monitoring described above. AxonOps agent captures the information, sends them securely to AxonOps server, and the information is stored in the backend data store. AxonOps GUI provides comprehensive set of metrics dashboards combined with the event log view. It also provides separate service check status view showing the health of the cluster. This section describes how the AxonOps GUI organises the dashboards of all three types of monitoring.","title":"Monitoring Overview"},{"location":"monitoring/overview/#performance-metrics","text":"Performance metrics in Cassandra is highly extensive and there is a large number that can be captured to understand how Cassandra is performing. Another key metrics that also must be captured in order to effectively understand the performance of a database is the system resource utilisations. AxonOps agent captures both Cassandra and OS metrics and pushes them to the AxonOps server.","title":"Performance Metrics"},{"location":"monitoring/overview/#events","text":"Cassandra event logs are, by default, written to log files. There are important information in the log files that allows SRE's and DevOps engineers to identify issues when they occur. AxonOps agent captures the logs and pushes them to the AxonOps server. These logs are visible within AxonOps dashboard allowing quick access to them without having to log in to the individual servers.","title":"Events"},{"location":"monitoring/overview/#service-availability","text":"Checking the momentary service availability and dashboards gives confidence that all services are running correctly as expected. Example service checks that allow engineers to gain confidence in the service availability are: System process Network open ports - e.g. CQL and storage ports Database availability - e.g. can execute CQL query","title":"Service Availability"},{"location":"monitoring/overview/#axonops-monitoring","text":"AxonOps implements all three types of monitoring described above. AxonOps agent captures the information, sends them securely to AxonOps server, and the information is stored in the backend data store. AxonOps GUI provides comprehensive set of metrics dashboards combined with the event log view. It also provides separate service check status view showing the health of the cluster. This section describes how the AxonOps GUI organises the dashboards of all three types of monitoring.","title":"AxonOps Monitoring"},{"location":"monitoring/logsandevents/logsandevents/","text":"Logs and Events \u00b6 The logs and events are visible within AxonOps dashboard allowing quick access to them without having to log in to the individual servers. For a free text search fulfill the content input. You can search by regex expression via the /<expression>/ pattern.","title":"Logs & Events"},{"location":"monitoring/logsandevents/logsandevents/#logs-and-events","text":"The logs and events are visible within AxonOps dashboard allowing quick access to them without having to log in to the individual servers. For a free text search fulfill the content input. You can search by regex expression via the /<expression>/ pattern.","title":"Logs and Events"},{"location":"monitoring/metricsdashboards/cassandra/","text":"AxonOps dashboards provides a comprehensive set of charts with an embedded view for logs and events. You can correlate metrics with logs/events as you can zoom in the logs histogram or metrics charts to drill down both results. Alert rules can be defined graphically in each chart and Log collection is defined in the bottom part of that page. Infomy","title":"Cassandra"},{"location":"monitoring/servicechecks/configurations/","text":"Adding Service Checks \u00b6 On the Axonops application menu, click Service Checks and select Setup tab. Creating Services \u00b6 > Note that for a Cassandra node, you can use the variable `{{.listen_address}}` which will correspond to Cassandra listening address. Example: !!! infomy [![servicecheckseditor](/img/servicecheckseditor.png)](/img/servicecheckseditor.png) #### Delete Services To Delete a service `copy`/`paste` into the editor and `click` save [![save](/img/disk.png)](/img/disk.png) ``` jsonld { \"shellchecks\": [], \"httpchecks\": [], \"tcpchecks\": [] } Example: Infomy","title":"Configurations"},{"location":"monitoring/servicechecks/configurations/#adding-service-checks","text":"On the Axonops application menu, click Service Checks and select Setup tab.","title":"Adding Service Checks"},{"location":"monitoring/servicechecks/configurations/#creating-services","text":"> Note that for a Cassandra node, you can use the variable `{{.listen_address}}` which will correspond to Cassandra listening address. Example: !!! infomy [![servicecheckseditor](/img/servicecheckseditor.png)](/img/servicecheckseditor.png) #### Delete Services To Delete a service `copy`/`paste` into the editor and `click` save [![save](/img/disk.png)](/img/disk.png) ``` jsonld { \"shellchecks\": [], \"httpchecks\": [], \"tcpchecks\": [] } Example: Infomy","title":"Creating Services"},{"location":"monitoring/servicechecks/notifications/","text":"Service checks will notify with one of the three statuses: Service Statuses. Success Warning Error Depending on the status of the service an appropriate alert will be sent. The alert will be sent based on the Default Routing that has been setup via the integrations menu. Noticed: If the Default Routing has not been set up no alerts will be sent. Service Alerts will be sent using the following rules. Info \u00b6 Default routing rules will be used to send success alerts Warning \u00b6 Default routing rules will be used to send warning alerts Error \u00b6 Default routing rules will be used to send error alerts","title":"Notifications"},{"location":"monitoring/servicechecks/notifications/#info","text":"Default routing rules will be used to send success alerts","title":"Info"},{"location":"monitoring/servicechecks/notifications/#warning","text":"Default routing rules will be used to send warning alerts","title":"Warning"},{"location":"monitoring/servicechecks/notifications/#error","text":"Default routing rules will be used to send error alerts","title":"Error"},{"location":"monitoring/servicechecks/overview/","text":"Overview \u00b6 Service Checks in AxonOps allows you to configure custom checks using three types of checks: Shell Scripts HTTP endpoint checks TCP endpoint checks The functionality is accessible via the Service Checks menu You can list the service checks by node : Or by services : You can click on a row within the node view to see all the services for that given Node . The following shows a successful check: And a failing check: Setup service checks \u00b6 To setup the checks, go to Settings > Service Checks and click on one of the + buttons Any changes made and saved are automatically pushed down to the agents. There is no need to deploy the check scripts to individual servers like you may do for instance with Nagios. The status will show once the check has been executed on the agent so it might take some time depending on the interval you have specified within the Service Checks. Although the first execution of the checks will be spread across 30 seconds to prevent running all the checks at the same time. Service checks templating \u00b6 You can provide templated checks with the following pattern: {{.variable_name}} {{.comp_listen_address}} will be replace with Cassandra listen address . For instance, port 7000 in the previous example for check storage port could be replaced with {{.comp_storage_port}} on a Cassandra cluster: endpoint: {{.comp_listen_address}}:{{.comp_storage_port}} Cassandra variables \u00b6 Here is the full list of variables that can be specified in any service check: agent_version comp_PROPERTY_PREFIX comp_SENSITIVE_KEYS comp_allocate_tokens_for_keyspace comp_authenticator comp_authorizer comp_auto_bootstrap comp_auto_snapshot comp_back_pressure_enabled comp_back_pressure_strategy comp_batch_size_fail_threshold_in_kb comp_batch_size_warn_threshold_in_kb comp_batchlog_replay_throttle_in_kb comp_broadcast_address comp_broadcast_rpc_address comp_buffer_pool_use_heap_if_exhausted comp_cas_contention_timeout_in_ms comp_cdc_enabled comp_cdc_free_space_check_interval_ms comp_cdc_raw_directory comp_cdc_total_space_in_mb comp_client_encryption_options comp_cluster_name comp_column_index_cache_size_in_kb comp_column_index_size_in_kb comp_commit_failure_policy comp_commitlog_compression comp_commitlog_directory comp_commitlog_max_compression_buffers_in_pool comp_commitlog_periodic_queue_size comp_commitlog_segment_size_in_mb comp_commitlog_sync comp_commitlog_sync_batch_window_in_ms comp_commitlog_sync_period_in_ms comp_commitlog_total_space_in_mb comp_compaction_large_partition_warning_threshold_mb comp_compaction_throughput_mb_per_sec comp_concurrent_compactors comp_concurrent_counter_writes comp_concurrent_materialized_view_writes comp_concurrent_reads comp_concurrent_replicates comp_concurrent_writes comp_counter_cache_keys_to_save comp_counter_cache_save_period comp_counter_cache_size_in_mb comp_counter_write_request_timeout_in_ms comp_credentials_cache_max_entries comp_credentials_update_interval_in_ms comp_credentials_validity_in_ms comp_cross_node_timeout comp_data_file_directories comp_dc comp_disk_access_mode comp_disk_failure_policy comp_disk_optimization_estimate_percentile comp_disk_optimization_page_cross_chance comp_disk_optimization_strategy comp_dynamic_snitch comp_dynamic_snitch_badness_threshold comp_dynamic_snitch_reset_interval_in_ms comp_dynamic_snitch_update_interval_in_ms comp_enable_materialized_views comp_enable_scripted_user_defined_functions comp_enable_user_defined_functions comp_enable_user_defined_functions_threads comp_encryption_options comp_endpoint_snitch comp_file_cache_round_up comp_file_cache_size_in_mb comp_gc_log_threshold_in_ms comp_gc_warn_threshold_in_ms comp_hinted_handoff_disabled_datacenters comp_hinted_handoff_enabled comp_hinted_handoff_throttle_in_kb comp_hints_compression comp_hints_directory comp_hints_flush_period_in_ms comp_hostId comp_incremental_backups comp_index_interval comp_index_summary_capacity_in_mb comp_index_summary_resize_interval_in_minutes comp_initial_token comp_inter_dc_stream_throughput_outbound_megabits_per_sec comp_inter_dc_tcp_nodelay comp_internode_authenticator comp_internode_compression comp_internode_recv_buff_size_in_bytes comp_internode_send_buff_size_in_bytes comp_isClientMode comp_jvm_VM name comp_jvm_VM vendor comp_jvm_VM version comp_jvm_awt.toolkit comp_jvm_boot classpath comp_jvm_cassandra-foreground comp_jvm_cassandra.config comp_jvm_cassandra.jmx.local.port comp_jvm_cassandra.native.epoll.enabled comp_jvm_com.sun.management.jmxremote.ssl comp_jvm_file.encoding comp_jvm_file.encoding.pkg comp_jvm_file.separator comp_jvm_gc_G1 Old Generation_collection count comp_jvm_gc_G1 Old Generation_collection time comp_jvm_gc_G1 Old Generation_memory pool names comp_jvm_gc_G1 Young Generation_collection count comp_jvm_gc_G1 Young Generation_collection time comp_jvm_gc_G1 Young Generation_memory pool names comp_jvm_heap_heapFreeSize comp_jvm_heap_heapMaxSize comp_jvm_heap_heapSize comp_jvm_input arguments comp_jvm_io.netty.native.workdir comp_jvm_java.awt.graphicsenv comp_jvm_java.awt.printerjob comp_jvm_java.class.path comp_jvm_java.class.version comp_jvm_java.endorsed.dirs comp_jvm_java.ext.dirs comp_jvm_java.home comp_jvm_java.io.tmpdir comp_jvm_java.library.path comp_jvm_java.rmi.server.hostname comp_jvm_java.rmi.server.randomIDs comp_jvm_java.runtime.name comp_jvm_java.runtime.version comp_jvm_java.specification.name comp_jvm_java.specification.vendor comp_jvm_java.specification.version comp_jvm_java.util.logging.SimpleFormatter.format comp_jvm_java.vendor comp_jvm_java.vendor.url comp_jvm_java.vendor.url.bug comp_jvm_java.version comp_jvm_java.vm.info comp_jvm_java.vm.name comp_jvm_java.vm.specification.name comp_jvm_java.vm.specification.vendor comp_jvm_java.vm.specification.version comp_jvm_java.vm.vendor comp_jvm_java.vm.version comp_jvm_jna.loaded comp_jvm_jna.platform.library.path comp_jvm_jnidispatch.path comp_jvm_library classpath comp_jvm_line.separator comp_jvm_log4j.configuration comp_jvm_management spec version comp_jvm_name comp_jvm_os.arch comp_jvm_os.name comp_jvm_os.version comp_jvm_path.separator comp_jvm_spec name comp_jvm_spec vendor comp_jvm_start time comp_jvm_sun.arch.data.model comp_jvm_sun.boot.class.path comp_jvm_sun.boot.library.path comp_jvm_sun.cpu.endian comp_jvm_sun.cpu.isalist comp_jvm_sun.io.unicode.encoding comp_jvm_sun.java.command comp_jvm_sun.java.launcher comp_jvm_sun.jnu.encoding comp_jvm_sun.management.compiler comp_jvm_sun.nio.ch.bugLevel comp_jvm_sun.os.patch.level comp_jvm_up time comp_jvm_user.country comp_jvm_user.dir comp_jvm_user.home comp_jvm_user.language comp_jvm_user.name comp_jvm_user.timezone comp_jvm_user.variant comp_key_cache_keys_to_save comp_key_cache_save_period comp_key_cache_size_in_mb comp_listen_address comp_listen_interface comp_listen_interface_prefer_ipv6 comp_listen_on_broadcast_address comp_logger comp_max_file_descriptors comp_max_hint_window_in_ms comp_max_hints_delivery_threads comp_max_hints_file_size_in_mb comp_max_mutation_size_in_kb comp_max_streaming_retries comp_max_value_size_in_mb comp_memtable_allocation_type comp_memtable_cleanup_threshold comp_memtable_flush_writers comp_memtable_heap_space_in_mb comp_memtable_offheap_space_in_mb comp_min_free_space_per_drive_in_mb comp_mode comp_native_transport_max_concurrent_connections comp_native_transport_max_concurrent_connections_per_ip comp_native_transport_max_frame_size_in_mb comp_native_transport_max_threads comp_native_transport_port comp_native_transport_port_ssl comp_num_tokens comp_open_file_descriptors comp_otc_backlog_expiration_interval_ms comp_otc_backlog_expiration_interval_ms_default comp_otc_coalescing_enough_coalesced_messages comp_otc_coalescing_strategy comp_otc_coalescing_window_us comp_otc_coalescing_window_us_default comp_ownership comp_partitioner comp_permissions_cache_max_entries comp_permissions_update_interval_in_ms comp_permissions_validity_in_ms comp_phi_convict_threshold comp_prepared_statements_cache_size_mb comp_rack comp_range_request_timeout_in_ms comp_read_request_timeout_in_ms comp_releaseVersion comp_request_scheduler comp_request_scheduler_id comp_request_scheduler_options comp_request_timeout_in_ms comp_role_manager comp_roles_cache_max_entries comp_roles_update_interval_in_ms comp_roles_validity_in_ms comp_row_cache_class_name comp_row_cache_keys_to_save comp_row_cache_save_period comp_row_cache_size_in_mb comp_rpc_address comp_rpc_interface comp_rpc_interface_prefer_ipv6 comp_rpc_keepalive comp_rpc_listen_backlog comp_rpc_max_threads comp_rpc_min_threads comp_rpc_port comp_rpc_recv_buff_size_in_bytes comp_rpc_send_buff_size_in_bytes comp_rpc_server_type comp_saved_caches_directory comp_schemaVersion comp_seed_provider comp_server_encryption_options comp_slow_query_log_timeout_in_ms comp_snapshot_before_compaction comp_ssl_storage_port comp_sstable_preemptive_open_interval_in_mb comp_start_native_transport comp_start_rpc comp_storage_port comp_stream_throughput_outbound_megabits_per_sec comp_streaming_keep_alive_period_in_secs comp_streaming_socket_timeout_in_ms comp_thrift_framed_transport_size_in_mb comp_thrift_max_message_length_in_mb comp_thrift_prepared_statements_cache_size_mb comp_tombstone_failure_threshold comp_tombstone_warn_threshold comp_tracetype_query_ttl comp_tracetype_repair_ttl comp_transparent_data_encryption_options comp_trickle_fsync comp_trickle_fsync_interval_in_kb comp_truncate_request_timeout_in_ms comp_unlogged_batch_across_partitions_warn_threshold comp_user_defined_function_fail_timeout comp_user_defined_function_warn_timeout comp_user_function_timeout_policy comp_windows_timer_interval comp_write_request_timeout_in_ms host_BootTime host_Ctxt host_HostID host_Hostname host_KernelArch host_KernelVersion host_OS host_Platform host_PlatformFamily host_PlatformVersion host_Procs host_ProcsBlocked host_ProcsRunning host_ProcsTotal host_Uptime host_VirtualizationRole host_VirtualizationSystem host_cpu_CPU host_cpu_CacheSize host_cpu_CoreID host_cpu_Cores host_cpu_Family host_cpu_Flags host_cpu_Mhz host_cpu_Microcode host_cpu_Model host_cpu_ModelName host_cpu_PhysicalID host_cpu_Stepping host_cpu_VendorID host_disk_/_Free host_disk_/_Total host_disk_/_Used host_disk_/_fstype host_swapmem_Free host_swapmem_PgFault host_swapmem_PgIn host_swapmem_PgMajFault host_swapmem_PgOut host_swapmem_Sin host_swapmem_Sout host_swapmem_Total host_swapmem_Used host_swapmem_UsedPercent host_virtualmem_Active host_virtualmem_Available host_virtualmem_Buffers host_virtualmem_Cached host_virtualmem_CommitLimit host_virtualmem_CommittedAS host_virtualmem_Dirty host_virtualmem_Free host_virtualmem_HighFree host_virtualmem_HighTotal host_virtualmem_HugePageSize host_virtualmem_HugePagesFree host_virtualmem_HugePagesTotal host_virtualmem_Inactive host_virtualmem_Laundry host_virtualmem_LowFree host_virtualmem_LowTotal host_virtualmem_Mapped host_virtualmem_PageTables host_virtualmem_SReclaimable host_virtualmem_SUnreclaim host_virtualmem_Shared host_virtualmem_Slab host_virtualmem_SwapCached host_virtualmem_SwapFree host_virtualmem_SwapTotal host_virtualmem_Total host_virtualmem_Used host_virtualmem_UsedPercent host_virtualmem_VMallocChunk host_virtualmem_VMallocTotal host_virtualmem_VMallocUsed host_virtualmem_Wired host_virtualmem_Writeback host_virtualmem_WritebackTmp human_readable_identifier human_readable_identifier_field","title":"Service Checks"},{"location":"monitoring/servicechecks/overview/#overview","text":"Service Checks in AxonOps allows you to configure custom checks using three types of checks: Shell Scripts HTTP endpoint checks TCP endpoint checks The functionality is accessible via the Service Checks menu You can list the service checks by node : Or by services : You can click on a row within the node view to see all the services for that given Node . The following shows a successful check: And a failing check:","title":"Overview"},{"location":"monitoring/servicechecks/overview/#setup-service-checks","text":"To setup the checks, go to Settings > Service Checks and click on one of the + buttons Any changes made and saved are automatically pushed down to the agents. There is no need to deploy the check scripts to individual servers like you may do for instance with Nagios. The status will show once the check has been executed on the agent so it might take some time depending on the interval you have specified within the Service Checks. Although the first execution of the checks will be spread across 30 seconds to prevent running all the checks at the same time.","title":"Setup service checks"},{"location":"monitoring/servicechecks/overview/#service-checks-templating","text":"You can provide templated checks with the following pattern: {{.variable_name}} {{.comp_listen_address}} will be replace with Cassandra listen address . For instance, port 7000 in the previous example for check storage port could be replaced with {{.comp_storage_port}} on a Cassandra cluster: endpoint: {{.comp_listen_address}}:{{.comp_storage_port}}","title":"Service checks templating"},{"location":"monitoring/servicechecks/overview/#cassandra-variables","text":"Here is the full list of variables that can be specified in any service check: agent_version comp_PROPERTY_PREFIX comp_SENSITIVE_KEYS comp_allocate_tokens_for_keyspace comp_authenticator comp_authorizer comp_auto_bootstrap comp_auto_snapshot comp_back_pressure_enabled comp_back_pressure_strategy comp_batch_size_fail_threshold_in_kb comp_batch_size_warn_threshold_in_kb comp_batchlog_replay_throttle_in_kb comp_broadcast_address comp_broadcast_rpc_address comp_buffer_pool_use_heap_if_exhausted comp_cas_contention_timeout_in_ms comp_cdc_enabled comp_cdc_free_space_check_interval_ms comp_cdc_raw_directory comp_cdc_total_space_in_mb comp_client_encryption_options comp_cluster_name comp_column_index_cache_size_in_kb comp_column_index_size_in_kb comp_commit_failure_policy comp_commitlog_compression comp_commitlog_directory comp_commitlog_max_compression_buffers_in_pool comp_commitlog_periodic_queue_size comp_commitlog_segment_size_in_mb comp_commitlog_sync comp_commitlog_sync_batch_window_in_ms comp_commitlog_sync_period_in_ms comp_commitlog_total_space_in_mb comp_compaction_large_partition_warning_threshold_mb comp_compaction_throughput_mb_per_sec comp_concurrent_compactors comp_concurrent_counter_writes comp_concurrent_materialized_view_writes comp_concurrent_reads comp_concurrent_replicates comp_concurrent_writes comp_counter_cache_keys_to_save comp_counter_cache_save_period comp_counter_cache_size_in_mb comp_counter_write_request_timeout_in_ms comp_credentials_cache_max_entries comp_credentials_update_interval_in_ms comp_credentials_validity_in_ms comp_cross_node_timeout comp_data_file_directories comp_dc comp_disk_access_mode comp_disk_failure_policy comp_disk_optimization_estimate_percentile comp_disk_optimization_page_cross_chance comp_disk_optimization_strategy comp_dynamic_snitch comp_dynamic_snitch_badness_threshold comp_dynamic_snitch_reset_interval_in_ms comp_dynamic_snitch_update_interval_in_ms comp_enable_materialized_views comp_enable_scripted_user_defined_functions comp_enable_user_defined_functions comp_enable_user_defined_functions_threads comp_encryption_options comp_endpoint_snitch comp_file_cache_round_up comp_file_cache_size_in_mb comp_gc_log_threshold_in_ms comp_gc_warn_threshold_in_ms comp_hinted_handoff_disabled_datacenters comp_hinted_handoff_enabled comp_hinted_handoff_throttle_in_kb comp_hints_compression comp_hints_directory comp_hints_flush_period_in_ms comp_hostId comp_incremental_backups comp_index_interval comp_index_summary_capacity_in_mb comp_index_summary_resize_interval_in_minutes comp_initial_token comp_inter_dc_stream_throughput_outbound_megabits_per_sec comp_inter_dc_tcp_nodelay comp_internode_authenticator comp_internode_compression comp_internode_recv_buff_size_in_bytes comp_internode_send_buff_size_in_bytes comp_isClientMode comp_jvm_VM name comp_jvm_VM vendor comp_jvm_VM version comp_jvm_awt.toolkit comp_jvm_boot classpath comp_jvm_cassandra-foreground comp_jvm_cassandra.config comp_jvm_cassandra.jmx.local.port comp_jvm_cassandra.native.epoll.enabled comp_jvm_com.sun.management.jmxremote.ssl comp_jvm_file.encoding comp_jvm_file.encoding.pkg comp_jvm_file.separator comp_jvm_gc_G1 Old Generation_collection count comp_jvm_gc_G1 Old Generation_collection time comp_jvm_gc_G1 Old Generation_memory pool names comp_jvm_gc_G1 Young Generation_collection count comp_jvm_gc_G1 Young Generation_collection time comp_jvm_gc_G1 Young Generation_memory pool names comp_jvm_heap_heapFreeSize comp_jvm_heap_heapMaxSize comp_jvm_heap_heapSize comp_jvm_input arguments comp_jvm_io.netty.native.workdir comp_jvm_java.awt.graphicsenv comp_jvm_java.awt.printerjob comp_jvm_java.class.path comp_jvm_java.class.version comp_jvm_java.endorsed.dirs comp_jvm_java.ext.dirs comp_jvm_java.home comp_jvm_java.io.tmpdir comp_jvm_java.library.path comp_jvm_java.rmi.server.hostname comp_jvm_java.rmi.server.randomIDs comp_jvm_java.runtime.name comp_jvm_java.runtime.version comp_jvm_java.specification.name comp_jvm_java.specification.vendor comp_jvm_java.specification.version comp_jvm_java.util.logging.SimpleFormatter.format comp_jvm_java.vendor comp_jvm_java.vendor.url comp_jvm_java.vendor.url.bug comp_jvm_java.version comp_jvm_java.vm.info comp_jvm_java.vm.name comp_jvm_java.vm.specification.name comp_jvm_java.vm.specification.vendor comp_jvm_java.vm.specification.version comp_jvm_java.vm.vendor comp_jvm_java.vm.version comp_jvm_jna.loaded comp_jvm_jna.platform.library.path comp_jvm_jnidispatch.path comp_jvm_library classpath comp_jvm_line.separator comp_jvm_log4j.configuration comp_jvm_management spec version comp_jvm_name comp_jvm_os.arch comp_jvm_os.name comp_jvm_os.version comp_jvm_path.separator comp_jvm_spec name comp_jvm_spec vendor comp_jvm_start time comp_jvm_sun.arch.data.model comp_jvm_sun.boot.class.path comp_jvm_sun.boot.library.path comp_jvm_sun.cpu.endian comp_jvm_sun.cpu.isalist comp_jvm_sun.io.unicode.encoding comp_jvm_sun.java.command comp_jvm_sun.java.launcher comp_jvm_sun.jnu.encoding comp_jvm_sun.management.compiler comp_jvm_sun.nio.ch.bugLevel comp_jvm_sun.os.patch.level comp_jvm_up time comp_jvm_user.country comp_jvm_user.dir comp_jvm_user.home comp_jvm_user.language comp_jvm_user.name comp_jvm_user.timezone comp_jvm_user.variant comp_key_cache_keys_to_save comp_key_cache_save_period comp_key_cache_size_in_mb comp_listen_address comp_listen_interface comp_listen_interface_prefer_ipv6 comp_listen_on_broadcast_address comp_logger comp_max_file_descriptors comp_max_hint_window_in_ms comp_max_hints_delivery_threads comp_max_hints_file_size_in_mb comp_max_mutation_size_in_kb comp_max_streaming_retries comp_max_value_size_in_mb comp_memtable_allocation_type comp_memtable_cleanup_threshold comp_memtable_flush_writers comp_memtable_heap_space_in_mb comp_memtable_offheap_space_in_mb comp_min_free_space_per_drive_in_mb comp_mode comp_native_transport_max_concurrent_connections comp_native_transport_max_concurrent_connections_per_ip comp_native_transport_max_frame_size_in_mb comp_native_transport_max_threads comp_native_transport_port comp_native_transport_port_ssl comp_num_tokens comp_open_file_descriptors comp_otc_backlog_expiration_interval_ms comp_otc_backlog_expiration_interval_ms_default comp_otc_coalescing_enough_coalesced_messages comp_otc_coalescing_strategy comp_otc_coalescing_window_us comp_otc_coalescing_window_us_default comp_ownership comp_partitioner comp_permissions_cache_max_entries comp_permissions_update_interval_in_ms comp_permissions_validity_in_ms comp_phi_convict_threshold comp_prepared_statements_cache_size_mb comp_rack comp_range_request_timeout_in_ms comp_read_request_timeout_in_ms comp_releaseVersion comp_request_scheduler comp_request_scheduler_id comp_request_scheduler_options comp_request_timeout_in_ms comp_role_manager comp_roles_cache_max_entries comp_roles_update_interval_in_ms comp_roles_validity_in_ms comp_row_cache_class_name comp_row_cache_keys_to_save comp_row_cache_save_period comp_row_cache_size_in_mb comp_rpc_address comp_rpc_interface comp_rpc_interface_prefer_ipv6 comp_rpc_keepalive comp_rpc_listen_backlog comp_rpc_max_threads comp_rpc_min_threads comp_rpc_port comp_rpc_recv_buff_size_in_bytes comp_rpc_send_buff_size_in_bytes comp_rpc_server_type comp_saved_caches_directory comp_schemaVersion comp_seed_provider comp_server_encryption_options comp_slow_query_log_timeout_in_ms comp_snapshot_before_compaction comp_ssl_storage_port comp_sstable_preemptive_open_interval_in_mb comp_start_native_transport comp_start_rpc comp_storage_port comp_stream_throughput_outbound_megabits_per_sec comp_streaming_keep_alive_period_in_secs comp_streaming_socket_timeout_in_ms comp_thrift_framed_transport_size_in_mb comp_thrift_max_message_length_in_mb comp_thrift_prepared_statements_cache_size_mb comp_tombstone_failure_threshold comp_tombstone_warn_threshold comp_tracetype_query_ttl comp_tracetype_repair_ttl comp_transparent_data_encryption_options comp_trickle_fsync comp_trickle_fsync_interval_in_kb comp_truncate_request_timeout_in_ms comp_unlogged_batch_across_partitions_warn_threshold comp_user_defined_function_fail_timeout comp_user_defined_function_warn_timeout comp_user_function_timeout_policy comp_windows_timer_interval comp_write_request_timeout_in_ms host_BootTime host_Ctxt host_HostID host_Hostname host_KernelArch host_KernelVersion host_OS host_Platform host_PlatformFamily host_PlatformVersion host_Procs host_ProcsBlocked host_ProcsRunning host_ProcsTotal host_Uptime host_VirtualizationRole host_VirtualizationSystem host_cpu_CPU host_cpu_CacheSize host_cpu_CoreID host_cpu_Cores host_cpu_Family host_cpu_Flags host_cpu_Mhz host_cpu_Microcode host_cpu_Model host_cpu_ModelName host_cpu_PhysicalID host_cpu_Stepping host_cpu_VendorID host_disk_/_Free host_disk_/_Total host_disk_/_Used host_disk_/_fstype host_swapmem_Free host_swapmem_PgFault host_swapmem_PgIn host_swapmem_PgMajFault host_swapmem_PgOut host_swapmem_Sin host_swapmem_Sout host_swapmem_Total host_swapmem_Used host_swapmem_UsedPercent host_virtualmem_Active host_virtualmem_Available host_virtualmem_Buffers host_virtualmem_Cached host_virtualmem_CommitLimit host_virtualmem_CommittedAS host_virtualmem_Dirty host_virtualmem_Free host_virtualmem_HighFree host_virtualmem_HighTotal host_virtualmem_HugePageSize host_virtualmem_HugePagesFree host_virtualmem_HugePagesTotal host_virtualmem_Inactive host_virtualmem_Laundry host_virtualmem_LowFree host_virtualmem_LowTotal host_virtualmem_Mapped host_virtualmem_PageTables host_virtualmem_SReclaimable host_virtualmem_SUnreclaim host_virtualmem_Shared host_virtualmem_Slab host_virtualmem_SwapCached host_virtualmem_SwapFree host_virtualmem_SwapTotal host_virtualmem_Total host_virtualmem_Used host_virtualmem_UsedPercent host_virtualmem_VMallocChunk host_virtualmem_VMallocTotal host_virtualmem_VMallocUsed host_virtualmem_Wired host_virtualmem_Writeback host_virtualmem_WritebackTmp human_readable_identifier human_readable_identifier_field","title":"Cassandra variables"},{"location":"operations/cassandra/repair/","text":"Repairs must be completed regularly to maintain Cassandra nodes. AxonOps provide two mechanisms to ease Cassandra repairs: Scheduled repair Adapative repair service Scheduled repair \u00b6 You can initiate three types of scheduled repair: Immediate scheduled repair: these will trigger immediately once Infomy Simple scheduled repair: these will trigger base on the selected schedule repeatedly Infomy Cron schedule repair: Same as simple scheduled repair but the schedule will be based on a Cron expression Infomy The following capture presents a running repair that has been initiated immediately and a scheduled repair that is scheduled for 12:00 AM UTC: Infomy Adapative repair service \u00b6 Since AxonOps collects performance metrics and logs, we built an \u201cAdaptive\u201d repair system which regulates the velocity (parallelism and pauses between each subrange repair) based on performance trending data. The regulation of repair velocity takes input from various metrics including CPU utilisation, query latencies, Cassandra thread pools pending statistics, and IOwait percentage, while tracking the schedule of repair based on gc_grace_seconds for each table. The idea of this is to achieve the following: Completion of repair within gc_grace_seconds of each table. Repair process does not affect query performance. In essence, adaptive repair regulator slows down the repair velocity when it deems the load is going to be high based on the gradient of the rate of increase of load, and speeds up to catch up with the repair schedule when the resources are more readily available. This mechanism also doesn't require JMX access. The adaptive repair service running on AxonOps server orchestrates and issues commands to the agents over the existing connection. Infomy If you want to keep the tables as fresh as possible, we do recommend to increate the table parallelism to be greater than the total number of tables of your cluster and reduce the segments per VNode to generate less repair requests. From a user\u2019s point of view, there is only a single switch to enable this service. Keep this enabled and AxonOps will take care of the repair of all tables for you. Also you can customize the following: Blacklist some tables Specify the number of tables to repair in parallel Specify the number of segments per VNode to repair The GC grace threshold in seconds: if a table has a gc grace lesser than the specified value, it will be ignored from the adaptive repair service","title":"Repair"},{"location":"operations/cassandra/repair/#scheduled-repair","text":"You can initiate three types of scheduled repair: Immediate scheduled repair: these will trigger immediately once Infomy Simple scheduled repair: these will trigger base on the selected schedule repeatedly Infomy Cron schedule repair: Same as simple scheduled repair but the schedule will be based on a Cron expression Infomy The following capture presents a running repair that has been initiated immediately and a scheduled repair that is scheduled for 12:00 AM UTC: Infomy","title":"Scheduled repair"},{"location":"operations/cassandra/repair/#adapative-repair-service","text":"Since AxonOps collects performance metrics and logs, we built an \u201cAdaptive\u201d repair system which regulates the velocity (parallelism and pauses between each subrange repair) based on performance trending data. The regulation of repair velocity takes input from various metrics including CPU utilisation, query latencies, Cassandra thread pools pending statistics, and IOwait percentage, while tracking the schedule of repair based on gc_grace_seconds for each table. The idea of this is to achieve the following: Completion of repair within gc_grace_seconds of each table. Repair process does not affect query performance. In essence, adaptive repair regulator slows down the repair velocity when it deems the load is going to be high based on the gradient of the rate of increase of load, and speeds up to catch up with the repair schedule when the resources are more readily available. This mechanism also doesn't require JMX access. The adaptive repair service running on AxonOps server orchestrates and issues commands to the agents over the existing connection. Infomy If you want to keep the tables as fresh as possible, we do recommend to increate the table parallelism to be greater than the total number of tables of your cluster and reduce the segments per VNode to generate less repair requests. From a user\u2019s point of view, there is only a single switch to enable this service. Keep this enabled and AxonOps will take care of the repair of all tables for you. Also you can customize the following: Blacklist some tables Specify the number of tables to repair in parallel Specify the number of segments per VNode to repair The GC grace threshold in seconds: if a table has a gc grace lesser than the specified value, it will be ignored from the adaptive repair service","title":"Adapative repair service"},{"location":"operations/cassandra/backup/overview/","text":"AxonOps provide scheduled backup and restore functionnality for your Cassandra cluster. The functionality is accessible via Operations > Backups & Restore > Backups Infomy Scheduled backup \u00b6 You can initiate three types of scheduled backup: Immediate scheduled backup: these will trigger immediately once Simple scheduled backup: these will trigger base on the selected schedule repeatedly Infomy Cron schedule backup: Same as simple scheduled backup but the schedule will be based on a Cron expression Infomy The following capture presents two backups, a local only and a local and remote backup: Infomy And the details of the local and remote backup: Infomy Remote backups \u00b6 Note that axonops user will need read access on Cassandra data folders to be able to proceed the remote backup. The current remote options are: AWS S3 Google Cloud Storage Microsoft Azure Blob Storage SFTP/SSH local filesystem example of the AWS S3 remote interface: Infomy","title":"Overview"},{"location":"operations/cassandra/backup/overview/#scheduled-backup","text":"You can initiate three types of scheduled backup: Immediate scheduled backup: these will trigger immediately once Simple scheduled backup: these will trigger base on the selected schedule repeatedly Infomy Cron schedule backup: Same as simple scheduled backup but the schedule will be based on a Cron expression Infomy The following capture presents two backups, a local only and a local and remote backup: Infomy And the details of the local and remote backup: Infomy","title":"Scheduled backup"},{"location":"operations/cassandra/backup/overview/#remote-backups","text":"Note that axonops user will need read access on Cassandra data folders to be able to proceed the remote backup. The current remote options are: AWS S3 Google Cloud Storage Microsoft Azure Blob Storage SFTP/SSH local filesystem example of the AWS S3 remote interface: Infomy","title":"Remote backups"},{"location":"operations/cassandra/restore/overview/","text":"AxonOps provides a restore functionnality from previous Cassandra snapshots. The functionality is accessible via Operations > Backups & Restore > Restore Infomy Note that axonops user will need temporary write access on Cassandra data folders to be able to proceed the restoration. To restore Cassandra, click on a relevant backup. This will provide the details of that backup and the ability to start the restoration by clicking the LOCAL RESTORE or REMOTE RESTORE button depending on if you prefer to restore from the local snapshot or the remote one (if you have one). You can also select which nodes you would like to restore on via the checkboxes in the Hosts list. Infomy Restore on a replacement node \u00b6 Use this procedure when a node in the Cassandra cluster needs to be replaced. Make sure that Cassandra is not running while you are doing the restoration on the replacement node and that Cassandra configuration is identical to the dead node. First you'll need to retrieve the axon-agent hostID of the dead node. You'll find it in the cluster overview by selecting a node: Infomy Once you get the hostID of the dead node, you'll start axon-agent on the new node passing the previous hostID as an env var: AXON_AGENT_HOSTID = 54cb2777-34e7-49dd-8fa9-5563aa5f05d8 /usr/share/axonops/axon-agent Once the agent is started and connected to axon-server with the previous hostID, you'll navigate to Operations > Backups & Restore > Restore ; select the backup you'd like to restore from; select the replacement node via the red checkbox and click REMOTE RESTORE . This will restore the data from the remote location to the selected node. Note that axonops user will need write access on Cassandra data folders to be able to proceed the restoration. Infomy Once the restore process is finished, you can start Cassandra on the replacement node.","title":"Restore"},{"location":"operations/cassandra/restore/overview/#restore-on-a-replacement-node","text":"Use this procedure when a node in the Cassandra cluster needs to be replaced. Make sure that Cassandra is not running while you are doing the restoration on the replacement node and that Cassandra configuration is identical to the dead node. First you'll need to retrieve the axon-agent hostID of the dead node. You'll find it in the cluster overview by selecting a node: Infomy Once you get the hostID of the dead node, you'll start axon-agent on the new node passing the previous hostID as an env var: AXON_AGENT_HOSTID = 54cb2777-34e7-49dd-8fa9-5563aa5f05d8 /usr/share/axonops/axon-agent Once the agent is started and connected to axon-server with the previous hostID, you'll navigate to Operations > Backups & Restore > Restore ; select the backup you'd like to restore from; select the replacement node via the red checkbox and click REMOTE RESTORE . This will restore the data from the remote location to the selected node. Note that axonops user will need write access on Cassandra data folders to be able to proceed the restoration. Infomy Once the restore process is finished, you can start Cassandra on the replacement node.","title":"Restore on a replacement node"},{"location":"operations/cassandra/rollingrestart/overview/","text":"AxonOps provides a rolling restart functionnality for Cassandra. The functionality is accessible via Operations > Rolling Restart Infomy axonops user will require permissions to be able to stop and start Cassandra service. To do so you will add axonops user in the sudoers with for instance the following permissions: #/etc/sudoers.d/axonops axonops ALL = NOPASSWD: /sbin/service cassandra *, /usr/bin/systemctl * cassandra* You can start an immediate rolling restart or schedule it. The script field let you able to tweak the predefined script executed by axon-agents during the restart process. You can also specify different degree of parallelism for the restart: DC , Rack and Node . For instance, to restart one entire rack at once across the cluster, you can set a large Node parallelism (greater than the number of nodes the rack has, ie 999). DC parallelism: 1 Rack parallelism: 1 Node parallelism: 999 To restart one entire rack across each DC : DC parallelism: 999 Rack parallelism: 1 Node parallelism: 999","title":"Rolling Restart"},{"location":"overview/architecture/","text":"Architecture \u00b6 Before \u00b6 Our deployment model with the use of open source tools Infomy AxonOps Deployment Model \u00b6 As you can see from the diagram below, we have massively simplified the stack with AxonOps. Infomy You can also use a CQL datastore such as Cassandra , Elassandra , or Scylla to store the metrics. We recommand storing metrics on a CQL store on 100+ nodes clusters to improve your experience navigating the metrics dashboards.","title":"Architecture"},{"location":"overview/architecture/#architecture","text":"","title":"Architecture"},{"location":"overview/architecture/#before","text":"Our deployment model with the use of open source tools Infomy","title":"Before"},{"location":"overview/architecture/#axonops-deployment-model","text":"As you can see from the diagram below, we have massively simplified the stack with AxonOps. Infomy You can also use a CQL datastore such as Cassandra , Elassandra , or Scylla to store the metrics. We recommand storing metrics on a CQL store on 100+ nodes clusters to improve your experience navigating the metrics dashboards.","title":"AxonOps Deployment Model"},{"location":"overview/axonops-cloud/","text":"","title":"Axonops cloud"},{"location":"overview/axonops-enterprise/","text":"","title":"Axonops enterprise"},{"location":"overview/motivation/","text":"Motivation \u00b6 AxonOps has been developed and actively maintained by digitalis.io , a company providing managed services for Apache Cassandra\u2122 and other modern distributed data technologies. digitalis.io used a variety of modern and popular open source tools to manage its customer's data platforms to gain quick insight into how the clusters are working, and be alerted when there are issues. The open source tools we used are: Grafana - metrics dashboarding Prometheus - time series database for metrics Prometheus Alertmanager - metrics alerting ELK - Log capture and visualisation elastalert - Alerting on logs Consul - Service Discovery and Health Checks consul-alerts - Alerting on service health check failures Rundeck - Job Scheduler Ansible - Provisioning automation Problems \u00b6 The tools listed above served us well. They gave us the confidence to manage enterprise deployment of distributed data platforms \u2013 alerting us when there are problems, ability to diagnose issues quickly, automatically performing routine scheduled tasks etc. However, using these tools and their problems were realised over time. Too many components - There are many components including the agents that need to be installed. Takes a lot of effort to integrate all components for each customer's on-premises environment, even with fully automated implementation using Ansible. Steep learning curve - The learning curve of deploying and configuring all the components is high. Patching hell - Patching schedule became a nightmare because of the sheer number of components. Imagine having to raise change requests for patching all above components! Enterprise hell - Firewall configurations became big for enterprise on-premises customers, often required many hours of tracing which change requests were unsuccessfully executed. Multiple dashboards - Multiple dashboards for metrics, logs and service availability. Complex alerting configurations - Alert notification configurations were all over the place. Fine tuning alerts and updating them takes a lot of work. Wish List \u00b6 With the above problems in mind, we needed to become more efficient as a company deploying the tools we need to manage our customers. After promoting the above tools to our customers, we ate the humble pie, and went back to the drawing board with the aim of reducing the efforts needed to on-board new customers. On-premises / cloud deployment Single dashboard for metrics / logs / service health Simple alert rules configurations Capture all metrics at high resolution (with Cassandra there are well over 20,000 metrics!) Capture logs and internal events like authentication, DDL, DML etc Scheduled backup / restore feature Performs domain specific administrative tasks, including Cassandra repair Manages the following products; Apache Cassandra Apache Kafka DataStax Enterprise Confluent Enterprise Elasticsearch Apache Spark etc Simplified deployment model Single agent for collecting metrics, logs, event, configs The same agent performs execution of health checks, backup, restore No JMX to capture the metrics, and must be push from the JVM and not pull Single socket connection initiated by agent to management server requiring only simple firewall rules Bi-directional communication between agent and management server over the single socket Modern snappy GUI","title":"Motivation"},{"location":"overview/motivation/#motivation","text":"AxonOps has been developed and actively maintained by digitalis.io , a company providing managed services for Apache Cassandra\u2122 and other modern distributed data technologies. digitalis.io used a variety of modern and popular open source tools to manage its customer's data platforms to gain quick insight into how the clusters are working, and be alerted when there are issues. The open source tools we used are: Grafana - metrics dashboarding Prometheus - time series database for metrics Prometheus Alertmanager - metrics alerting ELK - Log capture and visualisation elastalert - Alerting on logs Consul - Service Discovery and Health Checks consul-alerts - Alerting on service health check failures Rundeck - Job Scheduler Ansible - Provisioning automation","title":"Motivation"},{"location":"overview/motivation/#problems","text":"The tools listed above served us well. They gave us the confidence to manage enterprise deployment of distributed data platforms \u2013 alerting us when there are problems, ability to diagnose issues quickly, automatically performing routine scheduled tasks etc. However, using these tools and their problems were realised over time. Too many components - There are many components including the agents that need to be installed. Takes a lot of effort to integrate all components for each customer's on-premises environment, even with fully automated implementation using Ansible. Steep learning curve - The learning curve of deploying and configuring all the components is high. Patching hell - Patching schedule became a nightmare because of the sheer number of components. Imagine having to raise change requests for patching all above components! Enterprise hell - Firewall configurations became big for enterprise on-premises customers, often required many hours of tracing which change requests were unsuccessfully executed. Multiple dashboards - Multiple dashboards for metrics, logs and service availability. Complex alerting configurations - Alert notification configurations were all over the place. Fine tuning alerts and updating them takes a lot of work.","title":"Problems"},{"location":"overview/motivation/#wish-list","text":"With the above problems in mind, we needed to become more efficient as a company deploying the tools we need to manage our customers. After promoting the above tools to our customers, we ate the humble pie, and went back to the drawing board with the aim of reducing the efforts needed to on-board new customers. On-premises / cloud deployment Single dashboard for metrics / logs / service health Simple alert rules configurations Capture all metrics at high resolution (with Cassandra there are well over 20,000 metrics!) Capture logs and internal events like authentication, DDL, DML etc Scheduled backup / restore feature Performs domain specific administrative tasks, including Cassandra repair Manages the following products; Apache Cassandra Apache Kafka DataStax Enterprise Confluent Enterprise Elasticsearch Apache Spark etc Simplified deployment model Single agent for collecting metrics, logs, event, configs The same agent performs execution of health checks, backup, restore No JMX to capture the metrics, and must be push from the JVM and not pull Single socket connection initiated by agent to management server requiring only simple firewall rules Bi-directional communication between agent and management server over the single socket Modern snappy GUI","title":"Wish List"},{"location":"server/api/overview/","text":"","title":"Overview"}]}