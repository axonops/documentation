{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-axonops","title":"Welcome to AxonOps","text":"<p>AxonOps is the comprehensive operations platform for Apache Cassandra and Apache Kafka. Built by distributed systems experts, AxonOps provides all the capabilities required to effectively monitor, maintain, and manage your Cassandra databases and Kafka streaming infrastructure. Accessed through a single intuitive UI and driven by a highly efficient bi-directional protocol ensuring unprecedented functionality and exceptional performance.</p>"},{"location":"#unified-platform-for-cassandra-kafka","title":"Unified Platform for Cassandra &amp; Kafka","text":"Apache Cassandra <p>Complete lifecycle management for your distributed database</p> <ul> <li>Adaptive repairs &amp; maintenance automation</li> <li>Comprehensive backup &amp; restore</li> <li>Performance monitoring &amp; optimization</li> <li>Configuration management</li> </ul> Apache Kafka <p>Full operational control for your streaming platform</p> <ul> <li>Topic &amp; consumer group management</li> <li>ACL &amp; security administration</li> <li>Real-time performance monitoring</li> <li>KRaft &amp; ZooKeeper support</li> </ul>"},{"location":"#core-capabilities","title":"Core Capabilities","text":""},{"location":"#monitoring","title":"Monitoring","text":"<ul> <li>Unified Dashboards: Visualize metrics &amp; logs for both Cassandra and Kafka clusters</li> <li>Proactive Service Checks: Never miss an issue across your entire data infrastructure</li> <li>Comprehensive Alerting: Enterprise-wide integration for both platforms</li> <li>Real-time Insights: Monitor brokers, topics, consumer groups, nodes, and tables</li> </ul>"},{"location":"#maintenance-operations","title":"Maintenance &amp; Operations","text":"<ul> <li>Cassandra: Adaptive repairs, rolling restarts, and maintenance scheduling</li> <li>Kafka: Topic management, ACL administration, and configuration control</li> <li>Unified Job Scheduler: Automate key tasks across both platforms</li> <li>Configuration Management: Detailed views and controls for both systems</li> </ul>"},{"location":"#data-protection","title":"Data Protection","text":"<ul> <li>Cassandra Backup: Scheduled backups with point-in-time recovery</li> <li>Visual Management: Monitor and manage all backup operations</li> <li>Reliable Restore: Restore data with confidence and minimal downtime</li> <li>Cloud Storage Integration: S3, Azure Blob, and GCS support</li> </ul>"},{"location":"#enterprise-integrations","title":"Enterprise Integrations","text":"<p>AxonOps provides extensive integrations for notifications and operations:</p>       Notifications:             Backups:"},{"location":"#why-choose-axonops","title":"Why Choose AxonOps?","text":"For Your Cassandra Clusters: <ul> <li>Dynamic responsive dashboards curated by Cassandra experts</li> <li>Adaptive Repair process that maintains data integrity</li> <li>Efficient and intuitive backup you can rely on</li> <li>Easy log-file association and interrogation</li> <li>Reliable rolling restart through automation</li> </ul> For Your Kafka Infrastructure: <ul> <li>Comprehensive broker and topic monitoring</li> <li>Advanced ACL and security management</li> <li>Real-time consumer group tracking</li> <li>Support for both KRaft and ZooKeeper modes</li> <li>Multi-version compatibility (Kafka 2.x and 3.x)</li> </ul> Platform Benefits: <ul> <li>Single pane of glass for all your distributed systems</li> <li>Sophisticated alerting integration and routing</li> <li>PDF reporting to deliver insights across teams</li> <li>Highly efficient protocol ensuring exceptional performance at scale</li> <li>Built by experts who understand distributed systems</li> </ul> <p>All of this is underpinned by an efficient bi-directional protocol ensuring exceptional performance and scale across both Cassandra and Kafka deployments.</p>"},{"location":"#axonops-editions","title":"AxonOps Editions","text":"<p>We offer flexible deployment options to match your needs:</p>"},{"location":"#cloud-self-hosted-solutions","title":"Cloud &amp; Self-Hosted Solutions","text":"<ul> <li>Starter Edition - Perfect for smaller deployments</li> <li>Enterprise Edition - Full-featured for production workloads</li> </ul> <p>Both editions support Cassandra and Kafka with the same powerful feature set.</p>"},{"location":"#ready-to-transform-your-operations","title":"Ready to Transform Your Operations?","text":"<p>Whether you're managing Cassandra databases, Kafka streaming platforms, or both, AxonOps provides the tools you need for operational excellence.</p> <p>Dive into the Get Started guide and set up your account to start monitoring, maintaining, and managing your distributed systems in minutes.</p> <p>If you would like to schedule time with our distributed systems experts to walk through the platform and discuss your specific Cassandra or Kafka requirements:</p> <p>Book an Expert</p>"},{"location":"authentication/ldap/","title":"LDAP","text":""},{"location":"authentication/ldap/#ldap-authentication","title":"LDAP Authentication","text":"<p>To setup LDAP (Lightweight Directory Authentication Protocol) in AxonOps (On Premise Only) you will need to update the axon-server.yml configuration at the following location:</p> <p><code>/etc/axonops/axon-server.yml</code></p>"},{"location":"authentication/ldap/#ldap-fields","title":"LDAP Fields","text":"<p>All the configuration for the below fields should be provided by the LDAP Server administrator.</p> <ul> <li>host : IP Address or Hostname of the LDAP server (A domain controller for LDAP).</li> <li> <p>port : The configured LDAP port of the server.</p> <pre><code>  Standard Default ports are either \n  - 389 (Unencrypted) \n  - 636 (Encrypted LDAPS)\n  The ports can be changed by LDAP adminstrators.\n</code></pre> </li> <li> <p>useSSL : true/false - Connects to LDAP using a secure port.</p> </li> <li>startTLS : true/false - Start SSL/TLS encryption before LDAP authentication takes place, set this to true if your LDAP server uses StartTLS.</li> <li>base: A base DN is the point from which AxonOps wil search for users or groups. </li> <li>bindDN : The DN of the user who has access to bind to LDAP.</li> <li>bindPassword : The bindDN user's password.</li> <li> <p>userFilter : This is the LDAP filter that AxonOps will use to locate users.</p> <pre><code>  Some examples could be \n  - (uid=%s) : Search for users by using the LDAP \"uid\" field.\n  - (cn=%s) : Search for users by using the \"cn\" (Common Name) field.\n</code></pre> </li> <li> <p>rolesAttribute : The LDAP attribute that contains the user's list of groups.</p> </li> <li>rolesMapping : Mapping of LDAP user/groups to AxonOps security groups.</li> </ul>"},{"location":"authentication/ldap/#role-mapping","title":"Role Mapping","text":"<p>The rolesMapping has multiple levels based on the configuration of your AxonOps setup : </p> <p>Please Note :</p> <p>Values in UPPERCASE need to be updated with your configuration specific values.</p> <ul> <li>_global_ : Roles assigned to the global scope apply to all clusters connected to AxonOps</li> <li>ORGANISATIONNAME/CLUSTER_TYPE: Roles assigned to this scope apply to all clusters of the specified type, </li> <li>ORGANISATIONNAME/CLUSTER_TYPE/CLUSTER_NAME : Roles assigned to this scope apply to a single cluster.</li> </ul> <p>ORGANISATIONNAME :  The name of your organisation as shown in the AxonOps frontend, should be equal to the org_name option in axon-server.yml</p> <p>CLUSTER_TYPE : <code>cassandra</code> or <code>kafka</code></p> <p>CLUSTER_NAME : The name of the cluster as shown in the AxonOps frontend.</p> <p>For the above levels there are 4 role mappings which are required fields :</p> <ul> <li>superUserRole : The Super user which has permission to do everything on AxonOps setup.</li> <li>adminRole : Similar to superUserRole but cannot configure AxonOps settings or log collectors.</li> <li>backupAdminRole : The user that has adminstration priviledges to create and manage backups. Has read only access to the rest of the AxonOps server pages and components.</li> <li>readOnlyRole : A basic read-only role that cannot modify any configuration in AxonOps.</li> </ul> <p>Distinguished Names that are used in the role mappings can comprise of the following parts which define hierarchical structure in a LDAP directory.</p> <ul> <li>CN = Common Name</li> <li>OU = Organisational Unit</li> <li>O = Organisation Name</li> <li>DC = Domain Component</li> </ul>"},{"location":"authentication/ldap/#example-ldap-role-mappings","title":"Example LDAP Role Mappings","text":"<p>Take Note</p> <p>The default built-in LDAP OU names are case-sensitive.</p> <p>The following examples can be configured differently based on your LDAP setup.</p> <ul> <li> <p>LDAP Groups or Distribution Groups :</p> <p><code>cn=cassandra_superusers,ou=Groups,dc=example,dc=com</code></p> <ul> <li>cn = cassandra_superusers or cassandra__superusers group</li> <li>ou = Groups or Distribution Groups</li> <li>dc = example.com</li> </ul> </li> <li> <p>LDAP Users : </p> <p><code>cn=superuser,ou=Users,dc=example,dc=com</code></p> <ul> <li>cn = The name of the user e.g. superuser</li> <li>ou = Users</li> <li>dc = example.com</li> </ul> </li> </ul>"},{"location":"authentication/ldap/#axon-serveryml-configuration-example","title":"axon-server.yml configuration example","text":"<pre><code>auth:\n  enabled: true\n  type: \"LDAP\" # only LDAP is supported for now\n  settings:\n    host: \"myldapserver.example.com\"\n    port: 636\n    useSSL: true\n    startTLS: false\n    insecureSkipVerify: false # If true then skip SSL/TLS certificate verification\n\n    base: \"ou=Users,dc=example,dc=com\"   \n    bindDN: \"cn=administrator,ou=Users,dc=example,dc=com\"\n    bindPassword: \"##############\"\n    userFilter: \"(cn=%s)\"\n    rolesAttribute: \"memberOf\"\n    callAttempts: 3 # how many times to retry a connection to LDAP, in case of network issues.\n    rolesMapping:\n      _global_:\n        superUserRole: \"cn=superuser,ou=Groups,dc=example,dc=com\"\n        readOnlyRole: \"cn=readonly,ou=Groups,dc=example,dc=com\"\n        adminRole: \"cn=admin,ou=Groups,dc=example,dc=com\"\n        backupAdminRole: \"cn=backupadmin,ou=Groups,dc=example,dc=com\"\n      organisationName/cassandra:\n        superUserRole: \"cn=cassandra_superusers,ou=Groups,dc=example,dc=com\"\n        readOnlyRole: \"cn=cassandra_readonly,ou=Groups,dc=example,dc=com\"\n        adminRole: \"cn=cassandra_admins,ou=Groups,dc=example,dc=com\"\n        backupAdminRole: \"cn=cassandra_backupadmins,ou=Groups,dc=example,dc=com\"\n      organisationName/cassandra/prod:\n        superUserRole: \"cn=cassandra_prod_superusers,ou=Groups,dc=example,dc=com\"\n        readOnlyRole: \"cn=cassandra_prod_readonly,ou=Groups,dc=example,dc=com\"\n        adminRole: \"cn=cassandra_prod_admins,ou=Groups,dc=example,dc=com\"\n        backupAdminRole: \"cn=cassandra_prod_backupadmins,ou=Groups,dc=example,dc=com\"\n</code></pre>"},{"location":"authentication/jumpcloud-axonops-cloud/","title":"Configuring SAML authentication with JumpCloud for AxonOps Cloud","text":""},{"location":"authentication/jumpcloud-axonops-cloud/#configuring-saml-authentication-with-jumpcloud-for-axonops-cloud","title":"Configuring SAML authentication with JumpCloud for AxonOps Cloud","text":"<p>This guide will walk you through configuring JumpCloud for AxonOps, focusing on setting up Single Sign-On (SSO) and customizing user attributes</p>"},{"location":"authentication/jumpcloud-axonops-cloud/#prerequisites-and-notes","title":"Prerequisites and notes","text":""},{"location":"authentication/jumpcloud-axonops-cloud/#prerequisites","title":"Prerequisites","text":"<ol> <li>SAML support must be enabled for your account by AxonOps</li> <li>You will need an RSA certificate and key in PEM format. You can generate a self-signed certificate and key with this command: <pre><code>openssl req -new -newkey rsa:2048 -sha256 -days 3650 -nodes -x509 -keyout saml.key -out saml.crt\n</code></pre></li> </ol>"},{"location":"authentication/jumpcloud-axonops-cloud/#notes","title":"Notes","text":"<p>After SAML support is enabled on your AxonOps account the URLs used to access the dashboard will change from <code>dash.axonops.cloud</code> to <code>orgname.axonops.cloud</code> (where <code>orgname</code> is your AxonOps organisation). This does not affect normal operation but any bookmarks you have to dashboard pages will no longer work.</p> <p>Logging in after enabling SAML</p> <p>After SAML has been configured you will have 2 ways to login to the AxonOps console:</p> <ol> <li>https://console.axonops.cloud - Login with username+password or Google login</li> <li>https://orgname.axonops.cloud - Login with SAML via JumpCloud</li> </ol>"},{"location":"authentication/jumpcloud-axonops-cloud/#next-steps","title":"Next Steps","text":"<p>Configure JumpCloud</p> <p>Configure roles in JumpCloud</p> <p>Configure SAML in AxonOps Cloud</p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/","title":"JumpCloud SAML Configuration","text":""},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#jumpcloud-saml-configuration","title":"JumpCloud SAML Configuration","text":""},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#1-login-to-jumpcloud-as-an-administrator","title":"1. Login to JumpCloud as an administrator","text":"<p>Login as an administrator then go to the SSO Applications page</p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#2-click-add-new-application","title":"2. Click \"Add New Application\"","text":"<p>Add a new application.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#3-select-custom-application","title":"3. Select Custom Application","text":""},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#4-click-next","title":"4. Click \"Next\"","text":"<p>Proceed to the next step.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#5-click-manage-single-sign-on-sso","title":"5. Click \"Manage Single Sign-On (SSO)\"","text":"<p>Access Single Sign-On settings.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#6-click-next","title":"6. Click \"Next\"","text":"<p>Move on to the next section.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#7-enter-application-name","title":"7. Enter Application Name","text":"<p>Enter a friendly name for the application in the Display Label field</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#8-click-save-application","title":"8. Click \"Save Application\"","text":"<p>Save the application settings.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#9-click-configure-application","title":"9. Click \"Configure Application\"","text":"<p>Configure the application settings.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#12-click-idp-entity-id","title":"12. Click \"IdP Entity ID\"","text":"<p>Enter the IdP Entity ID.</p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#10-enter-the-idp-entity-id","title":"10. Enter the IdP Entity ID","text":"<p>This can be any string as long as the same is used in AxonOps. We recommend setting this to <code>jumpcloud-axonops</code>.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#11-enter-the-sp-entity-id","title":"11. Enter the SP Entity ID","text":"<p>Enter <code>https://axonops.com/saml/metadata</code> in the SP Entity ID field</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#12-set-the-acs-url","title":"12. Set the ACS URL","text":"<p>Enter <code>https://orgname.axonops.cloud/login-idp/callback</code> in the ACS URL field (replace <code>orgname</code> with your AxonOps organisation name)</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#13-click-replace-sp-certificate","title":"13. Click \"Replace SP Certificate\"","text":"<p>Upload the certificate you generated in the prerequisites</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#14-configure-assertion-signing","title":"14. Configure Assertion signing","text":"<p>Under the Sign option, select <code>Assertion</code></p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#15-configure-user-attributes","title":"15. Configure user attributes","text":"<p>Under User Attributes, click \"add attribute\"</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#16-configure-attribute-mapping","title":"16. Configure attribute mapping","text":"<p>Enter <code>axonopsroles</code> in the \"Service Provider Attribute\" field</p> <p></p> <p>Now select <code>Custom User or Group Attribute</code> and enter a custom value of <code>axonopsroles</code></p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#17-allow-groups-access-to-axonops","title":"17. Allow groups access to AxonOps","text":"<p>Access the User Groups section.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#18-select-groups-that-can-access-axonops","title":"18. Select groups that can access AxonOps","text":"<p>Tick all groups that you wish to provide access to AxonOps</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#19-return-to-the-sso-tab","title":"19. Return to the \"SSO\" tab","text":""},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#20-click-export-metadata","title":"20. Click \"Export Metadata\"","text":"<p>Export XML metadata from JumpCloud. You will need this to configure AxonOps.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#21-click-save","title":"21. Click \"save\"","text":"<p>Save the changes.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/01-jumpcloud-app/#next-steps","title":"Next Steps","text":"<p>Configure roles in JumpCloud</p> <p>Configure SAML in AxonOps Cloud</p>"},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/","title":"Configuring AxonOps Roles in JumpCloud","text":""},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#configuring-axonops-roles-in-jumpcloud","title":"Configuring AxonOps Roles in JumpCloud","text":"<p>The permissions granted to each user are controlled by a custom group attribute named <code>axonopsroles</code>. The <code>axonopsroles</code> attribute can contain a single role or a comma-separated list of roles which will be assigned to all members of the group.</p> <p>Global roles that can be assigned to AxonOps users: - <code>superAdmin</code> - <code>dba</code> - <code>readonly</code></p> <p>Finer-grained access can be controlled by cluster type or individual cluster, for example: - <code>orgname/cassandra/dba</code> This would give DBA-level access to all Cassandra clusters - <code>orgname/kafka/readonly</code> This would give read-only access to all Kafka clusters - <code>orgname/cassandra/cluster1/readonly</code> This would allow read-only access to Cassandra cluster <code>cluster1</code> only.</p> <p>replace <code>orgname</code> in these examples with your AxonOps organisation.</p>"},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#1-click-user-groups","title":"1. Click \"User Groups\"","text":"<p>Access the User Groups section.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#2-open-a-group","title":"2. Open a group","text":"<p>The group name could be anything, \"AxonOps Admins\" is only an example here</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#3-click-add-custom-attribute","title":"3. Click \"+ Add Custom Attribute\"","text":"<p>Add a custom attribute.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#4-select-string","title":"4. Select \"String\"","text":"<p>Select the data type.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#5-click-attribute-name","title":"5. Click \"Attribute Name\"","text":"<p>Enter the attribute name.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#6-enter-axonopsroles","title":"6. Enter \"axonopsroles\"","text":""},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#7-enter-axonops-roles-for-the-group","title":"7. Enter AxonOps roles for the group","text":"<p>Enter the AxonOps role(s) to assign to the members of this group. This could be a single role or a comma-separated list. See above for allowed values.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#8-click-save-group","title":"8. Click \"Save Group\"","text":"<p>Save the group settings.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#9-repeat-the-above-steps-to-configure-the-roles-for-other-groups","title":"9. Repeat the above steps to configure the roles for other groups","text":""},{"location":"authentication/jumpcloud-axonops-cloud/02-jumpcloud-roles/#next-steps","title":"Next Steps","text":"<p>Configure SAML in AxonOps Cloud</p>"},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/","title":"Configuring SAML authentication in AxonOps Cloud","text":""},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/#configuring-saml-authentication-in-axonops-cloud","title":"Configuring SAML authentication in AxonOps Cloud","text":""},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/#1-go-to-consoleaxonopscloud","title":"1. Go to \"console.axonops.cloud\"","text":"<p>Go to the AxonOps console and login as a user with superadmin rights. Open the SAML page by clicking the SAML link in the sidebar.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/#3-click-upload-idp-metadata-xml","title":"3. Click \"Upload IdP Metadata XML\"","text":"<p>Upload the IdP Metadata XML file that you downloaded from JumpCloud</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/#4-enter-the-idp-entity-id","title":"4. Enter the IdP Entity ID","text":"<p>Fill in the text box with <code>jumpcloud-axonops</code>, this must match the IdP Entity ID entered in JumpCloud.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/#5-enter-the-sp-entity-id","title":"5. Enter the SP Entity ID","text":"<p>Enter <code>https://axonops.com/saml/metadata</code> in the SP Entity ID field</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/#6-click-sp-certificate","title":"6. Click \"SP Certificate\"","text":"<p>Access the SP Certificate section.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/#7-paste-in-your-certificate","title":"7. Paste in your certificate","text":"<p>Paste the PEM-format certificate you generated in the prerequisites into the <code>SP Certificate</code> field</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/#8-click-sp-private-key","title":"8. Click \"SP Private Key\"","text":"<p>Access the SP Private Key section.</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/#9-paste-your-private-key","title":"9. Paste your private key","text":"<p>Paste the PEM-format private key you generated in the prerequisites into the <code>SP Private Key</code> field</p> <p></p>"},{"location":"authentication/jumpcloud-axonops-cloud/03-axonops-saml-jumpcloud/#10-click-save","title":"10. Click \"Save\"","text":"<p>Save the settings.</p> <p></p>"},{"location":"cluster/cluster-overview/","title":"Overview","text":""},{"location":"cluster/cluster-overview/#cluster-overview","title":"Cluster Overview","text":"<p>Cluster Overview is the home page and provides a visual overview of your clusters health.</p> <p>The information is automatically extracted by the AxonOps agent and pushed to AxonOps server. There is no need to configure anything on the agent or the server side for this information to be populated in the Cluster Overview dashboard.</p> <p></p> <p></p> <p></p>"},{"location":"cluster/cluster-overview/#supported-clusters","title":"Supported Clusters","text":"<ul> <li> <p>Apache Cassandra</p> </li> <li> <p>Apache Kafka</p> </li> </ul>"},{"location":"cluster/cluster-overview/#switching-between-clusters","title":"Switching between Clusters","text":"<ul> <li>On the page breadcrumb click on Show List of Clusters</li> </ul> <ul> <li>Select the Apache Cassandra or Apache Kafka Cluster</li> </ul>"},{"location":"cluster/cluster-overview/#overview-graph-and-list-views","title":"Overview - Graph and List Views","text":"<p>On the Axonops application menu, select <code>Cluster Overview</code>.</p> <p>Select a node to view configuration details.</p>"},{"location":"cluster/cluster-overview/#graph-view","title":"Graph View","text":""},{"location":"cluster/cluster-overview/#list-view","title":"List View","text":""},{"location":"cluster/cluster-overview/#configuration-detail-sections","title":"Configuration detail sections:","text":"<p>Configuration detail sections show service specific information and differ based on cluster and node type.</p> <ul> <li>Operating System (OS) Configuration</li> <li>Cassandra Configuration</li> <li>Kafka Configuration</li> <li>Zookeeper Configuration</li> <li>KRaft Broker Configuration</li> <li>KRaft Controller Configuration</li> <li>Kafka Connect Configuration</li> <li>Java (JVM) Configuration</li> </ul>"},{"location":"cluster/cluster-overview/#os-details","title":"OS Details","text":"<p>Operating System Details section shows general information including:</p> <ul> <li>General Information</li> <li>CPU</li> <li>Memory</li> <li>Swap</li> <li>Disk volumes</li> </ul> <p>Infomy</p> <p></p>"},{"location":"cluster/cluster-overview/#node-details","title":"Node Details","text":"<p>Node Details view shows the details from the specific node configuration files and differ based on cluster and node type. </p> <p>There is a search field available near the top to filter the configuration parameters.</p> <p>Node configuration files:</p> <ul> <li>Casssandra<ul> <li>cassandra.yml</li> </ul> </li> <li>Kafka <ul> <li>server.properties</li> <li>zookeeper.properties</li> </ul> </li> <li>KRaft<ul> <li>broker.properties</li> <li>controller.properties</li> <li>server.properties</li> </ul> </li> <li>Kafka Connect<ul> <li>connect-standalone.properties</li> <li>connect-distributed.properties</li> </ul> </li> </ul> <p>Infomy</p> <p></p>"},{"location":"cluster/cluster-overview/#jvm-details","title":"JVM Details","text":"<p>JVM Details section shows the general information about the Java Virtual Machine (JVM), including the version and some configuration options such as the heap and Garbage Collection settings.</p> <p>Infomy</p> <p></p>"},{"location":"configuration/agent-configuration/","title":"Configuring AxonOps Agent","text":""},{"location":"configuration/agent-configuration/#configuring-axonops-agent","title":"Configuring AxonOps Agent","text":"<p>Work in progress</p>"},{"location":"configuration/axondash/","title":"Configuring AxonOps Agent","text":""},{"location":"configuration/axondash/#configuring-axonops-agent","title":"Configuring AxonOps Agent","text":"<p>Work in progress</p>"},{"location":"configuration/server-configuration/","title":"Configuring AxonOps Server","text":""},{"location":"configuration/server-configuration/#configuring-axonops-server","title":"Configuring AxonOps Server","text":"<p>Work in progress</p>"},{"location":"dynamic_pages/axon_agent/cassandra/","title":"Cassandra","text":"Select the Cassandra Version Select the Java Version. <pre><code>sudo apt-get install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk17\n</code></pre> <pre><code>sudo yum install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk17\n</code></pre>"},{"location":"dynamic_pages/axon_agent/cassandra_agent/","title":"Cassandra agent","text":""},{"location":"dynamic_pages/axon_agent/cassandra_agent/#select-the-cassandra-version","title":"Select the Cassandra Version","text":""},{"location":"dynamic_pages/axon_agent/cassandra_agent/#select-the-java-version","title":"Select the Java Version","text":"<p>Install the AxonOps Cassandra Agent and its dependency <code>axon-agent</code>:</p> <pre><code>sudo apt-get install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk17\n</code></pre> <pre><code>sudo yum install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk17\n</code></pre>"},{"location":"dynamic_pages/axon_agent/cassandra_agent/#configuration-file-locations","title":"Configuration File Locations","text":""},{"location":"dynamic_pages/axon_agent/cassandra_agent/#axonops-cassandra-agent","title":"AxonOps Cassandra Agent","text":"<p>The AxonOps Cassandra Agent is the jar that is directly loaded by Cassandra. The AxonOps Cassandra Agent then reaches out directly to the AxonOps Agent binary which contacts the AxonOps Server directly.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-cassandra{version}-agent.jar</code></li> <li>Version number: <code>/usr/share/axonops/axon-cassandra{version}-agent.version</code></li> <li>Copyright: <code>/usr/share/doc/axonops/axon-cassandra{version}-agent/copyright</code></li> <li>Licenses: <code>/usr/share/axonops/licenses/axon-cassandra{version}-agent/</code></li> </ul>"},{"location":"dynamic_pages/axon_agent/cassandra_agent/#axonops-agent","title":"AxonOps Agent","text":"<p>The AxonOps Agent is a dependency of the AxonOps Cassandra Agent. This binary contacts the AxonOps Server directly while minimizing the memory footprint and CPU utilization of the Cassandra process.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-agent</code></li> <li>Logs: <code>/var/log/axonops/axon-agent.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-agent.service</code></li> </ul>"},{"location":"dynamic_pages/axon_agent/java/","title":"Java","text":"<p>Add the following line at the end of <code>/etc/cassandra/cassandra-env.sh</code>:</p> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.0-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.11-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra4.0-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra4.1-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\n</code></pre> <p>If Cassandra was installed using a tarball, the correct path for the <code>cassandra-env.sh</code> will be <code>&lt;Cassandra Installation Directory&gt;/conf/cassandra-env.sh</code>.</p> <p>NB. Make sure this configuration is not overridden by automation tools.</p>"},{"location":"dynamic_pages/axon_agent/java/#configure-cassandra-user-group","title":"Configure Cassandra user group","text":"<p>Configure the Linux user groups by:</p> <ul> <li>Adding the <code>axonops</code> user to the <code>cassandra</code> user group.</li> <li>Adding the <code>cassandra</code> user to the <code>axonops</code> user group.</li> </ul> <pre><code>CASSANDRA_GROUP=cassandra\nCASSANDRA_USER=cassandra\n\nsudo usermod -aG \"$CASSANDRA_GROUP\" axonops\nsudo usermod -aG axonops \"$CASSANDRA_USER\"\n</code></pre> <p>If Cassandra was setup to use a non-default user or group, <code>CASSANDRA_GROUP</code> and/or <code>CASSANDRA_USER</code> will need be updated accordingly for the above commands to work properly.</p>"},{"location":"dynamic_pages/axon_agent/java/#uninstall-needrestart-package","title":"Uninstall <code>needrestart</code> Package","text":"<p>Due to recent change with <code>needrestart</code>, as seen in Ubuntu 24.04, uninstalling the <code>needrestart</code> package is currently recommended.</p> <p>Failure to uninstall the <code>needrestart</code> package may cause the Cassandra service to be restarted when updating the <code>axon-agent</code> package.</p>"},{"location":"dynamic_pages/axon_agent/kafka_agent/","title":"Kafka agent","text":"Select the Kafka Version Select the Java Version. <p>Install the AxonOps Kafka Agent and its dependency <code>axon-agent</code>:</p> <pre><code>sudo apt-get install axon-kafka2-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka3-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka2-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka3-agent\n</code></pre> <pre><code>sudo yum install axon-kafka2-agent\n</code></pre> <pre><code>sudo yum install axon-kafka3-agent\n</code></pre> <pre><code>sudo yum install axon-kafka2-agent\n</code></pre> <pre><code>sudo yum install axon-kafka3-agent\n</code></pre>"},{"location":"dynamic_pages/axon_agent/kafka_agent/#configuration-file-locations","title":"Configuration File Locations","text":""},{"location":"dynamic_pages/axon_agent/kafka_agent/#axonops-kafka-agent","title":"AxonOps Kafka Agent","text":"<p>The AxonOps Kafka Agent is the jar that is directly loaded by Kafka. The AxonOps Kafka Agent then reaches out directly to the AxonOps Agent binary which contacts the AxonOps Server directly.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-kafka{version}-agent.jar</code></li> <li>Version number: <code>/usr/share/axonops/axon-kafka{version}-agent.version</code></li> <li>Copyright: <code>/usr/share/doc/axonops/axon-kafka{version}-agent/copyright</code></li> <li>Licenses: <code>/usr/share/axonops/licenses/axon-kafka{version}-agent/</code></li> </ul>"},{"location":"dynamic_pages/axon_agent/kafka_agent/#axonops-agent","title":"AxonOps Agent","text":"<p>The AxonOps Agent is a dependency of the AxonOps Kafka Agent. This binary contacts the AxonOps Server directly while minimizing the memory footprint and CPU utilization of the Kafka process.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-agent</code></li> <li>Logs: <code>/var/log/axonops/axon-agent.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-agent.service</code></li> </ul>"},{"location":"dynamic_pages/axon_agent/kafka_agent_config/","title":"Kafka agent config","text":"Kafka Broker Zookeeper KRaft Broker KRaft Controller Kafka Connect <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"broker\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"zookeeper\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Optionally specify a rack to group nodes in AxonOps\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"kraft-broker\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"kraft-controller\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"connect\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Optionally specify a rack to group nodes in AxonOps\n</code></pre> <p>Set file permissions on /etc/axonops/axon-agent.yml file by executing the following command</p> <pre><code>sudo chmod 0640 /etc/axonops/axon-agent.yml\n</code></pre> Configure Kafka  Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p> Configure Zookeeper  Edit zookeeper-server-start.sh, usually located in your Zookeeper install path such as:   <p><code>/&lt;Zookeeper_Home&gt;/bin/zookeeper-server-start.sh</code></p> Configure KRaft Broker  Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p> Configure KRaft Controller  Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p> Configure Connect  Edit connect-distributed.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/connect-distributed.sh </code></p> <p>Insert the line <code>. /usr/share/axonops/axonops-jvm.options</code> right before the final line in your config file. Look for the last line that starts with <code>exec</code>, as demonstrated in the example below.</p> <p>NB. Please note the period(.) at the beginning of the config line.</p> <p>Example:</p> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <p>NB. Make sure that this configuration will not get overridden by an automation tool.</p> Add axonops user to Kafka user group and Kafka user to axonops group <pre><code>sudo usermod -aG &lt;your_kafka_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kafka_user&gt;\n</code></pre> Start/Restart Kafka  To load the AxonOps Java Agent and Kafka config changes please either start the Kafka service if stopped restart the Kafka service if already running.  Add axonops user to Zookeeper user group and Zookeeper user to axonops group <pre><code>sudo usermod -aG &lt;your_zookeeper_group&gt; axonops\nsudo usermod -aG axonops &lt;your_zookeeper_user&gt;\n</code></pre> Start/Restart Zookeeper  To load the AxonOps Java Agent and Zookeeper config changes please either start the Zookeeper service if stopped or restart the Zookeeper service if already running.  Add axonops user to KRaft Broker user group and KRaft Broker user to axonops group <pre><code>sudo usermod -aG &lt;your_kraft_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kraft_user&gt;\n</code></pre> Start/Restart KRaft Broker  To load the AxonOps Java Agent and Kafka KRaft config changes please either start the Kafka KRaft service if stopped or restart the Kafka KRaft service if already running.  Add axonops user to KRaft Controller user group and KRaft Controller user to axonops group <pre><code>sudo usermod -aG &lt;your_kraft_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kraft_user&gt;\n</code></pre> Start/Restart KRaft Controller  To load the AxonOps Java Agent and Kafka KRaft config changes please either start the Kafka KRaft service if stopped or restart the Kafka KRaft service if already running.  Add axonops user to Kafka Connect user group and Kafka Connect user to axonops group <pre><code>sudo usermod -aG &lt;your_connect_group&gt; axonops\nsudo usermod -aG axonops &lt;your_connect_user&gt;\n</code></pre> Start/Restart Kafka Connect  To load the AxonOps Java Agent and Kafka Connect config changes please either:  * Start the Kafka Connect service if stopped. * Restart the Kafka Connect service if already running."},{"location":"dynamic_pages/axon_agent/kafka_java/","title":"Kafka java","text":"<p>Insert the line <code>. /usr/share/axonops/axonops-jvm.options</code> right before the final line in your config file. Look for the last line that starts with <code>exec</code>, as demonstrated in the example below.</p> <p>NB. Please note the period(.) at the beginning of the config line.</p> <p>Example:</p> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre>"},{"location":"dynamic_pages/axon_agent/os/","title":"Os","text":"<p>Select the OS Family</p> <p> </p> <p>Execute the following commands to setup the AxonOps repository:</p> <pre><code>sudo apt-get update\nsudo apt-get install -y curl gnupg ca-certificates\n\ncurl -L https://packages.axonops.com/apt/repo-signing-key.gpg \\\n  | sudo gpg --dearmor -o /usr/share/keyrings/axonops.gpg\n\necho \"deb [arch=arm64,amd64 signed-by=/usr/share/keyrings/axonops.gpg]\\\n  https://packages.axonops.com/apt axonops-apt main\" \\\n  | sudo tee /etc/apt/sources.list.d/axonops-apt.list\nsudo apt-get update\n</code></pre> <pre><code>sudo tee /etc/yum.repos.d/axonops-yum.repo &lt;&lt; EOL\n[axonops-yum]\nname=axonops-yum\nbaseurl=https://packages.axonops.com/yum/\nenabled=1\nrepo_gpgcheck=0\ngpgcheck=0\nEOL\n</code></pre>"},{"location":"dynamic_pages/axon_dash/os/","title":"Os","text":"<p>Select the OS Family</p> <p> </p> <p>Execute the following commands to setup the AxonOps GUI for your OS:</p> <pre><code>sudo apt-get update\nsudo apt-get install -y curl gnupg ca-certificates\n\ncurl -L https://packages.axonops.com/apt/repo-signing-key.gpg \\\n  | sudo gpg --dearmor -o /usr/share/keyrings/axonops.gpg\n\necho \"deb [arch=arm64,amd64 signed-by=/usr/share/keyrings/axonops.gpg]\\\n  https://packages.axonops.com/apt axonops-apt main\" \\\n  | sudo tee /etc/apt/sources.list.d/axonops-apt.list\nsudo apt-get update\n\nsudo apt-get install -y axon-dash\n</code></pre> <pre><code>sudo tee /etc/yum.repos.d/axonops-yum.repo &lt;&lt; EOL\n[axonops-yum]\nname=axonops-yum\nbaseurl=https://packages.axonops.com/yum/\nenabled=1\nrepo_gpgcheck=0\ngpgcheck=0\nEOL\n\nsudo yum install axon-dash\n</code></pre>"},{"location":"dynamic_pages/axon_server/elastic/","title":"Elastic","text":""},{"location":"dynamic_pages/axon_server/elastic/#installation","title":"Installation","text":"<p>Select the OS Family</p> <p> </p> <p>Execute the following commands to setup Elasticsearch for your OS:</p> <pre><code>sudo apt-get update\nsudo apt-get install -y gpg wget\nwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch \\\n  | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg\n\nsudo apt-get install apt-transport-https\necho \"deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg]\\\n https://artifacts.elastic.co/packages/7.x/apt stable main\" | \\\n  sudo tee /etc/apt/sources.list.d/elastic-7.x.list\n\nsudo apt-get update\nsudo apt-get install elasticsearch\n</code></pre> <pre><code>rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch\n\necho '[elasticsearch]\nname=Elasticsearch repository for 7.x packages\nbaseurl=https://artifacts.elastic.co/packages/7.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=0\nautorefresh=1\ntype=rpm-md' | sudo tee /etc/yum.repos.d/elasticsearch.repo\n\nsudo yum install --enablerepo=elasticsearch elasticsearch\n</code></pre>"},{"location":"dynamic_pages/axon_server/os/","title":"Os","text":"<p>Select the OS Family</p> <p> </p> <p>Execute the following commands to setup the AxonOps repository and install AxonOps Server:</p> <pre><code>sudo apt-get update\nsudo apt-get install -y curl gnupg ca-certificates\n\ncurl -L https://packages.axonops.com/apt/repo-signing-key.gpg \\\n  | sudo gpg --dearmor -o /usr/share/keyrings/axonops.gpg\n\necho \"deb [arch=arm64,amd64 signed-by=/usr/share/keyrings/axonops.gpg]\\\n  https://packages.axonops.com/apt axonops-apt main\" \\\n  | sudo tee /etc/apt/sources.list.d/axonops-apt.list\nsudo apt-get update\n\nsudo apt-get install axon-server\n</code></pre> <pre><code>sudo tee /etc/yum.repos.d/axonops-yum.repo &lt;&lt; EOL\n[axonops-yum]\nname=axonops-yum\nbaseurl=https://packages.axonops.com/yum/\nenabled=1\nrepo_gpgcheck=0\ngpgcheck=0\nEOL\nsudo yum install axon-server\n</code></pre>"},{"location":"editions/developer_edition/","title":"Developer Edition","text":""},{"location":"editions/developer_edition/#developer-edition","title":"Developer Edition","text":"<p>The free plan is avaialble for AxonOps Cloud. Developer which has a limited set of features</p> <p>Free Sign Up</p>"},{"location":"editions/developer_edition/#developer-edition-features","title":"Developer edition features","text":"<p>Develop software with ease with a desktop docker-compose install of a 3-node Cassandra cluster and AxonOps.</p> <ul> <li>Installed on developer desktop</li> <li>One command deployment</li> <li>A 3-node Cassandra cluster</li> <li>Only 1.5GB memory required</li> <li>Visualize your application queries</li> <li>Check your query consistency level</li> <li>Measure data model effectiveness</li> <li>Troubleshoot and optimize</li> <li>Accelerate production readiness</li> <li>No servers required</li> </ul>"},{"location":"editions/enterprise_edition/","title":"Enterprise Edition","text":""},{"location":"editions/enterprise_edition/#enterprise-edition","title":"Enterprise Edition","text":"<p>Scale-out Cassandra with Confidence!</p> <p>Scale-out with one-stop operations, full data retention, extended functionality and optional fully managed Cassandra.</p> <p>Book a consultation with a Cassandra Expert.</p> <p>Book an Expert</p>"},{"location":"editions/enterprise_edition/#enterprise-edition-features","title":"Enterprise edition features","text":"<ul> <li>Unlimited Cassandra nodes</li> <li>Unlimited Cloud User Accounts</li> <li>Maximum metrics &amp; logs retention</li> <li>Pre-configured Dashboards</li> <li>All metrics at 5 sec resolutions</li> <li>Hands-free Adaptive Repair</li> <li>Integrated Log &amp; Event Search</li> <li>Cluster Health Service Checks</li> <li>Automate Rolling Restarts</li> <li>Backups &amp; Restore for all storage needs</li> <li>Extensive Alerting Integrations</li> <li>Optional Cassandra Support</li> <li>Optional Consulting Services</li> <li>Optional Fully Managed Cassandra</li> </ul>"},{"location":"editions/intro/","title":"Get ready for enjoying one-stop Cassandra operations from AxonOps.","text":""},{"location":"editions/intro/#get-ready-for-enjoying-one-stop-cassandra-operations-from-axonops","title":"Get ready for enjoying one-stop Cassandra operations from AxonOps.","text":"<p>Soon you\u2019ll be enjoying the only Cassandra management tool that combines:</p> <ul> <li>Dynamic responsive dashboards curated by experts</li> <li>Adaptive Repair process that will never let you down</li> <li>Efficient and intuitive backup you can rely on</li> <li>Easy log-file association and interrogation</li> <li>Reliable rolling restart through automation</li> <li>Sophisticated alerting integration and routing</li> <li>PDF reporting to quickly deliver insights across the team</li> <li>Highly efficient protocol ensuring exceptional performance</li> </ul> <p>All of this is underpinned by an efficient bi-directional protocol ensuring exceptional performance and scale. If you would like to schedule some time with an AxonOps Cassandra expert to walk you through the install and the AxonOps platform please follow the link below.</p> <p>If you would like to schedule some time with an AxonOps Cassandra expert to walk you through the install and the AxonOps platform please follow the link below.</p> <p>Book an Expert</p>"},{"location":"editions/starter_edition/","title":"Starter Edition","text":""},{"location":"editions/starter_edition/#starter-edition","title":"Starter Edition","text":"<p>The free plan is avaialble for AxonOps Cloud. Starter version is free up to 6 nodes.</p> <p>Free Sign Up</p>"},{"location":"editions/starter_edition/#starter-edition-features","title":"Starter edition features","text":"<p>One-stop operations for your production cluster with everything you need to monitor, maintain and backup Cassandra.</p> <ul> <li>Cloud or Self-Hosted, you choose.</li> <li>Up to 6 Cassandra nodes</li> <li>2 Cloud User Accounts</li> <li>14 day metrics &amp; logs retention</li> <li>Pre-configured Dashboards</li> <li>All metrics at 5 sec resolutions</li> <li>Hands-free Adaptive Repair</li> <li>Integrated Log &amp; Event Search</li> <li>Alerting Integration</li> <li>Cluster Health Service Checks</li> <li>Automate Rolling Restarts</li> <li>Backups &amp; Restore for all storage needs</li> <li>Optional Cassandra Support</li> <li>Optional Consulting Services</li> </ul>"},{"location":"firewall/overview/","title":"Firewall Rules","text":""},{"location":"firewall/overview/#firewall-rules","title":"Firewall Rules","text":"<p>For axon-server, axon-dash, Elasticsearch, and Cassandra Metrics Node to connect together securely, a list of ports need to be included in a rule that will allow traffic through a firewall.</p>"},{"location":"firewall/overview/#firewall-ports-and-definitions","title":"Firewall Ports and Definitions","text":"Destination Port Origin Typical Use axon-server 1888 axon-agent from Cassandra or Kafka nodes Inbound agent connections. Server (axon-server) needs to be accessible from the agents (axon-agents) either directly or via an HTTP(s) proxy. axon-server 8080 axon-dash Server's (axon-server) internal port for Web UI (axon-dash) to connect to. axon-dash 3000 axon-server and HTTP/S proxy or browser Web UI (axon-dash) serves HTTP requests on this port. Recomendation is to run a HTTP proxy to secure traffic. Multi-Server setup: Cassandra Metrics Node 9042 axon-server Cassandra's default native client protocol port for CQL (Cassandra Query Language) connections. This is the default port for the server (axon-server) to connect to Cassandra. Multi-Server setup: Elasticsearch Node 9200 axon-server Elasticsearch's default port used for HTTP communication, including client requests, REST API calls, and search queries."},{"location":"firewall/overview/#configuration-options-for-on-premises-installations","title":"Configuration Options for On-Premises Installations","text":""},{"location":"firewall/overview/#single-server","title":"Single-Server","text":"<p>A single-server AxonOps setup would have the following services installed:</p> <ul> <li>axon-server</li> <li>axon-dash</li> <li>Elasticsearch (mandatory)</li> <li>Cassandra Metrics Node (optional)</li> </ul>"},{"location":"firewall/overview/#multi-server","title":"Multi-Server","text":"<p>A multi-server AxonOps setup with split roles and responsibilities would look like this:</p> <p>AxonOps frontend server:</p> <ul> <li>axon-server</li> <li>axon-dash</li> </ul> <p>AxonOps metrics backend server:</p> <ul> <li>Elasticsearch (mandatory)</li> <li>Cassandra Metrics Node (optional)</li> </ul>"},{"location":"get_started/agent_setup/","title":"Agent Setup","text":""},{"location":"get_started/agent_setup/#axon-agent-setup","title":"Axon Agent Setup","text":""},{"location":"get_started/agent_setup/#axonops-cloud-agent-network-requirements","title":"AxonOps Cloud Agent Network Requirements","text":"<p>AxonOps agent connects securely to the following AxonOps Cloud service endpoint;</p> <pre><code>https://agents.axonops.cloud\n</code></pre> <p>The TLS HTTPS connection initiated by the agent is upgraded to a WebSocket connection and thus requires WebSocket support in your corporate infrastructure, such as a secure web proxy service.</p> <p>If you have a DNS based security policy then you will be required to allow outbound access to the following domain.</p> <pre><code>agents.axonops.cloud\n</code></pre> <p>If you have an IP address based security policy you will be required to open access to the IP address ranges provided in the following links.</p> <pre><code>https://agents.axonops.cloud/ips-v4\nhttps://agents.axonops.cloud/ips-v6\n</code></pre> <p>In order to test your connectivity execute the following command:</p> <pre><code>curl https://agents.axonops.cloud/test.html\n</code></pre> <p>You should expect the following response:</p> <p>AxonOps Agent Test Page</p>"},{"location":"get_started/agent_setup/#setup-the-axonops-repository-and-install-axonops-agent","title":"Setup the AxonOps repository and install AxonOps Agent","text":"<p>Select the OS Family</p> <p> </p> <p>Execute the following commands to setup the AxonOps repository:</p> <pre><code>sudo apt-get update\nsudo apt-get install -y curl gnupg ca-certificates\n\ncurl -L https://packages.axonops.com/apt/repo-signing-key.gpg \\\n  | sudo gpg --dearmor -o /usr/share/keyrings/axonops.gpg\n\necho \"deb [arch=arm64,amd64 signed-by=/usr/share/keyrings/axonops.gpg]\\\n  https://packages.axonops.com/apt axonops-apt main\" \\\n  | sudo tee /etc/apt/sources.list.d/axonops-apt.list\nsudo apt-get update\n</code></pre> <pre><code>sudo tee /etc/yum.repos.d/axonops-yum.repo &lt;&lt; EOL\n[axonops-yum]\nname=axonops-yum\nbaseurl=https://packages.axonops.com/yum/\nenabled=1\nrepo_gpgcheck=0\ngpgcheck=0\nEOL\n</code></pre>"},{"location":"get_started/agent_setup/#select-the-service-you-want-to-configure","title":"Select the Service you want to configure","text":""},{"location":"get_started/agent_setup/#install-cassandra-agent","title":"Install Cassandra Agent","text":""},{"location":"get_started/agent_setup/#select-the-cassandra-version","title":"Select the Cassandra Version","text":""},{"location":"get_started/agent_setup/#select-the-java-version","title":"Select the Java Version","text":"<p>Install the AxonOps Cassandra Agent and its dependency <code>axon-agent</code>:</p> <pre><code>sudo apt-get install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk17\n</code></pre> <pre><code>sudo yum install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk17\n</code></pre>"},{"location":"get_started/agent_setup/#configuration-file-locations","title":"Configuration File Locations","text":""},{"location":"get_started/agent_setup/#axonops-cassandra-agent","title":"AxonOps Cassandra Agent","text":"<p>The AxonOps Cassandra Agent is the jar that is directly loaded by Cassandra. The AxonOps Cassandra Agent then reaches out directly to the AxonOps Agent binary which contacts the AxonOps Server directly.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-cassandra{version}-agent.jar</code></li> <li>Version number: <code>/usr/share/axonops/axon-cassandra{version}-agent.version</code></li> <li>Copyright: <code>/usr/share/doc/axonops/axon-cassandra{version}-agent/copyright</code></li> <li>Licenses: <code>/usr/share/axonops/licenses/axon-cassandra{version}-agent/</code></li> </ul>"},{"location":"get_started/agent_setup/#axonops-agent","title":"AxonOps Agent","text":"<p>The AxonOps Agent is a dependency of the AxonOps Cassandra Agent. This binary contacts the AxonOps Server directly while minimizing the memory footprint and CPU utilization of the Cassandra process.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-agent</code></li> <li>Logs: <code>/var/log/axonops/axon-agent.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-agent.service</code></li> </ul>"},{"location":"get_started/agent_setup/#agent-configuration","title":"Agent Configuration","text":"<p>Update the following highlighted lines from <code>/etc/axonops/axon-agent.yml</code>:</p> <p>Please update the key and org values, they can be viewed by logging into console.axonops.cloud</p> <ul> <li>Organization (org) name is next to the logo in the console</li> <li>Agent Keys (key) found in Agent Setup</li> </ul> <p></p> <p>If there is a Dedicated NTP server in your Organization please uncomment and update the NTP section. </p> <pre><code>  axon-server:\n      hosts: \"agents.axonops.cloud\"\n\n  axon-agent:\n      key: &lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\n      org: &lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\n\n  # Specify the NTP server IP addresses or hostnames configured for your Cassandra hosts\n  # if using Cassandra deployed in Kubernetes or if auto-detection fails.\n  # The port defaults to 123 if not specified.\n  # NTP:\n  #    hosts:\n  #        - \"x.x.x.x:123\"\n  # Optionally restrict which commands can be executed by axon-agent.\n  # If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n  # disable_command_exec: false\n  # If disable_command_exec is true then axon-agent is only allowed to execute scripts\n  # under this path\n  # scripts_location: /var/lib/axonops/scripts/\n</code></pre> <p>Set file permissions on /etc/axonops/axon-agent.yml file by executing the following command</p> <pre><code>sudo chmod 0640 /etc/axonops/axon-agent.yml\n</code></pre>"},{"location":"get_started/agent_setup/#configure-cassandra","title":"Configure Cassandra","text":"<p>Add the following line at the end of <code>/etc/cassandra/cassandra-env.sh</code>:</p> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.0-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.11-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra4.0-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra4.1-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\n</code></pre> <p>If Cassandra was installed using a tarball, the correct path for the <code>cassandra-env.sh</code> will be <code>&lt;Cassandra Installation Directory&gt;/conf/cassandra-env.sh</code>.</p> <p>NB. Make sure this configuration is not overridden by automation tools.</p>"},{"location":"get_started/agent_setup/#configure-cassandra-user-group","title":"Configure Cassandra user group","text":"<p>Configure the Linux user groups by:</p> <ul> <li>Adding the <code>axonops</code> user to the <code>cassandra</code> user group.</li> <li>Adding the <code>cassandra</code> user to the <code>axonops</code> user group.</li> </ul> <pre><code>CASSANDRA_GROUP=cassandra\nCASSANDRA_USER=cassandra\n\nsudo usermod -aG \"$CASSANDRA_GROUP\" axonops\nsudo usermod -aG axonops \"$CASSANDRA_USER\"\n</code></pre> <p>If Cassandra was setup to use a non-default user or group, <code>CASSANDRA_GROUP</code> and/or <code>CASSANDRA_USER</code> will need be updated accordingly for the above commands to work properly.</p>"},{"location":"get_started/agent_setup/#uninstall-needrestart-package","title":"Uninstall <code>needrestart</code> Package","text":"<p>Due to recent change with <code>needrestart</code>, as seen in Ubuntu 24.04, uninstalling the <code>needrestart</code> package is currently recommended.</p> <p>Failure to uninstall the <code>needrestart</code> package may cause the Cassandra service to be restarted when updating the <code>axon-agent</code> package.</p>"},{"location":"get_started/agent_setup/#startrestart-cassandra","title":"Start/Restart Cassandra","text":"<p>To load the AxonOps Java Agent and Cassandra config changes please,</p> <ul> <li>Start the Cassandra service if stopped. </li> <li>Restart the Cassandra service if already running.</li> </ul>"},{"location":"get_started/agent_setup/#install-kafka-agent","title":"Install Kafka Agent","text":""},{"location":"get_started/agent_setup/#select-the-kafka-version","title":"Select the Kafka Version","text":""},{"location":"get_started/agent_setup/#select-the-java-version_1","title":"Select the Java Version.","text":"<p>Install the AxonOps Kafka Agent and its dependency <code>axon-agent</code>:</p> <pre><code>sudo apt-get install axon-kafka2-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka3-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka2-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka3-agent\n</code></pre> <pre><code>sudo yum install axon-kafka2-agent\n</code></pre> <pre><code>sudo yum install axon-kafka3-agent\n</code></pre> <pre><code>sudo yum install axon-kafka2-agent\n</code></pre> <pre><code>sudo yum install axon-kafka3-agent\n</code></pre>"},{"location":"get_started/agent_setup/#configuration-file-locations_1","title":"Configuration File Locations","text":""},{"location":"get_started/agent_setup/#axonops-kafka-agent","title":"AxonOps Kafka Agent","text":"<p>The AxonOps Kafka Agent is the jar that is directly loaded by Kafka. The AxonOps Kafka Agent then reaches out directly to the AxonOps Agent binary which contacts the AxonOps Server directly.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-kafka{version}-agent.jar</code></li> <li>Version number: <code>/usr/share/axonops/axon-kafka{version}-agent.version</code></li> <li>Copyright: <code>/usr/share/doc/axonops/axon-kafka{version}-agent/copyright</code></li> <li>Licenses: <code>/usr/share/axonops/licenses/axon-kafka{version}-agent/</code></li> </ul>"},{"location":"get_started/agent_setup/#axonops-agent_1","title":"AxonOps Agent","text":"<p>The AxonOps Agent is a dependency of the AxonOps Kafka Agent. This binary contacts the AxonOps Server directly while minimizing the memory footprint and CPU utilization of the Kafka process.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-agent</code></li> <li>Logs: <code>/var/log/axonops/axon-agent.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-agent.service</code></li> </ul>"},{"location":"get_started/agent_setup/#agent-configuration_1","title":"Agent Configuration","text":"<p>Update the <code>key</code> and <code>org</code> values within the highlighted lines of <code>/etc/axonops/axon-agent.yml</code> below.</p> <p>The values can be found by logging into console.axonops.cloud:</p> <ul> <li>Organization (<code>org</code>) can be found next to the logo at the top of the console.</li> <li>Agent Keys (<code>key</code>) can be found within Agent setup &gt; Agent keys.</li> </ul> <p></p> <p>If there is a Dedicated NTP server in your Organization please uncomment and update the NTP section.</p> <p> </p> Kafka Broker Zookeeper KRaft Broker KRaft Controller Kafka Connect <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"broker\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"zookeeper\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Optionally specify a rack to group nodes in AxonOps\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"kraft-broker\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"kraft-controller\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"connect\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Optionally specify a rack to group nodes in AxonOps\n</code></pre> <p>Set file permissions on /etc/axonops/axon-agent.yml file by executing the following command</p> <pre><code>sudo chmod 0640 /etc/axonops/axon-agent.yml\n</code></pre> <p>Insert the line <code>. /usr/share/axonops/axonops-jvm.options</code> right before the final line in your config file. Look for the last line that starts with <code>exec</code>, as demonstrated in the example below.</p> <p>NB. Please note the period(.) at the beginning of the config line.</p> <p>Example:</p> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <p>NB. Make sure that this configuration will not get overridden by an automation tool.</p>"},{"location":"get_started/agent_setup/#configure-kafka","title":"Configure Kafka","text":"Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>"},{"location":"get_started/agent_setup/#configure-zookeeper","title":"Configure Zookeeper","text":"Edit zookeeper-server-start.sh, usually located in your Zookeeper install path such as:   <p><code>/&lt;Zookeeper_Home&gt;/bin/zookeeper-server-start.sh</code></p>"},{"location":"get_started/agent_setup/#configure-kraft-broker","title":"Configure KRaft Broker","text":"Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>"},{"location":"get_started/agent_setup/#configure-kraft-controller","title":"Configure KRaft Controller","text":"Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>"},{"location":"get_started/agent_setup/#configure-connect","title":"Configure Connect","text":"Edit connect-distributed.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/connect-distributed.sh </code></p>"},{"location":"get_started/agent_setup/#add-axonops-user-to-kafka-user-group-and-kafka-user-to-axonops-group","title":"Add axonops user to Kafka user group and Kafka user to axonops group","text":"<pre><code>sudo usermod -aG &lt;your_kafka_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kafka_user&gt;\n</code></pre>"},{"location":"get_started/agent_setup/#startrestart-kafka","title":"Start/Restart Kafka","text":"To load the AxonOps Java Agent and Kafka config changes please either start the Kafka service if stopped restart the Kafka service if already running."},{"location":"get_started/agent_setup/#add-axonops-user-to-zookeeper-user-group-and-zookeeper-user-to-axonops-group","title":"Add axonops user to Zookeeper user group and Zookeeper user to axonops group","text":"<pre><code>sudo usermod -aG &lt;your_zookeeper_group&gt; axonops\nsudo usermod -aG axonops &lt;your_zookeeper_user&gt;\n</code></pre>"},{"location":"get_started/agent_setup/#startrestart-zookeeper","title":"Start/Restart Zookeeper","text":"To load the AxonOps Java Agent and Zookeeper config changes please either start the Zookeeper service if stopped or restart the Zookeeper service if already running."},{"location":"get_started/agent_setup/#add-axonops-user-to-kraft-broker-user-group-and-kraft-broker-user-to-axonops-group","title":"Add axonops user to KRaft Broker user group and KRaft Broker user to axonops group","text":"<pre><code>sudo usermod -aG &lt;your_kraft_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kraft_user&gt;\n</code></pre>"},{"location":"get_started/agent_setup/#startrestart-kraft-broker","title":"Start/Restart KRaft Broker","text":"To load the AxonOps Java Agent and Kafka KRaft config changes please either start the Kafka KRaft service if stopped or restart the Kafka KRaft service if already running."},{"location":"get_started/agent_setup/#add-axonops-user-to-kraft-controller-user-group-and-kraft-controller-user-to-axonops-group","title":"Add axonops user to KRaft Controller user group and KRaft Controller user to axonops group","text":"<pre><code>sudo usermod -aG &lt;your_kraft_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kraft_user&gt;\n</code></pre>"},{"location":"get_started/agent_setup/#startrestart-kraft-controller","title":"Start/Restart KRaft Controller","text":"To load the AxonOps Java Agent and Kafka KRaft config changes please either start the Kafka KRaft service if stopped or restart the Kafka KRaft service if already running."},{"location":"get_started/agent_setup/#add-axonops-user-to-kafka-connect-user-group-and-kafka-connect-user-to-axonops-group","title":"Add axonops user to Kafka Connect user group and Kafka Connect user to axonops group","text":"<pre><code>sudo usermod -aG &lt;your_connect_group&gt; axonops\nsudo usermod -aG axonops &lt;your_connect_user&gt;\n</code></pre>"},{"location":"get_started/agent_setup/#startrestart-kafka-connect","title":"Start/Restart Kafka Connect","text":"To load the AxonOps Java Agent and Kafka Connect config changes please either:  * Start the Kafka Connect service if stopped. * Restart the Kafka Connect service if already running."},{"location":"get_started/agent_setup/#axonops-agent-behind-a-proxy","title":"AxonOps agent behind a proxy","text":"<p>If your network does not have direct internet access and it requires a proxy to connect to the AxonOps Server, follow these instructions.</p>"},{"location":"get_started/agent_setup/#start-axon-agent","title":"Start axon-agent","text":"<pre><code>sudo systemctl start axon-agent\n</code></pre> <p>Once the Agents have been setup please use the Using AxonOps to familiarise yourself with AxonOps UI.</p>"},{"location":"get_started/agent_setup_cassandra/","title":"Agent setup cassandra","text":"Install Cassandra Agent"},{"location":"get_started/agent_setup_cassandra/#select-the-cassandra-version","title":"Select the Cassandra Version","text":""},{"location":"get_started/agent_setup_cassandra/#select-the-java-version","title":"Select the Java Version","text":"<p>Install the AxonOps Cassandra Agent and its dependency <code>axon-agent</code>:</p> <pre><code>sudo apt-get install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk17\n</code></pre> <pre><code>sudo yum install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk17\n</code></pre>"},{"location":"get_started/agent_setup_cassandra/#configuration-file-locations","title":"Configuration File Locations","text":""},{"location":"get_started/agent_setup_cassandra/#axonops-cassandra-agent","title":"AxonOps Cassandra Agent","text":"<p>The AxonOps Cassandra Agent is the jar that is directly loaded by Cassandra. The AxonOps Cassandra Agent then reaches out directly to the AxonOps Agent binary which contacts the AxonOps Server directly.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-cassandra{version}-agent.jar</code></li> <li>Version number: <code>/usr/share/axonops/axon-cassandra{version}-agent.version</code></li> <li>Copyright: <code>/usr/share/doc/axonops/axon-cassandra{version}-agent/copyright</code></li> <li>Licenses: <code>/usr/share/axonops/licenses/axon-cassandra{version}-agent/</code></li> </ul>"},{"location":"get_started/agent_setup_cassandra/#axonops-agent","title":"AxonOps Agent","text":"<p>The AxonOps Agent is a dependency of the AxonOps Cassandra Agent. This binary contacts the AxonOps Server directly while minimizing the memory footprint and CPU utilization of the Cassandra process.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-agent</code></li> <li>Logs: <code>/var/log/axonops/axon-agent.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-agent.service</code></li> </ul> Agent Configuration  <p>Update the following highlighted lines from <code>/etc/axonops/axon-agent.yml</code>:</p> <p>Please update the key and org values, they can be viewed by logging into console.axonops.cloud</p> <ul> <li>Organization (org) name is next to the logo in the console</li> <li>Agent Keys (key) found in Agent Setup</li> </ul> <p></p> <p>If there is a Dedicated NTP server in your Organization please uncomment and update the NTP section. </p> <pre><code>  axon-server:\n      hosts: \"agents.axonops.cloud\"\n\n  axon-agent:\n      key: &lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\n      org: &lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\n\n  # Specify the NTP server IP addresses or hostnames configured for your Cassandra hosts\n  # if using Cassandra deployed in Kubernetes or if auto-detection fails.\n  # The port defaults to 123 if not specified.\n  # NTP:\n  #    hosts:\n  #        - \"x.x.x.x:123\"\n  # Optionally restrict which commands can be executed by axon-agent.\n  # If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n  # disable_command_exec: false\n  # If disable_command_exec is true then axon-agent is only allowed to execute scripts\n  # under this path\n  # scripts_location: /var/lib/axonops/scripts/\n</code></pre> <p>Set file permissions on /etc/axonops/axon-agent.yml file by executing the following command</p> <pre><code>sudo chmod 0640 /etc/axonops/axon-agent.yml\n</code></pre> Configure Cassandra <p>Add the following line at the end of <code>/etc/cassandra/cassandra-env.sh</code>:</p> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.0-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.11-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra4.0-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra4.1-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\n</code></pre> <p>If Cassandra was installed using a tarball, the correct path for the <code>cassandra-env.sh</code> will be <code>&lt;Cassandra Installation Directory&gt;/conf/cassandra-env.sh</code>.</p> <p>NB. Make sure this configuration is not overridden by automation tools.</p>"},{"location":"get_started/agent_setup_cassandra/#configure-cassandra-user-group","title":"Configure Cassandra user group","text":"<p>Configure the Linux user groups by:</p> <ul> <li>Adding the <code>axonops</code> user to the <code>cassandra</code> user group.</li> <li>Adding the <code>cassandra</code> user to the <code>axonops</code> user group.</li> </ul> <pre><code>CASSANDRA_GROUP=cassandra\nCASSANDRA_USER=cassandra\n\nsudo usermod -aG \"$CASSANDRA_GROUP\" axonops\nsudo usermod -aG axonops \"$CASSANDRA_USER\"\n</code></pre> <p>If Cassandra was setup to use a non-default user or group, <code>CASSANDRA_GROUP</code> and/or <code>CASSANDRA_USER</code> will need be updated accordingly for the above commands to work properly.</p>"},{"location":"get_started/agent_setup_cassandra/#uninstall-needrestart-package","title":"Uninstall <code>needrestart</code> Package","text":"<p>Due to recent change with <code>needrestart</code>, as seen in Ubuntu 24.04, uninstalling the <code>needrestart</code> package is currently recommended.</p> <p>Failure to uninstall the <code>needrestart</code> package may cause the Cassandra service to be restarted when updating the <code>axon-agent</code> package.</p> Start/Restart Cassandra <p>To load the AxonOps Java Agent and Cassandra config changes please,</p> <ul> <li>Start the Cassandra service if stopped. </li> <li>Restart the Cassandra service if already running.</li> </ul>"},{"location":"get_started/agent_setup_kafka/","title":"Agent setup kafka","text":""},{"location":"get_started/agent_setup_kafka/#install-kafka-agent","title":"Install Kafka Agent","text":"Select the Kafka Version Select the Java Version. <p>Install the AxonOps Kafka Agent and its dependency <code>axon-agent</code>:</p> <pre><code>sudo apt-get install axon-kafka2-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka3-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka2-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka3-agent\n</code></pre> <pre><code>sudo yum install axon-kafka2-agent\n</code></pre> <pre><code>sudo yum install axon-kafka3-agent\n</code></pre> <pre><code>sudo yum install axon-kafka2-agent\n</code></pre> <pre><code>sudo yum install axon-kafka3-agent\n</code></pre>"},{"location":"get_started/agent_setup_kafka/#configuration-file-locations","title":"Configuration File Locations","text":""},{"location":"get_started/agent_setup_kafka/#axonops-kafka-agent","title":"AxonOps Kafka Agent","text":"<p>The AxonOps Kafka Agent is the jar that is directly loaded by Kafka. The AxonOps Kafka Agent then reaches out directly to the AxonOps Agent binary which contacts the AxonOps Server directly.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-kafka{version}-agent.jar</code></li> <li>Version number: <code>/usr/share/axonops/axon-kafka{version}-agent.version</code></li> <li>Copyright: <code>/usr/share/doc/axonops/axon-kafka{version}-agent/copyright</code></li> <li>Licenses: <code>/usr/share/axonops/licenses/axon-kafka{version}-agent/</code></li> </ul>"},{"location":"get_started/agent_setup_kafka/#axonops-agent","title":"AxonOps Agent","text":"<p>The AxonOps Agent is a dependency of the AxonOps Kafka Agent. This binary contacts the AxonOps Server directly while minimizing the memory footprint and CPU utilization of the Kafka process.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-agent</code></li> <li>Logs: <code>/var/log/axonops/axon-agent.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-agent.service</code></li> </ul>"},{"location":"get_started/agent_setup_kafka/#agent-configuration","title":"Agent ConfigurationConfigure KafkaConfigure ZookeeperConfigure KRaft BrokerConfigure KRaft ControllerConfigure ConnectAdd axonops user to Kafka user group and Kafka user to axonops groupStart/Restart KafkaAdd axonops user to Zookeeper user group and Zookeeper user to axonops groupStart/Restart ZookeeperAdd axonops user to KRaft Broker user group and KRaft Broker user to axonops groupStart/Restart KRaft BrokerAdd axonops user to KRaft Controller user group and KRaft Controller user to axonops groupStart/Restart KRaft ControllerAdd axonops user to Kafka Connect user group and Kafka Connect user to axonops groupStart/Restart Kafka Connect","text":"<p>Update the <code>key</code> and <code>org</code> values within the highlighted lines of <code>/etc/axonops/axon-agent.yml</code> below.</p> <p>The values can be found by logging into console.axonops.cloud:</p> <ul> <li>Organization (<code>org</code>) can be found next to the logo at the top of the console.</li> <li>Agent Keys (<code>key</code>) can be found within Agent setup &gt; Agent keys.</li> </ul> <p></p> <p>If there is a Dedicated NTP server in your Organization please uncomment and update the NTP section.</p> <p> </p> Kafka Broker Zookeeper KRaft Broker KRaft Controller Kafka Connect <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"broker\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"zookeeper\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Optionally specify a rack to group nodes in AxonOps\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"kraft-broker\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"kraft-controller\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"connect\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Optionally specify a rack to group nodes in AxonOps\n</code></pre> <p>Set file permissions on /etc/axonops/axon-agent.yml file by executing the following command</p> <pre><code>sudo chmod 0640 /etc/axonops/axon-agent.yml\n</code></pre>   Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>   Edit zookeeper-server-start.sh, usually located in your Zookeeper install path such as:   <p><code>/&lt;Zookeeper_Home&gt;/bin/zookeeper-server-start.sh</code></p>   Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>   Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>   Edit connect-distributed.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/connect-distributed.sh </code></p> <p>Insert the line <code>. /usr/share/axonops/axonops-jvm.options</code> right before the final line in your config file. Look for the last line that starts with <code>exec</code>, as demonstrated in the example below.</p> <p>NB. Please note the period(.) at the beginning of the config line.</p> <p>Example:</p> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <p>NB. Make sure that this configuration will not get overridden by an automation tool.</p> <pre><code>sudo usermod -aG &lt;your_kafka_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kafka_user&gt;\n</code></pre>   To load the AxonOps Java Agent and Kafka config changes please either start the Kafka service if stopped restart the Kafka service if already running.  <pre><code>sudo usermod -aG &lt;your_zookeeper_group&gt; axonops\nsudo usermod -aG axonops &lt;your_zookeeper_user&gt;\n</code></pre>   To load the AxonOps Java Agent and Zookeeper config changes please either start the Zookeeper service if stopped or restart the Zookeeper service if already running.  <pre><code>sudo usermod -aG &lt;your_kraft_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kraft_user&gt;\n</code></pre>   To load the AxonOps Java Agent and Kafka KRaft config changes please either start the Kafka KRaft service if stopped or restart the Kafka KRaft service if already running.  <pre><code>sudo usermod -aG &lt;your_kraft_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kraft_user&gt;\n</code></pre>   To load the AxonOps Java Agent and Kafka KRaft config changes please either start the Kafka KRaft service if stopped or restart the Kafka KRaft service if already running.  <pre><code>sudo usermod -aG &lt;your_connect_group&gt; axonops\nsudo usermod -aG axonops &lt;your_connect_user&gt;\n</code></pre>   To load the AxonOps Java Agent and Kafka Connect config changes please either:  * Start the Kafka Connect service if stopped. * Restart the Kafka Connect service if already running."},{"location":"get_started/cloud/","title":"AxonOps Cloud account","text":"<p>Click on the Free Sign Up button to get started.</p>"},{"location":"get_started/cloud/#step-1-register-your-interest-in-axonops-cloud","title":"Step 1 - Register your interest in AxonOps Cloud","text":"<p>Fill in your details on the registration screen</p> <p></p> <p>Once your account has been registered a confirmation email will be sent. </p> <p></p>"},{"location":"get_started/cloud/#step-2-complete-your-axonops-cloud-account-sign-up","title":"Step 2 - Complete your AxonOps Cloud account sign-up","text":"<p>Click on the link in the email to complete the sign-up process. </p> <p>You will be taken to the sign-up screen where you can enter your details or choose to use either Google or Microsoft Azure to complete the process.</p> <p></p> <p>There will be another email sent to verify that your email address is correct. </p> <p></p> <p>Once the email has been verified you are signed in to AxonOps Cloud Console.</p>"},{"location":"get_started/cloud/#step-3-setup-your-organisation","title":"Step 3 - Setup your Organisation.","text":"<ul> <li>Enter your Organization name. (Organization names are unique and cannot be re-used.)</li> <li>Confirmation tick on Organization name box will show you if the name is available. </li> <li>Click Create.</li> </ul>"},{"location":"get_started/cloud/#step-4-choose-subscription","title":"Step 4 - Choose Subscription","text":"<ul> <li>On left hand menu select 'Subscriptions'</li> <li>Under 'Subscriptions' select 'Plans'</li> <li>On the 'Plans' page select 'Get Started Free'</li> </ul>"},{"location":"get_started/cloud/#step-5-setup-axonops-agents","title":"Step 5 - Setup AxonOps Agents","text":"<p>Follow the AxonOps Cloud agent setup to connect your cluster to AxonOps Cloud.</p>"},{"location":"get_started/docker/","title":"Quickstart - Docker","text":""},{"location":"get_started/docker/#docker-compose-3-node-cassandra-desktop-install","title":"Docker-compose 3-Node Cassandra Desktop Install","text":"<p>Install and start testing on a 3-node Cassandra cluster in minutes. No registration required just head to GitHub at: axonops-cassandra-dev-cluster</p> <ul> <li>Includes fully functional AxonOps management environment to enhance the developer experience.</li> <li>Visualize your application queries</li> <li>Check your query consistency level</li> <li>Measure data model effectiveness</li> <li>Troubleshoot and optimize</li> </ul>"},{"location":"get_started/getting_started/","title":"Get Started","text":""},{"location":"get_started/getting_started/#getting-started","title":"Getting Started","text":"<p>Installing AxonOps Unified Monitoring on your own premises as a self-managed cluster gives you full control over every aspect of your AxonOps deployment.</p> <p>AxonOps components run on a wide array of operating systems including (but not limited to):</p> <ul> <li>Ubuntu</li> <li>Debian</li> <li>RedHat Enterprise Linux (RHEL)</li> <li>Amazon Linux</li> </ul> <p>AxonOps Unified Monitoring consists of 4 main components:</p> <ul> <li>axon-server<ul> <li>backend that collects cluster information and interacts with your clusters.</li> </ul> </li> <li>axon-dash<ul> <li>web UI to display and interact with your clusters.</li> </ul> </li> <li>axon-agent<ul> <li>called from within the JVM to send metrics to axon-server.</li> </ul> </li> <li>storage engine<ul> <li>stores metrics, logs, configurations, and metadata about your cluster.</li> </ul> </li> </ul> <p>Below are the steps to install and configure an on-premise AxonOps Unified Monitoring installation.</p>"},{"location":"get_started/getting_started/#setup-storage-engine","title":"Setup Storage Engine","text":"<p>Elasticsearch is always required and the default data storage for all Cassandra and Kafka metrics as well as application logs, AxonOps configuration and metrics metadata. </p> <p>You can choose to use Cassandra as a metrics store instead of Elasticsearch for better performance when monitoring larger numbers of nodes.</p> <p>Elasticsearch is still required in conjunction with the dedicated AxonOps Cassandra cluster. </p>"},{"location":"get_started/getting_started/#elasticsearch-required","title":"Elasticsearch (Required)","text":"<p>AxonOps is currently compatible with Elasticsearch 7.x and 8.x.</p> <p>We recommend installing the latest available Elasticsearch release.</p>"},{"location":"get_started/getting_started/#cassandra-optional","title":"Cassandra (Optional)","text":"<p>For more information please read more on setting up Cassandra as a Metrics Database.</p>"},{"location":"get_started/getting_started/#setup-axonops-server","title":"Setup AxonOps Server","text":"<p>Install and configure AxonOps Server (<code>axon-server</code>).</p>"},{"location":"get_started/getting_started/#setup-axonops-dashboard","title":"Setup AxonOps Dashboard","text":"<p>Install and configure AxonOps Dashboard (<code>axon-dash</code>).</p>"},{"location":"get_started/getting_started/#setup-axonops-agent","title":"Setup AxonOps Agent","text":"<p>Install and configure AxonOps Agent (<code>axon-agent</code>) for Cassandra or Kafka.</p>"},{"location":"get_started/getting_started/#alternative-installation-options","title":"Alternative Installation Options","text":"<p>Below are different options for on-premise installations of the AxonOps platform, depending on your environment and preferences.</p>"},{"location":"get_started/getting_started/#docker-or-podman","title":"Docker or Podman","text":"<p>For quick evaluations or smaller clusters, our Docker and Podman Compose setup is the fastest way to get everything running.</p> <p>Instructions and files can be found here.</p>"},{"location":"get_started/getting_started/#ansible","title":"Ansible","text":"<p>For an automated and repeatable approach, the Ansible collection can install both the AxonOps Server and Agents across Cassandra or Kafka clusters.</p> <p>Instructions and files can be found here.</p>"},{"location":"get_started/getting_started/#kubernetes","title":"Kubernetes","text":"<p>For deployments into Kubernetes environments, a Helm chart is available.</p> <p>Instructions and files can be found here.</p>"},{"location":"get_started/getting_started/#offline-installations","title":"Offline Installations","text":"<p>If you need to download packages for offline installation due to security requirements, you can use our package downloader script.</p> <p>Instructions and files can be found here.</p>"},{"location":"get_started/getting_started/#configuration-automation","title":"Configuration Automation","text":"<p>To easily setup alerts, dashboards, backups, integrations, and other configurations, use this repository of Ansible playbooks to automate AxonOps configuration.</p> <p>Instructions and files can be found here.</p>"},{"location":"get_started/proxy/","title":"Proxy Configuration","text":""},{"location":"get_started/proxy/#axonops-agent-behind-a-proxy","title":"AxonOps agent behind a proxy","text":"<p>If your network does not have direct internet access and it requires a proxy to connect to the AxonOps Server, you will need to configure the AxonOps agent to use it.</p> <p>To configure the AxonOps agent to use a proxy, you can use a <code>systemd</code> override. This is the recommended approach as it keeps your configuration separate from the agent's default service file.</p> <ol> <li> <p>Create an override file for the <code>axon-agent</code> service:</p> <pre><code>sudo systemctl edit axon-agent.service\n</code></pre> </li> <li> <p>This will open an editor with a blank file. Add the following content, replacing <code>your_proxy_server</code> and <code>port</code> with your proxy's details:</p> <pre><code>[Service]\nEnvironment=\"https_proxy=http://your_proxy_server:port\"\nEnvironment=\"http_proxy=http://your_proxy_server:port\"\nEnvironment=\"no_proxy=localhost,127.0.0.1\"\n</code></pre> <p>If your proxy requires authentication, use the following format:</p> <pre><code>[Service]\nEnvironment=\"https_proxy=http://user:password@your_proxy_server:port\"\nEnvironment=\"http_proxy=http://user:password@your_proxy_server:port\"\nEnvironment=\"no_proxy=localhost,127.0.0.1\"\n</code></pre> </li> <li> <p>Save the file and exit the editor. <code>systemd</code> will automatically reload the configuration.</p> </li> <li> <p>Restart the <code>axon-agent</code> to apply the changes:</p> <pre><code>sudo systemctl restart axon-agent\n</code></pre> </li> <li> <p>You can verify that the environment variables have been applied by checking the service's status:</p> <pre><code>systemctl status axon-agent\n</code></pre> </li> </ol>"},{"location":"how-to/backup-restore-notifications/","title":"Setup Backup - Restore Notifications","text":""},{"location":"how-to/backup-restore-notifications/#setup-backup-restore-notifications","title":"Setup Backup - Restore Notifications","text":"<p>On the AxonOps application menu, click <code>Operations -&gt; Backups -&gt; Setup</code> and select <code>Notifications</code> tab. </p>"},{"location":"how-to/backup-restore-notifications/#notification-severities","title":"Notification Severities.","text":"<p>Notification Severities.</p> <p>For each notifications severity   Info     Warning     Error you can either use the slider  to use the default routing or use the   icon to customize the notification integrations.</p> <p>Notice:  not available when default routing   selected</p> <p>Infomy</p> <p></p>"},{"location":"how-to/backup-restore-notifications/#customize-notifications","title":"Customize Notifications.","text":"<p>To customize notifications <code>click</code> on  select the integrations that you require and click <code>Close</code>.</p> <p>Infomy</p> <p></p> <p>Noticed: The<code>Warning Integration</code> were customized. You can remove these by clicking the .</p> <p>If you want to remove default routing groups from a severity and create custom groups , use the slider bar to remove default routing <code>click</code> the  and follow this steps</p> <p>If you do not require any notifications <code>ensure</code> the <code>default routing</code> is off  and delete any previously created custom notification.</p> <p>Infomy</p> <p></p>"},{"location":"how-to/default-routing/","title":"Setup Default Routing","text":""},{"location":"how-to/default-routing/#setup-default-routing","title":"Setup Default Routing","text":"<p>Default Routing.</p> <p>Allows you to set up the channels though which alerts &amp; notifications will be received and the specific groups that will receive the alerts &amp; notifications</p>"},{"location":"how-to/default-routing/#setup-default-routing_1","title":"Setup Default Routing","text":"<p>On the Axonops application menu, select <code>Alert &amp; Notifications</code> -&gt; Integration and select<code>Default Routing</code> tab.</p> <ul> <li>Alert &amp; Notification types can be set up</li> </ul> <p>Infomy</p> <p>  Info   Warning   Error </p>"},{"location":"how-to/default-routing/#info","title":"Info","text":"<p>To Setup Default Routing For   Info click On  </p> <ul> <li>Select the desired group(s) from the dropdown menu for the desired integrations(s) and  click`   to confirm selections</li> </ul> <p>Infomy</p> <p></p> <p>The group should now appear in the   Info  Info box on the <code>Default Routing Tab</code></p> <p>Infomy</p> <p></p>"},{"location":"how-to/default-routing/#warning-error","title":"Warning - Error","text":"<p>Repeat these steps to setup the Default Routing for   Warning   Error</p>"},{"location":"how-to/default-routing/#edit-default-routing","title":"Edit Default Routing","text":"<p>To Edit <code>Default Routing</code> click on the    icon on either    Add or <code>Remove</code> existing integrations using the <code>dropdown</code> menus.</p>"},{"location":"how-to/default-routing/#delete-default-routing","title":"Delete Default Routing","text":"<p>To Remove a <code>group</code> <code>click</code> on the <code>Delete</code> icon</p> <p>Infomy</p> <p></p>"},{"location":"how-to/reuse-host-id/","title":"Re-use an existing host ID","text":""},{"location":"how-to/reuse-host-id/#re-using-an-existing-host-id","title":"Re-using an existing Host ID","text":"<p>Each agent connected to the AxonOps server is assigned a unique host ID that is used internally to associate metrics and events with the node. If a Cassandra host dies and is replaced by another one with the same IP and token range then normally a new host ID will be generated and the replacement server will appear as a new machine in AxonOps. In this situation it is possible to re-use the same host ID so AxonOps sees the replacement server as the same as the original one.</p> <p>You can find the host ID of a node in the AxonOps GUI by going to Cluster Overview and selecting a node. In Graph View the host ID is shown next to the hostname in the details panel and in List View it is shown as Agent ID at the top of the details popup. If the old server's filesystem is still accessible you can also find the host ID stored in <code>/var/lib/axonops/hostId</code>.</p> <p>Follow these steps to start up a replacement server using the old host ID:</p> <ol> <li>Install axon-agent on the replacement server</li> <li>Stop axon-agent if it is running then delete these files if they exist: <code>/var/lib/axonops/hostId</code>, <code>/var/lib/axonops/local.db</code></li> <li>Create a new file at <code>/var/lib/axonops/hostId</code> containing the host ID you wish to use</li> <li>Start axon-agent</li> </ol>"},{"location":"how-to/rolling-restart/","title":"Rolling Restart","text":""},{"location":"how-to/setup-alert-rules/","title":"Setup Alert Rules","text":""},{"location":"how-to/setup-alert-rules/#setup-alert-rules","title":"Setup alert rules","text":""},{"location":"how-to/setup-alert-rules/#insert-alert-rules-credentials","title":"Insert Alert Rules Credentials","text":"<p>On the Axonops application menu, click <code>Dashboards</code> and <code>select</code> required Dashboard. eg. <code>System</code></p> <p><code>Hover over</code> the desired Chart <code>click</code> on the   button.</p> <p>Infomy</p> <p></p>"},{"location":"how-to/setup-alert-rules/#complete-the-fields-in-form","title":"Complete The Fields In Form","text":"<ul> <li>Below the chart <code>click</code> on the <code>alert</code> tab.</li> </ul> <p>Infomy</p> <p></p> <ul> <li>A form will appear</li> </ul> <p>Infomy</p> <p></p> <ul> <li>Complete Alert settings in <code>Comparator Warning value</code> or <code>Critical value</code> or Both and the <code>Duration</code> ==&gt; (how often to check) In</li> </ul> <p>Infomy</p> <p></p>"},{"location":"how-to/setup-alert-rules/#annotations","title":"Annotations","text":"<p>In the <code>Summary</code> box you can include free text &amp; type one <code>or</code> many of the following <code>$labels</code></p> <pre><code>$labels:\n   - cluster\n   - dc\n   - hostname\n   - org\n   - rack\n   - type\n   - keyspace\n$value:\n</code></pre> <p>In the <code>Description</code> box you can include free along with one <code>or</code> many of the above  <code>$labels</code></p> <p>Example</p> <p><code>CPU usage per DC Alerts usage on {{ $labels.hostname }} and cluster {{$labels.cluster}}</code></p> <p>Infomy</p> <p></p>"},{"location":"how-to/setup-alert-rules/#integrations","title":"Integrations","text":"<ul> <li> <p>Using the slider bar   you can select any Integrations.</p> <p>Then <code>click</code> on the <code>Info</code>, <code>Warning</code>, <code>Error</code> icons, to select the group(s) of Integrations for the alert.</p> </li> </ul> <p>Infomy</p> <p> </p> <p>Not selecting integrations</p> <p>If you do not select any specific Integrations the Alert will automatically follow the <code>Global Dashboard Routing</code> or if this has not been setup the Default Routing Integrations.</p>"},{"location":"how-to/setup-alert-rules/#edit-alert-rule","title":"Edit Alert Rule","text":"<p>On the Axonops application menu, click <code>Alerts &amp; Notifications</code> and <code>click</code> Active. <code>Select</code> the <code>Alert Rules</code> tab and click  </p> <p>Infomy</p> <p></p>"},{"location":"how-to/setup-alert-rules/#delete-alert-rules","title":"Delete Alert Rule(s)","text":"<p>To Delete An Alert Either...</p> <ul> <li>On the Axonops application menu, click <code>Dashboards</code> and <code>select</code> required Dashboard. <code>eg. System</code> <code>Hover over</code> the desired Chart click on the   button. Below the chart <code>click</code> on the <code>alert</code> tab and <code>click</code> on the   of the alert rule you want to remove.</li> </ul> <p>OR...</p> <ul> <li>On the Axonops application menu, click <code>Alerts &amp; Notifications</code> and <code>click</code> Active. <code>Select</code> the Alert Rules tab and click   </li> </ul> <p>Infomy</p> <p></p>"},{"location":"how-to/setup-dashboards-global-integrations/","title":"Setup Dashboards Global Integrations","text":""},{"location":"how-to/setup-dashboards-global-integrations/#setup-dashboards-global-integrations","title":"Setup Dashboards Global Integrations","text":"<p>On the Axonops application menu, click <code>Alerts &amp; Notifications -&gt; Active</code> and select <code>Dashboards Global Routing</code> tab.</p>"},{"location":"how-to/setup-dashboards-global-integrations/#notification-severities","title":"Notification Severities.","text":"<p>Notification Severities.</p> <p>For each notifications severity    Info      Warning      Error you can either use the slider   to use the default routing or use the    icon to customize the notification integrations.</p> <p>Notice:   not available when default routing  selected</p> <p>Infomy</p> <p></p>"},{"location":"how-to/setup-dashboards-global-integrations/#customize-notifications","title":"Customize Notifications.","text":"<p>To customize notifications <code>click</code> on  select the integrations that you require and click <code>Close</code>.</p> <p>Infomy</p> <p></p> <p>Noticed: The<code>Warning Integration</code> were customized. You can remove these by clicking the .</p> <p>If you want to remove default routing groups from a severity and create custom groups , use the slider bar to remove default routing <code>click</code> the   and follow this steps</p> <p>If you do not require any notifications <code>ensure</code> the <code>default routing</code> is off  and delete any previously created custom notification.</p> <p>Infomy</p> <p></p>"},{"location":"how-to/setup-log-collection/","title":"Setup Log Collection","text":"<p>AxonOps dashboards provides a comprehensive set of charts with an embedded view for logs and events. The goal is to correlate metrics with logs/events as you can zoom in the logs histogram or metrics charts to drill down both results. </p> <p>Log and event view is located in the bottom part of that page that you can expand/collapse with the horizontal splitter.</p> <p></p> <p>The setup for log collection is accessible via Settings &gt; logs</p> <p>Infomy</p> <p></p> <p>newlineregex is used by the log collector to handle multilines logs. Default newlineregex for Cassandra should be ok unless you've customized it.</p>"},{"location":"how-to/setup-servicechecks/","title":"Setup Service Checks","text":""},{"location":"how-to/setup-servicechecks/#setup-service-checks","title":"Setup Service Checks","text":""},{"location":"how-to/setup-servicechecks/#add-service-checks","title":"Add Service Checks","text":"<p>On the Axonops application menu, click <code>Service Checks</code> and select <code>Setup</code> tab.</p> <p>Infomy</p> <p></p>"},{"location":"how-to/setup-servicechecks/#create-services","title":"Create Services","text":"<p>Below there few examples <code>copy</code> and <code>Paste</code> inside. and click <code>save</code> </p> <pre><code>{\n    \"shellchecks\": [\n     {\n        \"name\" : \"check_elastic\",\n        \"shell\" :  \"/bin/bash\",\n        \"script\":  \"if [ 'ps auxwww | grep elastic | wc -l' -lt 1 ] then exit 2 else exit 0  fi\",\n        \"interval\": \"5m\" ,\n        \"timeout\": \"1m\" \n     }\n   ],\n\n   \"httpchecks\": [],\n   \"tcpchecks\": [\n    {\n        \"name\": \"elastic_tcp_endpoint_check\",\n        \"interval\": \"5s\",\n        \"timeout\": \"1m\",\n        \"tcp\": \"localhost:9200\"\n    }\n   ]\n\n}\n</code></pre> <p>Example:</p> <p>Infomy</p> <p></p>"},{"location":"how-to/setup-servicechecks/#delete-services","title":"Delete Services","text":"<p>To Delete a service <code>copy</code> and <code>Paste</code> inside. and <code>click</code> save  </p> <pre><code>{\n    \"shellchecks\": [],\n    \"httpchecks\": [],\n    \"tcpchecks\": []\n\n}\n</code></pre> <p>Example:</p> <p>Infomy</p> <p></p>"},{"location":"installation/release_notes/","title":"Release Notes","text":""},{"location":"installation/release_notes/#release-2025-08-29","title":"Release 2025-08-29","text":"<ul> <li>axon-server: 2.0.10<ul> <li>Fix ordering when displaying event logs.</li> </ul> </li> </ul>"},{"location":"installation/release_notes/#fixes","title":"Fixes","text":"<ul> <li>[Server] Fix event log sorting with a faster tie-breaker mechanism.</li> </ul>"},{"location":"installation/release_notes/#release-2025-08-28","title":"Release 2025-08-28","text":"<ul> <li>axon-server: 2.0.9<ul> <li>Update dashboard templates for select installations.</li> </ul> </li> </ul>"},{"location":"installation/release_notes/#fixes_1","title":"Fixes","text":"<ul> <li>[Server] Update dashboard templates to support missing thread pool metrics for certain installations.</li> </ul>"},{"location":"installation/release_notes/#release-2025-08-21","title":"Release 2025-08-21","text":"<ul> <li>axon-server: 2.0.8<ul> <li>Prevents erroneously raised snapshot errors.</li> </ul> </li> <li>axon-agent: 2.0.7<ul> <li>Strengthen connection management and environment variable configurations for Kafka agent.</li> </ul> </li> </ul>"},{"location":"installation/release_notes/#fixes_2","title":"Fixes","text":"<ul> <li>[Server] Stop <code>clearing snapshot timed out</code> errors and prevent erroneously raised alerts.</li> <li>[Agent] Remove duplicate environment variables used to configure Kafka cluster name. Fixes an issue when running with Strimzi.</li> <li>[Agent] Reconnect idle Kafka agent connections instead of treating them as failed or terminated connections.</li> </ul>"},{"location":"installation/release_notes/#release-2025-08-20","title":"Release 2025-08-20","text":"<ul> <li>axon-server: 2.0.7<ul> <li>Fixes status messaging for backup/repairs as well as select thread pool metrics.</li> </ul> </li> </ul>"},{"location":"installation/release_notes/#fixes_3","title":"Fixes","text":"<ul> <li>[Server] Fix critical issue in backup and repair messaging (introduced in axon-server 2.0.4).</li> <li>[Server] Fix select dashboard thread pool templates.</li> </ul>"},{"location":"installation/release_notes/#release-2025-08-15","title":"Release 2025-08-15","text":"<ul> <li>axon-dash: 2.0.6<ul> <li>Fixes a couple of rare race conditions seen at startup.</li> </ul> </li> </ul>"},{"location":"installation/release_notes/#fixes_4","title":"Fixes","text":"<ul> <li>[Server] Fix race condition getting org details during startup.</li> <li>[Server] Fix race condition getting license details during startup.</li> </ul>"},{"location":"installation/release_notes/#release-2025-08-11","title":"Release 2025-08-11","text":"<ul> <li>axon-dash: 2.0.10<ul> <li>Fixes for user permissions and editing Alert Definitions.</li> </ul> </li> </ul>"},{"location":"installation/release_notes/#fixes_5","title":"Fixes","text":"<ul> <li>[Dash] Fix permissions issue when a user has multiple roles assigned.</li> <li>[Dash] Fix issue with certain strings causing blank fields when editing Alert Definitions.</li> </ul>"},{"location":"installation/release_notes/#release-2025-08-06","title":"Release 2025-08-06","text":"<ul> <li>axon-server: 2.0.5<ul> <li>Mainly new features and simple bug fixes.</li> </ul> </li> <li>axon-agent: 2.0.6<ul> <li>Introduction of new, efficient log collector. Tested thoroughly with edge cases.</li> </ul> </li> <li>axon-dash: 2.0.9<ul> <li>Fixes for adaptive repairs and Alerts dashboard timeline, along with new features.</li> </ul> </li> </ul>"},{"location":"installation/release_notes/#fixes_6","title":"Fixes","text":"<ul> <li>[Server] Handle race condition seen where restarting axon-server while running adaptive repairs would cancel the repair.</li> <li>[Agent] Redesign log collectors to avoid throwing too many open files errors and use inotify file handles efficiently.</li> <li>[Dash] Remove broken metrics tab from the Kafka broker view.</li> <li>[Dash] Ensure all alerts are displayed on the Alerts dashboard timeline.</li> </ul>"},{"location":"installation/release_notes/#customer-requests","title":"Customer Requests","text":"<ul> <li>[Server] Failed backups have been downgraded from Critical (red) alerts to Warning (yellow) alerts, reserving Critical alerts for operational issues.</li> <li>[Dash] Improve Firefox compatibilty.</li> <li>[Dash] Disable auto-saving of adaptive repair settings and add ability to revert settings.</li> </ul>"},{"location":"installation/release_notes/#new-features","title":"New Features","text":"<ul> <li>[Server] Replace the <code>elastic_hosts</code> configuration key with the forward-looking <code>search_db</code> key in the default axon-server.yml.</li> <li>[Agent] Add <code>--validate</code> to <code>axon-cassandra-restore</code> tooling that verifies all files referenced by a backup manifest are still accessible.</li> <li>[Dash] Add deeplinking URLs for better Workbench support.</li> <li>[Dash] New fluid progress animation for adaptive repairs.</li> </ul>"},{"location":"installation/release_notes/#release-2025-07-28","title":"Release 2025-07-28","text":"<ul> <li>axon-server: 2.0.4<ul> <li>Internal messages for repairs and backups have changed.</li> </ul> </li> <li>axon-agent: 2.0.5<ul> <li>Internal messages for repairs and backups have changed.</li> <li>OpenSearch support required changes that could have affected Elasticsearch access   code. Routinely tested with our nightly builds.</li> </ul> </li> <li>axon-dash: 2.0.8<ul> <li>Mainly internal changes and bug fixes.</li> </ul> </li> </ul>"},{"location":"installation/release_notes/#fixes_7","title":"Fixes","text":"<ul> <li>[Server, Agent] Improve resilience of repair and backup messages.</li> <li>[Server] Update Go and dependencies to eliminate known security vulnerabilities.</li> <li>[Server] Fix issues displayed when there are no failed adapative repair segments.</li> <li>[Agent] Fix concurrency issues for service checks.</li> <li>[Agent] Fix security issues when <code>disable_command_exec</code> is set to <code>true</code>.</li> <li>[Dash] Ensure the default shell that appears in the dashboard matches the backend <code>/bin/sh</code>.</li> <li>[Dash] Fix tooltip for button to kill the Kafka process.</li> <li>[Dash] No longer rely on externally-hosted fonts.</li> <li>[Dash] No longer present non-functioning integration actions to read-only users.</li> <li>[Dash] Fix internal permissions logic.</li> <li>[Dash] Remove unused internal dashboard template model definition.</li> <li>[Dash] Upgrade AppImage.</li> </ul>"},{"location":"installation/release_notes/#customer-requests_1","title":"Customer Requests","text":"<ul> <li>[Server] Make alert emails user friendly.</li> <li>[Server] Add ability to log alerts to file for ingestion by external log readers.</li> </ul>"},{"location":"installation/release_notes/#new-features_1","title":"New Features","text":"<ul> <li>[Server] Introduce OpenSearch support.</li> <li>[Dash] Filters can now be customized on new dashboards.</li> <li>[Dash] Allow restoring snapshots to new keyspace/tables when the keyspace/table no longer exists.</li> </ul>"},{"location":"installation/release_notes/#release-2025-07-01","title":"Release 2025-07-01","text":"<ul> <li>axon-dash: 2.0.7</li> </ul>"},{"location":"installation/release_notes/#fixes_8","title":"Fixes","text":"<ul> <li>[Dash] Allow deleting dashboards that contain widgets.</li> <li>[Dash] Remove PDF dependency preventing axon-dash RPM package installation on RHEL 9.</li> </ul>"},{"location":"installation/release_notes/#customer-requests_2","title":"Customer Requests","text":"<ul> <li>[Dash] Improve Firefox compatibility by no longer using experimental Javascript features.</li> </ul>"},{"location":"installation/release_notes/#release-2025-06-26","title":"Release 2025-06-26","text":"<ul> <li>axon-kafka3-agent: 1.0.2</li> </ul>"},{"location":"installation/release_notes/#fixes_9","title":"Fixes","text":"<ul> <li>[Kafka Agent] Remove override within the agent configuration and apply it the codebase.</li> </ul>"},{"location":"installation/release_notes/#release-2025-06-24","title":"Release 2025-06-24","text":"<ul> <li>axon-agent: 2.0.4</li> <li>axon-kafka3-agent: 1.0.1</li> <li>axon-kafka2-agent: 1.0.1</li> </ul>"},{"location":"installation/release_notes/#fixes_10","title":"Fixes","text":"<ul> <li>[Agent] Improve log collector logic and reliability.</li> <li>[Agent] Update Go and dependencies to eliminate known security vulnerabilities.</li> </ul>"},{"location":"installation/release_notes/#new-features_2","title":"New Features","text":"<ul> <li>[Agent, Kafka Agent] Allow Kafka Agent to be configured solely with environment variables.</li> </ul>"},{"location":"installation/agent/agent_setup_cassandra/","title":"Agent setup cassandra","text":""},{"location":"installation/agent/agent_setup_cassandra/#install-cassandra-agent","title":"Install Cassandra Agent","text":""},{"location":"installation/agent/agent_setup_cassandra/#select-the-cassandra-version","title":"Select the Cassandra Version","text":""},{"location":"installation/agent/agent_setup_cassandra/#select-the-java-version","title":"Select the Java Version","text":"<p>Install the AxonOps Cassandra Agent and its dependency <code>axon-agent</code>:</p> <pre><code>sudo apt-get install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk17\n</code></pre> <pre><code>sudo yum install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk17\n</code></pre>"},{"location":"installation/agent/agent_setup_cassandra/#configuration-file-locations","title":"Configuration File Locations","text":""},{"location":"installation/agent/agent_setup_cassandra/#axonops-cassandra-agent","title":"AxonOps Cassandra Agent","text":"<p>The AxonOps Cassandra Agent is the jar that is directly loaded by Cassandra. The AxonOps Cassandra Agent then reaches out directly to the AxonOps Agent binary which contacts the AxonOps Server directly.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-cassandra{version}-agent.jar</code></li> <li>Version number: <code>/usr/share/axonops/axon-cassandra{version}-agent.version</code></li> <li>Copyright: <code>/usr/share/doc/axonops/axon-cassandra{version}-agent/copyright</code></li> <li>Licenses: <code>/usr/share/axonops/licenses/axon-cassandra{version}-agent/</code></li> </ul>"},{"location":"installation/agent/agent_setup_cassandra/#axonops-agent","title":"AxonOps Agent","text":"<p>The AxonOps Agent is a dependency of the AxonOps Cassandra Agent. This binary contacts the AxonOps Server directly while minimizing the memory footprint and CPU utilization of the Cassandra process.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-agent</code></li> <li>Logs: <code>/var/log/axonops/axon-agent.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-agent.service</code></li> </ul>"},{"location":"installation/agent/agent_setup_cassandra/#agent-configuration","title":"Agent Configuration","text":"<p>Update the following lines within <code>/etc/axonops/axon-agent.yml</code>.</p> <p>The highlighted lines should match the <code>host</code> and <code>org</code> keys found within <code>/etc/axonops/axon-server.yml</code>.</p> <pre><code>axon-server:\n    hosts: \"axon-server_endpoint\" # Your axon-server IP or hostname, e.g. axonops.mycompany.com\n    port: 1888 # The default axon-server port is 1888\n\naxon-agent:\n    org: \"my-company\" # Your organisation name\n    # SSL/TLS Settings from AxonOps Agent to AxonOps Server\n    tls:\n        mode: \"disabled\" # disabled, TLS\n        # Only set below if mode is TLS\n        skipVerify: false # Disables CA and Hostname verification\n        caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n        certFile: \"path_to_certs_on_axon_agent_node.crt\"\n        keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\nNTP:\n    host: \"ntp.mycompany.com\" # Your NTP server IP address or hostname \n</code></pre>"},{"location":"installation/agent/agent_setup_cassandra/#ensure-proper-agent-configuration-permissions","title":"Ensure Proper Agent Configuration Permissions","text":"<p>After editing the file, ensure the file permissions for <code>/etc/axonops/axon-agent.yml</code> are set correctly by running the following commmand:</p> <pre><code>sudo chmod 0640 /etc/axonops/axon-agent.yml\n</code></pre>"},{"location":"installation/agent/agent_setup_cassandra/#configure-cassandra","title":"Configure Cassandra","text":"<p>Add the following line at the end of <code>/etc/cassandra/cassandra-env.sh</code>:</p> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.0-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.11-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra4.0-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra4.1-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\n</code></pre> <p>If Cassandra was installed using a tarball, the correct path for the <code>cassandra-env.sh</code> will be <code>&lt;Cassandra Installation Directory&gt;/conf/cassandra-env.sh</code>.</p> <p>NB. Make sure this configuration is not overridden by automation tools.</p>"},{"location":"installation/agent/agent_setup_cassandra/#configure-cassandra-user-group","title":"Configure Cassandra user group","text":"<p>Configure the Linux user groups by:</p> <ul> <li>Adding the <code>axonops</code> user to the <code>cassandra</code> user group.</li> <li>Adding the <code>cassandra</code> user to the <code>axonops</code> user group.</li> </ul> <pre><code>CASSANDRA_GROUP=cassandra\nCASSANDRA_USER=cassandra\n\nsudo usermod -aG \"$CASSANDRA_GROUP\" axonops\nsudo usermod -aG axonops \"$CASSANDRA_USER\"\n</code></pre> <p>If Cassandra was setup to use a non-default user or group, <code>CASSANDRA_GROUP</code> and/or <code>CASSANDRA_USER</code> will need be updated accordingly for the above commands to work properly.</p>"},{"location":"installation/agent/agent_setup_cassandra/#uninstall-needrestart-package","title":"Uninstall <code>needrestart</code> Package","text":"<p>Due to recent change with <code>needrestart</code>, as seen in Ubuntu 24.04, uninstalling the <code>needrestart</code> package is currently recommended.</p> <p>Failure to uninstall the <code>needrestart</code> package may cause the Cassandra service to be restarted when updating the <code>axon-agent</code> package.</p>"},{"location":"installation/agent/agent_setup_cassandra/#apply-changes-to-cassandra","title":"Apply Changes to Cassandra","text":"<p>To load the AxonOps Java Agent and Cassandra config changes, run the following command:</p> <pre><code>sudo systemctl restart cassandra\n</code></pre>"},{"location":"installation/agent/agent_setup_kafka/","title":"Agent setup kafka","text":""},{"location":"installation/agent/agent_setup_kafka/#install-kafka-agent","title":"Install Kafka Agent","text":"Select the Kafka Version Select the Java Version. <p>Install the AxonOps Kafka Agent and its dependency <code>axon-agent</code>:</p> <pre><code>sudo apt-get install axon-kafka2-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka3-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka2-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka3-agent\n</code></pre> <pre><code>sudo yum install axon-kafka2-agent\n</code></pre> <pre><code>sudo yum install axon-kafka3-agent\n</code></pre> <pre><code>sudo yum install axon-kafka2-agent\n</code></pre> <pre><code>sudo yum install axon-kafka3-agent\n</code></pre>"},{"location":"installation/agent/agent_setup_kafka/#configuration-file-locations","title":"Configuration File Locations","text":""},{"location":"installation/agent/agent_setup_kafka/#axonops-kafka-agent","title":"AxonOps Kafka Agent","text":"<p>The AxonOps Kafka Agent is the jar that is directly loaded by Kafka. The AxonOps Kafka Agent then reaches out directly to the AxonOps Agent binary which contacts the AxonOps Server directly.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-kafka{version}-agent.jar</code></li> <li>Version number: <code>/usr/share/axonops/axon-kafka{version}-agent.version</code></li> <li>Copyright: <code>/usr/share/doc/axonops/axon-kafka{version}-agent/copyright</code></li> <li>Licenses: <code>/usr/share/axonops/licenses/axon-kafka{version}-agent/</code></li> </ul>"},{"location":"installation/agent/agent_setup_kafka/#axonops-agent","title":"AxonOps Agent","text":"<p>The AxonOps Agent is a dependency of the AxonOps Kafka Agent. This binary contacts the AxonOps Server directly while minimizing the memory footprint and CPU utilization of the Kafka process.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-agent</code></li> <li>Logs: <code>/var/log/axonops/axon-agent.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-agent.service</code></li> </ul>"},{"location":"installation/agent/agent_setup_kafka/#agent-configuration","title":"Agent ConfigurationConfigure KafkaConfigure ZookeeperConfigure KRaft BrokerConfigure KRaft ControllerConfigure ConnectAdd axonops user to Kafka user group and Kafka user to axonops groupStart/Restart KafkaAdd axonops user to Zookeeper user group and Zookeeper user to axonops groupStart/Restart ZookeeperAdd axonops user to KRaft Broker user group and KRaft Broker user to axonops groupStart/Restart KRaft BrokerAdd axonops user to KRaft Controller user group and KRaft Controller user to axonops groupStart/Restart KRaft ControllerAdd axonops user to Kafka Connect user group and Kafka Connect user to axonops groupStart/Restart Kafka Connect","text":"<p>Update the highlighted lines in <code>/etc/axonops/axon-agent.yml</code>.</p> <p>These need to match the config that you have in your <code>axon-server.yml</code> setup.</p> <p> </p> Kafka Broker Zookeeper KRaft Broker KRaft Controller Kafka Connect <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"broker\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"zookeeper\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Optionally specify a rack to group nodes in AxonOps\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"kraft-broker\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"kraft-controller\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"connect\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Optionally specify a rack to group nodes in AxonOps\n</code></pre> <p>Set file permissions on /etc/axonops/axon-agent.yml file by executing the following command</p> <pre><code>sudo chmod 0640 /etc/axonops/axon-agent.yml\n</code></pre>   Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>   Edit zookeeper-server-start.sh, usually located in your Zookeeper install path such as:   <p><code>/&lt;Zookeeper_Home&gt;/bin/zookeeper-server-start.sh</code></p>   Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>   Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>   Edit connect-distributed.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/connect-distributed.sh </code></p> <p>Insert the line <code>. /usr/share/axonops/axonops-jvm.options</code> right before the final line in your config file. Look for the last line that starts with <code>exec</code>, as demonstrated in the example below.</p> <p>NB. Please note the period(.) at the beginning of the config line.</p> <p>Example:</p> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <p>NB. Make sure that this configuration will not get overridden by an automation tool.</p> <pre><code>sudo usermod -aG &lt;your_kafka_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kafka_user&gt;\n</code></pre>   To load the AxonOps Java Agent and Kafka config changes please either start the Kafka service if stopped restart the Kafka service if already running.  <pre><code>sudo usermod -aG &lt;your_zookeeper_group&gt; axonops\nsudo usermod -aG axonops &lt;your_zookeeper_user&gt;\n</code></pre>   To load the AxonOps Java Agent and Zookeeper config changes please either start the Zookeeper service if stopped or restart the Zookeeper service if already running.  <pre><code>sudo usermod -aG &lt;your_kraft_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kraft_user&gt;\n</code></pre>   To load the AxonOps Java Agent and Kafka KRaft config changes please either start the Kafka KRaft service if stopped or restart the Kafka KRaft service if already running.  <pre><code>sudo usermod -aG &lt;your_kraft_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kraft_user&gt;\n</code></pre>   To load the AxonOps Java Agent and Kafka KRaft config changes please either start the Kafka KRaft service if stopped or restart the Kafka KRaft service if already running.  <pre><code>sudo usermod -aG &lt;your_connect_group&gt; axonops\nsudo usermod -aG axonops &lt;your_connect_user&gt;\n</code></pre>   To load the AxonOps Java Agent and Kafka Connect config changes please either:  * Start the Kafka Connect service if stopped. * Restart the Kafka Connect service if already running."},{"location":"installation/agent/docker/","title":"Installing axon-agent for Cassandra in Docker","text":""},{"location":"installation/agent/docker/#installing-axon-agent-for-cassandra-in-docker","title":"Installing axon-agent for Cassandra in Docker","text":"<p>Caveats</p> <ul> <li>Cassandra logs cannot normally be collected by AxonOps as they are sent to stdout and handled by the     Docker logging driver.</li> <li>If axon-agent is running under Docker it assumes that the Cassandra user's GID is 999 as it is in the     official Cassandra images. If this is not the case then AxonOps may not be able to backup the Cassandra data.</li> </ul> <p>To enable the full functionality of the AxonOps agent some directories must be accessible to both the Cassandra and AxonOps Agent processes.</p> Directory Required Description <code>/var/lib/axonops</code> Required Contains UNIX domain sockets, Cassandra agent jars and local data stored by the agent. This directory must be readable and writable by Cassandra and AxonOps <code>/etc/axonops</code> Required Contains the configuration for AxonOps. This directory must be readable by Cassandra and AxonOps <code>/var/log/axonops</code> Required The Cassandra agent will write logs to this directory where they will be buffered and sent to the AxonOps server This directory must be writable by Cassandra and readable by AxonOps <code>/var/lib/cassandra</code> Optional For the backups feature to function correctly the Cassandra data directory must be readable by the AxonOps agent <p>When running Cassandra under Docker it is possible to run the AxonOps agent either on the host or in another  Docker container. When installing on the host, follow the instructions under AxonOps Cassandra agent installation to install the agent and ensure that the appropriate directories are mapped into the Cassandra container.</p>"},{"location":"installation/agent/docker/#example-with-docker-compose","title":"Example with Docker Compose","text":"<p>This example shows running a single Cassandra node and the AxonOps agent under Docker Compose using host volumes to share data between the containers.</p> <pre><code>version: \"3\"\n\nservices:\n  cassandra:\n    image: cassandra:4.0\n    container_name: cassandra\n    restart: always\n    volumes:\n      - ./cassandra:/var/lib/cassandra\n      - ./axonops/var:/var/lib/axonops\n      - ./axonops/etc:/etc/axonops\n      - ./axonops/log:/var/log/axonops\n    ports:\n      - \"9042:9042\"\n    environment:\n      - JVM_EXTRA_OPTS=-javaagent:/var/lib/axonops/axon-cassandra4.0-agent.jar=/etc/axonops/axon-agent.yml\n      - CASSANDRA_CLUSTER_NAME=my-cluster\n\n  axon-agent:\n    image: registry.axonops.com/axonops-public/axonops-docker/axon-agent:latest\n    restart: always\n    environment:\n      # Enter the hostname or IP address of your AxonOps server here\n      - AXON_AGENT_SERVER_HOST=axonops-server.example.com\n    volumes:\n      - ./cassandra:/var/lib/cassandra\n      - ./axonops/var:/var/lib/axonops\n      - ./axonops/etc:/etc/axonops\n      - ./axonops/log:/var/log/axonops\n</code></pre>"},{"location":"installation/agent/install/","title":"AxonOps Agent","text":""},{"location":"installation/agent/install/#axonops-agent-installation","title":"AxonOps Agent Installation","text":"<p>The AxonOps Agent enables collection of:</p> <ul> <li>Metrics</li> <li>Logs</li> <li>Events</li> </ul> <p>The AxonOps Agent also enables the following maintence operations to be performed on the cluster:</p> <ul> <li>Adaptive repairs</li> <li>Backups</li> </ul> <p>See Installing axon-agent for Cassandra in Docker if you are running Cassandra under Docker.</p>"},{"location":"installation/agent/install/#version-compatibility","title":"Version Compatibility","text":"<p>AxonOps Agent is available for the following versions of Apache Casssandra and Apache Kafka:</p>"},{"location":"installation/agent/install/#cassandra","title":"Cassandra","text":"<ul> <li>Apache Cassandra 3.0.x</li> <li>Apache Cassandra 3.11.x</li> <li>Apache Cassandra 4.0.x</li> <li>Apache Cassandra 4.1.x</li> <li>Apache Cassandra 5.0.x</li> </ul>"},{"location":"installation/agent/install/#kafka","title":"Kafka","text":"<ul> <li>Apache Kafa 2.x</li> <li>Apache Kafa 3.x</li> </ul>"},{"location":"installation/agent/install/#setup-the-package-repository","title":"Setup the Package Repository","text":"<p>Select the OS Family</p> <p> </p> <p>Execute the following commands to setup the AxonOps repository:</p> <pre><code>sudo apt-get update\nsudo apt-get install -y curl gnupg ca-certificates\n\ncurl -L https://packages.axonops.com/apt/repo-signing-key.gpg \\\n  | sudo gpg --dearmor -o /usr/share/keyrings/axonops.gpg\n\necho \"deb [arch=arm64,amd64 signed-by=/usr/share/keyrings/axonops.gpg]\\\n  https://packages.axonops.com/apt axonops-apt main\" \\\n  | sudo tee /etc/apt/sources.list.d/axonops-apt.list\nsudo apt-get update\n</code></pre> <pre><code>sudo tee /etc/yum.repos.d/axonops-yum.repo &lt;&lt; EOL\n[axonops-yum]\nname=axonops-yum\nbaseurl=https://packages.axonops.com/yum/\nenabled=1\nrepo_gpgcheck=0\ngpgcheck=0\nEOL\n</code></pre>"},{"location":"installation/agent/install/#select-service-to-configure","title":"Select Service to Configure","text":""},{"location":"installation/agent/install/#install-cassandra-agent","title":"Install Cassandra Agent","text":""},{"location":"installation/agent/install/#select-the-cassandra-version","title":"Select the Cassandra Version","text":""},{"location":"installation/agent/install/#select-the-java-version","title":"Select the Java Version","text":"<p>Install the AxonOps Cassandra Agent and its dependency <code>axon-agent</code>:</p> <pre><code>sudo apt-get install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo apt-get install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo apt-get install axon-cassandra5.0-agent-jdk17\n</code></pre> <pre><code>sudo yum install axon-cassandra3.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra3.11-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.0-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent-jdk8\n</code></pre> <pre><code>sudo yum install axon-cassandra4.1-agent\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk11\n</code></pre> <pre><code>sudo yum install axon-cassandra5.0-agent-jdk17\n</code></pre>"},{"location":"installation/agent/install/#configuration-file-locations","title":"Configuration File Locations","text":""},{"location":"installation/agent/install/#axonops-cassandra-agent","title":"AxonOps Cassandra Agent","text":"<p>The AxonOps Cassandra Agent is the jar that is directly loaded by Cassandra. The AxonOps Cassandra Agent then reaches out directly to the AxonOps Agent binary which contacts the AxonOps Server directly.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-cassandra{version}-agent.jar</code></li> <li>Version number: <code>/usr/share/axonops/axon-cassandra{version}-agent.version</code></li> <li>Copyright: <code>/usr/share/doc/axonops/axon-cassandra{version}-agent/copyright</code></li> <li>Licenses: <code>/usr/share/axonops/licenses/axon-cassandra{version}-agent/</code></li> </ul>"},{"location":"installation/agent/install/#axonops-agent","title":"AxonOps Agent","text":"<p>The AxonOps Agent is a dependency of the AxonOps Cassandra Agent. This binary contacts the AxonOps Server directly while minimizing the memory footprint and CPU utilization of the Cassandra process.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-agent</code></li> <li>Logs: <code>/var/log/axonops/axon-agent.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-agent.service</code></li> </ul>"},{"location":"installation/agent/install/#agent-configuration","title":"Agent Configuration","text":"<p>Update the following lines within <code>/etc/axonops/axon-agent.yml</code>.</p> <p>The highlighted lines should match the <code>host</code> and <code>org</code> keys found within <code>/etc/axonops/axon-server.yml</code>.</p> <pre><code>axon-server:\n    hosts: \"axon-server_endpoint\" # Your axon-server IP or hostname, e.g. axonops.mycompany.com\n    port: 1888 # The default axon-server port is 1888\n\naxon-agent:\n    org: \"my-company\" # Your organisation name\n    # SSL/TLS Settings from AxonOps Agent to AxonOps Server\n    tls:\n        mode: \"disabled\" # disabled, TLS\n        # Only set below if mode is TLS\n        skipVerify: false # Disables CA and Hostname verification\n        caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n        certFile: \"path_to_certs_on_axon_agent_node.crt\"\n        keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\nNTP:\n    host: \"ntp.mycompany.com\" # Your NTP server IP address or hostname \n</code></pre>"},{"location":"installation/agent/install/#ensure-proper-agent-configuration-permissions","title":"Ensure Proper Agent Configuration Permissions","text":"<p>After editing the file, ensure the file permissions for <code>/etc/axonops/axon-agent.yml</code> are set correctly by running the following commmand:</p> <pre><code>sudo chmod 0640 /etc/axonops/axon-agent.yml\n</code></pre>"},{"location":"installation/agent/install/#configure-cassandra","title":"Configure Cassandra","text":"<p>Add the following line at the end of <code>/etc/cassandra/cassandra-env.sh</code>:</p> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.0-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra3.11-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra4.0-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-cassandra4.1-agent.jar=/etc/axonops/axon-agent.yml\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\n</code></pre> <p>If Cassandra was installed using a tarball, the correct path for the <code>cassandra-env.sh</code> will be <code>&lt;Cassandra Installation Directory&gt;/conf/cassandra-env.sh</code>.</p> <p>NB. Make sure this configuration is not overridden by automation tools.</p>"},{"location":"installation/agent/install/#configure-cassandra-user-group","title":"Configure Cassandra user group","text":"<p>Configure the Linux user groups by:</p> <ul> <li>Adding the <code>axonops</code> user to the <code>cassandra</code> user group.</li> <li>Adding the <code>cassandra</code> user to the <code>axonops</code> user group.</li> </ul> <pre><code>CASSANDRA_GROUP=cassandra\nCASSANDRA_USER=cassandra\n\nsudo usermod -aG \"$CASSANDRA_GROUP\" axonops\nsudo usermod -aG axonops \"$CASSANDRA_USER\"\n</code></pre> <p>If Cassandra was setup to use a non-default user or group, <code>CASSANDRA_GROUP</code> and/or <code>CASSANDRA_USER</code> will need be updated accordingly for the above commands to work properly.</p>"},{"location":"installation/agent/install/#uninstall-needrestart-package","title":"Uninstall <code>needrestart</code> Package","text":"<p>Due to recent change with <code>needrestart</code>, as seen in Ubuntu 24.04, uninstalling the <code>needrestart</code> package is currently recommended.</p> <p>Failure to uninstall the <code>needrestart</code> package may cause the Cassandra service to be restarted when updating the <code>axon-agent</code> package.</p>"},{"location":"installation/agent/install/#apply-changes-to-cassandra","title":"Apply Changes to Cassandra","text":"<p>To load the AxonOps Java Agent and Cassandra config changes, run the following command:</p> <pre><code>sudo systemctl restart cassandra\n</code></pre>"},{"location":"installation/agent/install/#install-kafka-agent","title":"Install Kafka Agent","text":""},{"location":"installation/agent/install/#select-the-kafka-version","title":"Select the Kafka Version","text":""},{"location":"installation/agent/install/#select-the-java-version_1","title":"Select the Java Version.","text":"<p>Install the AxonOps Kafka Agent and its dependency <code>axon-agent</code>:</p> <pre><code>sudo apt-get install axon-kafka2-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka3-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka2-agent\n</code></pre> <pre><code>sudo apt-get install axon-kafka3-agent\n</code></pre> <pre><code>sudo yum install axon-kafka2-agent\n</code></pre> <pre><code>sudo yum install axon-kafka3-agent\n</code></pre> <pre><code>sudo yum install axon-kafka2-agent\n</code></pre> <pre><code>sudo yum install axon-kafka3-agent\n</code></pre>"},{"location":"installation/agent/install/#configuration-file-locations_1","title":"Configuration File Locations","text":""},{"location":"installation/agent/install/#axonops-kafka-agent","title":"AxonOps Kafka Agent","text":"<p>The AxonOps Kafka Agent is the jar that is directly loaded by Kafka. The AxonOps Kafka Agent then reaches out directly to the AxonOps Agent binary which contacts the AxonOps Server directly.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-kafka{version}-agent.jar</code></li> <li>Version number: <code>/usr/share/axonops/axon-kafka{version}-agent.version</code></li> <li>Copyright: <code>/usr/share/doc/axonops/axon-kafka{version}-agent/copyright</code></li> <li>Licenses: <code>/usr/share/axonops/licenses/axon-kafka{version}-agent/</code></li> </ul>"},{"location":"installation/agent/install/#axonops-agent_1","title":"AxonOps Agent","text":"<p>The AxonOps Agent is a dependency of the AxonOps Kafka Agent. This binary contacts the AxonOps Server directly while minimizing the memory footprint and CPU utilization of the Kafka process.</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-agent</code></li> <li>Logs: <code>/var/log/axonops/axon-agent.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-agent.service</code></li> </ul>"},{"location":"installation/agent/install/#agent-configuration_1","title":"Agent Configuration","text":"<p>Update the highlighted lines in <code>/etc/axonops/axon-agent.yml</code>.</p> <p>These need to match the config that you have in your <code>axon-server.yml</code> setup.</p> <p> </p> Kafka Broker Zookeeper KRaft Broker KRaft Controller Kafka Connect <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"broker\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"zookeeper\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Optionally specify a rack to group nodes in AxonOps\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"kraft-broker\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"kraft-controller\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Auto-detected from Kafka config, optionally override the rack to group nodes in AxonOps\n  kafka_client:\n    brokers: [\"&lt;host_listener_ip_address_or_fqdn&gt;:&lt;port&gt;&gt;\"] # 10.0.0.2:9092 or 10.20.30.40:9094 or this_is_my_server.domain.com:9093\n    # Authentication Settings\n    sasl:\n      username: &lt;THIS_IS_A_DUMMY_USERNAME_PLEASE_UPDATE&gt;\n      password: &lt;THIS_IS_A_DUMMY_PASSWORD_PLEASE_UPDATE&gt;\n      mechanism: PLAIN # SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER, GSSAPI\n      # For oauth support\n      # oauth:\n      #   token:\n      #   clientId:\n      #   clientSecret:\n      #   tokenEndpoint:\n      #   scope:\n      # For gssapi support\n      # gssapi:\n      #   authType:\n      #   keyTabPath:\n      #   kerberosConfigPath:\n      #   serviceName:\n      #   username:\n      #   password:\n      #   realm:\n      #   enableFast: true\n    # SSL settings for connection to Kafka\n    tls:\n      enabled: true\n      caFilepath: &lt;THIS_IS_A_DUMMY_CA_PATH_PLEASE_UPDATE&gt;\n      insecureSkipTlsVerify: false\n</code></pre> <pre><code>axon-server:\n  hosts: \"agents.axonops.cloud\" # AxonOps SaaS\n  # hosts: \"${AXONOPS_SERVER_HOSTS}\" # AxonOps Server On-Premise Endpoint\n  # port: 1888 # AxonOps Server On-Premise Port (Default is 1888)\n\naxon-agent:\n  key: \"&lt;THIS_IS_A_DUMMY_KEY_PLEASE_UPDATE&gt;\"\n  org: \"&lt;THIS_IS_A_DUMMY_ORG_NAME_PLEASE_UPDATE&gt;\"\n  cluster_name: \"&lt;THIS_IS_A_DUMMY_CLUSTER_NAME_PLEASE_UPDATE&gt;\"\n  tls:\n    mode: \"TLS\" # disabled, TLS\n    #skipVerify: false # Disables CA and Hostname verification\n    #caFile: \"path_to_certs_on_axon_agent_node.crt\" # required if skipVerify is not set and you are using a self-signed cert\n    #certFile: \"path_to_certs_on_axon_agent_node.crt\"\n    #keyFile: \"path_to_key_file_on_axon_agent_node.key\"\n\n# Specify the NTP server IP addresses or hostnames configured for your hosts\n# The port defaults to 123 if not specified.\n# NTP:\n#    hosts:\n#        - \"x.x.x.x:123\"\n# Optionally restrict which commands can be executed by axon-agent.\n# If \"true\", only scripts placed in scripts_location can be executed by axon-agent.\n# disable_command_exec: false\n# If disable_command_exec is true then axon-agent is only allowed to execute scripts\n# under this path\n# scripts_location: /var/lib/axonops/scripts/\n\nkafka:\n  node_type: \"connect\" # broker, kraft-broker, kraft-controller, zookeeper, connect\n  # rack: \"testrack\" # Optionally specify a rack to group nodes in AxonOps\n</code></pre> <p>Set file permissions on /etc/axonops/axon-agent.yml file by executing the following command</p> <pre><code>sudo chmod 0640 /etc/axonops/axon-agent.yml\n</code></pre> <p>Insert the line <code>. /usr/share/axonops/axonops-jvm.options</code> right before the final line in your config file. Look for the last line that starts with <code>exec</code>, as demonstrated in the example below.</p> <p>NB. Please note the period(.) at the beginning of the config line.</p> <p>Example:</p> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka2.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka \"$@\"\n</code></pre> <pre><code>. /usr/share/axonops/axonops-jvm.options\nexec $(dirname $0)/kafka-run-class.sh $EXTRA_ARGS org.apache.kafka.connect.cli.ConnectDistributed \"$@\"\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name zookeeper -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <pre><code>  EXTRA_ARGS=${EXTRA_ARGS-'-name connectDistributed -javaagent:/usr/share/axonops/axon-kafka3.0-agent.jar=/etc/axonops/axon-agent.yml --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED  --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.interceptor=ALL-UNNAMED --add-exports=java.management/com.sun.jmx.interceptor=ALL-UNNAMED'}\n</code></pre> <p>NB. Make sure that this configuration will not get overridden by an automation tool.</p>"},{"location":"installation/agent/install/#configure-kafka","title":"Configure Kafka","text":"Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>"},{"location":"installation/agent/install/#configure-zookeeper","title":"Configure Zookeeper","text":"Edit zookeeper-server-start.sh, usually located in your Zookeeper install path such as:   <p><code>/&lt;Zookeeper_Home&gt;/bin/zookeeper-server-start.sh</code></p>"},{"location":"installation/agent/install/#configure-kraft-broker","title":"Configure KRaft Broker","text":"Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>"},{"location":"installation/agent/install/#configure-kraft-controller","title":"Configure KRaft Controller","text":"Edit kafka-server-start.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/kafka-server-start.sh</code></p>"},{"location":"installation/agent/install/#configure-connect","title":"Configure Connect","text":"Edit connect-distributed.sh, usually located in your Kafka install path such as:   <p><code>/&lt;Kafka_Home&gt;/bin/connect-distributed.sh </code></p>"},{"location":"installation/agent/install/#add-axonops-user-to-kafka-user-group-and-kafka-user-to-axonops-group","title":"Add axonops user to Kafka user group and Kafka user to axonops group","text":"<pre><code>sudo usermod -aG &lt;your_kafka_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kafka_user&gt;\n</code></pre>"},{"location":"installation/agent/install/#startrestart-kafka","title":"Start/Restart Kafka","text":"To load the AxonOps Java Agent and Kafka config changes please either start the Kafka service if stopped restart the Kafka service if already running."},{"location":"installation/agent/install/#add-axonops-user-to-zookeeper-user-group-and-zookeeper-user-to-axonops-group","title":"Add axonops user to Zookeeper user group and Zookeeper user to axonops group","text":"<pre><code>sudo usermod -aG &lt;your_zookeeper_group&gt; axonops\nsudo usermod -aG axonops &lt;your_zookeeper_user&gt;\n</code></pre>"},{"location":"installation/agent/install/#startrestart-zookeeper","title":"Start/Restart Zookeeper","text":"To load the AxonOps Java Agent and Zookeeper config changes please either start the Zookeeper service if stopped or restart the Zookeeper service if already running."},{"location":"installation/agent/install/#add-axonops-user-to-kraft-broker-user-group-and-kraft-broker-user-to-axonops-group","title":"Add axonops user to KRaft Broker user group and KRaft Broker user to axonops group","text":"<pre><code>sudo usermod -aG &lt;your_kraft_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kraft_user&gt;\n</code></pre>"},{"location":"installation/agent/install/#startrestart-kraft-broker","title":"Start/Restart KRaft Broker","text":"To load the AxonOps Java Agent and Kafka KRaft config changes please either start the Kafka KRaft service if stopped or restart the Kafka KRaft service if already running."},{"location":"installation/agent/install/#add-axonops-user-to-kraft-controller-user-group-and-kraft-controller-user-to-axonops-group","title":"Add axonops user to KRaft Controller user group and KRaft Controller user to axonops group","text":"<pre><code>sudo usermod -aG &lt;your_kraft_group&gt; axonops\nsudo usermod -aG axonops &lt;your_kraft_user&gt;\n</code></pre>"},{"location":"installation/agent/install/#startrestart-kraft-controller","title":"Start/Restart KRaft Controller","text":"To load the AxonOps Java Agent and Kafka KRaft config changes please either start the Kafka KRaft service if stopped or restart the Kafka KRaft service if already running."},{"location":"installation/agent/install/#add-axonops-user-to-kafka-connect-user-group-and-kafka-connect-user-to-axonops-group","title":"Add axonops user to Kafka Connect user group and Kafka Connect user to axonops group","text":"<pre><code>sudo usermod -aG &lt;your_connect_group&gt; axonops\nsudo usermod -aG axonops &lt;your_connect_user&gt;\n</code></pre>"},{"location":"installation/agent/install/#startrestart-kafka-connect","title":"Start/Restart Kafka Connect","text":"To load the AxonOps Java Agent and Kafka Connect config changes please either:  * Start the Kafka Connect service if stopped. * Restart the Kafka Connect service if already running."},{"location":"installation/agent/install/#start-the-axonops-agent","title":"Start the AxonOps Agent","text":"<pre><code>sudo systemctl start axon-agent\n</code></pre>"},{"location":"installation/axon-dash/install/","title":"AxonOps Dashboard","text":""},{"location":"installation/axon-dash/install/#axonops-dashboard-installation","title":"AxonOps Dashboard Installation","text":"<p>The AxonOps Dashboard (<code>axon-dash</code>) is a GUI service that is installed as a separate service to AxonOps Server (<code>axon-server</code>). The GUI service can be co-hosted on the same server as the AxonOps Server process, or can be run on a separate server.</p> <p>This section describes the installation process for the GUI service.</p>"},{"location":"installation/axon-dash/install/#installation","title":"Installation","text":"<p>Select the OS Family</p> <p> </p> <p>Execute the following commands to setup the AxonOps GUI for your OS:</p> <pre><code>sudo apt-get update\nsudo apt-get install -y curl gnupg ca-certificates\n\ncurl -L https://packages.axonops.com/apt/repo-signing-key.gpg \\\n  | sudo gpg --dearmor -o /usr/share/keyrings/axonops.gpg\n\necho \"deb [arch=arm64,amd64 signed-by=/usr/share/keyrings/axonops.gpg]\\\n  https://packages.axonops.com/apt axonops-apt main\" \\\n  | sudo tee /etc/apt/sources.list.d/axonops-apt.list\nsudo apt-get update\n\nsudo apt-get install -y axon-dash\n</code></pre> <pre><code>sudo tee /etc/yum.repos.d/axonops-yum.repo &lt;&lt; EOL\n[axonops-yum]\nname=axonops-yum\nbaseurl=https://packages.axonops.com/yum/\nenabled=1\nrepo_gpgcheck=0\ngpgcheck=0\nEOL\n\nsudo yum install axon-dash\n</code></pre>"},{"location":"installation/axon-dash/install/#configuration-file-locations","title":"Configuration File Locations","text":"<p>The following files are installed into the local file system:</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-dash.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-dash</code></li> <li>Logs: <code>/var/log/axonops/axon-dash.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-dash.service</code></li> <li>Copyright : <code>/usr/share/doc/axonops/axon-dash/copyright</code></li> <li>Licenses : <code>/usr/share/axonops/licenses/axon-dash/</code></li> </ul>"},{"location":"installation/axon-dash/install/#configure-axonops-dashboard","title":"Configure AxonOps Dashboard","text":"<p>If AxonOps Server has been installed on a different machine, update the <code>axon-dash</code> configuration file found at <code>/etc/axonops/axon-dash.yml</code> to specify the <code>axon-server</code> listening address:</p> <p></p><pre><code>axon-server:\n  # HTTP endpoint to access axon-server API from axon-dash\n  private_endpoints: \"http://127.0.0.1:8080\"\n  # example: \"/gui\"\n  context_path: \"\"\n</code></pre> Note: The AxonOps Server <code>api_port</code> defaults to <code>8080</code>."},{"location":"installation/axon-dash/install/#configure-axonops-server","title":"Configure AxonOps Server","text":"<p>If AxonOps Dashboard requires being bound and exposed to a different <code>host</code> and <code>port</code>, update the <code>host</code> and/or <code>port</code> values for <code>axon-dash</code> from their defaults within <code>/etc/axonops/axon-dash.yml</code>:</p> <pre><code>axon-dash:\n  host: 127.0.0.1\n  port: 3000\n  https: false\n</code></pre> <p>Subesquently, update the <code>axon_dash_url</code> value within <code>/etc/axonops/axon-server.yml</code>:</p> <pre><code>axon_dash_url: http://127.0.0.1:3000\n</code></pre> <p>Note: The <code>axon-dash</code> address must be accessible from <code>axon-server</code>.</p>"},{"location":"installation/axon-dash/install/#restart-axon-server-to-apply-changes","title":"Restart <code>axon-server</code> to Apply Changes","text":"<pre><code>sudo systemctl restart axon-server\n</code></pre>"},{"location":"installation/axon-dash/install/#start-axonops-dashboard","title":"Start AxonOps Dashboard","text":"<p>The following will start the <code>axon-dash</code> process as the <code>axonops</code> user, which was created during the package installation.</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl start axon-dash\n</code></pre> <p>The default listening address is 0.0.0.0:3000.</p>"},{"location":"installation/axon-dash/install/#setup-ssltls-for-axonops-dashboard","title":"Setup SSL/TLS for AxonOps Dashboard","text":"<p>The AxonOps Dashboard does not support SSL/TLS and needs Nginx to be setup in front of the dashboard.</p>"},{"location":"installation/axon-dash/install/#installing-nginx","title":"Installing Nginx","text":"<p>Install Nginx using the official guide.</p>"},{"location":"installation/axon-dash/install/#configuration-file-locations_1","title":"Configuration File Locations","text":"<p>Most installations of Nginx use the default config location of <code>/etc/nginx/</code>.</p> <p>The default location depends on whether or not the installation is from an archive distribution (tar.gz or zip) or a package distribution (Debian or RPM packages).</p> <p>Based on the installation the default location can be either:</p> <ul> <li><code>/etc/nginx</code></li> <li><code>/usr/local/nginx/conf</code></li> <li><code>/usr/local/etc/nginx</code></li> </ul> <p>For more info on Nginx configuration, read Creating Nginx Configuration Files.</p>"},{"location":"installation/axon-dash/install/#configure-nginx","title":"Configure Nginx","text":"<p>Edit <code>/etc/nginx/nginx.conf</code> and add/update the following lines:</p> <pre><code>server {\n  listen &lt;ip&gt;:443 ssl;\n\n  server_name &lt;hostname&gt;;\n\n  client_max_body_size 100M;\n\n  root /usr/share/nginx;\n  index index.html;\n\n  ssl_certificate     /full/path/to/ssl_cert;\n  ssl_certificate_key /full/path/to/ssl_key/;\n  ssl_protocols       TLSv1.2 TLSv1.3;\n\n  location / {\n    proxy_pass http://localhost:3000; #Default AxonOps-Dash port\n  }\n}\n</code></pre>"},{"location":"installation/axon-dash/install/#next-installing-axonops-agents","title":"Next - Installing AxonOps Agents","text":"<p>Now that the AxonOps Dashboard is installed, we will  install the AxonOps Agents to populate the dashboard.</p>"},{"location":"installation/axon-server/axonserver_install/","title":"AxonOps Server","text":""},{"location":"installation/axon-server/axonserver_install/#axonops-server-installation","title":"AxonOps Server Installation","text":""},{"location":"installation/axon-server/axonserver_install/#installation","title":"Installation","text":"<p>Select the OS Family</p> <p> </p> <p>Execute the following commands to setup the AxonOps repository and install AxonOps Server:</p> <pre><code>sudo apt-get update\nsudo apt-get install -y curl gnupg ca-certificates\n\ncurl -L https://packages.axonops.com/apt/repo-signing-key.gpg \\\n  | sudo gpg --dearmor -o /usr/share/keyrings/axonops.gpg\n\necho \"deb [arch=arm64,amd64 signed-by=/usr/share/keyrings/axonops.gpg]\\\n  https://packages.axonops.com/apt axonops-apt main\" \\\n  | sudo tee /etc/apt/sources.list.d/axonops-apt.list\nsudo apt-get update\n\nsudo apt-get install axon-server\n</code></pre> <pre><code>sudo tee /etc/yum.repos.d/axonops-yum.repo &lt;&lt; EOL\n[axonops-yum]\nname=axonops-yum\nbaseurl=https://packages.axonops.com/yum/\nenabled=1\nrepo_gpgcheck=0\ngpgcheck=0\nEOL\nsudo yum install axon-server\n</code></pre>"},{"location":"installation/axon-server/axonserver_install/#configuration-file-locations","title":"Configuration File Locations","text":"<p>The following files are installed into the local file system:</p> <ul> <li>Configuration File: <code>/etc/axonops/axon-server.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-server</code></li> <li>Logs: <code>/var/log/axonops/axon-server.log</code></li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-server.service</code></li> <li>Copyright : <code>/usr/share/doc/axonops/axon-server/copyright</code></li> <li>Licenses : <code>/usr/share/axonops/licenses/axon-server/</code></li> </ul>"},{"location":"installation/axon-server/axonserver_install/#configure-axonops-server","title":"Configure AxonOps Server","text":""},{"location":"installation/axon-server/axonserver_install/#configure-elasticsearch","title":"Configure Elasticsearch","text":"<p>Confirm the <code>network.host</code> and <code>http.port</code> values within <code>/etc/elasticsearch/elasticsearch.yml</code> for the dedicated Elasticsearch instance correspond to the values for <code>search_db</code> within <code>/etc/axonops/axon-server.yml</code>.</p> <p>The following example works for the default Single-Server configuration:</p> <pre><code>search_db:\n  hosts:\n    - http://localhost:9200\n</code></pre>"},{"location":"installation/axon-server/axonserver_install/#basic-auth-in-elasticsearch","title":"Basic Auth in Elasticsearch","text":"<p>If using Basic Auth with the default Single-Server configuration, ensure <code>search_db</code> values are setup using the following format:</p> <pre><code>search_db:\n  hosts:\n    - http://localhost:9200\n\n  username: opensearch-user\n  password: my-strong-password\n</code></pre> <p>Update the above <code>username</code> and <code>password</code> with the dedicated service account/user created in Elasticsearch.</p>"},{"location":"installation/axon-server/axonserver_install/#load-balancing-for-elasticsearch","title":"Load Balancing for Elasticsearch","text":"<p>By default, AxonOps Server will only connect to the Elasticsearch nodes listed in its configuration and will not automatically discover other nodes in the cluster. To enable AxonOps' node discovery, set <code>search_db.discover_nodes:true</code> which will utilize the full list of discovered nodes to round-robin requests sent to Elasticsearch.</p> <p>When setting up load balancing nodes or infrastructure in front of Elasticsearch, the load balancer has smart load balancing capabilites and AxonOps' node discovery is not required.</p>"},{"location":"installation/axon-server/axonserver_install/#setup-axonops-license","title":"Setup AxonOps License","text":"<p>This section is for Enterprise plan clients and is not needed on the Free Forever plan.</p> <p>Ensure the following values are set to unlock the Enterprise features of AxonOps:</p> <pre><code>license_key: license-key\norg_name: my-company\n</code></pre> <p>Note: Both values need to match the information provided during the Enterprise onboarding process and are case-sensitive. These values cannot be found on console.axonops.com.</p>"},{"location":"installation/axon-server/axonserver_install/#configure-cassandra-as-metrics-store","title":"Configure Cassandra as Metrics Store","text":"<p>To use Cassandra as AxonOps' metrics store, specify at least one CQL host within the <code>cql_hosts</code> key within <code>/etc/axonops/axon-server.yml</code>.</p> <p>For better performance on larger clusters (10+ nodes), it is recommended to use Cassandra as a Metrics Storage engine.</p>"},{"location":"installation/axon-server/axonserver_install/#sample-configuration-file","title":"Sample Configuration File","text":"<p>The following is a sample configuration file that can be used as a quick reference:</p> <pre><code># axon-server listening address (used by axon-agents for connections)\n# (env variable: AXONSERVER_HOST)\nhost: 0.0.0.0\n# axon-server listening port for agent connections\nagents_port: 1888\n\n# axon-server listening address\n# (env variable: used by axon-dash for connections)\napi_host: 127.0.0.1\n\n# axon-server HTTP API listening port (used by axon-dash)\n# (AXONSERVER_PORT)\napi_port: 8080\n\nsearch_db:\n  # Elasticsearch endpoint\n  # (env variable:ELASTIC_HOSTS, comma separated list)\n  hosts:\n    - http://localhost:9200\n\n  username: opensearch-user\n  password: my-strong-password\n\n  # SSL/TLS config for Elasticsearch\n  skip_verify: false # Disables CA and Hostname verification\n\n  # Configure the number of replicas per shard. Defaults to 0 if not specified.\n  replicas: 0\n\n  # Configure the number of shards per index.\n  # The default value of 1 is recommended for most use cases\n  shards: 1\n\n  # Enable/disable Elasticsearch cluster discovery (sniffing).\n  # Defaults to false, set to true to enable\n  # Allows more nodes to be added to Elasticsearch for Metrics storage\n  # without having to restart Axon-Server\n  # and update search_db.hosts with all the ELK node values.\n  discover_nodes: false\n\n  # How often to perform cluster discovery.\n  # Default is every 5 minutes if this is omitted\n  discover_nodes_interval: 1m\n\n  max_results: 1000\n\n#integrations_proxy: # proxy endpoint for integrations. (INTEGRATIONS_PROXY)\n\n# AxonOps licensing\nlicense_key: license-key\norg_name: my-company\n\n# SSL/TLS Settings for AxonOps Agent connections\ntls:\n  mode: \"disabled\" # disabled, TLS\n  # Only set below if mode is TLS\n  skipVerify: false # Disables CA and Hostname verification\n  caFile: \"path_to_certs_on_axonops_server.crt\" # required if skipVerify is not set and you are using a self-signed cert\n  certFile: \"path_to_certs_on_axonops_server.crt\"\n  keyFile: \"path_to_key_file_on_axonops_server.key\"\n\n# For better performance on large clusters, you can use a CQL store for the metrics.\n# To opt-in for CQL metrics storage, just specify at least one CQL host.\n# We do recommend to specify a NetworkTopologyStrategy for cql_keyspace_replication\n#cql_hosts: #  (CQL_HOSTS, comma separated list)\n#  - 192.168.0.10:9042\n#  - 192.168.0.11:9042\n#cql_username: \"cassandra\" # (CQL_USERNAME)\n#cql_password: \"cassandra\" # (CQL_PASSWORD)\n#cql_local_dc: datacenter1 # (CQL_LOCAL_DC)\n#cql_ssl: false # (CQL_SSL)\n#cql_skip_verify: false  # (CQL_SSL_SKIP_VERIFY)\n#cql_ca_file: /path/to/ca_file  # (CQL_CA_FILE)\n#cql_cert_file: /path/to/cert_file  # (CQL_CERT_FILE)\n#cql_key_file: /path/to/key_file  # (CQL_KEY_FILE)\n#cql_autocreate_tables: true # (CQL_AUTO_CREATE_TABLES) this will tell axon-server to automatically create the metrics tables (true is recommended)\n#cql_keyspace_replication: \"{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\" # (CQL_KS_REPLICATION) keyspace replication for the metrics tables\n#cql_read_consistency: \"LOCAL_ONE\" # (CQL_READ_CONSISTENCY) #One of the following:  ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE\n#cql_write_consistency: \"LOCAL_ONE\" # (CQL_WRITE_CONSISTENCY) #One of the following:    ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE\n\naxon-dash: # This must point to the axon-dash address accessible from axon-server\n  host: 127.0.0.1\n  port: 3000\n  https: false\n\nalerting:\n# How long to wait before sending a notification again if it has already\n# been sent successfully for an alert. (Usually ~3h or more).\n  notification_interval: 3h\n\n# Default retention settings, most can be overridden from the frontend\nretention:\n  events: 8w # logs and events retention. Must be expressed in weeks (w)\n  metrics:\n      high_resolution: 14d # High frequency metrics. Must be expressed in days (d)\n      med_resolution: 12w # Must be expressed in weeks (w)\n      low_resolution: 12M # Must be expressed in months (M)\n      super_low_resolution: 2y # Must be expressed in years (y)\n  backups: # Those are use as defaults but can be overridden from the UI\n    local: 10d\n    remote: 30d\n</code></pre>"},{"location":"installation/axon-server/axonserver_install/#start-the-axonops-server","title":"Start the AxonOps Server","text":"<p>This following will start the <code>axon-server</code> process as the <code>axonops</code> user, which was created during the package installation. The default listening address is 0.0.0.0:8080.</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl start axon-server\nsudo systemctl status axon-server\n</code></pre>"},{"location":"installation/axon-server/axonserver_install/#next-install-axonops-dashboard","title":"Next - Install AxonOps Dashboard","text":"<p>Now that AxonOps Server (<code>axon-server</code>) is installed, you can start installing the GUI for it: AxonOps Dashboard (axon-dash).</p>"},{"location":"installation/axon-server/install/","title":"Install","text":""},{"location":"installation/axon-server/install/#step-3-axon-server-configurations","title":"Step 3 - axon-server configurations","text":"<p>Make sure elastic_host and elastic_port are corresponding to your Elasticsearch instance.</p> <p>Basic Auth in Elasticsearch </p> <ul> <li>Create a user that has a dedicated role and username password.</li> <li>Please dont use any of the built in users for Elasticsearch.</li> </ul> <p>To create users please refer to the Elasticsearch docs here</p> <p>AxonOps Server configuration file location : <code>/etc/axonops/axon-server.yml</code></p> <pre><code>host: 0.0.0.0  # axon-server listening address (used by axon-agents for connections) (env variable: AXONSERVER_HOST)\nagents_port: 1888 # axon-server listening port for agent connections \n\napi_host: 127.0.0.1 # axon-server listening address (used by axon-dash for connections)\napi_port: 8080 # axon-server HTTP API listening port (used by axon-dash) (AXONSERVER_PORT)\n\nelastic_hosts: #\u00a0Elasticsearch endpoint (env variable:ELASTIC_HOSTS, comma separated list)\n  - http://localhost:9200\n# SSL/TLS config for Elasticsearch\n# elastic_hosts:\n# - https://username:password@ip.or.hostname\n# - https://username:password@ip.or.hostname\n# - https://username:password@ip.or.hostname\n# elastic_skipVerify: true # Disables CA and Hostname verification\n\n# Used by Axon-Server to auto discover Elasticsearch nodes in a cluster.\n# Allows more nodes to be added to Elasticsearch for Metrics storage without having to restart Axon-Server and update elastic_hosts with all the ELK node values.\n#\u00a0elastic_discover_nodes: true # Default = true\n\n#integrations_proxy: # proxy endpoint for integrations. (INTEGRATIONS_PROXY)\n\n# AxonOps licensing\nlicense_key: license-key\norg_name: my-company\n\n# SSL/TLS Settings for AxonOps Agent connections\ntls:\n  mode: \"disabled\" # disabled, TLS\n  # Only set if mode is TLS\n  skipVerify: false # Disables CA and Hostname verification\n  caFile: \"path_to_certs_on_axonops_server.crt\"\n  certFile: \"path_to_certs_on_axonops_server.crt\"\n  keyFile: \"path_to_key_file_on_axonops_server.key\"\n\n# For better performance on large clusters, you can use a CQL store for the metrics.\n# To opt-in for CQL metrics storage, just specify at least one CQL host.\n# We do recommend to specify a NetworkTopologyStrategy for cql_keyspace_replication\n#cql_hosts: #  (CQL_HOSTS, comma separated list)\n#  - 192.168.0.10:9042\n#  - 192.168.0.11:9042\n#cql_username: \"cassandra\" # (CQL_USERNAME)\n#cql_password: \"cassandra\" # (CQL_PASSWORD)\n#cql_local_dc: datacenter1 # (CQL_LOCAL_DC)\n#cql_ssl: false # (CQL_SSL)\n#cql_skip_verify: false  # (CQL_SSL_SKIP_VERIFY)\n#cql_ca_file: /path/to/ca_file  # (CQL_CA_FILE)\n#cql_cert_file: /path/to/cert_file  # (CQL_CERT_FILE)\n#cql_key_file: /path/to/key_file  # (CQL_KEY_FILE)\n#cql_proto_version: 4  # (CQL_PROTO_VERSION)\n#cql_max_concurrent_reads: 1000  # (CQL_MAX_CONCURRENT_READS)\n#cql_batch_size: 1  # (CQL_BATCH_SIZE)\n#cql_page_size: 10  # (CQL_PAGE_SIZE)\n#cql_autocreate_tables: true # (CQL_AUTO_CREATE_TABLES) this will tell axon-server to automatically create the metrics tables (true is recommended)\n#cql_keyspace_replication: \"{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\" # (CQL_KS_REPLICATION) keyspace replication for the metrics tables\n#cql_retrypolicy_numretries: 3  # (CQL_RETRY_POLICY_NUM_RETRIES)\n#cql_retrypolicy_min: 1s  # (CQL_RETRY_POLICY_MIN)\n#cql_retrypolicy_max: 10s  # (CQL_RETRY_POLICY_MAX)\n#cql_reconnectionpolicy_maxretries: 10 # (CQL_RECONNECTION_POLICY_MAX_RETRIES)\n#cql_reconnectionpolicy_initialinterval: 1s # (CQL_RECONNECTION_POLICY_INITIAL_INTERVAL)\n#cql_reconnectionpolicy_maxinterval: 10s # (CQL_RECONNECTION_POLICY_MAX_INTERVAL)\n#cql_metrics_cache_max_size_mb: 100  #MB # (CQL_METRICS_CACHE_MAX_SIZE_MB)\n#cql_read_consistency: \"LOCAL_ONE\" # (CQL_READ_CONSISTENCY) #One of the following:  ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE\n#cql_write_consistency: \"LOCAL_ONE\" # (CQL_WRITE_CONSISTENCY) #One of the following:    ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE\n#cql_lvl1_compaction_window_size: 12 # (CQL_LVL1_COMPACTION_WINDOW_SIZE)\n#cql_lvl2_compaction_window_size: 1 # (CQL_LVL2_COMPACTION_WINDOW_SIZE)\n#cql_lvl3_compaction_window_size: 1 # (CQL_LVL3_COMPACTION_WINDOW_SIZE)\n#cql_lvl4_compaction_window_size: 10 # (CQL_LVL4_COMPACTION_WINDOW_SIZE)\n#cql_lvl5_compaction_window_size: 120 # (CQL_LVL5_COMPACTION_WINDOW_SIZE)\n\naxon-dash: # This must point to the axon-dash address accessible from axon-server\n  host: 127.0.0.1\n  port: 3000\n  https: false\n\nalerting:\n# How long to wait before sending a notification again if it has already\n# been sent successfully for an alert. (Usually ~3h or more).\n  notification_interval: 3h\n\n# Default retention settings, most can be overridden from the frontend\nretention:\n  events: 8w # logs and events retention. Must be expressed in weeks (w)\n  metrics:\n      high_resolution: 14d # High frequency metrics. Must be expressed in days (d)\n      med_resolution: 12w # Must be expressed in weeks (w)\n      low_resolution: 12M # Must be expressed in months (M)\n      super_low_resolution: 2y # Must be expressed in years (y)\n  backups: # Those are use as defaults but can be overridden from the UI\n    local: 10d\n    remote: 30d\n\n\n# Storage options for PDF reports\n# Override the default local path of /var/lib/axonops/reports\n#report_storage_path: /my/reports/storage/directory\n\n# Alternatively store PDF reports in an object store by providing report_storage_config\n#report_storage_path: my-reports-s3-bucket/reports-folder\n#report_storage_config:\n#  type: s3\n#  provider: AWS\n#  access_key_id: MY_ACCESS_KEY_ID\n#  secret_access_key: MY_SECRET_ACCESS_KEY\n#  region: us-east-1\n#  acl: private\n#  server_side_encryption: AES256\n#  storage_class: STANDARD\n</code></pre> <p>For better performances on large clusters (100+ nodes), you can use a CQL store for the metrics such as Cassandra. To opt-in for CQL metrics storage, specify at least one CQL host with axon-server configuration.</p>"},{"location":"installation/axon-server/install/#step-4-start-the-server","title":"Step 4 - Start the server","text":"<pre><code>sudo systemctl daemon-reload\nsudo systemctl start axon-server\nsudo systemctl status axon-server\n</code></pre> <p>This will start the <code>axon-server</code> process as the <code>axonops</code> user, which was created during the package installation.  The default listening address is <code>0.0.0.0:8080</code>.</p>"},{"location":"installation/axon-server/install/#package-details","title":"Package details","text":"<ul> <li>Configuration File: <code>/etc/axonops/axon-server.yml</code></li> <li>Binary: <code>/usr/share/axonops/axon-server</code></li> <li>Logs: <code>/var/log/axonops/axon-server.log</code> </li> <li>Systemd service: <code>/usr/lib/systemd/system/axon-server.service</code></li> <li>Copyright : <code>/usr/share/doc/axonops/axon-server/copyright</code></li> <li>Licenses : <code>/usr/share/axonops/licenses/axon-server/</code></li> </ul>"},{"location":"installation/axon-server/install/#next-installing-axon-dash","title":"Next - Installing axon-dash","text":"<p>Now axon-server is installed, you can start installing the GUI for it: axon-dash</p>"},{"location":"installation/axon-server/metricsdatabase/","title":"Cassandra as Metrics store","text":""},{"location":"installation/axon-server/metricsdatabase/#using-cassandra-as-a-metrics-store","title":"Using Cassandra as a Metrics Store","text":""},{"location":"installation/axon-server/metricsdatabase/#prerequisites","title":"Prerequisites","text":"<p>A dedicated Cassandra cluster is required to use Cassandra as AxonOps' metrics store. Using a Cassandra cluster with at least 3 nodes is recommended.</p> <p>For better performance on larger clusters (10+ nodes), it is recommended to use Cassandra as a Metrics Storage engine.</p> <p>Currently supported versions of Cassandra include:</p> <ul> <li>Latest GA Version</li> <li>Previous Stable Version</li> <li>Older Stable Version</li> </ul> <p>For more information on Cassandra versioning, see the Cassandra Downloads Page.</p>"},{"location":"installation/axon-server/metricsdatabase/#update-axon-serveryml","title":"Update axon-server.yml","text":"<p>To use a Cassandra cluster as the AxonOps metrics store, specify CQL hosts in <code>axon-server.yml</code>:</p> <pre><code>cql_hosts :\n    - 192.168.0.1:9042\n    - 192.168.0.2:9042\n    ...\n</code></pre> <p>By default, the AxonOps server automatically creates the necessary keyspace and tables. You can override this behavior by specifying the following fields in <code>axon-server.yml</code>:</p> <pre><code>cql_autocreate_tables : false\ncql_keyspace : \"axonops\"\ncql_keyspace_replication : \"{ 'class' : 'NetworkTopologyStrategy', 'dc1' : 3 }\"\n</code></pre> <p>Setting up at least a 3 nodes cluster with <code>NetworkTopologyStrategy</code> and a replication factor of <code>3</code> is recommended.</p>"},{"location":"installation/axon-server/metricsdatabase/#connecting-to-an-encrypted-cassandra-metrics-store","title":"Connecting to an Encrypted Cassandra Metrics Store","text":"<p>Setting up a Secured Socket Layer (SSL) connection to Cassandra is recommended.</p> <p>When connecting to Cassandra using SSL, update the following fields in <code>axon-server.yml</code>:</p> <pre><code>cql_ssl: true\ncql_skip_verify: false\ncql_ca_file: '/path/to/ca_cert'\ncql_cert_file: '/path/to/cert_file'\ncql_key_file: '/path/to/key_file'\n</code></pre>"},{"location":"installation/axon-server/metricsdatabase/#additional-cql-fields","title":"Additional CQL fields","text":"<p>Additional CQL fields are available within <code>axon-server.yml</code>, as required:</p> <pre><code>cql_proto_version int                   \ncql_batch_size  int                   \ncql_page_size int                   \ncql_local_dc string                \ncql_username string                \ncql_password string                \ncql_max_concurrent_reads int                   \ncql_retrypolicy_numretries int                   \ncql_retrypolicy_min string \"1s\"\ncql_retrypolicy_max string \"10s\"\ncql_reconnectionpolicy_maxretries int                   \ncql_reconnectionpolicy_initialinterval string \"1s\"\ncql_reconnectionpolicy_maxinterval string  \"10s\"                     \ncql_read_consistency string (controls the consistency of read operations, defaults to LOCAL_ONE)              \ncql_write_consistency string (controls the consistency of write operations, defaults to LOCAL_ONE)               \ncql_lvl1_compaction_window_size int (used for the table named 'metrics5' when you let axonserver managing the tables automatically)                  \ncql_lvl2_compaction_window_size int (used for the table named 'metrics60' when you let axonserver managing the tables automatically)                  \ncql_lvl3_compaction_window_size int (used for the table named 'metrics720' when you let axonserver managing the tables automatically)                  \ncql_lvl4_compaction_window_size int (used for the table named 'metrics7200' when you let axonserver managing the tables automatically)                  \ncql_lvl5_compaction_window_size int (used for the table named 'metrics86400' when you let axonserver managing the tables automatically)                  \n</code></pre>"},{"location":"installation/axon-server/metricsdatabase/#create-axonops-schema","title":"Create AxonOps Schema","text":"<p>The default metrics keyspace/table definition can be found below.</p> <pre><code>CREATE KEYSPACE axonops WITH\n    replication = {'class': 'NetworkTopologyStrategy', 'dc1': '3'};\n\nCREATE TABLE v2metrics5 (\n    orgid text,\n    clusterhash bigint,\n    metricid bigint,\n    time int,\n    value float,\n    PRIMARY KEY ((orgid, clusterhash, metricid), time)\n) WITH CLUSTERING ORDER BY (time DESC)\n    AND caching = {'keys': 'ALL', 'rows_per_partition': '256'}\n    AND compaction = {'class': 'TimeWindowCompactionStrategy',\n        'compaction_window_size': '1', 'compaction_window_unit': 'DAYS',\n        'max_threshold': '32', 'min_threshold': '4'}\n    AND default_time_to_live = 604800\n    AND comment = '7 days retention for 5 seconds resolution metrics';\n\nCREATE TABLE v2metrics60 (\n    orgid text,\n    clusterhash bigint,\n    metricid bigint,\n    time int,\n    value float,\n    PRIMARY KEY ((orgid, clusterhash, metricid), time)\n) WITH CLUSTERING ORDER BY (time DESC)\n    AND caching = {'keys': 'ALL', 'rows_per_partition': '256'}\n    AND compaction = {'class': 'TimeWindowCompactionStrategy',\n        'compaction_window_size': '1', 'compaction_window_unit': 'DAYS',\n        'max_threshold': '32', 'min_threshold': '4'}\n    AND default_time_to_live = 2592000\n    AND comment = '30 days retention for 60 seconds resolution metrics';\n\nCREATE TABLE v2metrics720 (\n    orgid text,\n    clusterhash bigint,\n    metricid bigint,\n    time int,\n    value float,\n    PRIMARY KEY ((orgid, clusterhash, metricid), time)\n) WITH CLUSTERING ORDER BY (time DESC)\n    AND caching = {'keys': 'ALL', 'rows_per_partition': '256'}\n    AND compaction = {'class': 'TimeWindowCompactionStrategy',\n        'compaction_window_size': '4', 'compaction_window_unit': 'DAYS',\n        'max_threshold': '32', 'min_threshold': '4'}\n    AND default_time_to_live = 5184000\n    AND comment = '60 days retention for 720 seconds resolution metrics';\n\nCREATE TABLE v2metrics7200 (\n    orgid text,\n    clusterhash bigint,\n    metricid bigint,\n    time int,\n    value float,\n    PRIMARY KEY ((orgid, clusterhash, metricid), time)\n) WITH CLUSTERING ORDER BY (time DESC)\n    AND caching = {'keys': 'ALL', 'rows_per_partition': '256'}\n    AND compaction = {'class': 'TimeWindowCompactionStrategy',\n        'compaction_window_size': '30', 'compaction_window_unit': 'DAYS',\n        'max_threshold': '32', 'min_threshold': '4'}\n    AND default_time_to_live = 15552000\n    AND comment = '180 days retention for 7200 seconds resolution metrics';\n\nCREATE TABLE v2metrics86400 (\n    orgid text,\n    clusterhash bigint,\n    metricid bigint,\n    time int,\n    value float,\n    PRIMARY KEY ((orgid, clusterhash, metricid), time)\n) WITH CLUSTERING ORDER BY (time DESC)\n    AND caching = {'keys': 'ALL', 'rows_per_partition': '365'}\n    AND compaction = {'class': 'TimeWindowCompactionStrategy',\n        'compaction_window_size': '60', 'compaction_window_unit': 'DAYS',\n        'max_threshold': '32', 'min_threshold': '4'}\n    AND default_time_to_live = 31536000\n    AND comment = '365 days retention for 86400 seconds resolution metrics';\n</code></pre>"},{"location":"installation/compat_matrix/compat_matrix/","title":"Interoperability Matrix","text":""},{"location":"installation/compat_matrix/compat_matrix/#axonops-server","title":"AxonOps Server","text":"Operating Systems Target Architecture RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04, 22.04], Debian [10,11,12] x86_64"},{"location":"installation/compat_matrix/compat_matrix/#axonops-gui-server","title":"AxonOps GUI Server","text":"Operating Systems Target Architecture RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04, 22.04], Debian [10,11,12] x86_64"},{"location":"installation/compat_matrix/compat_matrix/#axonops-cassandra-agent","title":"AxonOps Cassandra Agent","text":"System AxonOps Cassandra Agent Name Java Versions Operating Systems Target Architecture Cassandra 3.0.x axon-cassandra3.0-agent Java 8 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04, 22.04], Debian [11,12] x86_64, arm64 Cassandra 3.11.x axon-cassandra3.11-agent Java 8 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04, 22.04], Debian [11,12] x86_64, arm64 Cassandra 4.0.x axon-cassandra4.0-agent Java 11 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04, 22.04], Debian [11,12] x86_64, arm64 Cassandra 4.0.x axon-cassandra4.0-agent-jdk8 Java 8 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04, 22.04], Debian [11,12] x86_64, arm64 Cassandra 4.1.x axon-cassandra4.1-agent Java 11 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04, 22.04], Debian [11,12] x86_64, arm64 Cassandra 4.1.x axon-cassandra4.1-agent-jdk8 Java 8 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04, 22.04], Debian [11,12] x86_64, arm64 Cassandra 5.0.x axon-cassandra5.0-agent-jdk11 Java 11 RedHat [7,8], CentOS [7,8], Ubuntu [18.04, 20.04, 22.04], Debian [11,12] x86_64, arm64"},{"location":"installation/compat_matrix/compat_matrix/#java-versions","title":"Java Versions","text":"<ul> <li>Oracle Java Standard Edition 8 </li> <li>Oracle Java Standard Edition 11 (Long Term Support)</li> <li>OpenJDK 8</li> <li>OpenJDK 11</li> </ul>"},{"location":"installation/dse-agent/install/","title":"axon-java-agent for DSE installation","text":""},{"location":"installation/dse-agent/install/#axon-java-agent-for-dse-installation","title":"axon-java-agent for DSE installation","text":"<p>This agent will enable metrics collection from DSE and enable adaptive repairs and backups.</p>"},{"location":"installation/dse-agent/install/#prerequisites","title":"Prerequisites","text":"<p>DSE agent needs axon-agent to be installed and configured properly. If not installed already, please go to axon-agent installation  page.</p>"},{"location":"installation/dse-agent/install/#setup-axon-agent-for-dse","title":"Setup axon-agent for DSE","text":"<p>You'll need the specify/update the following lines from axon-agent.yml located in <code>/etc/axonops/axon-agent.yml</code>:</p> <p></p><pre><code>axon-server:\n    hosts: \"axon-server_endpoint\" # Specify axon-server endpoint\n\naxon-agent:\n    host: 0.0.0.0 # axon-agent listening address for it's OpenTSDB endpoint\n    port: 9916 # axon-agent listening port for it's OpenTSDB endpoint\n    org: \"your_organisation_name\" # Specify your organisation name\n    standalone_mode: false\n    type: \"dse\"\n    #cluster_name: \"standalone\" # comment that line\n    ssl: false # SSL flag for it's OpenTSDB endpoint\n</code></pre> * Set <code>standalone_mode</code> to false * Set <code>type</code> to dse * Don't forget to comment or remove the <code>cluster_name</code> as it will be deduced from DSE configuration. * Don't forget to specify axon-server host and port if that's not already specified."},{"location":"installation/dse-agent/install/#dse-agent-installation","title":"DSE agent installation","text":"<p>Make sure the <code>{version}</code> of your DSE and DSE agent are compatible from the compatibility matrix. </p>"},{"location":"installation/dse-agent/install/#centos-redhat-installer","title":"CentOS / RedHat installer","text":"<pre><code>sudo yum install &lt;TODO&gt;\n</code></pre>"},{"location":"installation/dse-agent/install/#debian-ubuntu-installer","title":"Debian / Ubuntu installer","text":"<pre><code>sudo apt-get install &lt;TODO&gt;\n</code></pre>"},{"location":"installation/dse-agent/install/#package-details","title":"Package details","text":"<ul> <li>Configuration File: <code>/etc/axonops/axon-java-agent.yml</code></li> <li>Binary: <code>usr/share/axonops/axon-dse{version}-agent-1.0.jar</code></li> <li>Version number: <code>usr/share/axonops/axon-dse{version}-agent-1.0.version</code></li> </ul>"},{"location":"installation/dse-agent/install/#configure-dse","title":"Configure DSE","text":"<p>Edit <code>cassandra-env.sh</code> usually located in your dse install path such as <code>/&lt;path_to_DSE&gt;/resources/cassandra/conf/cassandra-env.sh</code> and add at the end of the file the following line:</p> <pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-dse{version}-agent-1.0.jar=/etc/axonops/axon-java-agent.yml\"\n</code></pre> <p>example: </p><pre><code>JVM_OPTS=\"$JVM_OPTS -javaagent:/usr/share/axonops/axon-dse6.0.4-agent-1.0.jar=/etc/axonops/axon-java-agent.yml\"\n</code></pre>"},{"location":"installation/dse-agent/install/#start-dse","title":"Start DSE","text":"<p>All you need to do now is start DSE.</p>"},{"location":"installation/dse-agent/install/#configuration-defaults","title":"Configuration defaults","text":"<pre><code>tier0: # metrics collected every 5 seconds\n    metrics:\n        jvm_:\n          - \"java.lang:*\"\n        cas_:\n          - \"org.apache.cassandra.metrics:*\"\n          - \"org.apache.cassandra.net:type=FailureDetector\"\n          - \"com.datastax.bdp:type=dsefs,*\"\n\ntier1:\n    frequency: 300 # metrics collected every 300 seconds (5m)\n    metrics:\n        cas_:\n          - \"org.apache.cassandra.metrics:name=EstimatedPartitionCount,*\"\n\n#tier2:\n#    frequency: 3600 # 1h\n\n#tier3:\n#    frequency: 86400 # 1d\n\nblacklist: #\u00a0You can blacklist metrics based on MBean query pattern\n  - \"org.apache.cassandra.metrics:type=ColumnFamily,*\" # dup of tables\n  - \"org.apache.cassandra.metrics:name=SnapshotsSize,*\" # generally takes time\n\nfree_text_blacklist: #\u00a0You can blacklist metrics based on Regex pattern\n  - \"org.apache.cassandra.metrics:type=ThreadPools,path=internal,scope=Repair#.*\"\n\nwarningThresholdMillis: 100 # This will warn in logs when a MBean takes longer than the specified value.\n\nwhitelisted_clients: # Whitelist for CQL connections\n  - \"127.0.0.1\"\n  - \"^*.*.*.*\"\n</code></pre>"},{"location":"installation/elasticsearch/elastic/","title":"Elastic","text":""},{"location":"installation/elasticsearch/elastic/#configuration-file-locations","title":"Configuration File Locations","text":"<p>Most installations of Elasticsearch have the default configuration location at <code>/etc/elasticsearch/</code>.</p> <p>The default location depends on whether the installation is from an archive distribution (.tar.gz or .zip file) or a package distribution (Debian or RPM packages). For more info on Elasticsearch configuration, please read Configuring Elasticsearch.</p> <p>All commands on this page assume Elasticsearch was installed via a Debian or RPM package.</p>"},{"location":"installation/elasticsearch/elastic/#other-default-locations","title":"Other Default Locations","text":"<p>Depending on the installation method the default location for Elasticsearch configuration and binary files can change. Use these Elasticsearch docs for more information:</p> <ul> <li>Tarball Installation</li> <li>Debian Package</li> <li>RPM Package</li> </ul>"},{"location":"installation/elasticsearch/elastic/#configure-elasticsearch","title":"Configure Elasticsearch","text":""},{"location":"installation/elasticsearch/elastic/#increase-bulk-queue-size","title":"Increase Bulk Queue Size","text":"<p>Increase the bulk queue size of Elasticsearch by running the following command:</p> <pre><code>echo 'thread_pool.write.queue_size: 2000' \\\n    | sudo tee --append /etc/elasticsearch/elasticsearch.yml\n</code></pre>"},{"location":"installation/elasticsearch/elastic/#increase-heap-size","title":"Increase Heap Size","text":"<p>Increase the default heap size of elasticsearch by editing <code>/etc/elasticsearch/jvm.options</code>.</p> <p>Set Xmx and Xms to no more than 50% of the machine's physical RAM.</p> <p>Elasticsearch requires memory for purposes other than the JVM heap and it is important to leave available memory (RAM) space for this.</p>"},{"location":"installation/elasticsearch/elastic/#example","title":"Example","text":"<p>If you have 16 GB of physical RAM, change the settings from:</p> <pre><code>$ sudo grep 'Xm' /etc/elasticsearch/jvm.options\n# -Xms4g\n# -Xmx4g\n</code></pre> <p>to:</p> <pre><code>$ sudo grep 'Xm' /etc/elasticsearch/jvm.options\n-Xms8g\n-Xmx8g \n</code></pre> <p>In the above example, we set the minimum and maximum heap size to 8 GB.</p>"},{"location":"installation/elasticsearch/elastic/#increase-log-compression","title":"Increase Log Compression","text":"<p>Set the following index codec by running the following command:</p> <pre><code>echo 'index.codec: best_compression' \\\n    | sudo tee --append /etc/elasticsearch/elasticsearch.yml\n</code></pre>"},{"location":"installation/elasticsearch/elastic/#increase-number-of-available-memory-maps","title":"Increase Number of Available Memory Maps","text":"<p>Elasticsearch uses an mmapfs directory by default to store its indices. </p> <p>The default operating system limits on mmap counts is likely to be too low, which may result in out of memory exceptions.</p> <p>To increase the limits, run the following command:</p> <pre><code>sudo sysctl -w vm.max_map_count=262144\n</code></pre> <p>To make this change persist across reboots run this command:</p> <pre><code>echo \"vm.max_map_count = 262144\" \\\n    | sudo tee --append /etc/sysctl.d/10-elasticsearch.conf\n</code></pre>"},{"location":"installation/elasticsearch/elastic/#increase-number-of-file-descriptors","title":"Increase Number of File Descriptors","text":"<p>Note: This section is only required for non-package installations. Debian and RPM packages already use the intended value.</p> <p>Elasticsearch needs <code>max file descriptors</code> system settings to be at least <code>65536</code>, which can be updated with this command:</p> <pre><code>sudo mkdir -p /etc/security/limits.conf.d\necho 'elasticsearch  -  nofile  65536' \\\n    | sudo tee --append /etc/security/limits.conf.d/elastic.conf\n</code></pre>"},{"location":"installation/elasticsearch/elastic/#enable-security-features","title":"Enable Security Features","text":"<p>Enable the Elasticsearch security features to enable basic authentication. Basic authentication is available as part of the basic Elasticsearch license, but disabled by default.</p> <p>Run the following command to allow access to the cluster using username and password authentication:</p> <pre><code>echo 'xpack.security.enabled: true' \\\n    | sudo tee --append /etc/elasticsearch/elasticsearch.yml\n</code></pre>"},{"location":"installation/elasticsearch/elastic/#start-elasticsearch","title":"Start Elasticsearch","text":"<pre><code>sudo systemctl start elasticsearch.service\n</code></pre> <p>After a short period of time, it is possible to verify that the Elasticsearch node is running by sending an HTTP request to port 9200 on localhost:</p> <pre><code>curl \"localhost:9200\"\n</code></pre>"},{"location":"installation/elasticsearch/elastic/#securing-elasticsearch","title":"Securing Elasticsearch","text":""},{"location":"installation/elasticsearch/elastic/#set-passwords-for-default-user","title":"Set Passwords for Default User","text":"<p>In the Elasticsearch <code>home</code> folder run one of the following commands to setup the default passwords for the built-in <code>elastic</code> user.</p> <p>This commands creates a random secure password:</p> <pre><code>echo y | /usr/share/elasticsearch/bin/elasticsearch-setup-passwords auto\n</code></pre> <p>This commands sets a self-assigned password:</p> <pre><code>/usr/share/elasticsearch/bin/elasticsearch-setup-passwords interactive\n</code></pre>"},{"location":"installation/elasticsearch/elastic/#create-a-dedicated-role","title":"Create a Dedicated Role","text":"<p>When creating a dedicated AxonOps role in Elasticsearch, the following privileges are required:</p> <ul> <li>Cluster privileges:<ul> <li><code>monitor</code></li> <li><code>manage_index_templates</code></li> </ul> </li> <li>Index privileges:<ul> <li><code>auto_configure</code></li> <li><code>manage</code></li> <li><code>read</code></li> <li><code>view_index_metadata</code></li> <li><code>write</code></li> </ul> </li> </ul> <p>The index privileges should be applied to the the following indices:</p> <ul> <li><code>orgs</code></li> <li><code>orgname_*</code><ul> <li>Where the <code>orgname</code> prefix should match the <code>org_name</code> value in the AxonOps server and agent config files.</li> </ul> </li> </ul> <p></p>"},{"location":"installation/elasticsearch/elastic/#advanced-user-setups","title":"Advanced User Setups","text":"<p>You can learn more about other User Authentication options using the Elastic's official documentation.</p>"},{"location":"installation/elasticsearch/install/","title":"Elasticsearch","text":""},{"location":"installation/elasticsearch/install/#install-elasticsearch","title":"Install Elasticsearch","text":""},{"location":"installation/elasticsearch/install/#installation","title":"Installation","text":"<p>Select the OS Family</p> <p> </p> <p>Execute the following commands to setup Elasticsearch for your OS:</p> <pre><code>sudo apt-get update\nsudo apt-get install -y gpg wget\nwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch \\\n  | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg\n\nsudo apt-get install apt-transport-https\necho \"deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg]\\\n https://artifacts.elastic.co/packages/7.x/apt stable main\" | \\\n  sudo tee /etc/apt/sources.list.d/elastic-7.x.list\n\nsudo apt-get update\nsudo apt-get install elasticsearch\n</code></pre> <pre><code>rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch\n\necho '[elasticsearch]\nname=Elasticsearch repository for 7.x packages\nbaseurl=https://artifacts.elastic.co/packages/7.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=0\nautorefresh=1\ntype=rpm-md' | sudo tee /etc/yum.repos.d/elasticsearch.repo\n\nsudo yum install --enablerepo=elasticsearch elasticsearch\n</code></pre>"},{"location":"installation/elasticsearch/install/#configuration-file-locations","title":"Configuration File Locations","text":"<p>Most installations of Elasticsearch have the default configuration location at <code>/etc/elasticsearch/</code>.</p> <p>The default location depends on whether the installation is from an archive distribution (.tar.gz or .zip file) or a package distribution (Debian or RPM packages). For more info on Elasticsearch configuration, please read Configuring Elasticsearch.</p> <p>All commands on this page assume Elasticsearch was installed via a Debian or RPM package.</p>"},{"location":"installation/elasticsearch/install/#other-default-locations","title":"Other Default Locations","text":"<p>Depending on the installation method the default location for Elasticsearch configuration and binary files can change. Use these Elasticsearch docs for more information:</p> <ul> <li>Tarball Installation</li> <li>Debian Package</li> <li>RPM Package</li> </ul>"},{"location":"installation/elasticsearch/install/#configure-elasticsearch","title":"Configure Elasticsearch","text":""},{"location":"installation/elasticsearch/install/#increase-bulk-queue-size","title":"Increase Bulk Queue Size","text":"<p>Increase the bulk queue size of Elasticsearch by running the following command:</p> <pre><code>echo 'thread_pool.write.queue_size: 2000' \\\n    | sudo tee --append /etc/elasticsearch/elasticsearch.yml\n</code></pre>"},{"location":"installation/elasticsearch/install/#increase-heap-size","title":"Increase Heap Size","text":"<p>Increase the default heap size of elasticsearch by editing <code>/etc/elasticsearch/jvm.options</code>.</p> <p>Set Xmx and Xms to no more than 50% of the machine's physical RAM.</p> <p>Elasticsearch requires memory for purposes other than the JVM heap and it is important to leave available memory (RAM) space for this.</p>"},{"location":"installation/elasticsearch/install/#example","title":"Example","text":"<p>If you have 16 GB of physical RAM, change the settings from:</p> <pre><code>$ sudo grep 'Xm' /etc/elasticsearch/jvm.options\n# -Xms4g\n# -Xmx4g\n</code></pre> <p>to:</p> <pre><code>$ sudo grep 'Xm' /etc/elasticsearch/jvm.options\n-Xms8g\n-Xmx8g \n</code></pre> <p>In the above example, we set the minimum and maximum heap size to 8 GB.</p>"},{"location":"installation/elasticsearch/install/#increase-log-compression","title":"Increase Log Compression","text":"<p>Set the following index codec by running the following command:</p> <pre><code>echo 'index.codec: best_compression' \\\n    | sudo tee --append /etc/elasticsearch/elasticsearch.yml\n</code></pre>"},{"location":"installation/elasticsearch/install/#increase-number-of-available-memory-maps","title":"Increase Number of Available Memory Maps","text":"<p>Elasticsearch uses an mmapfs directory by default to store its indices. </p> <p>The default operating system limits on mmap counts is likely to be too low, which may result in out of memory exceptions.</p> <p>To increase the limits, run the following command:</p> <pre><code>sudo sysctl -w vm.max_map_count=262144\n</code></pre> <p>To make this change persist across reboots run this command:</p> <pre><code>echo \"vm.max_map_count = 262144\" \\\n    | sudo tee --append /etc/sysctl.d/10-elasticsearch.conf\n</code></pre>"},{"location":"installation/elasticsearch/install/#increase-number-of-file-descriptors","title":"Increase Number of File Descriptors","text":"<p>Note: This section is only required for non-package installations. Debian and RPM packages already use the intended value.</p> <p>Elasticsearch needs <code>max file descriptors</code> system settings to be at least <code>65536</code>, which can be updated with this command:</p> <pre><code>sudo mkdir -p /etc/security/limits.conf.d\necho 'elasticsearch  -  nofile  65536' \\\n    | sudo tee --append /etc/security/limits.conf.d/elastic.conf\n</code></pre>"},{"location":"installation/elasticsearch/install/#enable-security-features","title":"Enable Security Features","text":"<p>Enable the Elasticsearch security features to enable basic authentication. Basic authentication is available as part of the basic Elasticsearch license, but disabled by default.</p> <p>Run the following command to allow access to the cluster using username and password authentication:</p> <pre><code>echo 'xpack.security.enabled: true' \\\n    | sudo tee --append /etc/elasticsearch/elasticsearch.yml\n</code></pre>"},{"location":"installation/elasticsearch/install/#start-elasticsearch","title":"Start Elasticsearch","text":"<pre><code>sudo systemctl start elasticsearch.service\n</code></pre> <p>After a short period of time, it is possible to verify that the Elasticsearch node is running by sending an HTTP request to port 9200 on localhost:</p> <pre><code>curl \"localhost:9200\"\n</code></pre>"},{"location":"installation/elasticsearch/install/#securing-elasticsearch","title":"Securing Elasticsearch","text":""},{"location":"installation/elasticsearch/install/#set-passwords-for-default-user","title":"Set Passwords for Default User","text":"<p>In the Elasticsearch <code>home</code> folder run one of the following commands to setup the default passwords for the built-in <code>elastic</code> user.</p> <p>This commands creates a random secure password:</p> <pre><code>echo y | /usr/share/elasticsearch/bin/elasticsearch-setup-passwords auto\n</code></pre> <p>This commands sets a self-assigned password:</p> <pre><code>/usr/share/elasticsearch/bin/elasticsearch-setup-passwords interactive\n</code></pre>"},{"location":"installation/elasticsearch/install/#create-a-dedicated-role","title":"Create a Dedicated Role","text":"<p>When creating a dedicated AxonOps role in Elasticsearch, the following privileges are required:</p> <ul> <li>Cluster privileges:<ul> <li><code>monitor</code></li> <li><code>manage_index_templates</code></li> </ul> </li> <li>Index privileges:<ul> <li><code>auto_configure</code></li> <li><code>manage</code></li> <li><code>read</code></li> <li><code>view_index_metadata</code></li> <li><code>write</code></li> </ul> </li> </ul> <p>The index privileges should be applied to the the following indices:</p> <ul> <li><code>orgs</code></li> <li><code>orgname_*</code><ul> <li>Where the <code>orgname</code> prefix should match the <code>org_name</code> value in the AxonOps server and agent config files.</li> </ul> </li> </ul> <p></p>"},{"location":"installation/elasticsearch/install/#advanced-user-setups","title":"Advanced User Setups","text":"<p>You can learn more about other User Authentication options using the Elastic's official documentation.</p>"},{"location":"installation/kubernetes/","title":"Kubernetes","text":""},{"location":"installation/kubernetes/#running-axonops-on-kubernetes","title":"Running AxonOps on Kubernetes","text":""},{"location":"installation/kubernetes/#introduction","title":"Introduction","text":"<p>The following shows how to install AxonOps for monitoring cassandra. AxonOps requires ElasticSearch and the documentation below shows how to install both. If you already have ElasticSearch running, you can omit the installation and just ensure the AxonOps config points to it.</p> <p>AxonOps installation uses Helm Charts. Helm v3.8.0 or later is required in order to access the OCI repository hosting the charts. The raw charts can be downloaded from the GitHub repository.</p>"},{"location":"installation/kubernetes/#preparing-the-configuration","title":"Preparing the configuration","text":""},{"location":"installation/kubernetes/#resources","title":"Resources","text":"Cassandra Nodes ElasticSearch CPU ElasticSearch Memory AxonOps Server CPU AxonOps Server Memory &lt;10 1000m 4Gi 750m 1Gi &lt;50 1000m 4Gi 2000m 6Gi 100 2000m 16Gi 4000m 12Gi 200 4000m 32Gi 8000m 24Gi"},{"location":"installation/kubernetes/#elasticsearch","title":"ElasticSearch","text":"<p>The example below is a configuration file for the official ElasticSearch helm repository. See inline comments:</p> <pre><code>---\nclusterName: \"axonops-elastic\"\n\nreplicas: 1\n\nesConfig:\n  elasticsearch.yml: |\n    thread_pool.write.queue_size: 2000\n\nroles:\n  master: \"true\"\n  ingest: \"true\"\n  data: \"true\"\n  remote_cluster_client: \"false\"\n  ml: \"false\"\n\n# Adjust the memory and cpu requirements to your deployment\n# \nesJavaOpts: \"-Xms2g -Xmx2g\"\n\nresources:\n  requests:\n    cpu: \"750m\"\n    memory: \"2Gi\"\n  limits:\n    cpu: \"1500m\"\n    memory: \"4Gi\"\n\nvolumeClaimTemplate:\n  accessModes: [\"ReadWriteOnce\"]\n  storageClassName: \"\" # adjust to your storageClass if you don't want to use default\n  resources:\n    requests:\n      storage: 50Gi\n\nrbac:\n  create: true\n</code></pre> <p>Save the configuration as <code>elastic.yaml</code> and you install it with:</p> <pre><code>helm upgrade --install elasticsearch elastic/elasticsearch --create-namespace -n axonops \\\n  --set secret.password=\"password\" -f elastic.yaml\n</code></pre> <p>NOTE: This example uses as password in plaintext. Check out the helm chart documentation on how to use secrets and consider using a secrets manager.</p>"},{"location":"installation/kubernetes/#axonops","title":"AxonOps","text":"<p>The default AxonOps installation does not expose the services outside of the cluster. We recommend that you use either a LoadBalancer service or an Ingress.</p> <p>Below you can find an example using <code>Ingress</code> to expose both the dashboard and the AxonOps server.</p> <pre><code>axon-dash:\n  image:\n    pullPolicy: IfNotPresent\n    repository: registry.axonops.com/axonops-public/axonops-docker/axon-dash\n    tag: latest\n  ingress:\n    enabled: true\n    className: nginx\n    annotations:\n      external-dns.alpha.kubernetes.io/hostname: axonops.mycompany.com\n    hosts:\n      - host: axonops.mycompany.com\n        path: \"/\"\n    tls:\n      - hosts:\n          - axonops.mycompany.com\n        secretName: axon-dash-tls\n  resources:\n    limits:\n      cpu: 1000m\n      memory: 1536Mi\n    requests:\n      cpu: 25m\n      memory: 256Mi\n\n# If you are using an existing ElasticSearch rather than installing it \n# as shown above then make sure you update the elasticHost URL below\naxon-server:\n  elasticHost: http://username:password@axonops-elastic-master:9200\n  dashboardUrl: https://axonops.mycompany.com\n  config:\n    # Set your organization name here. This must match the name used in your license key\n    org_name: demo\n    # Enter your AxonOps license key here\n    license_key: \"...\"\n  image:\n    pullPolicy: IfNotPresent\n    repository: registry.axonops.com/axonops-public/axonops-docker/axon-server\n    tag: latest\n  # Enable the agent ingress to allow agents to connect from outside the Kubernetes cluster\n  agentIngress:\n    enabled: true\n    className: nginx\n    annotations:\n      external-dns.alpha.kubernetes.io/hostname: axonops-server.mycompany.com\n    hosts:\n      - host: axonops-server.mycompany.com\n        path: \"/\"\n    tls:\n      - hosts:\n          - axonops-server.mycompany.com\n        secretName: axon-server-tls\n\n  resources:\n    limits:\n      cpu: 1\n      memory: 1Gi\n    requests:\n      cpu: 100m\n      memory: 256Mi\n</code></pre> <p>An example values file showing all available options can be found in the GitHub repository here: values-full.yaml</p>"},{"location":"installation/kubernetes/#installing","title":"Installing","text":""},{"location":"installation/kubernetes/#elasticsearch_1","title":"ElasticSearch","text":"<p>Now you can install Elasticsearch referencing the configuration file created in the previous step:</p> <pre><code>helm repo add elastic https://helm.elastic.co\nhelm update\nhelm upgrade -n axonops --install \\\n  --create-namespace \\\n  -f \"elasticsearch.yaml\" \\\n  elasticsearch elastic/elasticsearch\n</code></pre>"},{"location":"installation/kubernetes/#axonops_1","title":"AxonOps","text":"<p>Finally install the AxonOps helm chart:</p> <pre><code>helm upgrade -n axonops --install \\\n  --create-namespace \\\n  -f \"axonops.yaml\" \\\n  axonops oci://helm.axonops.com/axonops-public/axonops-helm/axonops\n</code></pre>"},{"location":"installation/kubernetes/minikube/","title":"Cassandra with AxonOps on Kubernetes","text":""},{"location":"installation/kubernetes/minikube/#cassandra-with-axonops-on-kubernetes","title":"Cassandra with AxonOps on Kubernetes","text":""},{"location":"installation/kubernetes/minikube/#introduction","title":"Introduction","text":"<p>The following shows how to install AxonOps for monitoring cassandra. This process specifically requires the official cassandra helm repository.</p>"},{"location":"installation/kubernetes/minikube/#using-minikube","title":"Using minikube","text":"<p>The deployment should work fine on latest versions of minikube as long as you provide enough memory for it.</p> <p></p><pre><code>minikube start --memory 8192 --cpus=4\nminikube addons enable storage-provisioner\n</code></pre>  Make sure you use a recent version of minikube. Also check available drivers and select the most appropriate for your platform"},{"location":"installation/kubernetes/minikube/#helmfile","title":"Helmfile","text":""},{"location":"installation/kubernetes/minikube/#overview","title":"Overview","text":"<p>As this deployment contains multiple applications we recommend you use an automation system such as Ansible or Helmfile to put together the config. The example below uses helmfile.</p>"},{"location":"installation/kubernetes/minikube/#install-requirements","title":"Install requirements","text":"<p>You would need to install the following components:</p> <ul> <li>helm: https://helm.sh/docs/intro/install/</li> <li>helmfile: https://github.com/roboll/helmfile/releases</li> </ul> <p>Alternatively you can consider using a dockerized version of them both such as https://hub.docker.com/r/chatwork/helmfile</p>"},{"location":"installation/kubernetes/minikube/#config-files","title":"Config files","text":"<p>The values below are set for running on a laptop with <code>minikube</code>, adjust accordingly for larger deployments.</p>"},{"location":"installation/kubernetes/minikube/#helmfileyaml","title":"helmfile.yaml","text":"<pre><code>---\nrepositories:\n  - name: axonops\n    url: helm.axonops.com/axonops-public/axonops-helm/axonops\n    oci: true\n  - name: bitnami\n    url: https://charts.bitnami.com/bitnami\n  - name: ckotzbauer\n    url: https://ckotzbauer.github.io/helm-charts\nreleases:\n  - name: axon-elastic\n    namespace: {{ env \"NAMESPACE\" | default \"axonops\" }}\n    chart: \"bitnami/elasticsearch\"\n    version: '12.8.1'\n    wait: true\n    values:\n      - fullnameOverride: axon-elastic\n      - imageTag: \"7.8.0\"\n      - data:\n          replicas: 1\n          persistence:\n            size: 1Gi\n            enabled: true\n            accessModes: [ \"ReadWriteOnce\" ]\n      - curator:\n          enabled: true\n      - coordinating:\n          replicas: 1\n      - master:\n          replicas: 1\n          persistence:\n            size: 1Gi\n            enabled: true\n            accessModes: [ \"ReadWriteOnce\" ]\n\n  - name: axonops\n    namespace: {{ env \"NAMESPACE\" | default \"axonops\" }}\n    chart: \"digitalis/axonops\"\n    wait: true\n    values:\n      - values.yaml\n\n  - name: cassandra\n    namespace: cassandra\n    chart: \"digitalis/cassandra\"\n    wait: true\n    values:\n      - values.yaml\n\n  - name: cadvisor\n    namespace: kube-system\n    chart: ckotzbauer/cadvisor\n    version: 1.2.0\n    values:\n      - container:\n          additionalArgs:\n            - --housekeeping_interval=5s                       # kubernetes default args\n            - --max_housekeeping_interval=10s\n            - --event_storage_event_limit=default=0\n            - --event_storage_age_limit=default=0\n            - --disable_metrics=percpu,process,sched,tcp,udp    # enable only diskIO, cpu, memory, network, disk\n            - --docker_only\n      - image:\n          repository: gcr.io/cadvisor/cadvisor\n          tag: v0.37.0\n</code></pre>"},{"location":"installation/kubernetes/minikube/#valuesyaml","title":"values.yaml","text":"<pre><code>---\npersistence:\n  enabled: true\n  size: 2Gi\n  accessMode: ReadWriteMany\n\npodSettings:\n  terminationGracePeriodSeconds: 300\n\nimage:\n  tag: 3.11.6\n  pullPolicy: IfNotPresent\n\nconfig:\n  cluster_name: digitalis\n  cluster_size: 2\n  dc_name: dc1\n  seed_size: 1\n  num_tokens: 256\n  max_heap_size: 512M\n  heap_new_size: 512M\n  endpoint_snitch: GossipingPropertyFileSnitch\n\nenv:\n  JVM_OPTS: \"-javaagent:/var/lib/axonops/axon-cassandra3.11-agent.jar=/etc/axonops/axon-agent.yml\"\n\nserviceAccount:\n  create: true\n  rules:\n  - apiGroups:\n    - \"\"\n    resources:\n    - nodes\n    - nodes/metrics\n    - pods\n    verbs:\n    - get\n    - list\n    - watch\n  - nonResourceURLs:\n    - /metrics\n    verbs:\n    - get\n\nextraVolumes:\n  - name: axonops-agent-config\n    configMap:\n      name: axonops-agent\n  - name: axonops-shared\n    emptyDir: {}\n  - name: axonops-logs\n    emptyDir: {}\n\nextraVolumeMounts:\n  - name: axonops-shared\n    mountPath: /var/lib/axonops\n    readOnly: false\n  - name: axonops-agent-config\n    mountPath: /etc/axonops\n    readOnly: true\n  - name: axonops-logs\n    mountPath: /var/log/axonops\n\nextraContainers:\n  - name: axonops-agent\n    image: digitalisdocker/axon-agent:latest\n    env:\n      - name: AXON_AGENT_VERBOSITY\n        value: \"1\"\n      - name: AXON_AGENT_ARGS\n        value: \"-v 1\"\n      - name: DATA_FILE_DIRECTORY\n        value: \"/var/lib/cassandra\"\n      - name: CASSANDRA_POD_NAME\n        valueFrom:\n          fieldRef:\n            fieldPath: metadata.name\n      - name: CASSANDRA_POD_NAMESPACE\n        valueFrom:\n          fieldRef:\n            fieldPath: metadata.namespace\n      - name: CASSANDRA_NODE_NAME\n        valueFrom:\n          fieldRef:\n            fieldPath: spec.nodeName\n      - name: CASSANDRA_POD_IP\n        valueFrom:\n          fieldRef:\n            apiVersion: v1\n            fieldPath: status.podIP\n    volumeMounts:\n      - name: axonops-agent-config\n        mountPath: /etc/axonops\n        readOnly: true\n      - name: axonops-shared\n        mountPath: /var/lib/axonops\n        readOnly: false\n      - name: axonops-logs\n        mountPath: /var/log/axonops\n      - name: data\n        mountPath: /var/lib/cassandra\n\n\naxon-server:\n  global:\n    customer: minikube\n    baseDomain: axonops.com\n\n  elasticHost: http://axon-elastic-elasticsearch-master.axonops:9200\n  dashboardUrl: https://axonops.axonops.com\n\n  image:\n    repository: digitalisdocker/axon-server\n    tag: latest\n    pullPolicy: IfNotPresent\n  config:\n    extraConfig:\n      cql_hosts:\n        - cassandra-0.cassandra.cassandra.svc.cluster.local\n      cql_username: \"cassandra\"\n      cql_password: \"cassandra\"\n      cql_local_dc: dc1\n      cql_proto_version: 4\n      cql_max_searchqueriesparallelism: 100\n      cql_batch_size: 100\n      cql_page_size: 100\n      cql_autocreate_tables: false\n      cql_retrypolicy_numretries: 3\n      cql_retrypolicy_min: 2s\n      cql_retrypolicy_max: 10s\n      cql_reconnectionpolicy_maxretries: 10\n      cql_reconnectionpolicy_initialinterval: 1s\n      cql_reconnectionpolicy_maxinterval: 10s\n      cql_keyspace_replication: \"{ 'class': 'NetworkTopologyStrategy', 'dc1': 1 }\"\n      cql_metrics_cache_max_size: 128  #MB\n      cql_metrics_cache_max_items : 500000\n\naxon-dash:\n  replicaCount: 1\n  config:\n    axonServerUrl: http://axonops-axon-server:8080\n  service:\n    type: NodePort\n  ingress:\n    enabled: true\n    annotations:\n      nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    hosts:\n      - hosts: axonops.axonops.com\n        paths:\n          - /\n  image:\n    repository: digitalisdocker/axon-dash\n    tag: latest\n    pullPolicy: IfNotPresent\n  autoscaling:\n    enabled: true\n  resources:\n    limits:\n      cpu: 500m\n      memory: 512Mi\n    requests:\n      cpu: 50m\n      memory: 128Mi\n</code></pre>"},{"location":"installation/kubernetes/minikube/#axon-agentyml","title":"axon-agent.yml","text":"<pre><code>axon-server:\n    hosts: \"axonops-axon-server.axonops\" # Specify axon-server IP axon-server.mycompany.\n    port: 1888\n\naxon-agent:\n    org: \"digitalis\"\n    human_readable_identifier: \"axon_agent_ip\" # one of the following:\n\nNTP:\n    host: \"pool.ntp.org\" # Specify a NTP to determine a NTP offset\n\ncassandra:\n  tier0: # metrics collected every 5 seconds\n      metrics:\n          jvm_:\n            - \"java.lang:*\"\n          cas_:\n            - \"org.apache.cassandra.metrics:*\"\n            - \"org.apache.cassandra.net:type=FailureDetector\"\n\n  tier1:\n      frequency: 300 # metrics collected every 300 seconds (5m)\n      metrics:\n          cas_:\n            - \"org.apache.cassandra.metrics:name=EstimatedPartitionCount,*\"\n\n  blacklist: # You can blacklist metrics based on Regex pattern. Hit the agent on http://agentIP:9916/metricslist to list JMX metrics it is collecting\n    - \"org.apache.cassandra.metrics:type=ColumnFamily.*\" # duplication of table metrics\n    - \"org.apache.cassandra.metrics:.*scope=Repair#.*\" # ignore each repair instance metrics\n    - \"org.apache.cassandra.metrics:.*name=SnapshotsSize.*\" # Collecting SnapshotsSize metrics slows down collection\n    - \"org.apache.cassandra.metrics:.*Max.*\"\n    - \"org.apache.cassandra.metrics:.*Min.*\"\n    - \".*999thPercentile|.*50thPercentile|.*FifteenMinuteRate|.*FiveMinuteRate|.*MeanRate|.*Mean|.*OneMinuteRate|.*StdDev\"\n\n  JMXOperationsBlacklist:\n    - \"getThreadInfo\"\n    - \"getDatacenter\"\n    - \"getRack\"\n\n  DMLEventsWhitelist: # You can whitelist keyspaces / tables (list of \"keyspace\" and/or \"keyspace.table\") to log DML queries. Data is not analysed.\n  # - \"system_distributed\"\n\n  DMLEventsBlacklist: # You can blacklist keyspaces / tables from the DMLEventsWhitelist (list of \"keyspace\" and/or \"keyspace.table\") to log DML queries. Data is not analysed.\n  # - system_distributed.parent_repair_history\n\n  logSuccessfulRepairs: false # set it to true if you want to log all the successful repair events.\n\n  warningThresholdMillis: 200 # This will warn in logs when a MBean takes longer than the specified value.\n\n  logFormat: \"%4$s %1$tY-%1$tm-%1$td %1$tH:%1$tM:%1$tS,%1$tL %5$s%6$s%n\"\n</code></pre>"},{"location":"installation/kubernetes/minikube/#start-up","title":"Start up","text":""},{"location":"installation/kubernetes/minikube/#create-axon-agent-configuration","title":"Create Axon Agent configuration","text":"<pre><code>kubectl create ns cassandra\nkubectl create configmap axonops-agent --from-file=axon-agent.yml -n cassandra\n</code></pre>"},{"location":"installation/kubernetes/minikube/#run-helmfile","title":"Run helmfile","text":""},{"location":"installation/kubernetes/minikube/#with-locally-installed-helm-and-helmfile","title":"With locally installed helm and helmfile","text":"<pre><code>cd your/config/directory\nhemlfile sync\n</code></pre>"},{"location":"installation/kubernetes/minikube/#with-docker-image","title":"With docker image","text":"<pre><code>docker run --rm \\\n    -v ~/.kube:/root/.kube \\\n    -v ${PWD}/.helm:/root/.helm \\\n    -v ${PWD}/helmfile.yaml:/helmfile.yaml \\\n    -v ${PWD}/values.yaml:/values.yaml \\\n    --net=host chatwork/helmfile sync\n</code></pre>"},{"location":"installation/kubernetes/minikube/#access","title":"Access","text":""},{"location":"installation/kubernetes/minikube/#minikube","title":"Minikube","text":"<p>If you used <code>minikube</code>, identify the name of the service with <code>kubectl get svc -n monitoring</code> and launch it with </p> <pre><code>minikube service axonops-axon-dash -n monitoring\n</code></pre>"},{"location":"installation/kubernetes/minikube/#loadbalancer","title":"LoadBalancer","text":"<p>Find the DNS entry for it:</p> <pre><code>kubectl get svc -n monitoring -o wide\n</code></pre> <p>Open your browser and copy and paste the URL.</p>"},{"location":"installation/kubernetes/minikube/#troubleshooting","title":"Troubleshooting","text":"<p>Check the status of the pods:</p> <pre><code>kubectl get pod -n monitoring\nkubectl get pod -n cassandra\n</code></pre> <p>Any pod which is not on state <code>Running</code> check it out with</p> <pre><code>kubectl describe -n NAMESPACE pod POD-NAME\n</code></pre>"},{"location":"installation/kubernetes/minikube/#storage","title":"Storage","text":"<p>One common problem is regarding storage. If you have enabled persistent storage you may see an error about persistent volume claims (not found, unclaimed, etc.). If you're using <code>minikube</code> make sure you enable storage with </p> <pre><code>minikube addons enable storage-provisioner\n</code></pre>"},{"location":"installation/kubernetes/minikube/#memory","title":"Memory","text":"<p>The second most common problem is not enough memory (OOMKilled). You will see this often if your node does not have enough memory to run the containers or if the <code>heap</code> settings for Cassandra are not right. <code>kubectl describe</code> command will be showing <code>Error 127</code> when this occurs.</p> <p>In the <code>values.yaml</code> file adjust the heap options to match your hardware:</p> <pre><code>  max_heap_size: 512M\n  heap_new_size: 512M\n</code></pre>"},{"location":"installation/kubernetes/minikube/#minikube_1","title":"Minikube","text":"<p>Review the way you have started up <code>minikube</code> and assign more memory if you can. Also check the available drivers and select the appropriate for your platform. On macOS where I tested <code>hyperkit</code> or <code>virtualbox</code> are the best ones.</p> <pre><code>minikube start --memory 10240 --cpus=4 --driver=hyperkit\n</code></pre>"},{"location":"installation/kubernetes/minikube/#putting-it-all-together","title":"Putting it all together","text":""},{"location":"integrations/email-integration/","title":"SMTP / Email","text":""},{"location":"integrations/email-integration/#setup-smtp-email-notifications","title":"Setup SMTP / Email Notifications","text":"<p>On the Axonops application menu, select <code>Settings -&gt; Integrations</code> .</p> <p>Click on the <code>SMTP</code> area.</p> <p>Infomy</p> <p></p> <p>Fill in the appropriate details.</p> <p></p>"},{"location":"integrations/log-file-integration/","title":"Log Files","text":""},{"location":"integrations/log-file-integration/#send-notifications-to-log-files","title":"Send Notifications to Log Files","text":"<p>Unlike the other integrations, the Log Files Integration is configured by adding the <code>alert_log</code> key to your <code>axon-server.yml</code>, typically located at <code>/etc/axonops/axon-server.yml</code>.</p> <p>When <code>alert_log.enabled</code> is <code>true</code>, logs will be written to <code>alert_log.path</code> for consumption by external services like Splunk.</p> <pre><code>alert_log:\n  enabled: true\n  path: /var/log/axonops/axon-server-alert.log\n  max_size_mb: 50\n  max_files: 5\n</code></pre> <p><code>max_size_mb</code> and <code>max_files</code> are used to define how log rotation is handled.</p>"},{"location":"integrations/microsoft-teams-integration/","title":"Microsoft Teams","text":""},{"location":"integrations/microsoft-teams-integration/#setup-microsoft-teams-integration","title":"Setup Microsoft Teams Integration","text":""},{"location":"integrations/microsoft-teams-integration/#create-microsoft-teams-webhook","title":"Create Microsoft Teams Webhook","text":"<p>On the Microsoft Teams interface, go to <code>Connectors</code>.</p> <p></p> <p><code>Configure</code> the <code>Incoming Webhook</code> connector.</p> <p></p> <p>Provide a name and select <code>Create</code>.</p> <p></p> <p>Copy the url provided to the clipboard.</p> <p></p>"},{"location":"integrations/microsoft-teams-integration/#create-the-microsoft-teams-integration-on-axon-server","title":"Create the Microsoft Teams Integration on axon-server","text":"<p>On the AxonOps application menu, select <code>Settings -&gt; Integrations</code>.</p> <p>Click on the <code>Microsoft Teams</code> area.</p> <p></p> <p>Enter a <code>name</code>, copy the url in the <code>Webhook URL</code> field, and select <code>Create</code>.</p> <p></p>"},{"location":"integrations/overview/","title":"Overview","text":"<p>AxonOps provide various integrations for the notifications.</p> <p>The functionality is accessible via Settings &gt; Integrations</p> <p>The current integrations are:</p> <ul> <li>SMTP / Email</li> <li>Pagerduty</li> <li>Slack</li> <li>Microsoft Teams</li> <li>ServiceNow</li> <li>OpsGenie</li> <li>Generic webhooks</li> <li>Log file (configurable through <code>axon-server.yml</code>)</li> </ul> <p>Infomy</p> <p></p>"},{"location":"integrations/overview/#incident-management-integration","title":"Incident Management Integration","text":"<p>AxonOps is designed as a monitoring and alerting system that:</p> <ul> <li>Detects issues</li> <li>Triggers alerts</li> <li>Sends recovery events when conditions return to normal</li> </ul> <p>However, AxonOps is not intended to replace dedicated incident management platforms like PagerDuty or OpsGenie.</p> <p>Incident management platforms provide capabilities such as:</p> <ul> <li>Converting alerts into incidents with defined workflows</li> <li>Escalation policies when initial responders don't acknowledge</li> <li>Repeat notifications until someone takes action</li> <li>Acknowledgment to pause notifications while investigating</li> <li>Auto-resolution when recovery events arrive</li> </ul>"},{"location":"integrations/overview/#reducing-alert-fatigue","title":"Reducing Alert Fatigue","text":"<p>One of the most valuable features of incident management platforms is alert grouping. When a systemic issue affects your Cassandra or Kafka cluster, it often triggers alerts from multiple nodes simultaneously. Without grouping, an on-call engineer might receive dozens of notifications for what is essentially a single incident.</p> <p>Alert grouping consolidates related alerts into a single incident, providing clarity on the nature of the outage while dramatically reducing notification noise.</p> <p>For more information on configuring alert grouping and incident rules, see:</p> <ul> <li>OpsGenie: Automatically Create an Incident via Incident Rules - Configure rules to automatically create incidents from matching alerts, with built-in deduplication</li> <li>PagerDuty: Content-Based Alert Grouping - Group alerts based on matching field values like source, component, or severity</li> <li>PagerDuty: Time-Based Alert Grouping - Group all alerts on a service within a specified time window</li> </ul>"},{"location":"integrations/overview/#routing","title":"Routing","text":"<p>AxonOps provide a rich routing mechanism for the notifications.</p> <p>The current routing options are:</p> <ul> <li>Global - this will route all the notifications</li> <li>Metrics - notifications about the alerts on metrics</li> <li>Backups - notifications about the backups / restore</li> <li>Service Checks - notifications about the service checks / health checks</li> <li>Nodes - notifications raised from the nodes</li> <li>Commands - notifications from generic tasks</li> <li>Repairs - notifications from Cassandra repairs</li> <li>Rolling Restart - notification from the rolling restart feature</li> </ul> <p>Each severity (<code>info, warning, error</code>) can be routed independently </p> <p></p>"},{"location":"integrations/overview/#errors-per-routing-mechanism-and-severity-levels","title":"Errors per routing mechanism and severity levels","text":""},{"location":"integrations/overview/#backup","title":"Backup","text":"Source Severity Description Backup Critical Any error that is returned from the 3rd party remote location providers. Backup Warning Clear local snapshots timed out Backup Warning Unable to find local snapshot Backup Warning Local backup process erros Backup Warning Clear remote snapshot timed out Backup Warning Remote backup process errors Backup Warning Unable to find remote snapshot Backup Warning Clear remote snapshot timed out Backup Warning Backup not triggered (Backups paused) Backup Warning Failed to create backup Backup Warning Failed to create remote config for backups Backup Warning Create cassandra snapshot failed Backup Warning Snapshot request timed out Backup Warning Cassandra node is inactive Backup Info Local backup created successfully Backup Info Backup deleted succesfully"},{"location":"integrations/overview/#repair","title":"Repair","text":"Source Severity Description Repair Critical Update repairs error, can be casued by tables being created or removed while a repair is running Repair Critical Any error that is generated by Cassandra for a repair processes Repair Critical Repair job is over 60% complete and the estimated time to completion is after gc_grace deadline Repair Warning Repair job is over 40% complete and the estimated time to completion is after gc_grace deadline Repair Warning Repair segment failed Repair Warning Repair segment timed out Repair Warning Cassandra repair error after n-amount of retries Repair Warning Repair unit errors Repair Warning Repair errors for nonexistent correlation ID Repair Warning Repair request timed out after n-amount of attempts to connect to host"},{"location":"integrations/pagerduy-integration/","title":"PagerDuty","text":""},{"location":"integrations/pagerduy-integration/#setup-pagerduty-integration","title":"Setup Pagerduty Integration","text":""},{"location":"integrations/pagerduy-integration/#create-pagerduty-routing-key","title":"Create Pagerduty Routing Key","text":"<p>Using these steps, note the pagerduty <code>routing key</code>.</p>"},{"location":"integrations/pagerduy-integration/#insert-pagerduty-routing-key","title":"Insert Pagerduty Routing Key","text":"<p>On the Axonops application menu, select <code>Settings -&gt; Integrations</code> .</p> <p><code>Click</code> on the <code>Pagerduty</code> area.</p> <p>Infomy</p> <p></p> <p>Add the Pagerduty <code>routing key</code> from the previous step into the <code>integration_key</code> field.</p> <p></p>"},{"location":"integrations/servicenow-integration/","title":"ServiceNow","text":""},{"location":"integrations/servicenow-integration/#setup-servicenow-integration","title":"Setup ServiceNow Integration","text":""},{"location":"integrations/servicenow-integration/#login-to-servicenow","title":"Login to ServiceNow","text":"<p>Navigate to  <code>Settings -&gt; Integrations</code> and click on <code>ServiceNow</code>.</p> <p></p> <p>Gather the <code>instance name</code>, <code>username</code>, and <code>password</code> from ServiceNow to fill out the form: </p>"},{"location":"integrations/servicenow-integration/#update-servicenow-incident-template","title":"Update ServiceNow Incident Template","text":"<p>If you want to see the detailed description of a notification, you'll need to add the <code>description</code> field into the ServiceNow incidents templates.</p> <p></p> <p></p>"},{"location":"integrations/slack-integration/","title":"Slack","text":""},{"location":"integrations/slack-integration/#setup-slack-integration","title":"Setup Slack Integration","text":""},{"location":"integrations/slack-integration/#create-slack-incoming-webhooks","title":"Create Slack Incoming Webhooks","text":"<p>Add the Incoming WebHooks app to Slack.</p> <p>Note: Ensure you're on the correct Slack Workspace by using the Workspace indicator on the top left.</p> <p>In the <code>Post to Channel</code> Box, select an option from the <code>Choose a channel...</code> dropdown menu.</p> <p>Click <code>Add Incoming WebHooks Integration</code>.</p> <p>Infomy</p> <p></p> <p>Copy and make a note of the <code>WebHook URL</code> that appears in the <code>Setup Instructions</code>.</p> <p>Infomy</p> <p></p>"},{"location":"integrations/slack-integration/#creating-the-slack-integration-on-axon-server","title":"Creating the Slack integration on axon-server","text":"<p>On the Axonops application menu, select <code>Settings -&gt; Integrations</code> .</p> <p>Click on the <code>Slack</code> area.</p> <p>Infomy</p> <p></p> <p>Add the <code>Webhook URL</code> from the previous step into the <code>url</code> field.</p> <p>Optionally, set the <code>Channel</code> field to send alerts to a channel other than the default channel that was defined when the WebHooks Integration was added to the Slack Workspace.</p> <p>Infomy</p> <p></p>"},{"location":"introduction/overview/","title":"Overview","text":"<p>Thank you for your interest in AxonOps, the only tool in the market that provides a single environment to monitor, maintain and backup your Apache Cassandra clusters.</p> <p>As a Get Started Free user you are able to connect up to 6 nodes and enjoy the full functionality of AxonOps.</p> <p>As a Cassandra Sandbox user you have access to a realistic representation of a production Cassandra environment consisting of the following:</p> <ul> <li>Qty of clusters \u2013 1</li> <li>Qty of racks \u2013 4</li> <li>Qty of DCs \u2013 2</li> <li>Qty of nodes \u2013 8</li> <li>Nodes per Rack \u2013 2</li> <li>Nodes per DC \u2013 4</li> </ul> <p>This is a typical Cassandra set-up providing redundancy across data centers, racks and nodes. It should be noted that AxonOps can scale to 100s of clusters and 1000s of nodes across many data centers.</p> <p>To get started with the Cassandra Sandbox:</p> <p>Log in at https://demo.axonops.cloud</p> <p>To get started with the Starter:</p> <p>Log in at https://axonops.com/signin</p> <p>Input the user name and password provided to you after you selected the Cassandra Sandbox instant access link or via the Get Started Free signup process.</p> <p>For a Cassandra Sandbox user you have immediate access to a live Cassandra environment.</p> <p>For a Get Started Free user simply follow the instructions displayed after login to connect your cluster.</p> <p>If you have any issues or questions please email community@axonops.com</p> <p>As mentioned, AxonOps is all about monitoring, maintaining and backup of Apache Cassandra.</p> <p>This walk-through is intended to help you quickly review the power and ease of use of AxonOps and covers the following areas.</p>"},{"location":"introduction/overview/#1-monitoring","title":"1. Monitoring","text":"<p>You will now see the Cluster Overview, a graphic representation of the cluster.</p> <p></p> <p>The demo cluster has two data centers, with each DC having two racks, with each rack having two nodes. When hovering over your mouse, you will see the details of each DC, rack and node.</p> <p>If you prefer a table view, just click on the List view.</p> <p></p> <p>For this demo environment, we are also using ChaosMonkey to randomly cause failures in the cluster. If that\u2019s the case at the moment, you\u2019ll see areas of the cluster showing red for errors or orange for warnings.</p> <p>You can click on the nodes to see the details of each node.</p> <p></p> <p>If there is an issue, you\u2019ll see the alerts.</p> <p></p>"},{"location":"introduction/overview/#11-dashboards","title":"1.1. Dashboards","text":"<p>Our experts have carefully crafted all relevant dashboards for you to drill deeper into what\u2019s going on with your cluster. But you can also create your own dashboards or add to existing ones. The dashboards have been built from the ground up to be best described as snappy with great performance and zero lag. The last thing you want when you are woken up in the middle of the night to solve an issue with your Cassandra cluster is to wait for dashboards to load.</p> <p>You can easily filter your dashboards by DC, rack and node.</p> <p></p> <p>AxonOps also allows you to select the timeline you\u2019re looking at. You can stop the dashboard from refreshing by clicking on the pause button (\u0965) in the top right corner.</p> <p></p> <p>The timeline can be selected by either the last 5 minutes, 30 minutes, day, etc., or by entering a date and time range.</p> <p></p> <p>If you want to look at it closer, you can enlarge the dashboard by clicking on two arrows in the top right corner of the dashboard.</p> <p></p> <p>It\u2019s also possible to zoom in on an event by selecting the timeline on a graph when dragging your mouse over a portion of the timeline.</p> <p>Switch back to 1hr timeline to see the data coming in again. Click on the time range area on the top of the screen to do this.</p> <p></p>"},{"location":"introduction/overview/#12-alerts","title":"1.2. Alerts","text":"<p>Alerts can be sent to various platforms that you can set up in the Settings \u2192 Integrations menu.</p> <p>You can easily filter your dashboards by DC, rack and node.</p> <p></p> <p>Once the integration has been set up, you can use it for various types of alerts. And the great thing is, you can override certain notifications. For example, if you have a separate team dealing with backups, you can route backup-related alerts to their Slack channel.</p> <p></p> <p>In AxonOps we are running Service Checks that you can configure in the Settings menu.</p> <p></p> <p>You can add your own checks. For example, let\u2019s create a simple Shell check echo \u201cHello\u201d. Scroll down to click on \u201cADD NEW SHELL CHECK\u201d. Enter a name in Check Name \u2013 this will identify your script. Click on the Script bar and enter your desired script. In our case, this is:</p> <p>echo \u201cHello world\u201d</p> <p>But this could be any script you want to run. Click on X to save the script.</p> <p>You can enter the parameters for how often you want to run this script and when it times out.</p> <p>Then click on the green SAVE CHANGES button to save everything.</p> <p>AxonOps will now start deploying the script to all the nodes and execute accordingly.</p> <p> </p> <p>NOTE: We made a mapping from the cluster configuration, so you don\u2019t have to use IP addresses, port numbers, etc. Any script you create will work in other DCs, clusters, etc.</p> <p>NOTE: You can prevent rogue commands in the scripts by maintaining a whitelist of commands in the AxonOps agent configuration.</p> <p>You can also create your own events. For example, let\u2019s create a security event. If you go to the Security dashboard, you\u2019ll see the Failed Authentication dashboard.</p> <p></p> <p>When you click on the three dots in the top right corner of that window and click Edit, you can create an Alert Definition by clicking on the ALERT DEFINITIONS and then the blue ADD NEW ALERT DEFINITION button.</p> <p> </p> <p>AxonOps already creates the matching Alert Expression for you. The Alert Expressions are Prometheus Query language compatible. If necessary, change the values for the number of events and duration before a Warning or Error is raised.</p> <p>Each alert will be sent to the default integration which you can override here too by clicking on the OVERRIDE INTEGRATIONS slider and selecting where you want to send the alerts using your defined integrations.</p> <p>Click on CREATE ALERT DEFINITION to save the Alert.</p>"},{"location":"introduction/overview/#13-logs","title":"1.3. Logs","text":"<p>So we\u2019ve been looking at predefined monitoring dashboards and alerts so far. Let\u2019s have a look at the logs.</p> <p>AxonOps is a great tool to dive deeper into your Cassandra logs to solve an issue with your cluster.</p> <p>Let\u2019s assume we\u2019re looking at CPU utilisation at the Performance dashboard.</p> <p>At the bottom of the screen, you can pull up the log files for the selection you are looking at.</p> <p></p> <p>Even the filters are applied to the log entries.</p> <p>You see, how easy it is to zoom in with laser precision on the issue you want to investigate.</p> <p>You can also look at all the logs and zoom in on the Logs &amp; Events part of the menu.</p> <p></p> <p>Now, we have been looking at Monitoring, all the dashboards that give you all the necessary information about your Cassandra cluster. We looked at events &amp; alerts and how they can be integrated with your own messaging system of choice. And we looked at Service Checks and how you can customise these.</p> <p>Let\u2019s move on to the Maintaining side of Cassandra operations.</p>"},{"location":"introduction/overview/#2-maintenance","title":"2. Maintenance","text":""},{"location":"introduction/overview/#21-repairs","title":"2.1. Repairs","text":"<p>AxonOps has a powerful feature called Adaptive Repairs, enabled through the fact AxonOps monitors node throughput and pushes repair operations via a single agent.</p> <p>This is a unique feature ensuring repair processes do not run when the cluster is busy and accelerates repair processes when there is spare capacity. So when enabled, Adaptive Repair automatically increases and decreases the intensity of repairs depending on the workload of a node. When the node is busy we slow down the repairs so there is no impact on query latencies. And when there is available headroom, we increase the repairs.</p> <p>That\u2019s all there is to it! Just enable Adaptive Repairs and you\u2019re done. AxonOps will ensure your nodes are always ahead of their repair schedule.</p> <p></p> <p>If there are not enough resources available to complete repairs at all (within the GC grace period), we will generate an alert.</p> <p>Because of the way Adaptive Repairs works, when you do capacity planning for your cluster, you have a reduced need for capacity. You do not need to take into account capacity for these heavy repairs that also run when you need the cluster to perform. With speeding repairs up and down, you can use the headroom on the server and save on</p> <p>There may be edge cases when you still want to schedule your repairs which can be managed through Scheduled Repair.</p>"},{"location":"introduction/overview/#22-rolling-restarts-job-scheduler","title":"2.2. Rolling Restarts / Job Scheduler","text":"<p>Being able to schedule Rolling Restarts and automate key tasks such as nodetool commands is available straight from the console.</p> <p>You can configure how the Rolling Restart is executed in the Settings menu. The number of DCs, racks or nodes in parallel and the script you want to run.</p> <p></p> <p>By entering the script you want to execute in the Script field many different commands can be executed through a schedule or immediately, with or without the execution of a Rolling Restart.</p> <p>Note AxonOps is already populated with Cassandra stop and Cassandra start commands.</p> <p></p> <p>You can see how this can save you from running commands on many nodes, wait until they\u2019re running again, and then move on to the next node.</p>"},{"location":"introduction/overview/#3-backup-restore","title":"3. Backup &amp; Restore","text":"<p>With AxonOps, you can easily schedule and run all the backups you need. We can store the backups locally or remotely on any of the popular cloud providers or just through an SFTP upload.</p> <p></p> <p>You can see what backup schedules are running. Under that list, you can create your own backup schedule. Enter the details of what you want to back up.</p> <p>When clicking the REMOTE BACKUP tick-box, you can enter the remote location where you want to store the backups.</p> <p>AxonOps is highly efficient as it detects what data files have changed and only backups the delta changes of the files. It should be noted that implementing a generic backup solution to handle delta changes of Cassandra storage is complex and often not implemented. AxonOps delivers this capability out of the box.</p> <p>Restoring a backup is simply selecting the backups available and then selecting whether to restore it locally or remotely.</p> <p></p>"},{"location":"introduction/overview/#4-pdf-reports","title":"4. PDF Reports","text":"<p>One final feature to walk you through is the ability to generate PDF reports.</p> <p>You can instantly create a PDF report of any dashboard you select. By default, we have a Report dashboard that will be used to generate reports.</p> <p>Select the dashboard you want to create a report for.</p> <p>You can filter the report data based on DC, rack, or a few other parameters.</p> <p>You can select to create a PDF immediately which opens a new window with the PDF.</p> <p>You can also create a daily, weekly or monthly schedule and have the report automatically sent to an email address being setup at the integrations.</p> <p></p> <p>You can test AxonOps for free on one of your own clusters too.</p> <p>Go to https://axonops.com/signin to create your own account and connect your cluster.</p>"},{"location":"kafka/acl/configure_acl/","title":"Topic Access Control List (ACL).","text":""},{"location":"kafka/acl/configure_acl/#topic-access-control-list-acl","title":"Topic Access Control List (ACL).","text":""},{"location":"kafka/acl/configure_acl/#create-an-access-control-list-acl","title":"Create an Access Control List (ACL).","text":""},{"location":"kafka/acl/configure_acl/#click-acls-in-the-left-navigation","title":"Click ACLs in the Left Navigation.","text":""},{"location":"kafka/acl/configure_acl/#click-create-acl-button","title":"Click Create ACL Button.","text":""},{"location":"kafka/acl/configure_acl/#on-the-acl-create-screen-complete-the-following-fields","title":"On the ACL Create screen complete the following fields:","text":""},{"location":"kafka/acl/configure_acl/#select-the-acl-resource-type","title":"Select the ACL Resource Type.","text":""},{"location":"kafka/acl/configure_acl/#select-the-topic-to-apply-the-acl-too","title":"Select the Topic to apply the ACL too.","text":""},{"location":"kafka/acl/configure_acl/#edit-the-host-that-will-have-access-to-the-topic","title":"Edit the Host that will have access to the Topic.","text":""},{"location":"kafka/acl/configure_acl/#select-principal-user-or-group-and-principal-value","title":"Select Principal User or Group and Principal Value","text":"<p>The user or application (e.g., User:alice, User:app1, Group:developers)</p> <p></p> <p></p>"},{"location":"kafka/acl/configure_acl/#select-the-operation-of-the-acl","title":"Select the Operation of the ACL.","text":"<p>If you toggle the Operation switch it will flip between </p>"},{"location":"kafka/acl/configure_acl/#allow","title":"Allow","text":""},{"location":"kafka/acl/configure_acl/#deny","title":"Deny","text":""},{"location":"kafka/acl/create_acl/","title":"Create ACL","text":""},{"location":"kafka/acl/create_acl/#topic-access-control-list-acl","title":"Topic Access Control List (ACL).","text":""},{"location":"kafka/acl/create_acl/#create-an-access-control-list-acl","title":"Create an Access Control List (ACL).","text":""},{"location":"kafka/acl/create_acl/#click-acls-in-the-left-navigation","title":"Click ACLs in the Left Navigation.","text":""},{"location":"kafka/acl/create_acl/#click-create-acl-button","title":"Click Create ACL Button.","text":""},{"location":"kafka/acl/create_acl/#on-the-acl-create-screen-complete-the-following-fields","title":"On the ACL Create screen complete the following fields:","text":""},{"location":"kafka/acl/create_acl/#select-the-acl-resource-type","title":"Select the ACL Resource Type.","text":""},{"location":"kafka/acl/create_acl/#select-the-topic-to-apply-the-acl-too","title":"Select the Topic to apply the ACL too.","text":""},{"location":"kafka/acl/create_acl/#edit-the-host-that-will-have-access-to-the-topic","title":"Edit the Host that will have access to the Topic.","text":""},{"location":"kafka/acl/create_acl/#select-principal-user-or-group-and-principal-value","title":"Select Principal User or Group and Principal Value","text":"<p>The user or application (e.g., User:alice, User:app1, Group:developers)</p> <p></p> <p></p>"},{"location":"kafka/acl/create_acl/#select-the-operation-of-the-acl","title":"Select the Operation of the ACL.","text":"<p>If you toggle the Operation switch it will flip between </p>"},{"location":"kafka/acl/create_acl/#allow","title":"Allow","text":""},{"location":"kafka/acl/create_acl/#deny","title":"Deny","text":""},{"location":"kafka/acl/delete_acl/","title":"Delete Kafka ACL with Axonops","text":""},{"location":"kafka/acl/delete_acl/#delete-kafka-acl-with-axonops","title":"Delete Kafka ACL with Axonops","text":"<p>Click here to watch</p>"},{"location":"kafka/acl/delete_acl/#_1","title":"Delete Kafka ACL with Axonops","text":"<p>The new ACL deletion feature in Axonops is designed for Kafka administrators looking to streamline access control management. By simplifying the process of removing unnecessary ACLs, this feature enhances security and operational efficiency, ensuring that only the right users have access to critical resources.</p>"},{"location":"kafka/acl/delete_acl/#go-to-00003001","title":"Go to 0.0.0.0:3001","text":""},{"location":"kafka/acl/delete_acl/#1-click-acls","title":"1. Click \"ACLS\"","text":"<p>Revisiting the ACLs section allows you to see all current access controls, making it easy to identify which ones need to be modified or removed.</p> <p></p>"},{"location":"kafka/acl/delete_acl/#2-click-search-by-topic-principal-operation","title":"2. Click \"Search by topic, principal, operation...\"","text":"<p>Utilizing the search function streamlines the process of finding specific ACLs, saving you time and effort in navigating through numerous entries.</p> <p></p>"},{"location":"kafka/acl/delete_acl/#3-search-for-acl","title":"3. Search for ACL","text":"<p>Search by topic, principal or operation to find the ACL you want to delete</p> <p></p>"},{"location":"kafka/acl/delete_acl/#4-click-remove-acl","title":"4. Click \"Remove ACL\"","text":""},{"location":"kafka/acl/delete_acl/#5-click-confirm","title":"5. Click \"Confirm\"","text":"<p>Confirm deletion of the ACL</p> <p></p>"},{"location":"kafka/acl/overview/","title":"Overview","text":""},{"location":"kafka/acl/overview/#topic-access-control-list-acl","title":"Topic Access Control List (ACL)","text":""},{"location":"kafka/acl/overview/#what-is-an-access-control-list","title":"What is an Access Control List","text":"<p>Kafka Access Control Lists (ACLs) are a core part of Kafka\u2019s security, defining which authenticated users or applications (principals) can perform specific operations on Kafka resources such as topics, consumer groups, or the cluster itself.</p>"},{"location":"kafka/acl/overview/#how-kafka-acls-work","title":"How Kafka ACLs Work","text":""},{"location":"kafka/acl/overview/#authorization-framework","title":"Authorization Framework:","text":"<p>Kafka uses a pluggable authorization framework, enabled by setting the <code>authorizer.class.name</code> property in the broker configuration.</p> <ul> <li>AclAuthorizer is used for ZooKeeper-based clusters (stores ACLs in ZooKeeper).</li> <li>StandardAuthorizer is used for KRaft-based clusters (stores ACLs in Kafka metadata).</li> </ul>"},{"location":"kafka/acl/overview/#authentication-prerequisite","title":"Authentication Prerequisite:","text":"<p>Before ACLs can be enforced, clients must be authenticated (commonly using SASL mechanisms). The authenticated identity is the principal referenced in ACLs</p>"},{"location":"kafka/acl/overview/#acl-structure-and-components","title":"ACL Structure and Components","text":"<ul> <li>Principal (the user/application)</li> <li>Operation (e.g., READ, WRITE)</li> <li>Resource type (topic, group, cluster, delegation_token or transactional_id)</li> <li>Permission type (ALLOW or DENY)</li> <li>Host (the IP address or hostname)</li> </ul>"},{"location":"kafka/acl/overview/#principal","title":"Principal","text":"<p>The user or service account identity. </p> <p>Format examples:</p> <p><code>User:alice</code></p> <p><code>User:admin</code></p> <p><code>Group:devs</code></p>"},{"location":"kafka/acl/overview/#operations","title":"Operations","text":"<p>Define which users or services (principals) can perform specific operations.</p>"},{"location":"kafka/acl/overview/#common-kafka-acl-operation","title":"Common Kafka ACL Operation","text":"Operation Description Typical Resource(s) READ Consume messages from a topic, or read from a consumer group Topic, Group WRITE Produce (write) messages to a topic Topic CREATE Create a new topic or consumer group Topic, Group, Cluster DELETE Delete a topic or consumer group Topic, Group ALTER Change configuration of a topic, group, or cluster Topic, Group, Cluster ALTER_CONFIGS Change resource configuration (more granular than ALTER) Topic, Cluster DESCRIBE View metadata of a resource (e.g., see topic or group details) Topic, Group, Cluster DESCRIBE_CONFIGS View resource configuration Topic, Cluster CLUSTER_ACTION Perform internal cluster operations (e.g., leader election, replication) Cluster ALL   All possible operations (admin-level permission) Any IDEMPOTENT_WRITE Allow idempotent producer operations Cluster"},{"location":"kafka/acl/overview/#transactional-and-delegation-token-operations","title":"Transactional and Delegation Token Operations","text":"Operation Description Typical Resource(s) WRITE Initiate and commit/abort transactions TransactionalId DESCRIBE View transactional state or delegation token details TransactionalId, DelegationToken"},{"location":"kafka/acl/overview/#resource-types","title":"Resource Types","text":"<p>The type of Kafka resource to which the ACL applies:</p> <ul> <li> <p>Topic : </p> <p>Represents a Kafka topic, which is where messages are published and consumed.</p> </li> <li> <p>Group : </p> <p>Refers to a consumer group, which is used for coordinating message consumption among multiple consumers.</p> </li> <li> <p>Cluster : </p> <p>The entire Kafka cluster as a resource. Used for operations that affect the whole cluster.</p> </li> <li> <p>Transactional ID : </p> <p>Identifies a transactional producer instance, enabling exactly-once semantics (EOS).</p> </li> <li> <p>Delegation Token : </p> <p>Represents a token used for authentication between brokers and clients, often as part of SASL authentication.</p> </li> </ul>"},{"location":"kafka/acl/overview/#permission-type","title":"Permission Type","text":"<ul> <li> <p>ALLOW:</p> <p>Grants the specified operation(s) to the principal on the resource. If an ACL with ALLOW is present and matches the request, the operation is permitted.</p> </li> <li> <p>DENY:</p> <p>Explicitly forbids the specified operation(s) to the principal on the resource. If an ACL with DENY matches, the operation is blocked\u2014even if another ALLOW rule would also match.</p> </li> </ul>"},{"location":"kafka/acl/overview/#host","title":"Host","text":"<ul> <li> <p>Host Limiting:</p> <p>By specifying a host in an ACL, you restrict the permission so it only applies when the user connects from that host.</p> <p>e.g. setting the host as <code>192.168.1.100</code>, will only allow or deny connections originating from that IP to perform the specific operation on the topic.</p> </li> <li> <p>Wildcard Host:</p> <p>Using <code>*</code> means the permission applies from any host (no restriction).</p> </li> </ul>"},{"location":"kafka/acl/overview/#best-practices","title":"Best Practices","text":"<ul> <li>Principals: Use a separate principal for each application or service. This limits the blast radius of a compromise and aids auditing.</li> <li>Least Privilege: Grant only the permissions required for each principal - no more.</li> <li>Host Restrictions: Use the host option to restrict access to trusted network locations or hosts.</li> <li>Wildcard ACLs: Use with caution, typically only for admin users</li> </ul>"},{"location":"kafka/brokers/overview/","title":"Overview","text":""},{"location":"kafka/brokers/overview/#kafka-brokers","title":"Kafka Brokers","text":""},{"location":"kafka/brokers/overview/#what-is-a-broker","title":"What is a Broker","text":"<p>A Kafka broker is a server that stores data and handles all data streaming requests in an Apache Kafka cluster. Each running instance of the Kafka server process is called a broker. Brokers manage the storage of messages in topics, handle read and write requests from clients (producers and consumers), and ensure data is distributed and replicated for scalability and reliability.</p> <ul> <li> <p>Cluster Formation: Multiple brokers form a Kafka cluster. Each broker is identified by a unique numeric ID. The cluster distributes topic partitions across brokers, allowing Kafka to scale horizontally and handle high throughput.</p> </li> <li> <p>Data Management: When producers send messages, they are written to specific partitions on brokers. Consumers fetch data directly from the broker storing the partition.</p> </li> <li> <p>Metadata Coordination: Historically, Kafka used ZooKeeper to coordinate brokers and manage metadata, but since Kafka 4.0, this has shifted to KRaft, Kafka\u2019s built-in Raft-based metadata management system.</p> </li> <li> <p>Physical Deployment: Brokers can run on physical servers, cloud instances, or even small devices like Raspberry Pi.</p> </li> </ul>"},{"location":"kafka/brokers/overview/#broker-configuration","title":"Broker Configuration","text":"<p>Broker configuration consists of settings that control how each broker operates within the Kafka cluster. </p> <p>These configurations are typically defined in a properties file (like server.properties) and can be customized per broker.</p> <p>Note</p> <p>Some parameters are specific to KRaft mode or ZooKeeper mode. KRaft is the default for new clusters as of recent Kafka versions</p>"},{"location":"kafka/brokers/overview/#example-broker-configuration-snippet","title":"Example Broker Configuration Snippet","text":"<pre><code>broker.id=0\nlog.dirs=/var/lib/kafka/data\nnum.partitions=4\ndefault.replication.factor=2\nlisteners=PLAINTEXT://:9092\nadvertised.listeners=PLAINTEXT://my-broker.example.com:9092\nzookeeper.connect=localhost:2181\nauto.create.topics.enable=true\nlog.retention.hours=168\n</code></pre>"},{"location":"kafka/brokers/overview/#networking-and-listeners","title":"Networking and Listeners","text":"<ul> <li> <p>listeners: Defines the network interfaces and ports the broker will listen on for client connections.</p> </li> <li> <p>advertised.listeners: Specifies the addresses clients should use to connect, which can differ from internal addresses (useful for NAT, proxies, or external DNS).</p> </li> <li> <p>inter.broker.listener.name: When multiple listeners are configured, this property specifies which one brokers should use for inter-broker communication.</p> </li> </ul>"},{"location":"kafka/brokers/overview/#operational-notes","title":"Operational Notes","text":"<p>Each broker in a cluster must have a unique broker.id.</p> <p>Configuration can be fine-tuned for performance, fault tolerance, and network setup.</p>"},{"location":"kafka/brokers/overview/#view-broker-listbroker-metrics-and-broker-configuration","title":"View Broker List,Broker Metrics and Broker Configuration","text":""},{"location":"kafka/brokers/overview/#click-brokers-in-the-left-navigation","title":"Click Brokers in the Left Navigation","text":"<p>Navigate to the Brokers section.</p> <p></p>"},{"location":"kafka/brokers/overview/#click-on-any-of-the-brokers-in-the-list","title":"Click on any of the Brokers in the list.","text":"<p>Select a specific broker and access detailed broker information.</p> <p></p>"},{"location":"kafka/brokers/overview/#configurations","title":"Configurations","text":"<p>Access and view all the configurations settings. This cannot be changed or updated from the UI and needs to be updated on the Broker configuration file.</p> <p></p>"},{"location":"kafka/brokers/overview/#metrics","title":"Metrics","text":"<p>View performance metrics for the specific Broker.</p> <p></p>"},{"location":"kafka/consumers/overview/","title":"Overview","text":""},{"location":"kafka/consumers/overview/#kafka-consumers","title":"Kafka Consumers","text":""},{"location":"kafka/consumers/overview/#what-is-a-consumer","title":"What is a Consumer","text":"<p>Kafka consumers are client applications that read (consume) messages from Kafka topics.  They are fundamental for retrieving and processing data from a Kafka cluster.  Consumers connect to Kafka brokers, subscribe to one or more topics, and continuously poll for new messages to process.</p>"},{"location":"kafka/consumers/overview/#how-consumers-work","title":"How Consumers Work:","text":"<p>A consumer subscribes to one or more topics and fetches messages from assigned partitions.</p> <p>Kafka tracks the offset (position) of each message consumed, enabling consumers to resume from where they left off in case of restarts or failures.</p> <p>Multiple consumers can be grouped into a consumer group.  Each consumer in a group is assigned a subset of partitions, allowing for parallel processing and scaling.  No two consumers in the same group will read the same partition at the same time.</p> <p>Multiple consumer groups can independently consume the same data from a topic, supporting different applications or processing pipelines.</p>"},{"location":"kafka/consumers/overview/#example-use-cases","title":"Example Use Cases","text":"<ul> <li>Real-time analytics</li> <li>Event-driven microservices</li> <li>Data ingestion pipelines</li> </ul>"},{"location":"kafka/consumers/overview/#key-configuration-tips","title":"Key Configuration Tips:","text":"<ul> <li> <p>Use a unique <code>group.id</code> for each logical application or processing pipeline.</p> </li> <li> <p>Decide between automatic (<code>enable.auto.commit=true</code>) and manual offset commits depending on your need for processing guarantees.</p> </li> <li> <p>Adjust <code>max.poll.records</code> and <code>max.poll.interval.ms</code> based on your message processing time and throughput needs.</p> </li> <li> <p>Set up security parameters (security.protocol, SSL/SASL configs) if your Kafka cluster requires authentication or encryption</p> </li> </ul>"},{"location":"kafka/consumers/overview/#view-consumer-list-and-consumer-metrics","title":"View consumer List and Consumer Metrics","text":""},{"location":"kafka/consumers/overview/#click-consumer-in-the-left-navigation","title":"Click Consumer in the Left Navigation","text":"<p>Navigate to the Consumers Section</p> <p></p>"},{"location":"kafka/consumers/overview/#click-any-of-the-consumers-in-the-list","title":"Click any of the Consumers in the list","text":""},{"location":"kafka/consumers/overview/#partitions-and-consumer-overview","title":"Partitions and Consumer Overview","text":""},{"location":"kafka/topics/configure_topic/","title":"Configure Topic","text":""},{"location":"kafka/topics/configure_topic/#kafka-topics","title":"Kafka Topics","text":""},{"location":"kafka/topics/configure_topic/#topic-configuration","title":"Topic Configuration","text":"<p>Topic configuration refers to the settings that control the behavior and characteristics of a Kafka topic.  These configurations can be set at the time of topic creation or modified later.</p>"},{"location":"kafka/topics/configure_topic/#core-topic-configuration-options","title":"Core Topic Configuration Options","text":"Option Description Example/Default Value retention.ms How long (in milliseconds) to retain messages in the topic. 604800000 (7 days) retention.bytes Maximum total bytes to retain in the topic. -1 (unlimited) cleanup.policy How old data is removed: delete (default) or compact (log compaction). delete min.insync.replicas Minimum number of replicas that must acknowledge a write for it to be considered successful. 1 segment.bytes Size of each log segment file. 1073741824 (1 GB) segment.ms Time after which a new log segment is rolled. 604800000 (7 days) max.message.bytes Maximum size of a single message. 1048588 (1 MB) compression.type Compression algorithm for topic data: gzip, snappy, lz4, zstd, uncompressed, producer producer message.timestamp.type Whether to use CreateTime or LogAppendTime for message timestamps. CreateTime <p>For all Apache Kafka Topic Configuration options please see Apache Kafka Topic Configs</p>"},{"location":"kafka/topics/configure_topic/#how-to-change-configuration-options","title":"How to change configuration options:","text":""},{"location":"kafka/topics/configure_topic/#click-topics-in-the-left-navigation","title":"Click Topics in the Left Navigation.","text":"<p>Go to the Topics section.</p> <p></p>"},{"location":"kafka/topics/configure_topic/#click-the-name-of-the-topic-to-edit","title":"Click the name of the topic to edit.","text":"<p>Click on the topic name in the list to open the condifuration and metrics popup. </p> <p></p>"},{"location":"kafka/topics/configure_topic/#filter-specific-config-options-by-name-value-or-source","title":"Filter specific config options by name value or source.","text":""},{"location":"kafka/topics/configure_topic/#edit-or-delete-configuration-option","title":"Edit or Delete configuration option.","text":"<p>Perform the specified action. </p> <ul> <li>Edit Config : </li> <li>Delete Config : </li> </ul> <p></p>"},{"location":"kafka/topics/configure_topic/#updatechange-the-value-of-the-confiuration-option","title":"Update/Change the value of the confiuration option.","text":"<p>Update the value to the required value and Save Changes</p> <p></p>"},{"location":"kafka/topics/create_topic/","title":"Create Topic","text":""},{"location":"kafka/topics/create_topic/#kafka-topics","title":"Kafka Topics","text":""},{"location":"kafka/topics/create_topic/#create-a-topic","title":"Create a Topic","text":""},{"location":"kafka/topics/create_topic/#click-topics-in-the-left-navigation","title":"Click Topics in the Left Navigation","text":""},{"location":"kafka/topics/create_topic/#click-create-topic-button","title":"Click Create Topic Button","text":""},{"location":"kafka/topics/create_topic/#topic-creation-configuration","title":"Topic Creation Configuration.","text":"<ul> <li>Fill in the Topic Name</li> <li>Set the number of partitions.</li> <li>Set the replication factor.</li> <li>Add conditional configuration options if needed.</li> <li>Finalize by clicking Create New Topic.</li> </ul>"},{"location":"kafka/topics/create_topic/#core-topic-configuration-options","title":"Core Topic Configuration Options","text":"Option Description Example/Default Value retention.ms How long (in milliseconds) to retain messages in the topic. 604800000 (7 days) retention.bytes Maximum total bytes to retain in the topic. -1 (unlimited) cleanup.policy How old data is removed: delete (default) or compact (log compaction). delete min.insync.replicas Minimum number of replicas that must acknowledge a write for it to be considered successful. 1 segment.bytes Size of each log segment file. 1073741824 (1 GB) segment.ms Time after which a new log segment is rolled. 604800000 (7 days) max.message.bytes Maximum size of a single message. 1048588 (1 MB) compression.type Compression algorithm for topic data: gzip, snappy, lz4, zstd, uncompressed, producer producer message.timestamp.type Whether to use CreateTime or LogAppendTime for message timestamps. CreateTime <p>For all Apache Kafka Topic Configuration options please see Apache Kafka Topic Configs</p>"},{"location":"kafka/topics/overview/","title":"Overview","text":""},{"location":"kafka/topics/overview/#kafka-topics","title":"Kafka Topics","text":""},{"location":"kafka/topics/overview/#what-is-a-topic","title":"What is a topic","text":"<p>A Kafka topic is a core concept in Apache Kafka, serving as a logical channel or category where data streams are organized and managed. Producers write (publish) messages to topics, and consumers read (subscribe) to messages from topics. Topics decouple producers from consumers, enabling scalable and real-time data pipelines</p> <ul> <li> <p>Naming: Topics are named to reflect the data they contain, such as temperature_readings or user_activity.</p> </li> <li> <p>Decoupling: Producers and consumers operate independently, using the topic as an intermediary.</p> </li> <li> <p>Retention: Kafka retains messages in a topic for a configurable period (default is 7 days), regardless of whether they have been consumed.</p> </li> <li> <p>Partitions: Each topic is split into one or more partitions. Partitions allow Kafka to scale horizontally and enable parallel processing. Each partition is an ordered, immutable sequence of records, and each record within a partition has a unique offset.</p> </li> <li> <p>Replication: Partitions are replicated across multiple brokers for fault tolerance. Each partition has a leader (handles reads/writes) and followers (replicate data for redundancy).</p> </li> </ul>"},{"location":"kafka/topics/overview/#topic-overview","title":"Topic Overview","text":"<p>In the topic overview page you can get a holistic view of all the topics in you Kafka Cluster.</p> <p>Click Topics in the Left Navigation to open the Overview page.</p> <p></p> <p>On the overview page interact with topics and topic information relating to Topics, Partitions, ISR(In-Sync Replicas), Alerts, Counters, Sizes and Topic Actions like:</p> <ul> <li>Edit Topic : </li> <li>Clone Topic : </li> <li>Delete Topic : </li> </ul> <p></p>"},{"location":"kafka/topics/overview/#selected-topic-information","title":"Selected Topic Information","text":"<p>Once a topic has been selected the following information is displayed.</p> <ul> <li>Configuration - Kafka Topic Configuration Options. To read more about configuration options Click here</li> <li>Partitions - View information such as Partition ID, Brokers the Partition resides and offsets.</li> <li>Consumers - Current list of consumers that are consuming from the topic.</li> <li>ACLs -  Current ACLs applied to the Topic. To read more about ACLs Click here</li> </ul>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/","title":"Metrics Reference","text":""},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#axonops-all-dashboards-metrics-reference","title":"AxonOps All Dashboards Metrics Reference","text":"<p>This document provides a comprehensive reference of all metrics used across AxonOps dashboards, organized by metric prefix and category.</p>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#table-of-contents","title":"Table of Contents","text":"<ol> <li>System Metrics (host_)</li> <li>JVM Metrics (jvm_)</li> <li>Cassandra Metrics (cas_)</li> <li>Client Metrics (client_)</li> <li>Authentication Metrics</li> <li>Event-Based Monitoring</li> <li>Special Functions and Attributes</li> </ol>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#system-metrics-host_","title":"System Metrics (host_)","text":"<p>System-level metrics collected from the operating system.</p>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#cpu-metrics","title":"CPU Metrics","text":"Metric Description Common Attributes Used In <code>host_CPU_Percent_Merge</code> Merged CPU usage percentage <code>time</code> (real/user/sys), <code>dc</code>, <code>rack</code>, <code>host_id</code> System, Overview, Reporting"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#memory-metrics","title":"Memory Metrics","text":"Metric Description Common Attributes Used In <code>host_Memory_Used</code> Used memory in bytes <code>dc</code>, <code>rack</code>, <code>host_id</code> System, Overview <code>host_Memory_Free</code> Free memory in bytes <code>dc</code>, <code>rack</code>, <code>host_id</code> System <code>host_Memory_Total</code> Total memory in bytes <code>dc</code>, <code>rack</code>, <code>host_id</code> System <code>host_Memory_Buffers</code> Buffer memory <code>dc</code>, <code>rack</code>, <code>host_id</code> System <code>host_Memory_Cached</code> Cached memory <code>dc</code>, <code>rack</code>, <code>host_id</code> System"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#disk-metrics","title":"Disk Metrics","text":"Metric Description Common Attributes Used In <code>host_Disk_UsedPercent</code> Disk usage percentage <code>mountpoint</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> System, Overview, Reporting <code>host_Disk_Used</code> Used disk space in bytes <code>mountpoint</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> System, Reporting <code>host_Disk_SectorsRead</code> Disk sectors read <code>partition</code>, <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> System, Reporting <code>host_Disk_SectorsWrite</code> Disk sectors written <code>partition</code>, <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> System, Reporting"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#network-metrics","title":"Network Metrics","text":"Metric Description Common Attributes Used In <code>host_Network_ReceiveBytes</code> Network bytes received <code>interface</code>, <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> System <code>host_Network_TransmitBytes</code> Network bytes transmitted <code>interface</code>, <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> System"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#jvm-metrics-jvm_","title":"JVM Metrics (jvm_)","text":"<p>Java Virtual Machine metrics for monitoring Cassandra's JVM.</p>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#memory-pool-metrics","title":"Memory Pool Metrics","text":"Metric Description Common Attributes Used In <code>jvm_Memory_Heap</code> Heap memory usage <code>type</code> (usage/init/committed/max), <code>dc</code>, <code>rack</code>, <code>host_id</code> System, Overview <code>jvm_MemoryPool_*</code> Specific memory pool metrics <code>pool_name</code>, <code>type</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> System"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#garbage-collection-metrics","title":"Garbage Collection Metrics","text":"Metric Description Common Attributes Used In <code>jvm_GarbageCollector_*</code> GC metrics by collector <code>collector_name</code>, <code>function</code> (CollectionTime/CollectionCount), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> System, Table <code>jvm_GarbageCollector_G1_Young_Generation</code> G1 young gen GC See above System, Table <code>jvm_GarbageCollector_Shenandoah_Cycles</code> Shenandoah GC cycles See above Table <code>jvm_GarbageCollector_Shenandoah_Pauses</code> Shenandoah GC pauses See above Table <code>jvm_GarbageCollector_ZGC</code> ZGC metrics See above Table"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#cassandra-metrics-cas_","title":"Cassandra Metrics (cas_)","text":"<p>Cassandra-specific metrics.</p>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#client-connection-metrics","title":"Client Connection Metrics","text":"Metric Description Common Attributes Used In <code>cas_Client_connectedNativeClients</code> Connected native protocol clients <code>dc</code>, <code>rack</code>, <code>host_id</code> Application, Coordinator"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#client-request-metrics","title":"Client Request Metrics","text":"Metric Description Common Attributes Used In <code>cas_ClientRequest_Latency</code> Request latency at coordinator <code>scope</code> (Read/Write/RangeSlice), <code>function</code> (percentiles/Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Overview, Coordinator, Reporting <code>cas_ClientRequest_Timeouts</code> Request timeouts <code>scope</code> (Read/Write), <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Overview, Entropy <code>cas_ClientRequest_Unavailables</code> Unavailable exceptions <code>scope</code> (Read/Write), <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Overview, Entropy"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#cache-metrics","title":"Cache Metrics","text":"Metric Description Common Attributes Used In <code>cas_Cache_*</code> Cache statistics <code>scope</code> (KeyCache/RowCache/CounterCache), <code>metric</code> (Capacity/Size/Hits/Requests), <code>dc</code>, <code>rack</code>, <code>host_id</code> Cache"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#compaction-metrics","title":"Compaction Metrics","text":"Metric Description Common Attributes Used In <code>cas_Compaction_TotalCompactionsCompleted</code> Completed compactions <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Compactions <code>cas_Compaction_BytesCompacted</code> Bytes compacted <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Compactions <code>cas_CompactionManager_*</code> Compaction manager metrics <code>metric</code> (PendingTasks/CompletedTasks), <code>dc</code>, <code>rack</code>, <code>host_id</code> Compactions"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#table-metrics","title":"Table Metrics","text":"Metric Description Common Attributes Used In <code>cas_Table_ReadLatency</code> Local read latency <code>keyspace</code>, <code>scope</code> (table), <code>function</code> (percentiles/Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Table <code>cas_Table_WriteLatency</code> Local write latency See above Table <code>cas_Table_RangeLatency</code> Local range query latency See above Table <code>cas_Table_CoordinatorReadLatency</code> Coordinator read latency See above Table <code>cas_Table_CoordinatorWriteLatency</code> Coordinator write latency See above Table <code>cas_Table_CoordinatorScanLatency</code> Coordinator range scan latency See above Table <code>cas_Table_LiveDiskSpaceUsed</code> Live data disk space <code>keyspace</code>, <code>scope</code> (table), <code>function</code> (Count), <code>dc</code>, <code>rack</code>, <code>host_id</code> Data, Table, Keyspace <code>cas_Table_TotalDiskSpaceUsed</code> Total disk space See above Data <code>cas_Table_CompressionRatio</code> Compression effectiveness <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code> Data <code>cas_Table_LiveSSTableCount</code> Number of SSTables See above Data, Table <code>cas_Table_MinPartitionSize</code> Minimum partition size See above Data <code>cas_Table_MeanPartitionSize</code> Average partition size See above Data, Table <code>cas_Table_MaxPartitionSize</code> Maximum partition size See above Data, Table <code>cas_Table_EstimatedPartitionCount</code> Estimated partitions See above Table <code>cas_Table_SSTablesPerReadHistogram</code> SSTables per read <code>function</code> (percentiles), See above Table <code>cas_Table_TombstoneScannedHistogram</code> Tombstones scanned See above Table <code>cas_Table_SpeculativeRetries</code> Speculative retry attempts <code>function</code> (Count), <code>axonfunction</code> (rate), See above Table <code>cas_Table_BloomFilterFalseRatio</code> Bloom filter false positive ratio See above Table <code>cas_Table_BloomFilterDiskSpaceUsed</code> Bloom filter disk usage See above Table <code>cas_Table_AllMemtablesHeapSize</code> Memtable heap memory See above Table <code>cas_Table_AllMemtablesOffHeapSize</code> Memtable off-heap memory See above Table"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#keyspace-metrics","title":"Keyspace Metrics","text":"Metric Description Common Attributes Used In <code>cas_Keyspace_ReadLatency</code> Keyspace read latency <code>keyspace</code>, <code>function</code> (percentiles/Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Keyspace <code>cas_Keyspace_WriteLatency</code> Keyspace write latency See above Keyspace <code>cas_Keyspace_RangeLatency</code> Keyspace range latency See above Keyspace <code>cas_Keyspace_MemtableOnHeapDataSize</code> Keyspace memtable heap size <code>keyspace</code>, <code>function</code> (Value), <code>dc</code>, <code>rack</code>, <code>host_id</code> Keyspace <code>cas_Keyspace_SSTablesPerReadHistogram</code> SSTables per read by keyspace <code>keyspace</code>, <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Keyspace"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#thread-pool-metrics","title":"Thread Pool Metrics","text":"Metric Description Common Attributes Used In <code>cas_ThreadPools_request</code> Request thread pools <code>scope</code> (pool name), <code>key</code> (ActiveTasks/PendingTasks/CompletedTasks), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Thread Pools, Entropy <code>cas_ThreadPools_internal</code> Internal thread pools See above Thread Pools, Entropy <code>cas_ThreadPools_transport</code> Transport thread pools See above Thread Pools"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#storage-metrics","title":"Storage Metrics","text":"Metric Description Common Attributes Used In <code>cas_Storage_TotalHints</code> Total hints created <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Entropy <code>cas_Storage_TotalHintsInProgress</code> Active hints being delivered <code>dc</code>, <code>rack</code>, <code>host_id</code> Entropy"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#read-repair-metrics","title":"Read Repair Metrics","text":"Metric Description Common Attributes Used In <code>cas_ReadRepair_Attempted</code> Read repair attempts <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Entropy <code>cas_ReadRepair_RepairedBackground</code> Background repairs completed See above Entropy <code>cas_ReadRepair_RepairedBlocking</code> Blocking repairs completed See above Entropy"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#cql-metrics","title":"CQL Metrics","text":"Metric Description Common Attributes Used In <code>cas_CQL_PreparedStatementsExecuted</code> Prepared statements executed <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> CQL <code>cas_CQL_RegularStatementsExecuted</code> Regular statements executed See above CQL <code>cas_CQL_PreparedStatementsCount</code> Cached prepared statements <code>function</code> (Value), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> CQL <code>cas_CQL_PreparedStatementsRatio</code> Prepared statement ratio <code>function</code> (Value), <code>dc</code>, <code>rack</code>, <code>host_id</code> CQL"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#dropped-message-metrics","title":"Dropped Message Metrics","text":"Metric Description Common Attributes Used In <code>cas_DroppedMessage_Dropped</code> Dropped messages by type <code>scope</code> (MUTATION/READ/HINT/etc), <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Dropped Messages"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#commitlog-metrics","title":"CommitLog Metrics","text":"Metric Description Common Attributes Used In <code>cas_CommitLog_WaitingOnSegmentAllocation</code> Time waiting for segment allocation <code>function</code> (percentile), <code>dc</code>, <code>rack</code>, <code>host_id</code> Coordinator"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#client-metrics-client_","title":"Client Metrics (client_)","text":"<p>Application-level client interaction metrics.</p> Metric Description Common Attributes Used In <code>client_throughput_read</code> Client read throughput <code>dc</code>, <code>rack</code>, <code>host_id</code> Application, Overview <code>client_throughput_write</code> Client write throughput <code>dc</code>, <code>rack</code>, <code>host_id</code> Application, Overview <code>client_latency_read</code> Client read latency <code>function</code> (percentile), <code>dc</code>, <code>rack</code>, <code>host_id</code> Application, Overview <code>client_latency_write</code> Client write latency <code>function</code> (percentile), <code>dc</code>, <code>rack</code>, <code>host_id</code> Application, Overview"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#authentication-metrics","title":"Authentication Metrics","text":"Metric Description Common Attributes Used In <code>cas_authentication_success</code> Successful authentications <code>username</code>, <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> Security"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#event-based-monitoring","title":"Event-Based Monitoring","text":"<p>The Security dashboard primarily uses event filtering rather than metrics.</p>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#event-types","title":"Event Types","text":"Event Type Source Description Used In <code>authentication</code> Cassandra Authentication attempts Security <code>authorization</code> Cassandra Authorization attempts Security <code>DDL_query</code> Cassandra Data Definition Language queries Security <code>DCL_query</code> Cassandra Data Control Language queries Security <code>DML_query</code> Cassandra Data Manipulation Language queries Security <code>jmx</code> System JMX access events Security"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#special-functions-and-attributes","title":"Special Functions and Attributes","text":""},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#common-function-values","title":"Common Function Values","text":"<ul> <li> <p>Percentiles: <code>50thPercentile</code>, <code>75thPercentile</code>, <code>95thPercentile</code>, <code>98thPercentile</code>, <code>99thPercentile</code>, <code>999thPercentile</code></p> </li> <li> <p>Aggregations: <code>Count</code>, <code>Min</code>, <code>Max</code>, <code>Mean</code>, <code>Value</code></p> </li> <li> <p>Special: <code>axonfunction='rate'</code> - Converts counter to rate</p> </li> </ul>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#common-attributes","title":"Common Attributes","text":"<ul> <li> <p>Location: <code>dc</code> (datacenter), <code>rack</code>, <code>host_id</code> (node)</p> </li> <li> <p>Scope: Varies by metric type (table name, cache name, thread pool name, etc.)</p> </li> <li> <p>Filtering: <code>groupBy</code> - Dynamic aggregation dimension</p> </li> </ul>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#scope-patterns-for-clientrequest-metrics","title":"Scope Patterns for ClientRequest Metrics","text":"<ul> <li> <p>Read Operations: <code>Read</code>, <code>Read-ALL</code>, <code>Read-ONE</code>, <code>Read-QUORUM</code>, etc.</p> </li> <li> <p>Write Operations: <code>Write</code>, <code>Write-ALL</code>, <code>Write-ANY</code>, <code>Write-QUORUM</code>, etc.</p> </li> <li> <p>Range Operations: <code>RangeSlice</code></p> </li> </ul>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#dropped-message-scopes","title":"Dropped Message Scopes","text":"<ul> <li><code>MUTATION</code>, <code>COUNTER_MUTATION</code>, <code>HINT</code>, <code>READ</code>, <code>RANGE_SLICE</code>, <code>PAGED_RANGE</code></li> <li><code>READ_REPAIR</code>, <code>BATCH_STORE</code>, <code>BATCH_REMOVE</code>, <code>REQUEST_RESPONSE</code>, <code>_TRACE</code></li> </ul>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#metric-naming-conventions","title":"Metric Naming Conventions","text":"<p>Prefix indicates source:</p> <ul> <li><code>host_</code> - System metrics</li> <li><code>jvm_</code> - JVM metrics</li> <li><code>cas_</code> - Cassandra metrics</li> <li><code>client_</code> - Client application metrics</li> </ul> <p>Middle part indicates component:</p> <ul> <li>Examples: <code>CPU</code>, <code>Memory</code>, <code>Disk</code>, <code>Table</code>, <code>Keyspace</code>, <code>Cache</code></li> </ul> <p>Suffix indicates measurement:</p> <ul> <li>Examples: <code>Latency</code>, <code>Count</code>, <code>Size</code>, <code>Ratio</code>, <code>Used</code></li> </ul>"},{"location":"metrics/cassandra/all_dashboards_metrics_reference/#notes","title":"Notes","text":"<ul> <li>Some metrics use <code>axonfunction='rate'</code> to calculate per-second rates from counters</li> <li>The <code>function</code> attribute typically indicates the aggregation or percentile</li> <li>Many queries filter out <code>Min</code> and <code>Max</code> values using <code>function!='Min|Max'</code></li> <li>Event-based panels (mainly in Security dashboard) don't use metrics queries</li> <li>Some metrics have special scope filters like <code>scope!=''</code> to exclude empty values</li> </ul>"},{"location":"metrics/cassandra/application_metrics_mapping/","title":"Application Dashboard","text":""},{"location":"metrics/cassandra/application_metrics_mapping/#axonops-application-dashboard-metrics-mapping","title":"AxonOps Application Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Application dashboard to their corresponding sources.</p>"},{"location":"metrics/cassandra/application_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Application dashboard provides visibility into client application interactions with Cassandra, including throughput metrics (reads, writes, batches) and connection information. It helps monitor application-level performance and usage patterns.</p>"},{"location":"metrics/cassandra/application_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/application_metrics_mapping/#throughput-metrics","title":"Throughput Metrics","text":"Dashboard Metric Source Description Attributes <code>client_throughput_read</code> Client metrics Read operations throughput <code>username</code>, <code>remoteIP</code>, <code>keyspace</code>, <code>table</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>client_throughput_write</code> Client metrics Write operations throughput <code>username</code>, <code>remoteIP</code>, <code>keyspace</code>, <code>table</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>client_throughput_batch_logged</code> Client metrics Logged batch operations <code>username</code>, <code>remoteIP</code>, <code>keyspace</code>, <code>table</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>client_throughput_batch_counter</code> Client metrics Counter batch operations <code>username</code>, <code>remoteIP</code>, <code>keyspace</code>, <code>table</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>client_throughput_batch_unlogged</code> Client metrics Unlogged batch operations <code>username</code>, <code>remoteIP</code>, <code>keyspace</code>, <code>table</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/application_metrics_mapping/#connection-metrics","title":"Connection Metrics","text":"Dashboard Metric Description Attributes <code>cas_Client_connectedNativeClients</code> Number of connected native protocol clients <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_authentication_success</code> Successful authentication attempts <code>username</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/application_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/application_metrics_mapping/#reads-per-second","title":"Reads per Second","text":"<pre><code>sum by(remoteIP, username, keyspace, table) (client_throughput_read{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id',keyspace=~'$keyspace', table=~'$scope'})\n</code></pre>"},{"location":"metrics/cassandra/application_metrics_mapping/#writes-per-second","title":"Writes per Second","text":"<pre><code>sum by (remoteIP, username, keyspace, table) (client_throughput_write{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id',keyspace=~'$keyspace', table=~'$scope'})\n</code></pre>"},{"location":"metrics/cassandra/application_metrics_mapping/#logged-batches-per-second","title":"Logged Batches per Second","text":"<pre><code>client_throughput_batch_logged{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id',keyspace=~'$keyspace', table=~'$scope'}\n</code></pre>"},{"location":"metrics/cassandra/application_metrics_mapping/#native-connections","title":"Native Connections","text":"<pre><code>ceil(cas_Client_connectedNativeClients{dc=~'$dc',rack=~'$rack',host_id=~'$host_id'})\n</code></pre>"},{"location":"metrics/cassandra/application_metrics_mapping/#successful-authentications-rate","title":"Successful Authentications Rate","text":"<pre><code>sum(cas_authentication_success{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by (username)\n</code></pre>"},{"location":"metrics/cassandra/application_metrics_mapping/#panel-types-and-descriptions","title":"Panel Types and Descriptions","text":""},{"location":"metrics/cassandra/application_metrics_mapping/#throughput-section","title":"Throughput Section","text":"<ul> <li> <p>Reads/sec - Line chart showing read operations per second by user, IP, keyspace, and table</p> </li> <li> <p>Writes/sec - Line chart showing write operations per second by user, IP, keyspace, and table</p> </li> <li> <p>Batches/sec (logged) - Line chart showing logged batch operations per second</p> </li> <li> <p>Batches/sec (counter) - Line chart showing counter batch operations per second</p> </li> <li> <p>Batches/sec (unlogged) - Line chart showing unlogged batch operations per second</p> </li> </ul>"},{"location":"metrics/cassandra/application_metrics_mapping/#connections-section","title":"Connections Section","text":"<ul> <li> <p>Native connections - Line chart showing number of connected native protocol clients</p> </li> <li> <p>Successful Authentications by user (rate) - Line chart showing authentication success rate by username</p> </li> </ul>"},{"location":"metrics/cassandra/application_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>username - Filter by client username</p> </li> <li> <p>keyspace - Filter by keyspace</p> </li> <li> <p>table (<code>scope</code>) - Filter by table</p> </li> </ul>"},{"location":"metrics/cassandra/application_metrics_mapping/#metric-details","title":"Metric Details","text":""},{"location":"metrics/cassandra/application_metrics_mapping/#client-throughput-metrics","title":"Client Throughput Metrics","text":"<ul> <li>Track operations at the application level</li> <li>Include client identity (username, IP address)</li> <li>Provide keyspace and table level granularity</li> <li>Use <code>axonfunction='rate'</code> to calculate per-second rates</li> </ul>"},{"location":"metrics/cassandra/application_metrics_mapping/#connection-metrics_1","title":"Connection Metrics","text":"<ul> <li><code>connectedNativeClients</code> shows current connection count</li> <li><code>authentication_success</code> tracks login attempts</li> <li>Both metrics help monitor client access patterns</li> </ul>"},{"location":"metrics/cassandra/application_metrics_mapping/#legend-format","title":"Legend Format","text":"<p>The dashboard uses descriptive legends combining multiple attributes:</p> <ul> <li>Throughput: <code>$username @ $remoteIP $keyspace $table</code></li> <li>Connections: <code>$dc - $host_id</code></li> <li>Authentication: <code>$username</code></li> </ul>"},{"location":"metrics/cassandra/application_metrics_mapping/#notes","title":"Notes","text":"<ol> <li>Client throughput metrics provide application-level visibility not available in standard Cassandra metrics</li> <li>These metrics help identify heavy users, problematic applications, or unusual access patterns</li> <li>The <code>ceil()</code> function is used for connection counts to ensure whole numbers</li> <li>Batch type separation (logged/unlogged/counter) helps monitor different write patterns</li> <li>Remote IP tracking enables geographic or network-based analysis of client access</li> </ol>"},{"location":"metrics/cassandra/cache_metrics_mapping/","title":"Cache Dashboard","text":""},{"location":"metrics/cassandra/cache_metrics_mapping/#axonops-cache-dashboard-metrics-mapping","title":"AxonOps Cache Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Cache dashboard.</p>"},{"location":"metrics/cassandra/cache_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Cache dashboard monitors Cassandra's caching layers including KeyCache, RowCache, and CounterCache. These caches improve read performance by storing frequently accessed data in memory. The dashboard helps optimize cache configuration and monitor cache effectiveness.</p>"},{"location":"metrics/cassandra/cache_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/cache_metrics_mapping/#cache-metrics-applied-to-all-cache-types","title":"Cache Metrics (Applied to all cache types)","text":"Dashboard Metric Description Attributes <code>cas_Cache_HitRate</code> Cache hit ratio (0.0-1.0) <code>scope</code> (KeyCache/RowCache/CounterCache), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Cache_Size</code> Current cache size in bytes <code>scope</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Cache_Capacity</code> Maximum cache capacity in bytes <code>scope</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Cache_Entries</code> Number of entries in cache <code>scope</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Cache_Requests</code> Total cache requests <code>scope</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/cache_metrics_mapping/#cache-types","title":"Cache Types","text":""},{"location":"metrics/cassandra/cache_metrics_mapping/#keycache","title":"KeyCache","text":"<ul> <li>Caches partition index entries</li> <li>Enabled by default in Cassandra</li> <li>Reduces disk seeks for finding partition locations</li> </ul>"},{"location":"metrics/cassandra/cache_metrics_mapping/#rowcache","title":"RowCache","text":"<ul> <li>Caches entire rows of data</li> <li>Disabled by default due to memory overhead</li> <li>Useful for small, hot datasets</li> </ul>"},{"location":"metrics/cassandra/cache_metrics_mapping/#countercache","title":"CounterCache","text":"<ul> <li>Caches counter column values</li> <li>Improves counter read performance</li> <li>Only applies to counter columns</li> </ul>"},{"location":"metrics/cassandra/cache_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/cache_metrics_mapping/#keycache-hit-rate","title":"KeyCache Hit Rate","text":"<pre><code>cas_Cache_HitRate{scope='KeyCache',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/cache_metrics_mapping/#keycache-size-by-group","title":"KeyCache Size by Group","text":"<pre><code>sum(cas_Cache_Size{scope='KeyCache',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/cache_metrics_mapping/#keycache-requests-per-second","title":"KeyCache Requests per Second","text":"<pre><code>sum(cas_Cache_Requests{axonfunction='rate',scope='KeyCache',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/cache_metrics_mapping/#rowcache-entries-count","title":"RowCache Entries Count","text":"<pre><code>sum(cas_Cache_Entries{scope='RowCache',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/cache_metrics_mapping/#countercache-capacity","title":"CounterCache Capacity","text":"<pre><code>sum(cas_Cache_Capacity{scope='CounterCache',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/cache_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/cache_metrics_mapping/#key-cache-section","title":"Key Cache Section","text":"<ul> <li> <p>KeyCache HitRate Per Node - Line chart showing cache hit effectiveness (0-1 scale)</p> </li> <li> <p>KeyCache Size - Line chart showing memory used by cache</p> </li> <li> <p>KeyCache Capacity - Line chart showing maximum cache size</p> </li> <li> <p>KeyCache Number of Entries - Line chart showing entry count</p> </li> <li> <p>KeyCache Requests Count Per Second - Line chart showing request rate</p> </li> </ul>"},{"location":"metrics/cassandra/cache_metrics_mapping/#row-cache-section","title":"Row Cache Section","text":"<ul> <li> <p>RowCache Size - Line chart showing memory used</p> </li> <li> <p>RowCache Capacity - Line chart showing maximum size</p> </li> <li> <p>RowCache Number of Entries - Line chart showing entry count</p> </li> <li> <p>RowCache Requests Count Per Second - Line chart showing request rate</p> </li> </ul>"},{"location":"metrics/cassandra/cache_metrics_mapping/#counter-cache-section","title":"Counter Cache Section","text":"<ul> <li> <p>CounterCache HitRate - Line chart showing hit ratio</p> </li> <li> <p>CounterCache Size - Line chart showing memory used</p> </li> <li> <p>CounterCache Capacity - Line chart showing maximum size</p> </li> <li> <p>CounterCache Number of Entries - Line chart showing entry count</p> </li> <li> <p>CounterCache Requests Count Per Second - Line chart showing request rate</p> </li> </ul>"},{"location":"metrics/cassandra/cache_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>groupBy - Dynamic grouping by dc, rack, or host_id</p> </li> </ul>"},{"location":"metrics/cassandra/cache_metrics_mapping/#metric-aggregation","title":"Metric Aggregation","text":"<p>The dashboard uses the <code>groupBy</code> variable for flexible aggregation: - Group by data center to see cache usage per DC - Group by rack for rack-level analysis - Group by host_id for node-level details</p> <p>Legend format: - Size metrics: <code>size_$groupBy</code> - Capacity metrics: <code>capacity_$groupBy</code> - Other metrics: <code>$groupBy</code></p>"},{"location":"metrics/cassandra/cache_metrics_mapping/#important-notes","title":"Important Notes","text":"<p>Hit Rate Interpretation:</p> <ul> <li>Value between 0.0 and 1.0 (shown as <code>percentunit</code>)</li> <li>Higher values indicate better cache effectiveness</li> <li>Low hit rates may indicate cache size needs adjustment</li> </ul> <p>Cache Sizing:</p> <ul> <li>Size should not exceed Capacity</li> <li>Monitor the Size/Capacity ratio</li> <li>Adjust capacity in cassandra.yaml if needed</li> </ul> <p>Version Compatibility:</p> <ul> <li>Note states \"Only Cassandra and DSE prior to version 6.0\" for some metrics</li> <li>Cache metrics may vary in newer versions</li> </ul> <p>Performance Impact:</p> <ul> <li>KeyCache has minimal overhead and high benefit</li> <li>RowCache can consume significant memory</li> <li>Monitor request rates to understand cache load</li> </ul> <p>Units:</p> <ul> <li>Size and Capacity: bytes (with SI units disabled)</li> <li>Hit Rate: percentunit (0.0-1.0 scale)</li> <li>Requests: operations per second (ops)</li> </ul>"},{"location":"metrics/cassandra/compactions_metrics_mapping/","title":"Compactions Dashboard","text":""},{"location":"metrics/cassandra/compactions_metrics_mapping/#axonops-compactions-dashboard-metrics-mapping","title":"AxonOps Compactions Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Compactions dashboard.</p>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Compactions dashboard monitors Cassandra's compaction operations, which merge SSTables to improve read performance and reclaim disk space. It tracks compaction throughput, pending tasks, and bytes processed to help identify compaction bottlenecks.</p>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/compactions_metrics_mapping/#compaction-metrics","title":"Compaction Metrics","text":"Dashboard Metric Description Attributes <code>cas_Compaction_TotalCompactionsCompleted</code> Total number of completed compactions <code>function=Count</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Compaction_CompletedTasks</code> Completed compaction tasks in thread pool <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Compaction_BytesCompacted</code> Total bytes compacted <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Compaction_PendingTasks</code> Pending compaction tasks in thread pool <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Keyspace_PendingCompactions</code> Pending compactions per keyspace <code>keyspace</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/compactions_metrics_mapping/#total-compactions-completed-per-second","title":"Total Compactions Completed per Second","text":"<pre><code>cas_Compaction_TotalCompactionsCompleted{axonfunction='rate',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#completed-thread-pool-compaction-tasks-per-second","title":"Completed Thread Pool Compaction Tasks per Second","text":"<pre><code>cas_Compaction_CompletedTasks{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#bytes-compacted-per-second","title":"Bytes Compacted per Second","text":"<pre><code>cas_Compaction_BytesCompacted{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#pending-thread-pool-compaction-tasks","title":"Pending Thread Pool Compaction Tasks","text":"<pre><code>cas_Compaction_PendingTasks{dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#keyspace-pending-compactions-per-second","title":"Keyspace Pending Compactions per Second","text":"<pre><code>sum(cas_Keyspace_PendingCompactions{axonfunction='rate',keyspace='$keyspace',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/compactions_metrics_mapping/#compactions-per-node-section","title":"Compactions Per Node Section","text":"<ul> <li> <p>Total Compactions Completed per sec - Line chart showing overall compaction completion rate</p> </li> <li> <p>Completed TP Compactions Tasks per sec - Line chart showing thread pool task completion rate</p> </li> <li> <p>Bytes Compacted per sec - Line chart showing data throughput of compactions</p> </li> <li> <p>Pending TP Compaction Tasks - Line chart showing backlog of compaction tasks</p> </li> </ul>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#pending-compactions-per-keyspace-section","title":"Pending Compactions Per Keyspace Section","text":"<ul> <li>$keyspace TP Keyspace Pending Compactions per sec - Line chart showing pending compactions rate for selected keyspace</li> </ul>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>groupBy - Dynamic grouping (dc, rack, host_id, keyspace)</p> </li> <li> <p>keyspace - Filter by specific keyspace</p> </li> </ul>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#metric-details","title":"Metric Details","text":""},{"location":"metrics/cassandra/compactions_metrics_mapping/#compaction-task-metrics","title":"Compaction Task Metrics","text":"<ul> <li> <p>TotalCompactionsCompleted: Cumulative counter of all compactions finished</p> </li> <li> <p>CompletedTasks: Thread pool level metric for task completion</p> </li> <li> <p>Both metrics use <code>axonfunction='rate'</code> to show per-second rates</p> </li> </ul>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#throughput-metrics","title":"Throughput Metrics","text":"<ul> <li> <p>BytesCompacted: Shows data processing rate</p> </li> <li> <p>Helps identify if compaction is keeping up with write load</p> </li> <li>Unit displayed as bytes/second</li> </ul>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#pending-tasks","title":"Pending Tasks","text":"<ul> <li> <p>PendingTasks: Thread pool queue size</p> </li> <li> <p>PendingCompactions: Keyspace-specific pending count</p> </li> <li> <p>High values indicate compaction falling behind</p> </li> </ul>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#important-considerations","title":"Important Considerations","text":"<p>Compaction Performance:</p> <ul> <li>High pending tasks indicate compaction bottleneck</li> <li>May need to tune concurrent_compactors</li> <li>Consider compaction throughput limits</li> </ul> <p>Resource Impact:</p> <ul> <li>Compactions consume CPU, disk I/O, and memory</li> <li>Monitor bytes compacted rate vs write rate</li> <li>Balance between compaction speed and query performance</li> </ul> <p>Keyspace Specifics:</p> <ul> <li>Different keyspaces may have different compaction strategies</li> <li>Monitor pending compactions per keyspace</li> <li>Some keyspaces may require different tuning</li> </ul> <p>Thread Pool Monitoring:</p> <ul> <li>CompactionExecutor thread pool handles all compactions</li> <li>Pool saturation affects all keyspaces</li> <li>May need to adjust thread pool size</li> </ul>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#units-and-display","title":"Units and Display","text":"<ul> <li> <p>Rates: Operations per second (short unit)</p> </li> <li> <p>Bytes: Displayed with binary units (bytes/s)</p> </li> <li> <p>Counts: Simple numeric values (short unit)</p> </li> <li> <p>Legend Format: <code>$dc - $host_id</code> for most panels</p> </li> </ul>"},{"location":"metrics/cassandra/compactions_metrics_mapping/#compaction-strategy-impact","title":"Compaction Strategy Impact","text":"<p>Different compaction strategies have different characteristics:</p> <ul> <li> <p>STCS: Fewer, larger compactions</p> </li> <li> <p>LCS: Many smaller, predictable compactions</p> </li> <li> <p>TWCS: Time-based, minimal overlap</p> </li> <li> <p>Monitor patterns based on your strategy</p> </li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/","title":"Coordinator Dashboard","text":""},{"location":"metrics/cassandra/coordinator_metrics_mapping/#axonops-coordinator-dashboard-metrics-mapping","title":"AxonOps Coordinator Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Coordinator dashboard.</p>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Coordinator dashboard monitors coordinator-level request handling in Cassandra. When a client sends a request, the coordinator node handles the request and coordinates with replica nodes. This dashboard tracks latency and throughput broken down by consistency level, providing insights into how different consistency levels impact performance.</p>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/coordinator_metrics_mapping/#client-request-metrics","title":"Client Request Metrics","text":"Dashboard Metric Description Attributes <code>cas_ClientRequest_Latency</code> Request latency at coordinator level <code>scope</code> (Read/Write/RangeSlice), <code>function</code> (percentiles/count), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Client_connectedNativeClients</code> Number of connected native protocol clients <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_CommitLog_WaitingOnSegmentAllocation</code> Time waiting for commit log segment allocation <code>function</code> (percentile), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#scope-patterns","title":"Scope Patterns","text":""},{"location":"metrics/cassandra/coordinator_metrics_mapping/#read-operations","title":"Read Operations","text":"<ul> <li><code>Read</code> - Simple read (no consistency level)</li> <li><code>Read-ALL</code> - Read with ALL consistency</li> <li><code>Read-ONE</code> - Read with ONE consistency</li> <li><code>Read-TWO</code> - Read with TWO consistency</li> <li><code>Read-THREE</code> - Read with THREE consistency</li> <li><code>Read-QUORUM</code> - Read with QUORUM consistency</li> <li><code>Read-LOCAL_QUORUM</code> - Read with LOCAL_QUORUM consistency</li> <li><code>Read-EACH_QUORUM</code> - Read with EACH_QUORUM consistency</li> <li><code>Read-SERIAL</code> - Read with SERIAL consistency</li> <li><code>Read-LOCAL_SERIAL</code> - Read with LOCAL_SERIAL consistency</li> <li><code>Read-LOCAL_ONE</code> - Read with LOCAL_ONE consistency</li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#write-operations","title":"Write Operations","text":"<ul> <li><code>Write</code> - Simple write (no consistency level)</li> <li><code>Write-ALL</code> - Write with ALL consistency</li> <li><code>Write-ANY</code> - Write with ANY consistency</li> <li><code>Write-ONE</code> - Write with ONE consistency</li> <li><code>Write-TWO</code> - Write with TWO consistency</li> <li><code>Write-THREE</code> - Write with THREE consistency</li> <li><code>Write-QUORUM</code> - Write with QUORUM consistency</li> <li><code>Write-LOCAL_QUORUM</code> - Write with LOCAL_QUORUM consistency</li> <li><code>Write-EACH_QUORUM</code> - Write with EACH_QUORUM consistency</li> <li><code>Write-LOCAL_ONE</code> - Write with LOCAL_ONE consistency</li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#range-operations","title":"Range Operations","text":"<ul> <li><code>RangeSlice</code> - Range query operations (SELECT with ranges)</li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/coordinator_metrics_mapping/#coordinator-read-distribution-pie-chart","title":"Coordinator Read Distribution (Pie Chart)","text":"<pre><code>sum(cas_ClientRequest_Latency{axonfunction='rate',scope='Read*',scope!='Read',function='Count',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by (scope)\n</code></pre>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#coordinator-write-distribution-pie-chart","title":"Coordinator Write Distribution (Pie Chart)","text":"<pre><code>sum(cas_ClientRequest_Latency{axonfunction='rate',scope='Write*',scope!='Write',function='Count',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by (scope)\n</code></pre>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#read-latency-by-consistency-level","title":"Read Latency by Consistency Level","text":"<pre><code>cas_ClientRequest_Latency{scope='Read.*$consistency',function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#range-read-latency","title":"Range Read Latency","text":"<pre><code>cas_ClientRequest_Latency{scope='RangeSlice',function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#write-latency-by-consistency-level","title":"Write Latency by Consistency Level","text":"<pre><code>cas_ClientRequest_Latency{scope='Write.*$consistency',function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#read-throughput-by-consistency","title":"Read Throughput by Consistency","text":"<pre><code>sum(cas_ClientRequest_Latency{axonfunction='rate',scope='Read.*$consistency',function='Count',function!='Min|Max',dc=~'$dc',rack=~'$rack', host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#commit-log-waiting-time","title":"Commit Log Waiting Time","text":"<pre><code>cas_CommitLog_WaitingOnSegmentAllocation{dc=~'$dc',rack='$rack',host_id=~'$host_id',function='$percentile'}\n</code></pre>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/coordinator_metrics_mapping/#consistency-distribution-section","title":"Consistency Distribution Section","text":"<ul> <li> <p>Coordinator Reads distribution - Pie chart showing read request distribution by consistency level</p> </li> <li> <p>Coordinator Writes distribution - Pie chart showing write request distribution by consistency level</p> </li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#latency-statistics-by-node-section","title":"Latency Statistics By Node Section","text":"<ul> <li> <p>Coordinator Read $consistency Latency - $percentile - Line chart for read latency at selected consistency</p> </li> <li> <p>Coordinator Range Read Request Latency - $percentile - Line chart for range query latency</p> </li> <li> <p>Coordinator Write $consistency Latency - $percentile - Line chart for write latency at selected consistency</p> </li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#throughput-statistics-section","title":"Throughput Statistics Section","text":"<ul> <li> <p>Coordinator Read Throughput Per $groupBy ($consistency) - Count Per Second - Read operations per second</p> </li> <li> <p>Coordinator Range Read Request Throughput - Count Per Second - Range queries per second</p> </li> <li> <p>Coordinator Write Throughput Per $groupBy ($consistency) - Count Per Second - Write operations per second</p> </li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#connections-section","title":"Connections Section","text":"<ul> <li>Number of Native Connections per host - Line chart showing client connections</li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#commitlog-statistics-section","title":"Commitlog Statistics Section","text":"<ul> <li>Waiting on Segment Allocation - Time spent waiting for commit log segments</li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>groupBy - Dynamic grouping (dc, rack, host_id)</p> </li> <li> <p>percentile - Select latency percentile (50th, 75th, 95th, 98th, 99th, 999th)</p> </li> <li> <p>consistency - Filter by consistency level (ALL, ANY, ONE, TWO, THREE, SERIAL, QUORUM, etc.)</p> </li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#consistency-levels","title":"Consistency Levels","text":""},{"location":"metrics/cassandra/coordinator_metrics_mapping/#strong-consistency","title":"Strong Consistency","text":"<ul> <li> <p>ALL - All replicas must respond</p> </li> <li> <p>QUORUM - Majority of replicas must respond</p> </li> <li> <p>LOCAL_QUORUM - Majority in local datacenter</p> </li> <li> <p>EACH_QUORUM - Quorum in each datacenter</p> </li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#weak-consistency","title":"Weak Consistency","text":"<ul> <li> <p>ONE - Only one replica must respond</p> </li> <li> <p>TWO - Two replicas must respond</p> </li> <li> <p>THREE - Three replicas must respond</p> </li> <li> <p>ANY - Any node can accept write (including hints)</p> </li> <li> <p>LOCAL_ONE - One replica in local datacenter</p> </li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#serial-consistency","title":"Serial Consistency","text":"<ul> <li> <p>SERIAL - Linearizable consistency</p> </li> <li> <p>LOCAL_SERIAL - Linearizable in local datacenter</p> </li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#important-considerations","title":"Important Considerations","text":"<p>Latency vs Consistency Trade-off:</p> <ul> <li>Higher consistency levels increase latency</li> <li>Monitor percentiles to understand impact</li> <li>Consider LOCAL variants for multi-DC</li> </ul> <p>Throughput Patterns:</p> <ul> <li>Distribution shows application consistency preferences</li> <li>Imbalanced distribution may indicate issues</li> <li>Monitor for consistency level changes</li> </ul> <p>Coordinator Load:</p> <ul> <li>Each node can be a coordinator</li> <li>High coordinator load impacts performance</li> <li>Balance using client-side load balancing</li> </ul> <p>Range Queries:</p> <ul> <li>Typically more expensive than point reads</li> <li>Monitor separately from regular reads</li> <li>Consider pagination for large ranges</li> </ul>"},{"location":"metrics/cassandra/coordinator_metrics_mapping/#units-and-display","title":"Units and Display","text":"<ul> <li> <p>Latency: microseconds</p> </li> <li> <p>Throughput: reads/writes per second (rps/wps)</p> </li> <li> <p>Connections: count (short)</p> </li> <li> <p>Legend Format: <code>$dc - $host_id</code> or <code>$groupBy</code> for aggregated views</p> </li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/","title":"CQL Dashboard","text":""},{"location":"metrics/cassandra/cql_metrics_mapping/#axonops-cql-dashboard-metrics-mapping","title":"AxonOps CQL Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps CQL dashboard.</p>"},{"location":"metrics/cassandra/cql_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The CQL (Cassandra Query Language) dashboard monitors CQL statement execution and prepared statement management. It provides insights into query patterns, prepared statement cache efficiency, and CQL workload distribution across the cluster.</p>"},{"location":"metrics/cassandra/cql_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/cql_metrics_mapping/#cql-statement-metrics","title":"CQL Statement Metrics","text":"Dashboard Metric Description Attributes <code>cas_CQL_PreparedStatementsExecuted</code> Number of prepared statements executed <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_CQL_RegularStatementsExecuted</code> Number of regular (non-prepared) statements executed <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_CQL_PreparedStatementsCount</code> Current number of cached prepared statements <code>function</code> (Value), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_CQL_PreparedStatementsRatio</code> Ratio of prepared statements to total statements <code>function</code> (Value), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/cql_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/cql_metrics_mapping/#prepared-statements-executed-per-second","title":"Prepared Statements Executed per Second","text":"<pre><code>sum(cas_CQL_PreparedStatementsExecuted{axonfunction='rate',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/cql_metrics_mapping/#regular-statements-executed-per-second","title":"Regular Statements Executed per Second","text":"<pre><code>sum(cas_CQL_RegularStatementsExecuted{axonfunction='rate',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/cql_metrics_mapping/#number-of-cached-prepared-statements","title":"Number of Cached Prepared Statements","text":"<pre><code>cas_CQL_PreparedStatementsCount{function='Value',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/cql_metrics_mapping/#prepared-statements-evicted-per-second","title":"Prepared Statements Evicted per Second","text":"<pre><code>cas_CQL_PreparedStatementsCount{axonfunction='rate',function='Value',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/cql_metrics_mapping/#prepared-statements-ratio","title":"Prepared Statements Ratio","text":"<pre><code>cas_CQL_PreparedStatementsRatio{function='Value',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/cql_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/cql_metrics_mapping/#cql-stats-section","title":"CQL Stats Section","text":"<ul> <li> <p>Prepared Statements Executed per Second - Rate of prepared statement execution</p> </li> <li> <p>Regular Statements Executed per Second - Rate of regular statement execution</p> </li> <li> <p>Number of Cached Prepared Statements per Node - Current cache size</p> </li> <li> <p>Prepared Statements Evicted per Second per Node - Cache eviction rate</p> </li> <li> <p>Prepared Statements Ratio per Node - Ratio of prepared to total statements</p> </li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>groupBy - Dynamic grouping (dc, rack, host_id, keyspace)</p> </li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/#important-metrics-explained","title":"Important Metrics Explained","text":""},{"location":"metrics/cassandra/cql_metrics_mapping/#prepared-vs-regular-statements","title":"Prepared vs Regular Statements","text":"<ul> <li> <p>Prepared Statements: Pre-parsed and optimized queries with placeholders</p> </li> <li> <p>Regular Statements: Ad-hoc queries parsed on each execution</p> </li> <li> <p>Prepared statements are more efficient for repeated queries</p> </li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/#prepared-statement-count","title":"Prepared Statement Count","text":"<ul> <li>Shows current number of statements in cache</li> <li>High values may indicate memory pressure</li> <li>Monitor for cache size limits</li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/#eviction-rate","title":"Eviction Rate","text":"<ul> <li>When <code>axonfunction='rate'</code> is applied to PreparedStatementsCount</li> <li>Indicates cache pressure when positive</li> <li>High eviction rates impact performance</li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/#prepared-statements-ratio_1","title":"Prepared Statements Ratio","text":"<ul> <li>Percentage of executed statements that are prepared</li> <li>Higher ratios indicate better query optimization</li> <li>Low ratios suggest opportunities for optimization</li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Maximize Prepared Statement Usage:</p> <ul> <li>Aim for high prepared statement ratio (&gt;90%)</li> <li>Use prepared statements for all repeated queries</li> <li>Avoid string concatenation in queries</li> </ul> <p>Monitor Cache Size:</p> <ul> <li>Watch for increasing cache counts</li> <li>Set appropriate cache size limits</li> <li>Monitor memory usage</li> </ul> <p>Track Eviction Rates:</p> <ul> <li>Zero evictions is ideal</li> <li>Positive rates indicate cache thrashing</li> <li>May need to increase cache size or optimize queries</li> </ul> <p>Analyze Query Patterns:</p> <ul> <li>Group by keyspace to identify heavy users</li> <li>Compare prepared vs regular by node</li> <li>Look for imbalanced query distribution</li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/#performance-considerations","title":"Performance Considerations","text":"<p>Prepared Statement Benefits:</p> <ul> <li>Reduced parsing overhead</li> <li>Better performance for repeated queries</li> <li>Protection against CQL injection</li> </ul> <p>Cache Management:</p> <ul> <li>Each unique prepared statement uses memory</li> <li>Too many unique statements can cause evictions</li> <li>Balance between reuse and memory usage</li> </ul> <p>Regular Statement Overhead:</p> <ul> <li>Each execution requires full parsing</li> <li>Higher CPU usage on coordinator</li> <li>Should be minimized in production</li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/#units-and-display","title":"Units and Display","text":"<ul> <li> <p>Execution Rates: statements per second (short)</p> </li> <li> <p>Counts: absolute numbers (short)</p> </li> <li> <p>Ratio: decimal between 0-1 (short)</p> </li> </ul> <p>Legend Format:</p> <ul> <li>Aggregated views: <code>$groupBy</code></li> <li>Node-specific views: <code>$host_id</code></li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/#troubleshooting","title":"Troubleshooting","text":"<p>High Regular Statement Rate:</p> <ul> <li>Review application code for ad-hoc queries</li> <li>Convert repeated patterns to prepared statements</li> <li>Check for dynamic query generation</li> </ul> <p>High Eviction Rate:</p> <ul> <li>Increase prepared statement cache size</li> <li>Review for unique statement explosion</li> <li>Consider query consolidation</li> </ul> <p>Low Prepared Statement Ratio:</p> <ul> <li>Audit application query patterns</li> <li>Implement prepared statement best practices</li> <li>Monitor after code changes</li> </ul>"},{"location":"metrics/cassandra/cql_metrics_mapping/#notes","title":"Notes","text":"<ul> <li>The <code>groupBy</code> filter includes keyspace for workload analysis</li> <li>Rate calculations use <code>axonfunction='rate'</code> for per-second metrics</li> <li>All metrics are collected at the coordinator level</li> <li>Cache metrics reflect local node state, not cluster-wide</li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/","title":"Data Dashboard","text":""},{"location":"metrics/cassandra/data_metrics_mapping/#axonops-data-dashboard-metrics-mapping","title":"AxonOps Data Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Data dashboard.</p>"},{"location":"metrics/cassandra/data_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Data dashboard provides insights into data storage characteristics including compression ratios, disk space usage, SSTable counts, and partition sizes. It helps monitor data distribution and identify tables with potential issues like large partitions or poor compression.</p>"},{"location":"metrics/cassandra/data_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/data_metrics_mapping/#compression-metrics","title":"Compression Metrics","text":"Dashboard Metric Description Attributes <code>cas_Table_CompressionRatio</code> Compression effectiveness ratio <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_CompressionMetadataOffHeapMemoryUsed</code> Off-heap memory used by compression metadata <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/data_metrics_mapping/#disk-space-metrics","title":"Disk Space Metrics","text":"Dashboard Metric Description Attributes <code>cas_Table_LiveDiskSpaceUsed</code> Live data disk space (excludes deleted data) <code>keyspace</code>, <code>scope</code> (table), <code>function=Count</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_TotalDiskSpaceUsed</code> Total disk space including tombstones <code>keyspace</code>, <code>scope</code> (table), <code>function=Count</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_LiveSSTableCount</code> Number of live SSTables <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/data_metrics_mapping/#partition-size-metrics","title":"Partition Size Metrics","text":"Dashboard Metric Description Attributes <code>cas_Table_MinPartitionSize</code> Minimum partition size in bytes <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_MeanPartitionSize</code> Average partition size in bytes <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_MaxPartitionSize</code> Maximum partition size in bytes <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/data_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/data_metrics_mapping/#compression-ratio","title":"Compression Ratio","text":"<pre><code>cas_Table_CompressionRatio{scope=~'$scope', scope!='', dc=~'$dc',rack=~'$rack',host_id=~'$host_id',keyspace=~'$keyspace'}\n</code></pre>"},{"location":"metrics/cassandra/data_metrics_mapping/#compression-metadata-memory","title":"Compression Metadata Memory","text":"<pre><code>cas_Table_CompressionMetadataOffHeapMemoryUsed{scope=~'$scope', scope!='', dc=~'$dc',rack=~'$rack',host_id=~'$host_id',keyspace=~'$keyspace'}\n</code></pre>"},{"location":"metrics/cassandra/data_metrics_mapping/#live-disk-space-per-table","title":"Live Disk Space Per Table","text":"<pre><code>cas_Table_LiveDiskSpaceUsed{function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id',keyspace=~'$keyspace',scope=~'$scope', scope!=''}\n</code></pre>"},{"location":"metrics/cassandra/data_metrics_mapping/#total-disk-space-per-table","title":"Total Disk Space Per Table","text":"<pre><code>cas_Table_TotalDiskSpaceUsed{function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id',keyspace=~'$keyspace',scope=~'$scope'}\n</code></pre>"},{"location":"metrics/cassandra/data_metrics_mapping/#sstable-count","title":"SSTable Count","text":"<pre><code>cas_Table_LiveSSTableCount{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',scope=~'$scope', scope!=''}\n</code></pre>"},{"location":"metrics/cassandra/data_metrics_mapping/#partition-size-metrics_1","title":"Partition Size Metrics","text":"<pre><code>// Minimum\ncas_Table_MinPartitionSize{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',scope=~'$scope', scope!=''}\n\n// Mean\ncas_Table_MeanPartitionSize{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',scope=~'$scope', scope!=''}\n\n// Maximum\ncas_Table_MaxPartitionSize{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',scope=~'$scope', scope!=''}\n</code></pre>"},{"location":"metrics/cassandra/data_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/data_metrics_mapping/#compression-section","title":"Compression Section","text":"<ul> <li> <p>Compression Ratio - Line chart showing compression effectiveness (lower is better)</p> </li> <li> <p>Compression Metadata Off-Heap Memory per Table - Memory overhead of compression</p> </li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/#disk-space-per-node-section","title":"Disk Space Per Node Section","text":"<ul> <li> <p>Live Disk Space Per Table - Active data size per table</p> </li> <li> <p>Total Disk Space Per Table - Total size including tombstones</p> </li> <li> <p>Live SSTable Count Per Table - Number of SSTables per table</p> </li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/#row-size-per-node-section","title":"Row Size Per Node Section","text":"<ul> <li> <p>Min Partition Size Per Table - Smallest partition in each table</p> </li> <li> <p>Mean Partition Size Per Table - Average partition size</p> </li> <li> <p>Max Row Size Per Table - Largest partition (identifies potential hotspots)</p> </li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>keyspace - Filter by keyspace</p> </li> <li> <p>table (<code>scope</code>) - Filter by table</p> </li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/#important-metrics-explained","title":"Important Metrics Explained","text":""},{"location":"metrics/cassandra/data_metrics_mapping/#compression-ratio_1","title":"Compression Ratio","text":"<ul> <li>Shows how well data compresses</li> <li>Lower values mean better compression</li> <li>Typical values: 0.3-0.5 for text data</li> <li>Depends on compression algorithm and data type</li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/#disk-space-metrics_1","title":"Disk Space Metrics","text":"<ul> <li> <p>Live Space: Only counts active data</p> </li> <li> <p>Total Space: Includes tombstones and deleted data</p> </li> <li> <p>Difference indicates space that can be reclaimed by compaction</p> </li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/#sstable-count_1","title":"SSTable Count","text":"<ul> <li> <p>High counts may indicate:</p> <ul> <li>Need for compaction tuning</li> <li>High write load</li> <li>Compaction falling behind</li> </ul> </li> <li> <p>Affects read performance (more SSTables = more files to check)</p> </li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/#partition-size-distribution","title":"Partition Size Distribution","text":"<ul> <li> <p>Min Size: Usually very small (empty or near-empty partitions)</p> </li> <li> <p>Mean Size: Average across all partitions</p> </li> <li> <p>Max Size: Critical for identifying large partitions</p> </li> <li> <p>Partitions &gt; 100MB can cause performance issues</p> </li> <li>Partitions &gt; 1GB should be investigated</li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/#legend-format","title":"Legend Format","text":"<p>All panels use: <code>$dc - $host_id-$keyspace-$scope</code></p> <ul> <li>Shows data center, node, keyspace, and table</li> <li>Allows easy identification of specific table metrics</li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Monitor Compression Ratio:</p> <ul> <li>Sudden changes may indicate data pattern changes</li> <li>Poor compression might suggest wrong algorithm choice</li> </ul> <p>Watch Disk Space Growth:</p> <ul> <li>Compare live vs total space</li> <li>Large differences suggest need for compaction</li> </ul> <p>Track SSTable Counts:</p> <ul> <li>Consistently high counts impact read performance</li> <li>May need to adjust compaction strategy</li> </ul> <p>Monitor Partition Sizes:</p> <ul> <li>Large partitions (&gt;100MB) need investigation</li> <li>Very large partitions (&gt;1GB) can cause operational issues</li> <li>Consider data model changes for tables with large partitions</li> </ul>"},{"location":"metrics/cassandra/data_metrics_mapping/#notes","title":"Notes","text":"<ul> <li>The <code>scope!=''</code> filter excludes empty table names</li> <li><code>function='Count'</code> is used for disk space metrics</li> <li>All size metrics use binary units (bytes, not SI units)</li> <li>Partition size metrics are estimates based on sampling</li> </ul>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/","title":"Dropped Messages Dashboard","text":""},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#axonops-dropped-messages-dashboard-metrics-mapping","title":"AxonOps Dropped Messages Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Dropped Messages dashboard.</p>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Dropped Messages dashboard monitors when Cassandra drops messages due to overload or timeout conditions. Dropped messages are a critical indicator of cluster health and performance issues. When Cassandra cannot process messages within configured timeouts, it drops them to prevent system overload.</p>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#dropped-message-metrics","title":"Dropped Message Metrics","text":"Dashboard Metric Description Attributes <code>cas_DroppedMessage_Dropped</code> Count of dropped messages by type <code>scope</code> (message type), <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#message-types-scopes","title":"Message Types (Scopes)","text":""},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#data-operation-messages","title":"Data Operation Messages","text":"Scope Description Common Causes <code>MUTATION</code> Write operations (INSERT, UPDATE, DELETE) Write overload, slow disks, GC pauses <code>COUNTER_MUTATION</code> Counter column updates Similar to MUTATION but for counter operations <code>HINT</code> Hinted handoff messages Node recovery backlog, network issues <code>READ</code> Read operations (SELECT) Read overload, large partitions, slow queries <code>RANGE_SLICE</code> Range queries (token ranges) Large range scans, inefficient queries <code>PAGED_RANGE</code> Paginated range queries Similar to RANGE_SLICE but with pagination"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#repair-and-maintenance-messages","title":"Repair and Maintenance Messages","text":"Scope Description Common Causes <code>READ_REPAIR</code> Read repair operations Inconsistent data, repair overload <code>BATCH_STORE</code> Batch log writes Batch operation overload <code>BATCH_REMOVE</code> Batch log cleanup Batch completion backlog"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#internal-messages","title":"Internal Messages","text":"Scope Description Common Causes <code>REQUEST_RESPONSE</code> Inter-node response messages Network latency, coordinator overload <code>_TRACE</code> Tracing messages Heavy tracing load"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#dropped-mutations-per-second","title":"Dropped Mutations per Second","text":"<pre><code>cas_DroppedMessage_Dropped{axonfunction='rate',function='Count',scope='MUTATION',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#dropped-hints-per-second","title":"Dropped Hints per Second","text":"<pre><code>cas_DroppedMessage_Dropped{axonfunction='rate',function='Count',scope='HINT',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#dropped-reads-per-second","title":"Dropped Reads per Second","text":"<pre><code>cas_DroppedMessage_Dropped{axonfunction='rate',function='Count',scope='READ',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#total-count-queries-not-rate","title":"Total Count Queries (not rate)","text":"<pre><code>// Counter Mutations\ncas_DroppedMessage_Dropped{function='Count',scope='COUNTER_MUTATION',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n\n// Paged Range\ncas_DroppedMessage_Dropped{function='Count',scope='PAGED_RANGE',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#dropped-messages-section","title":"Dropped Messages Section","text":"<p>Row 1: - Dropped Mutation per secs - Write operation drops</p> <ul> <li> <p>Dropped Hints per secs - Hinted handoff drops</p> </li> <li> <p>Dropped Read per secs - Read operation drops</p> </li> </ul> <p>Row 2: - Dropped Counter Mutation - Counter operation drops (total count)</p> <ul> <li> <p>Dropped Read Repair per secs - Read repair drops</p> </li> <li> <p>Dropped Paged Range - Paginated range query drops (total count)</p> </li> </ul> <p>Row 3: - Dropped Batch Store - Batch log write drops (total count)</p> <ul> <li> <p>Dropped Batch Remove - Batch log cleanup drops (total count)</p> </li> <li> <p>Dropped Request Response - Inter-node response drops (total count)</p> </li> </ul> <p>Row 4: - Dropped Range Slice - Range query drops (total count)</p> <ul> <li>Dropped Trace - Tracing message drops (total count)</li> </ul>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>groupBy - Dynamic grouping (dc, rack, host_id, keyspace)</p> </li> </ul>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#understanding-dropped-messages","title":"Understanding Dropped Messages","text":""},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#why-messages-are-dropped","title":"Why Messages Are Dropped","text":"<ul> <li> <p>Timeout: Message exceeds configured timeout</p> </li> <li> <p>Queue Full: Internal queue reaches capacity</p> </li> <li> <p>Overload: Node cannot keep up with request rate</p> </li> <li> <p>Resource Constraints: Memory, CPU, or I/O limitations</p> </li> </ul>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#message-type-timeouts-default","title":"Message Type Timeouts (Default)","text":"<ul> <li><code>MUTATION</code>: 5000ms (write_request_timeout_in_ms)</li> <li><code>READ</code>: 5000ms (read_request_timeout_in_ms)</li> <li><code>RANGE_SLICE</code>: 10000ms (range_request_timeout_in_ms)</li> <li><code>COUNTER_MUTATION</code>: 5000ms (counter_write_request_timeout_in_ms)</li> <li><code>REQUEST_RESPONSE</code>: 10000ms (request_timeout_in_ms)</li> </ul>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#impact-of-dropped-messages","title":"Impact of Dropped Messages","text":"<p>Dropped Mutations:</p> <ul> <li>Write failures at consistency level</li> <li>Potential data loss if hints also dropped</li> <li>Client receives timeout exceptions</li> </ul> <p>Dropped Reads:</p> <ul> <li>Read timeouts for clients</li> <li>Incomplete query results</li> <li>Application errors</li> </ul> <p>Dropped Hints:</p> <ul> <li>Delayed consistency</li> <li>Requires repair to fix</li> <li>Indicates replica communication issues</li> </ul> <p>Dropped Read Repairs:</p> <ul> <li>Inconsistencies persist longer</li> <li>Manual repair may be needed</li> <li>Background repair falling behind</li> </ul>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#high-dropped-mutations","title":"High Dropped Mutations","text":"<ol> <li>Check disk I/O performance</li> <li>Monitor GC pauses</li> <li>Review write load distribution</li> <li>Consider increasing timeout</li> <li>Check for large batches</li> </ol>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#high-dropped-reads","title":"High Dropped Reads","text":"<ol> <li>Look for large partitions</li> <li>Check read patterns</li> <li>Monitor CPU usage</li> <li>Review query efficiency</li> <li>Consider read timeout increase</li> </ol>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#high-dropped-hints","title":"High Dropped Hints","text":"<ol> <li>Check node availability</li> <li>Monitor network health</li> <li>Review hint storage capacity</li> <li>Check for overloaded nodes</li> <li>Consider hint delivery throttling</li> </ol>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#general-recommendations","title":"General Recommendations","text":"<ul> <li> <p>Zero Tolerance: Aim for zero dropped messages</p> </li> <li> <p>Early Warning: Any drops indicate problems</p> </li> <li> <p>Root Cause: Always investigate underlying cause</p> </li> <li> <p>Capacity Planning: Drops often indicate need for scaling</p> </li> </ul>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#units-and-display","title":"Units and Display","text":"<ul> <li> <p>Rate Metrics: messages per second (short)</p> </li> <li> <p>Count Metrics: absolute count (short)</p> </li> <li> <p>Legend Format: <code>$dc - $host_id</code></p> </li> </ul>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Monitor Continuously:</p> <ul> <li>Set alerts for any dropped messages</li> <li>Track trends over time</li> <li>Correlate with other metrics</li> </ul> <p>Investigate Immediately:</p> <ul> <li>Dropped messages indicate serious issues</li> <li>Check system resources</li> <li>Review recent changes</li> </ul> <p>Preventive Measures:</p> <ul> <li>Proper capacity planning</li> <li>Regular performance tuning</li> <li>Appropriate timeout configuration</li> <li>Load testing before production</li> </ul>"},{"location":"metrics/cassandra/dropped_messages_metrics_mapping/#notes","title":"Notes","text":"<ul> <li>Some panels show rate (<code>axonfunction='rate'</code>), others show total count</li> <li>Rate metrics are more useful for real-time monitoring</li> <li>Total counts help understand historical impact</li> <li>The <code>_TRACE</code> scope has underscore prefix in the actual metric</li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/","title":"Entropy Dashboard","text":""},{"location":"metrics/cassandra/entropy_metrics_mapping/#axonops-entropy-dashboard-metrics-mapping","title":"AxonOps Entropy Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Entropy dashboard.</p>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Entropy dashboard (also known as Anti-Entropy) monitors Cassandra's data consistency mechanisms including hinted handoff, read repairs, and repair operations. These features ensure eventual consistency across the cluster by detecting and fixing data inconsistencies.</p>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/entropy_metrics_mapping/#hints-metrics","title":"Hints Metrics","text":"Dashboard Metric Description Attributes <code>cas_Storage_TotalHints</code> Total number of hints created <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Storage_TotalHintsInProgress</code> Currently active hints being delivered <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#read-repair-metrics","title":"Read Repair Metrics","text":"Dashboard Metric Description Attributes <code>cas_ReadRepair_Attempted</code> Read repair attempts <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_ReadRepair_RepairedBackground</code> Background read repairs completed <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_ReadRepair_RepairedBlocking</code> Blocking read repairs completed <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#coordinator-error-metrics","title":"Coordinator Error Metrics","text":"Dashboard Metric Description Attributes <code>cas_ClientRequest_Timeouts</code> Request timeouts at coordinator <code>scope</code> (Read/Write), <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_ClientRequest_Unavailables</code> Unavailable exceptions at coordinator <code>scope</code> (Read/Write), <code>function</code> (Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#thread-pool-metrics","title":"Thread Pool Metrics","text":"Dashboard Metric Description Attributes <code>cas_ThreadPools_request</code> Request thread pool statistics <code>scope</code> (pool name), <code>key</code> (CompletedTasks), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_ThreadPools_internal</code> Internal thread pool statistics <code>scope</code> (pool name), <code>key</code> (CompletedTasks), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/entropy_metrics_mapping/#hints-section","title":"Hints Section","text":"<pre><code>// Total Hints Created Rate\ncas_Storage_TotalHints{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n\n// Hints Currently In Progress\ncas_Storage_TotalHintsInProgress{dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#read-repairs-section","title":"Read Repairs Section","text":"<pre><code>// Attempted Per Second\nsum(cas_ReadRepair_Attempted{axonfunction='rate',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n\n// Repaired Background\nsum(cas_ReadRepair_RepairedBackground{axonfunction='rate',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n\n// Repaired Blocking\nsum(cas_ReadRepair_RepairedBlocking{axonfunction='rate',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#coordinator-request-errors-section","title":"Coordinator Request Errors Section","text":"<pre><code>// Read Timeouts\nsum(cas_ClientRequest_Timeouts{axonfunction='rate',function='Count',scope='Read',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n\n// Read Unavailables\nsum(cas_ClientRequest_Unavailables{axonfunction='rate',function='Count',scope='Read',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n\n// Write Timeouts\nsum(cas_ClientRequest_Timeouts{axonfunction='rate',scope='Write',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n\n// Write Unavailables\nsum(cas_ClientRequest_Unavailables{axonfunction='rate',scope='Write',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#thread-pools-section","title":"Thread Pools Section","text":"<pre><code>// Request Thread Pool Distribution (Pie Chart)\nsum(cas_ThreadPools_request{axonfunction='rate',key='CompletedTasks',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by (scope)\n\n// Internal Thread Pool Distribution (Pie Chart)\nsum(cas_ThreadPools_internal{axonfunction='rate',key='CompletedTasks',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by (scope)\n\n// Anti-Entropy Stage Tasks\nsum(cas_ThreadPools_internal{axonfunction='rate',scope='AntiEntropyStage',key='CompletedTasks',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n\n// Read Repair Stage Tasks\nsum(cas_ThreadPools_internal{axonfunction='rate',scope='ReadRepairStage',key='CompletedTasks',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n\n// Hints Dispatcher Tasks\nsum(cas_ThreadPools_internal{axonfunction='rate',scope='HintsDispatcher',key='CompletedTasks',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/entropy_metrics_mapping/#hints-section_1","title":"Hints Section","text":"<ul> <li> <p>Total Hints Created By Each Node - Rate of hint creation</p> </li> <li> <p>Total Hints In Progress - Active hint delivery count</p> </li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#read-repairs-section_1","title":"Read Repairs Section","text":"<ul> <li> <p>Attempted Per Second - Read repair attempt rate</p> </li> <li> <p>Repaired Background - Background repairs completed</p> </li> <li> <p>Repaired Blocked - Blocking repairs completed</p> </li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#coordinator-requests-errors-section","title":"Coordinator Requests Errors Section","text":"<ul> <li> <p>Read Timeouts Per Second - Read operation timeout rate</p> </li> <li> <p>Read Unavailables Per Second - Read unavailable exception rate</p> </li> <li> <p>Write Timeouts Per Second - Write operation timeout rate</p> </li> <li> <p>Write Unavailables Per Second - Write unavailable exception rate</p> </li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#thread-pools-section_1","title":"Thread Pools Section","text":"<ul> <li> <p>ThreadPools Request - Request thread pool activity distribution</p> </li> <li> <p>ThreadPools Internal - Internal thread pool activity distribution</p> </li> <li> <p>Completed Tasks per sec - Anti Entropy Stage - Repair coordination tasks</p> </li> <li> <p>Completed Tasks per sec - Read Repair Stage - Read repair execution tasks</p> </li> <li> <p>Completed Tasks per sec - Hinted Handoff - Hint delivery tasks</p> </li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#events-section","title":"Events Section","text":"<ul> <li> <p>Starting Repair Events - Repair start event frequency</p> </li> <li> <p>Streaming Events - Data streaming event frequency</p> </li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>groupBy - Dynamic grouping (dc, rack, host_id, keyspace)</p> </li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#understanding-anti-entropy-mechanisms","title":"Understanding Anti-Entropy Mechanisms","text":""},{"location":"metrics/cassandra/entropy_metrics_mapping/#hinted-handoff","title":"Hinted Handoff","text":"<ul> <li> <p>Purpose: Temporary storage of writes when replicas are unavailable</p> </li> <li> <p>TotalHints: Accumulating counter of all hints created</p> </li> <li> <p>HintsInProgress: Current active hint deliveries</p> </li> <li> <p>Impact: High hint rates indicate replica availability issues</p> </li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#read-repair","title":"Read Repair","text":"<ul> <li> <p>Attempted: All read repair attempts</p> </li> <li> <p>RepairedBackground: Asynchronous repairs (non-blocking)</p> </li> <li> <p>RepairedBlocking: Synchronous repairs (blocks read response)</p> </li> </ul> <p>Types:</p> <ul> <li>Background: Happens after read completes</li> <li>Blocking: Happens before read response</li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#coordinator-errors","title":"Coordinator Errors","text":"<ul> <li> <p>Timeouts: Request exceeded configured timeout</p> </li> <li> <p>Unavailables: Not enough replicas available</p> </li> </ul> <p>Causes:</p> <ul> <li>Node overload</li> <li>Network issues</li> <li>Insufficient replicas</li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#thread-pools","title":"Thread Pools","text":"<ul> <li> <p>AntiEntropyStage: Handles repair coordination</p> </li> <li> <p>ReadRepairStage: Executes read repairs</p> </li> <li> <p>HintsDispatcher: Delivers hints to recovered nodes</p> </li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#best-practices","title":"Best Practices","text":""},{"location":"metrics/cassandra/entropy_metrics_mapping/#hints-monitoring","title":"Hints Monitoring","text":"<ul> <li> <p>Zero Hints Ideal: Indicates all replicas available</p> </li> <li> <p>Growing Hints: Sign of persistent replica issues</p> </li> <li> <p>High In-Progress: May indicate slow hint delivery</p> </li> </ul> <p>Actions:</p> <ul> <li>Check node health</li> <li>Review network connectivity</li> <li>Monitor hint storage capacity</li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#read-repair-monitoring","title":"Read Repair Monitoring","text":"<p>Background vs Blocking:</p> <ul> <li>High blocking repairs impact read latency</li> <li>Background repairs are preferred</li> </ul> <p>High Attempt Rate:</p> <ul> <li>Indicates data inconsistency</li> <li>May need full repair</li> </ul> <p>Success Rate:</p> <ul> <li>Compare attempted vs repaired</li> <li>Low success indicates issues</li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#error-monitoring","title":"Error Monitoring","text":"<p>Zero Tolerance:</p> <ul> <li>Any timeouts/unavailables are concerning</li> <li>Investigate root cause immediately</li> </ul> <p>Read vs Write:</p> <ul> <li>Different implications</li> <li>Write unavailables risk data loss</li> </ul> <p>Correlation:</p> <ul> <li>Check with dropped messages</li> <li>Monitor system resources</li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#thread-pool-health","title":"Thread Pool Health","text":"<p>Balanced Distribution:</p> <ul> <li>Even work across pools</li> <li>No single pool dominating</li> </ul> <p>Anti-Entropy Activity:</p> <ul> <li>Spikes during repairs</li> <li>Should be low normally</li> </ul> <p>Hints Dispatcher:</p> <ul> <li>Activity indicates recovery</li> <li>Should complete eventually</li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"metrics/cassandra/entropy_metrics_mapping/#high-hint-rate","title":"High Hint Rate","text":"<ol> <li>Check node status</li> <li>Review network connectivity</li> <li>Monitor disk space for hints</li> <li>Consider max_hint_window_in_ms setting</li> </ol>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#high-read-repair-rate","title":"High Read Repair Rate","text":"<ol> <li>Run nodetool repair</li> <li>Check consistency levels</li> <li>Review replication factor</li> <li>Monitor for flapping nodes</li> </ol>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#timeoutunavailable-errors","title":"Timeout/Unavailable Errors","text":"<ol> <li>Check system resources</li> <li>Review timeout settings</li> <li>Monitor GC activity</li> <li>Check request patterns</li> </ol>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#thread-pool-congestion","title":"Thread Pool Congestion","text":"<ol> <li>Monitor pending tasks</li> <li>Check blocked tasks</li> <li>Review pool sizing</li> <li>Consider capacity expansion</li> </ol>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#units-and-display","title":"Units and Display","text":"<ul> <li> <p>Rates: operations per second (short)</p> </li> <li> <p>Counts: absolute numbers (short)</p> </li> </ul> <p>Legend Format:</p> <ul> <li>Aggregated: <code>$groupBy</code></li> <li>Node-specific: <code>$dc - $host_id</code></li> <li>Thread pools: <code>$scope</code></li> </ul>"},{"location":"metrics/cassandra/entropy_metrics_mapping/#notes","title":"Notes","text":"<ul> <li>Events use message filtering for repair and streaming activities</li> <li>Thread pool metrics use <code>key='CompletedTasks'</code> for rate calculations</li> <li>The dashboard name \"Entropy\" refers to anti-entropy (consistency) mechanisms</li> <li>All rate metrics use <code>axonfunction='rate'</code> for per-second calculations</li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/","title":"Keyspace Dashboard","text":""},{"location":"metrics/cassandra/keyspace_metrics_mapping/#axonops-keyspace-dashboard-metrics-mapping","title":"AxonOps Keyspace Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Keyspace dashboard.</p>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Keyspace dashboard provides keyspace-level performance metrics including latency, throughput, and data distribution. It helps monitor performance characteristics across different keyspaces and identify which keyspaces are consuming the most resources or experiencing performance issues.</p>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/keyspace_metrics_mapping/#keyspace-performance-metrics","title":"Keyspace Performance Metrics","text":"Dashboard Metric Description Attributes <code>cas_Keyspace_ReadLatency</code> Read operation latency <code>keyspace</code>, <code>function</code> (percentiles/Count), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Keyspace_RangeLatency</code> Range query latency <code>keyspace</code>, <code>function</code> (percentiles/Count), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Keyspace_WriteLatency</code> Write operation latency <code>keyspace</code>, <code>function</code> (percentiles/Count), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#data-size-metrics","title":"Data Size Metrics","text":"Dashboard Metric Description Attributes <code>cas_Table_LiveDiskSpaceUsed</code> Live data size per table <code>keyspace</code>, <code>scope</code> (table), <code>function=Count</code>, <code>dc</code>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/keyspace_metrics_mapping/#keyspace-data-size-distribution-pie-chart","title":"Keyspace Data Size Distribution (Pie Chart)","text":"<pre><code>sum by (keyspace) (cas_Table_LiveDiskSpaceUsed{function='Count',dc=~'$dc'})\n</code></pre>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#read-latency-by-keyspace","title":"Read Latency by Keyspace","text":"<pre><code>cas_Keyspace_ReadLatency{function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id',keyspace=~'$keyspace'}\n</code></pre>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#range-read-latency","title":"Range Read Latency","text":"<pre><code>cas_Keyspace_RangeLatency{keyspace=~'$keyspace',function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#write-latency","title":"Write Latency","text":"<pre><code>cas_Keyspace_WriteLatency{keyspace=~'$keyspace',function='$percentile',function!='Max|Min',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#read-throughput-opssec","title":"Read Throughput (ops/sec)","text":"<pre><code>cas_Keyspace_ReadLatency{axonfunction='rate',keyspace=~'$keyspace',function='Count',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#range-read-throughput","title":"Range Read Throughput","text":"<pre><code>cas_Keyspace_RangeLatency{axonfunction='rate',keyspace=~'$keyspace',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#write-throughput","title":"Write Throughput","text":"<pre><code>cas_Keyspace_WriteLatency{axonfunction='rate',keyspace=~'$keyspace',function='Count',function!='Max|Min',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/keyspace_metrics_mapping/#keyspaces-overview-section","title":"Keyspaces Overview Section","text":"<ul> <li>Keyspace Data Size % Distribution - Pie chart showing relative data size per keyspace</li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#latency-statistics-section","title":"Latency Statistics Section","text":"<ul> <li> <p>Read Latency $percentile - Line chart showing read latency at selected percentile</p> </li> <li> <p>Range Read Request Latency $percentile - Line chart for range query latency</p> </li> <li> <p>Write Latency $percentile - Line chart showing write latency</p> </li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#throughput-statistics-section","title":"Throughput Statistics Section","text":"<ul> <li> <p>Reads/sec - Line chart showing read operations per second</p> </li> <li> <p>Range Read Requests/sec - Line chart for range queries per second</p> </li> <li> <p>Writes/sec - Line chart showing write operations per second</p> </li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>groupBy - Dynamic grouping (dc, rack, host_id)</p> </li> <li> <p>percentile - Select latency percentile (50th, 75th, 95th, 98th, 99th, 999th)</p> </li> <li> <p>keyspace - Filter by specific keyspace(s)</p> </li> <li> <p>table (<code>scope</code>) - Filter by specific table(s)</p> </li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#metric-details","title":"Metric Details","text":""},{"location":"metrics/cassandra/keyspace_metrics_mapping/#latency-metrics","title":"Latency Metrics","text":"<ul> <li>Measured in microseconds</li> <li>Available percentiles: 50th, 75th, 95th, 98th, 99th, 999th</li> <li><code>Min</code> and <code>Max</code> values are excluded from queries</li> <li>Shows latency at the keyspace aggregation level</li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#throughput-metrics","title":"Throughput Metrics","text":"<ul> <li>Uses <code>axonfunction='rate'</code> to calculate per-second rates</li> <li>Based on the Count function of latency metrics</li> <li>Units: </li> <li>Reads: rps (reads per second)</li> <li>Writes: wps (writes per second)</li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#data-size-distribution","title":"Data Size Distribution","text":"<ul> <li>Aggregates <code>LiveDiskSpaceUsed</code> across all tables in each keyspace</li> <li>Shows relative size as percentage in pie chart</li> <li>Helps identify keyspaces consuming most storage</li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#legend-format","title":"Legend Format","text":"<ul> <li>Latency/Throughput panels: <code>$host_id - $keyspace</code></li> <li>Shows both node and keyspace for easy correlation</li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#performance-insights","title":"Performance Insights","text":"<p>Keyspace Comparison:</p> <ul> <li>Compare latencies across keyspaces</li> <li>Identify keyspaces with performance issues</li> <li>Monitor throughput distribution</li> </ul> <p>Data Distribution:</p> <ul> <li>Pie chart shows storage distribution</li> <li>Helps with capacity planning</li> <li>Identifies data hotspots</li> </ul> <p>Operation Types:</p> <ul> <li>Separate metrics for reads, writes, and range queries</li> <li>Range queries typically have higher latency</li> <li>Monitor all three for complete picture</li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Monitor Latency Percentiles:</p> <ul> <li>50th percentile: median performance</li> <li>95th/99th percentile: tail latencies</li> <li>Large differences indicate inconsistent performance</li> </ul> <p>Track Throughput Patterns:</p> <ul> <li>Correlate with application usage</li> <li>Identify peak usage times</li> <li>Plan capacity accordingly</li> </ul> <p>Data Size Monitoring:</p> <ul> <li>Regular growth indicates active keyspace</li> <li>Sudden changes may indicate issues</li> <li>Use for storage capacity planning</li> </ul>"},{"location":"metrics/cassandra/keyspace_metrics_mapping/#notes","title":"Notes","text":"<ul> <li>Keyspace metrics aggregate all tables within the keyspace</li> <li>Metrics are collected at the coordinator level</li> <li>Range queries include operations like <code>SELECT</code> with <code>ALLOW FILTERING</code> or token ranges</li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/","title":"Reporting Dashboard","text":""},{"location":"metrics/cassandra/reporting_metrics_mapping/#axonops-reporting-dashboard-metrics-mapping","title":"AxonOps Reporting Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Reporting dashboard.</p>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Reporting dashboard provides high-level system resource utilization and coordinator performance metrics for reporting and capacity planning. It focuses on aggregated views of resource usage and request distribution by consistency level.</p>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/reporting_metrics_mapping/#system-resource-metrics","title":"System Resource Metrics","text":"Dashboard Metric Description Attributes <code>host_Disk_Used</code> Used disk space in bytes <code>mountpoint</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Disk_UsedPercent</code> Disk usage percentage <code>mountpoint</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Disk_SectorsWrite</code> Disk sectors written <code>partition</code>, <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Disk_SectorsRead</code> Disk sectors read <code>partition</code>, <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_CPU_Percent_Merge</code> CPU usage percentage <code>time</code> (real), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#coordinator-metrics","title":"Coordinator Metrics","text":"Dashboard Metric Description Attributes <code>cas_ClientRequest_Latency</code> Request latency at coordinator <code>scope</code> (Read/Write), <code>function</code> (percentiles/Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/reporting_metrics_mapping/#system-resource-utilization","title":"System Resource Utilization","text":"<pre><code>// Used Disk Space Per Node\nhost_Disk_Used{mountpoint=~'$mountpoint',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n\n// Average Disk % Usage (Pie Chart)\n// Used\navg(host_Disk_UsedPercent{mountpoint=~'$mountpoint',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'})\n// Free\navg(100-host_Disk_UsedPercent{mountpoint=~'$mountpoint',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'})\n\n// Max Disk Write Per Second\nmax(host_Disk_SectorsWrite{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id',partition=~'$partition'})\n\n// Max Disk Read Per Second\nmax(host_Disk_SectorsRead{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id',partition=~'$partition'})\n\n// Average CPU Usage per DC\navg(host_CPU_Percent_Merge{time='real',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by (dc)\n</code></pre>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#coordinator-distribution","title":"Coordinator Distribution","text":"<pre><code>// Coordinator Reads Distribution (Pie Chart)\nsum(cas_ClientRequest_Latency{axonfunction='rate',scope='Read*',scope!='Read',function='Count',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by (scope)\n\n// Coordinator Writes Distribution (Pie Chart)\nsum(cas_ClientRequest_Latency{axonfunction='rate',scope='Write*',scope!='Write',function='Count',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by (scope)\n</code></pre>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#coordinator-performance-by-consistency","title":"Coordinator Performance by Consistency","text":"<pre><code>// Read Throughput by Consistency\nsum(cas_ClientRequest_Latency{axonfunction='rate',scope='Read.*$consistency',function='Count',function!='Min|Max',dc=~'$dc',rack=~'$rack', host_id=~'$host_id'}) by ($groupBy)\n\n// Write Throughput by Consistency\nsum(cas_ClientRequest_Latency{axonfunction='rate',scope='Write.*$consistency',function='Count',function!='Min|Max',dc=~'$dc',rack=~'$rack', host_id=~'$host_id'}) by ($groupBy)\n\n// Max Read Latency by Consistency\nmax(cas_ClientRequest_Latency{scope='Read.*$consistency',function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'})\n\n// Max Write Latency by Consistency\nmax(cas_ClientRequest_Latency{scope='Write.*$consistency',function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'})\n</code></pre>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/reporting_metrics_mapping/#system-resource-utilisation","title":"System Resource Utilisation","text":"<ul> <li> <p>Average Disk % Usage - Pie chart showing used vs free disk space</p> </li> <li> <p>Used Disk Space Per Node - Line chart of disk usage trends</p> </li> <li> <p>Max Disk Read Per Second - Peak disk read throughput</p> </li> <li> <p>Max Disk Write Per Second - Peak disk write throughput</p> </li> <li> <p>Average CPU Usage per DC - CPU utilization by datacenter</p> </li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#coordinator","title":"Coordinator","text":"<ul> <li> <p>Coordinator Reads distribution - Pie chart of read consistency level distribution</p> </li> <li> <p>Coordinator Writes distribution - Pie chart of write consistency level distribution</p> </li> <li> <p>Coordinator Read Throughput Per $groupBy ($consistency) - Read ops/sec by consistency</p> </li> <li> <p>Total Coordinator Write Throughput Per $groupBy ($consistency) - Write ops/sec by consistency</p> </li> <li> <p>Max Coordinator Read $consistency Latency - Maximum read latency for selected consistency</p> </li> <li> <p>Max Coordinator Write $consistency Latency - Maximum write latency for selected consistency</p> </li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>percentile - Select latency percentile (50th, 75th, 95th, 98th, 99th, 999th)</p> </li> <li> <p>groupBy - Dynamic grouping (dc, rack, host_id)</p> </li> <li> <p>mount point (<code>mountpoint</code>) - Filter by disk mount point</p> </li> <li> <p>partition - Filter by disk partition</p> </li> <li> <p>consistency - Filter by consistency level (ALL, ANY, ONE, TWO, THREE, SERIAL, QUORUM, etc.)</p> </li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#understanding-the-reporting-dashboard","title":"Understanding the Reporting Dashboard","text":""},{"location":"metrics/cassandra/reporting_metrics_mapping/#purpose","title":"Purpose","text":"<ul> <li>High-level cluster health overview</li> <li>Resource capacity planning</li> <li>Performance trend analysis</li> <li>Consistency level impact assessment</li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#key-metrics-for-reporting","title":"Key Metrics for Reporting","text":"<p>Resource Utilization:</p> <ul> <li>Disk usage trends for capacity planning</li> <li>I/O throughput for performance baseline</li> <li>CPU usage for load distribution</li> </ul> <p>Consistency Patterns:</p> <ul> <li>Distribution shows application behavior</li> <li>Performance impact of consistency choices</li> <li>Helps optimize consistency settings</li> </ul> <p>Aggregated Views:</p> <ul> <li>DC-level CPU averages</li> <li>Cluster-wide consistency distribution</li> <li>Peak performance metrics</li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#report-generation-use-cases","title":"Report Generation Use Cases","text":""},{"location":"metrics/cassandra/reporting_metrics_mapping/#capacity-planning-reports","title":"Capacity Planning Reports","text":"<pre><code>Metrics to Include:\n- Average Disk % Usage - Current utilization\n- Used Disk Space Per Node - Growth trends\n- Average CPU Usage per DC - Processing capacity\n</code></pre>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#performance-baseline-reports","title":"Performance Baseline Reports","text":"<pre><code>Metrics to Include:\n- Max Disk Read/Write Per Second - I/O capacity\n- Max Coordinator Latencies - SLA compliance\n- Throughput by Consistency - Workload patterns\n</code></pre>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#consistency-analysis-reports","title":"Consistency Analysis Reports","text":"<pre><code>Metrics to Include:\n- Coordinator Read/Write distribution - Usage patterns\n- Latency by Consistency - Performance impact\n- Throughput by Consistency - Load distribution\n</code></pre>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#best-practices","title":"Best Practices","text":""},{"location":"metrics/cassandra/reporting_metrics_mapping/#resource-monitoring","title":"Resource Monitoring","text":"<p>Disk Space:</p> <ul> <li>Monitor usage trends</li> <li>Set alerts at 80% utilization</li> <li>Plan expansion at 70%</li> </ul> <p>I/O Performance:</p> <ul> <li>Track peak read/write rates</li> <li>Identify I/O bottlenecks</li> <li>Correlate with application load</li> </ul> <p>CPU Usage:</p> <ul> <li>Monitor DC-level averages</li> <li>Identify hot spots</li> <li>Balance load distribution</li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#consistency-reporting","title":"Consistency Reporting","text":"<p>Distribution Analysis:</p> <ul> <li>Understand application patterns</li> <li>Identify consistency misuse</li> <li>Optimize for performance</li> </ul> <p>Performance Impact:</p> <ul> <li>Compare latency by consistency</li> <li>Measure throughput differences</li> <li>Make data-driven decisions</li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#data-aggregation-notes","title":"Data Aggregation Notes","text":""},{"location":"metrics/cassandra/reporting_metrics_mapping/#disk-metrics","title":"Disk Metrics","text":"<ul> <li>Sectors are converted to bytes for display</li> <li>Rates calculated using <code>axonfunction='rate'</code></li> <li>Mount points exclude system paths (<code>/etc*</code>)</li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#cpu-metrics","title":"CPU Metrics","text":"<ul> <li>Uses <code>time='real'</code> for actual CPU usage</li> <li>Averaged by datacenter for overview</li> <li>Percentage scale 0-100</li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#coordinator-metrics_1","title":"Coordinator Metrics","text":"<ul> <li>Excludes base scopes (<code>scope!='Read'</code>, <code>scope!='Write'</code>)</li> <li>Filters out Min/Max functions for cleaner data</li> <li>Groups by configurable dimensions</li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#units-and-display","title":"Units and Display","text":"<ul> <li> <p>Disk Space: bytes (binary units)</p> </li> <li> <p>Disk I/O: bytes/second</p> </li> <li> <p>CPU: percent (0-100)</p> </li> <li> <p>Latency: microseconds</p> </li> <li> <p>Throughput: rps/wps (reads/writes per second)</p> </li> </ul> <p>Legend Format:</p> <ul> <li>Resources: <code>$dc - $host_id - $mountpoint/$partition</code></li> <li>Coordinator: <code>$groupBy</code> or <code>$scope</code></li> </ul>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#troubleshooting","title":"Troubleshooting","text":""},{"location":"metrics/cassandra/reporting_metrics_mapping/#missing-disk-metrics","title":"Missing Disk Metrics","text":"<ol> <li>Verify mount point filter</li> <li>Check partition naming</li> <li>Confirm agent disk collection</li> </ol>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#inconsistent-cpu-averages","title":"Inconsistent CPU Averages","text":"<ol> <li>Check node availability</li> <li>Verify DC assignment</li> <li>Review time range</li> </ol>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#no-consistency-distribution","title":"No Consistency Distribution","text":"<ol> <li>Ensure client requests exist</li> <li>Check consistency filter</li> <li>Verify scope patterns</li> </ol>"},{"location":"metrics/cassandra/reporting_metrics_mapping/#notes","title":"Notes","text":"<ul> <li>Pie charts show current distribution, not historical</li> <li>Max functions used for worst-case reporting</li> <li>Some queries use special filtering like excluding empty consistency (<code>.*$consistency</code>)</li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/","title":"Security Dashboard","text":""},{"location":"metrics/cassandra/security_metrics_mapping/#axonops-security-dashboard-metrics-mapping","title":"AxonOps Security Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Security dashboard and event sources.</p>"},{"location":"metrics/cassandra/security_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Security dashboard provides comprehensive security monitoring for Cassandra, including authentication tracking, authorization monitoring, and audit logging of DDL, DCL, and DML queries. It also tracks JMX access events for complete security visibility.</p>"},{"location":"metrics/cassandra/security_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/security_metrics_mapping/#authentication-metrics","title":"Authentication Metrics","text":"Dashboard Metric Description Attributes <code>cas_authentication_success</code> Successful authentication attempts <code>username</code>, <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/security_metrics_mapping/#event-based-security-monitoring","title":"Event-Based Security Monitoring","text":"<p>Unlike other dashboards that primarily use metrics, the Security dashboard is heavily event-driven, using AxonOps' event collection and filtering capabilities.</p>"},{"location":"metrics/cassandra/security_metrics_mapping/#event-types-and-filters","title":"Event Types and Filters","text":"Event Type Source Level Description Panel Usage <code>authentication</code> Cassandra <code>error</code> Failed authentication attempts Failed Authentications (timeline &amp; table) <code>DDL_query</code> Cassandra all Data Definition Language queries (CREATE, ALTER, DROP) DDL queries (timeline &amp; table) <code>DCL_query</code> Cassandra all Data Control Language queries (GRANT, REVOKE) DCL queries (timeline &amp; table) <code>DML_query</code> Cassandra all Data Manipulation Language queries (SELECT, INSERT, UPDATE, DELETE) DML queries (timeline &amp; table) <code>authorization</code> Cassandra <code>error</code> Failed authorization attempts Failed Authorizations (timeline &amp; table) <code>jmx</code> System all JMX access events JMX (timeline &amp; table)"},{"location":"metrics/cassandra/security_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/security_metrics_mapping/#authentication-metrics_1","title":"Authentication Metrics","text":"<pre><code>// Successful Authentications by User (Rate)\nsum(cas_authentication_success{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by (username)\n</code></pre>"},{"location":"metrics/cassandra/security_metrics_mapping/#event-filters","title":"Event Filters","text":"<pre><code># Failed Authentications\n{\n  \"host_id\": \"$host_id\",\n  \"level\": \"error\",\n  \"type\": \"authentication\"\n}\n\n# DDL Queries\n{\n  \"host_id\": \"$host_id\",\n  \"source\": \"Cassandra\",\n  \"type\": \"DDL_query\"\n}\n\n# DCL Queries\n{\n  \"source\": \"Cassandra\",\n  \"type\": \"DCL_query\"\n}\n\n# DML Queries\n{\n  \"host_id\": \"$host_id\",\n  \"source\": \"Cassandra\",\n  \"type\": \"DML_query\"\n}\n\n# Failed Authorizations\n{\n  \"level\": \"error\",\n  \"source\": \"Cassandra\",\n  \"type\": \"authorization\"\n}\n\n# JMX Events\n{\n  \"host_id\": \"$host_id\",\n  \"type\": \"jmx\"\n}\n</code></pre>"},{"location":"metrics/cassandra/security_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/security_metrics_mapping/#authentications-section","title":"Authentications Section","text":"<ul> <li> <p>Failed Authentications - Timeline view of authentication failures</p> </li> <li> <p>Failed Authentications - Table view with detailed event information</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#cassandra-queries-section","title":"Cassandra Queries Section","text":"<ul> <li> <p>DDL queries - Timeline of schema changes</p> </li> <li> <p>DDL queries - Table view of DDL operations</p> </li> <li> <p>DCL queries - Timeline of permission changes</p> </li> <li> <p>DCL query - Table view of DCL operations</p> </li> <li> <p>DML queries - Timeline of data modifications</p> </li> <li> <p>DML queries - Table view of DML operations</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#authorizations-section","title":"Authorizations Section","text":"<ul> <li> <p>Failed Authorizations - Timeline of authorization failures</p> </li> <li> <p>Failed Authorizations - Table view with details</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#jmx-section","title":"JMX Section","text":"<ul> <li> <p>JMX - Timeline of JMX access events</p> </li> <li> <p>JMX - Table view of JMX operations</p> </li> <li> <p>Successful Authentications by user (rate) - Line chart showing authentication success rates per user</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>groupBy - Dynamic grouping (dc, rack, host_id)</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#security-event-details","title":"Security Event Details","text":""},{"location":"metrics/cassandra/security_metrics_mapping/#authentication-events","title":"Authentication Events","text":"<ul> <li> <p>Failed Authentication: Captured when invalid credentials are provided</p> </li> <li> <p>Successful Authentication: Tracked via metrics for rate analysis</p> </li> <li> <p>Event Fields: timestamp, host_id, username, source IP, error message</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#ddl-query-events","title":"DDL Query Events","text":"<ul> <li> <p>CREATE: Keyspace, table, index, user, role creation</p> </li> <li> <p>ALTER: Schema modifications</p> </li> <li> <p>DROP: Object deletion</p> </li> <li> <p>Event Fields: timestamp, host_id, username, query, keyspace, table</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#dcl-query-events","title":"DCL Query Events","text":"<ul> <li> <p>GRANT: Permission grants to users/roles</p> </li> <li> <p>REVOKE: Permission revocations</p> </li> <li> <p>Event Fields: timestamp, host_id, username, query, resource, permission</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#dml-query-events","title":"DML Query Events","text":"<ul> <li> <p>SELECT: Data reads (when audit enabled)</p> </li> <li> <p>INSERT/UPDATE: Data modifications</p> </li> <li> <p>DELETE: Data removal</p> </li> <li> <p>Event Fields: timestamp, host_id, username, query, keyspace, table</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#authorization-events","title":"Authorization Events","text":"<ul> <li> <p>Failed Authorization: User lacks required permissions</p> </li> <li> <p>Event Fields: timestamp, host_id, username, resource, operation, required permission</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#jmx-events","title":"JMX Events","text":"<ul> <li> <p>JMX Operations: MBean access and modifications</p> </li> <li> <p>Event Fields: timestamp, host_id, operation, MBean, user</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#event-timeline-vs-table-views","title":"Event Timeline vs Table Views","text":""},{"location":"metrics/cassandra/security_metrics_mapping/#timeline-views-events_timeline","title":"Timeline Views (<code>events_timeline</code>)","text":"<ul> <li>Visual representation of event frequency over time</li> <li>Quickly identify security incident patterns</li> <li>Useful for trend analysis and anomaly detection</li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#table-views-events_table","title":"Table Views (<code>events_table</code>)","text":"<ul> <li>Detailed event information</li> <li>Full query text and parameters</li> <li>User attribution and source information</li> <li>Sortable and searchable</li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#security-best-practices","title":"Security Best Practices","text":""},{"location":"metrics/cassandra/security_metrics_mapping/#authentication-monitoring","title":"Authentication Monitoring","text":"<p>Monitor Failed Attempts:</p> <ul> <li>Set alerts for repeated failures</li> <li>Identify brute force attempts</li> <li>Track source IPs</li> </ul> <p>Track Success Rates:</p> <ul> <li>Monitor per-user authentication rates</li> <li>Identify unusual access patterns</li> <li>Detect compromised accounts</li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#query-auditing","title":"Query Auditing","text":"<p>DDL Monitoring:</p> <ul> <li>Track all schema changes</li> <li>Maintain change history</li> <li>Identify unauthorized modifications</li> </ul> <p>DCL Monitoring:</p> <ul> <li>Track permission changes</li> <li>Audit role modifications</li> <li>Ensure least privilege</li> </ul> <p>DML Monitoring (if enabled):</p> <ul> <li>Monitor sensitive data access</li> <li>Track data modifications</li> <li>Compliance reporting</li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#authorization-monitoring","title":"Authorization Monitoring","text":"<p>Failed Authorization:</p> <ul> <li>Identify permission gaps</li> <li>Detect privilege escalation attempts</li> <li>Review access patterns</li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#jmx-security","title":"JMX Security","text":"<p>Access Monitoring:</p> <ul> <li>Track administrative operations</li> <li>Monitor configuration changes</li> <li>Audit system modifications</li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#configuration-requirements","title":"Configuration Requirements","text":""},{"location":"metrics/cassandra/security_metrics_mapping/#enable-security-features","title":"Enable Security Features","text":"<ul> <li> <p>Authentication: Set <code>authenticator</code> in cassandra.yaml</p> </li> <li> <p>Authorization: Set <code>authorizer</code> in cassandra.yaml</p> </li> <li> <p>Audit Logging: Configure audit log settings</p> </li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#axonops-agent-configuration","title":"AxonOps Agent Configuration","text":"<ol> <li>Enable event collection</li> <li>Configure event retention</li> <li>Set appropriate event filters</li> </ol>"},{"location":"metrics/cassandra/security_metrics_mapping/#compliance-and-reporting","title":"Compliance and Reporting","text":""},{"location":"metrics/cassandra/security_metrics_mapping/#audit-trail","title":"Audit Trail","text":"<ul> <li>Complete record of security events</li> <li>User attribution for all actions</li> <li>Timestamp precision for forensics</li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#compliance-support","title":"Compliance Support","text":"<ul> <li>PCI DSS: Track access to cardholder data</li> <li>HIPAA: Monitor PHI access</li> <li>GDPR: Audit data access and modifications</li> <li>SOX: Track financial data access</li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#reporting-capabilities","title":"Reporting Capabilities","text":"<ul> <li>Export event data for analysis</li> <li>Generate compliance reports</li> <li>Security incident investigation</li> </ul>"},{"location":"metrics/cassandra/security_metrics_mapping/#troubleshooting","title":"Troubleshooting","text":""},{"location":"metrics/cassandra/security_metrics_mapping/#no-events-showing","title":"No Events Showing","text":"<ol> <li>Verify security features enabled in Cassandra</li> <li>Check AxonOps agent event collection</li> <li>Confirm event filters match your setup</li> </ol>"},{"location":"metrics/cassandra/security_metrics_mapping/#missing-authentication-metrics","title":"Missing Authentication Metrics","text":"<ol> <li>Ensure authentication is enabled</li> <li>Verify metrics collection is active</li> <li>Check user activity exists</li> </ol>"},{"location":"metrics/cassandra/security_metrics_mapping/#performance-impact","title":"Performance Impact","text":"<ol> <li>DML auditing can impact performance</li> <li>Consider sampling for high-volume systems</li> <li>Adjust event retention policies</li> </ol>"},{"location":"metrics/cassandra/security_metrics_mapping/#notes","title":"Notes","text":"<ul> <li>Event-based panels don't show metrics queries</li> <li>Filters use exact matching for event fields</li> <li>Some panels filter by <code>$host_id</code>, others show cluster-wide</li> <li>Timeline and table views often paired for same event type</li> <li>The dashboard emphasizes security event visibility over performance metrics</li> </ul>"},{"location":"metrics/cassandra/system_metrics_mapping/","title":"System Dashboard","text":""},{"location":"metrics/cassandra/system_metrics_mapping/#axonops-system-dashboard-metrics-mapping","title":"AxonOps System Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps System dashboard to their corresponding sources.</p>"},{"location":"metrics/cassandra/system_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The System dashboard provides comprehensive monitoring of system resources including CPU, memory, disk, network, and JVM metrics. It helps monitor the health and performance of Cassandra nodes at the operating system level.</p>"},{"location":"metrics/cassandra/system_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/system_metrics_mapping/#cpu-and-load-metrics","title":"CPU and Load Metrics","text":"Dashboard Metric Source Description Attributes <code>host_CPU_Percent_Merge</code> System metrics Overall CPU usage percentage <code>time=real</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_CPU</code> System metrics CPU usage by mode <code>mode</code> (system/nice/user/iowait/irq/softirq), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_load15</code> System metrics 15-minute load average <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/system_metrics_mapping/#memory-metrics","title":"Memory Metrics","text":"Dashboard Metric Source Description Attributes <code>host_Memory_Used</code> System metrics Used memory in bytes <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Memory_UsedPercent</code> System metrics Used memory percentage <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Memory_Cached</code> System metrics Cached memory in bytes <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/system_metrics_mapping/#disk-metrics","title":"Disk Metrics","text":"Dashboard Metric Source Description Attributes <code>host_Disk_UsedPercent</code> System metrics Disk usage percentage <code>mountpoint</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Disk_Used</code> System metrics Used disk space in bytes <code>mountpoint</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Disk_avgqsz</code> System metrics Average queue size <code>partition</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Disk_IOCount</code> System metrics I/O operations count <code>partition</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Disk_SectorsRead</code> System metrics Sectors read <code>partition</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Disk_SectorsWrite</code> System metrics Sectors written <code>partition</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Disk_WeightedIO</code> System metrics Weighted I/O time <code>partition</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_Disk_IoTime</code> System metrics Time spent on disk I/O <code>partition</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_filefd_allocated</code> System metrics Allocated file descriptors <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_filefd_max</code> System metrics Maximum file descriptors <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/system_metrics_mapping/#network-metrics","title":"Network Metrics","text":"Dashboard Metric Source Description Attributes <code>host_netIOCounters_BytesRecv</code> System metrics Network bytes received <code>Interface</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_netIOCounters_BytesSent</code> System metrics Network bytes sent <code>Interface</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>host_ntp_offset_seconds</code> System metrics NTP time offset in seconds <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/system_metrics_mapping/#jvm-metrics","title":"JVM Metrics","text":"Dashboard Metric Description Attributes <code>jvm_Memory_</code> JVM memory usage <code>function</code> (used/max/committed), <code>scope</code> (HeapMemoryUsage/NonHeapMemoryUsage) <code>jvm_Threading_</code> JVM thread information <code>function</code> (ThreadCount) <code>jvm_GarbageCollector_*</code> GC statistics <code>function</code> (CollectionCount/CollectionTime), collector name"},{"location":"metrics/cassandra/system_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/system_metrics_mapping/#cpu-usage-per-host","title":"CPU Usage per Host","text":"<pre><code>host_CPU_Percent_Merge{time='real',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/system_metrics_mapping/#average-io-wait-cpu-per-host","title":"Average IO Wait CPU per Host","text":"<pre><code>avg(host_CPU{axonfunction='rate',mode='iowait',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by (host_id) * 100\n</code></pre>"},{"location":"metrics/cassandra/system_metrics_mapping/#disk-usage-percentage","title":"Disk Usage Percentage","text":"<pre><code>host_Disk_UsedPercent{mountpoint=~'$mountpoint',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/system_metrics_mapping/#network-received-bytes-rate","title":"Network Received Bytes Rate","text":"<pre><code>host_netIOCounters_BytesRecv{axonfunction='rate',Interface=~'$Interface',Interface!='lo',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/system_metrics_mapping/#jvm-heap-utilization","title":"JVM Heap Utilization","text":"<pre><code>jvm_Memory_{function='used',scope='HeapMemoryUsage',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/system_metrics_mapping/#gc-count-per-second","title":"GC Count per Second","text":"<pre><code>jvm_GarbageCollector_G1_Young_Generation{axonfunction='rate',function='CollectionCount',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/system_metrics_mapping/#panel-types-and-descriptions","title":"Panel Types and Descriptions","text":"<ul> <li> <p>CPU usage per host - Line chart showing overall CPU utilization</p> </li> <li> <p>Avg IO wait CPU per Host - Line chart highlighting I/O wait time</p> </li> <li> <p>Load Average (15m) - Line chart displaying system load</p> </li> <li> <p>CPU Usage Detail - Multiple line charts for different CPU modes (User, System, Nice, I/O Wait, Interrupt)</p> </li> <li> <p>Disk Statistics - Charts for disk usage, IOPS, bytes read/write, queue size</p> </li> <li> <p>Memory Statistics - Charts for memory usage, JVM heap, GC activity</p> </li> <li> <p>Network Statistics - Charts for network I/O and NTP offset</p> </li> </ul>"},{"location":"metrics/cassandra/system_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>mount point (<code>mountpoint</code>) - Filter by disk mount point</p> </li> <li> <p>partition - Filter by disk partition</p> </li> <li> <p>interface (<code>Interface</code>) - Filter by network interface</p> </li> </ul>"},{"location":"metrics/cassandra/system_metrics_mapping/#notes","title":"Notes","text":"<ol> <li>Host metrics are collected by the AxonOps agent at the OS level</li> <li>JVM metrics are collected via JMX from the Cassandra process</li> <li>The <code>axonfunction='rate'</code> label calculates rate-based metrics</li> <li>Network interface 'lo' (loopback) is typically excluded from network metrics</li> <li>CPU percentages are calculated from rate metrics and multiplied by 100</li> <li>File descriptor usage is shown as a percentage: <code>(allocated/max)*100</code></li> </ol>"},{"location":"metrics/cassandra/table_metrics_mapping/","title":"Table Dashboard","text":""},{"location":"metrics/cassandra/table_metrics_mapping/#axonops-table-dashboard-metrics-mapping","title":"AxonOps Table Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Table dashboard.</p>"},{"location":"metrics/cassandra/table_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Table dashboard provides comprehensive table-level metrics including coordinator and replica statistics, latency metrics, throughput, data distribution, and performance indicators. It helps identify table-specific issues and optimization opportunities.</p>"},{"location":"metrics/cassandra/table_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/table_metrics_mapping/#data-distribution-metrics","title":"Data Distribution Metrics","text":"Dashboard Metric Description Attributes <code>cas_Table_LiveDiskSpaceUsed</code> Live data size per table <code>keyspace</code>, <code>scope</code> (table), <code>function=Count</code>, <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/table_metrics_mapping/#coordinator-metrics-table-level","title":"Coordinator Metrics (Table-level)","text":"Dashboard Metric Description Attributes <code>cas_Table_CoordinatorReadLatency</code> Read latency at coordinator level <code>keyspace</code>, <code>scope</code> (table), <code>function</code> (percentiles/Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_CoordinatorWriteLatency</code> Write latency at coordinator level <code>keyspace</code>, <code>scope</code> (table), <code>function</code> (percentiles/Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_CoordinatorScanLatency</code> Range scan latency at coordinator <code>keyspace</code>, <code>scope</code> (table), <code>function</code> (percentiles/Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/table_metrics_mapping/#replica-metrics-local","title":"Replica Metrics (Local)","text":"Dashboard Metric Description Attributes <code>cas_Table_ReadLatency</code> Local read latency <code>keyspace</code>, <code>scope</code> (table), <code>function</code> (percentiles/Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_WriteLatency</code> Local write latency <code>keyspace</code>, <code>scope</code> (table), <code>function</code> (percentiles/Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_RangeLatency</code> Local range query latency <code>keyspace</code>, <code>scope</code> (table), <code>function</code> (percentiles/Count), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/table_metrics_mapping/#partition-and-sstable-metrics","title":"Partition and SSTable Metrics","text":"Dashboard Metric Description Attributes <code>cas_Table_MeanPartitionSize</code> Average partition size <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_MaxPartitionSize</code> Maximum partition size <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_EstimatedPartitionCount</code> Estimated number of partitions <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_LiveSSTableCount</code> Number of live SSTables <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_SSTablesPerReadHistogram</code> SSTables accessed per read <code>keyspace</code>, <code>scope</code> (table), <code>function</code> (percentiles), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/table_metrics_mapping/#performance-indicators","title":"Performance Indicators","text":"Dashboard Metric Description Attributes <code>cas_Table_TombstoneScannedHistogram</code> Tombstones scanned per query <code>keyspace</code>, <code>scope</code> (table), <code>function</code> (percentiles), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_SpeculativeRetries</code> Speculative retry attempts <code>keyspace</code>, <code>scope</code> (table), <code>function=Count</code>, <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_BloomFilterFalseRatio</code> Bloom filter false positive ratio <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_BloomFilterDiskSpaceUsed</code> Disk space used by bloom filters <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/table_metrics_mapping/#memory-metrics","title":"Memory Metrics","text":"Dashboard Metric Description Attributes <code>cas_Table_AllMemtablesHeapSize</code> Heap memory used by memtables <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>cas_Table_AllMemtablesOffHeapSize</code> Off-heap memory used by memtables <code>keyspace</code>, <code>scope</code> (table), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/table_metrics_mapping/#jvm-garbage-collection-metrics","title":"JVM Garbage Collection Metrics","text":"Dashboard Metric Description Attributes <code>jvm_GarbageCollector_G1_Young_Generation</code> G1 young generation GC <code>function</code> (CollectionTime/CollectionCount), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>jvm_GarbageCollector_Shenandoah_Cycles</code> Shenandoah GC cycles <code>function</code> (CollectionCount), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>jvm_GarbageCollector_Shenandoah_Pauses</code> Shenandoah GC pauses <code>function</code> (CollectionTime), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>jvm_GarbageCollector_ZGC</code> ZGC garbage collector <code>function</code> (CollectionTime/CollectionCount), <code>axonfunction</code> (rate), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/table_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/table_metrics_mapping/#tables-overview-section","title":"Tables Overview Section","text":"<pre><code>// Table Data Size Distribution (Pie Chart)\nsum by (keyspace,scope) (cas_Table_LiveDiskSpaceUsed{function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'})\n\n// Coordinator Table Reads Distribution (Pie Chart)\nsum by (keyspace,scope) (cas_Table_CoordinatorReadLatency{axonfunction='rate',dc=~'$dc',rack=~'$rack',host_id=~'$host_id',function='Count'})\n\n// Coordinator Table Writes Distribution (Pie Chart)\nsum by (keyspace, scope) (cas_Table_CoordinatorWriteLatency{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',axonfunction='rate',function=~'Count'})\n</code></pre>"},{"location":"metrics/cassandra/table_metrics_mapping/#coordinator-table-statistics","title":"Coordinator Table Statistics","text":"<pre><code>// Max Coordinator Read Latency\nmax(cas_Table_CoordinatorReadLatency{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',function='$percentile',keyspace=~'$keyspace',scope=~'$scope'}) by ($groupBy,keyspace,scope)\n\n// Max Coordinator Write Latency\nmax(cas_Table_CoordinatorWriteLatency{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',function='$percentile',keyspace=~'$keyspace',scope=~'$scope'}) by ($groupBy,keyspace,scope)\n\n// Max Coordinator Range Read Latency\nmax(cas_Table_CoordinatorScanLatency{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',function=~'$percentile',keyspace=~'$keyspace',scope=~'$scope'}) by ($groupBy,keyspace,scope)\n\n// Total Coordinator Reads/sec\nsum (cas_Table_CoordinatorReadLatency{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',axonfunction='rate',function=~'Count',keyspace=~'$keyspace',scope=~'$scope'}) by ($groupBy,keyspace,scope)\n\n// Average Coordinator Range Reads/sec\navg(cas_Table_CoordinatorScanLatency{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',axonfunction='rate',function=~'Count',keyspace=~'$keyspace',scope=~'$scope'}) by ($groupBy,keyspace,scope)\n\n// Total Coordinator Writes/sec\nsum (cas_Table_CoordinatorWriteLatency{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',axonfunction='rate',function='Count',keyspace=~'$keyspace',scope=~'$scope'}) by ($groupBy,keyspace,scope)\n</code></pre>"},{"location":"metrics/cassandra/table_metrics_mapping/#table-replica-statistics","title":"Table Replica Statistics","text":"<pre><code>// Average Replica Read Latency\navg(cas_Table_ReadLatency{scope=~'$scope',scope!='',keyspace=~'$keyspace',function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy,keyspace,scope)\n\n// Average Replica Range Read Latency\navg(cas_Table_RangeLatency{scope=~'$scope',scope!='',keyspace=~'$keyspace',function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy,keyspace,scope)\n\n// Average Replica Write Latency\navg(cas_Table_WriteLatency{scope=~'$scope',scope!='',keyspace=~'$keyspace',function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy,keyspace,scope)\n\n// Total Replica Reads/sec\nsum(cas_Table_ReadLatency{axonfunction='rate',scope=~'$scope',scope!='',keyspace=~'$keyspace',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy,keyspace,scope)\n\n// Total Replica Range Reads/sec\nsum(cas_Table_RangeLatency{axonfunction='rate',scope=~'$scope',scope!='',keyspace=~'$keyspace',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy,keyspace,scope)\n\n// Total Replica Writes/sec\nsum(cas_Table_WriteLatency{axonfunction='rate',scope=~'$scope',scope!='',keyspace=~'$keyspace',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy,keyspace,scope)\n</code></pre>"},{"location":"metrics/cassandra/table_metrics_mapping/#latency-causes","title":"Latency Causes","text":"<pre><code>// Average Mean Partition Size\navg(cas_Table_MeanPartitionSize{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',scope=~'$scope',scope!=''}) by ($groupBy,keyspace,scope)\n\n// Total Estimated Partitions\nsum(cas_Table_EstimatedPartitionCount{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',keyspace='$keyspace',scope='$scope'}) by ($groupBy,keyspace,scope)\n\n// Max Partition Size\nmax(cas_Table_MaxPartitionSize{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',scope=~'$scope',scope!=''}) by ($groupBy,keyspace,scope)\n\n// SSTables Per Read\ncas_Table_SSTablesPerReadHistogram{scope=~'$scope',scope!='',keyspace=~'$keyspace',function='$percentile',function!='Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n\n// Max Live SSTables\nmax(cas_Table_LiveSSTableCount{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',scope=~'$scope',scope!=''}) by ($groupBy,keyspace,scope)\n\n// Tombstones Scanned\ncas_Table_TombstoneScannedHistogram{scope=~'$scope',scope!='',keyspace=~'$keyspace',function='$percentile',function!='Count|Min|Max',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n\n// Speculative Retries\ncas_Table_SpeculativeRetries{axonfunction='rate',scope=~'$scope',scope!='',keyspace=~'$keyspace',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n\n// Bloom Filter False Ratio\ncas_Table_BloomFilterFalseRatio{scope=~'$scope',scope!='',keyspace=~'$keyspace',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n\n// Max Bloom Filter Disk\nmax(cas_Table_BloomFilterDiskSpaceUsed{dc=~'$dc',rack=~'$rack',host_id=~'$host_id',keyspace='$keyspace',scope='$scope'}) by ($groupBy,keyspace,scope)\n</code></pre>"},{"location":"metrics/cassandra/table_metrics_mapping/#memory-statistics","title":"Memory Statistics","text":"<pre><code>// Total Table Heap Memory\nsum(cas_Table_AllMemtablesHeapSize{dc=~'$dc',rack='$rack',host_id=~'$host_id',keyspace='$keyspace',scope='$scope'}) by ($groupBy,keyspace,scope)\n\n// Total Table Off-Heap Memory\nsum(cas_Table_AllMemtablesOffHeapSize{dc=~'$dc',rack='$rack',host_id=~'$host_id',keyspace='$keyspace',scope='$scope'}) by ($groupBy,keyspace,scope)\n\n// GC Duration - G1 YoungGen\njvm_GarbageCollector_G1_Young_Generation{axonfunction='rate',function='CollectionTime',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n\n// GC Count per sec - G1 YoungGen\njvm_GarbageCollector_G1_Young_Generation{axonfunction='rate',function='CollectionCount',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/cassandra/table_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/cassandra/table_metrics_mapping/#tables-overview","title":"Tables Overview","text":"<ul> <li> <p>Table Data Size % Distribution - Pie chart showing relative data size per table</p> </li> <li> <p>Coordinator Table Reads % Distribution - Read request distribution by table</p> </li> <li> <p>Coordinator Table Writes % Distribution - Write request distribution by table</p> </li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#coordinator-table-statistics_1","title":"Coordinator Table Statistics","text":"<ul> <li> <p>Max Coordinator Table Read Latency - Maximum read latency at coordinator</p> </li> <li> <p>Max Coordinator Table Write Latency - Maximum write latency at coordinator</p> </li> <li> <p>Max Coordinator Table Range Read Latency - Maximum range query latency</p> </li> <li> <p>Total Coordinator Table Reads/Sec - Read throughput at coordinator</p> </li> <li> <p>Average Coordinator Table Range Reads/Sec - Range query throughput</p> </li> <li> <p>Total Coordinator Table Writes/Sec - Write throughput at coordinator</p> </li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#table-replica-statistics_1","title":"Table Replica Statistics","text":"<ul> <li> <p>Average Replica Read Latency - Local read latency</p> </li> <li> <p>Average Replica Range Read Latency - Local range query latency</p> </li> <li> <p>Average Replica Write Latency - Local write latency</p> </li> <li> <p>Total Replica Reads/sec - Local read throughput</p> </li> <li> <p>Total Replica Table Range Reads/sec - Local range query throughput</p> </li> <li> <p>Total Replica Writes/sec - Local write throughput</p> </li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#latency-causes_1","title":"Latency Causes","text":"<ul> <li> <p>Average Mean Table Partition Size - Average partition size indicator</p> </li> <li> <p>Total Estimated Table Partitions Count - Partition count per table</p> </li> <li> <p>Max Table Partition Size - Largest partition (hotspot indicator)</p> </li> <li> <p>SSTables Per Read - SSTable access efficiency</p> </li> <li> <p>Max Live SSTables per Table - SSTable count (compaction indicator)</p> </li> <li> <p>Tombstones Scanned per Table - Tombstone impact on reads</p> </li> <li> <p>SpeculativeRetries By Node For Table Reads - Retry attempts</p> </li> <li> <p>Bloom Filter False Positive Ratio - Filter efficiency</p> </li> <li> <p>Max Table Bloom Filter Disk - Bloom filter storage</p> </li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#memory-statistics_1","title":"Memory Statistics","text":"<ul> <li> <p>Total Table Heap Memory - Memtable heap usage</p> </li> <li> <p>Total Table Off-Heap Memory - Memtable off-heap usage</p> </li> <li> <p>GC duration - G1 YoungGen - Young generation GC time</p> </li> <li> <p>GC count per sec - G1 YoungGen - Young generation GC frequency</p> </li> <li> <p>GC duration - Shenandoah - Shenandoah GC time</p> </li> <li> <p>GC Count per sec - Shenandoah - Shenandoah GC frequency</p> </li> <li> <p>GC duration - ZGC - ZGC time</p> </li> <li> <p>GC Count per sec - ZGC - ZGC frequency</p> </li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>groupBy - Dynamic grouping (dc, rack, host_id)</p> </li> <li> <p>percentile - Select latency percentile (50th, 75th, 95th, 98th, 99th, 999th)</p> </li> <li> <p>keyspace - Filter by keyspace</p> </li> <li> <p>table (<code>scope</code>) - Filter by table</p> </li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#understanding-table-metrics","title":"Understanding Table Metrics","text":""},{"location":"metrics/cassandra/table_metrics_mapping/#coordinator-vs-replica-metrics","title":"Coordinator vs Replica Metrics","text":"<ul> <li> <p>Coordinator: Metrics from the node coordinating the request</p> </li> <li> <p>Replica: Metrics from nodes storing the data</p> </li> <li> <p>Coordinator latency includes network and replica time</p> </li> <li>Replica latency is local operation time only</li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#performance-indicators_1","title":"Performance Indicators","text":"<p>Partition Size:</p> <ul> <li>Large partitions (&gt;100MB) cause performance issues</li> <li>Monitor max size for hotspot detection</li> <li>Mean size indicates data distribution</li> </ul> <p>SSTable Metrics:</p> <ul> <li>High SSTable count impacts read performance</li> <li>More SSTables = more files to check</li> <li>Indicates compaction strategy effectiveness</li> </ul> <p>Tombstones:</p> <ul> <li>Deleted data markers</li> <li>High tombstone counts slow reads</li> <li>Indicates need for compaction or TTL review</li> </ul> <p>Bloom Filters:</p> <ul> <li>Probabilistic data structure for SSTable lookups</li> <li>False positive ratio should be &lt;0.1</li> <li>Higher ratios mean unnecessary SSTable reads</li> </ul> <p>Speculative Retries:</p> <ul> <li>Proactive retry mechanism for slow reads</li> <li>High rates indicate inconsistent performance</li> <li>May need tuning or investigation</li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#best-practices","title":"Best Practices","text":""},{"location":"metrics/cassandra/table_metrics_mapping/#table-design","title":"Table Design","text":"<ul> <li> <p>Partition Size: Keep &lt;100MB, ideally &lt;10MB</p> </li> <li> <p>Even Distribution: Avoid hotspots</p> </li> <li> <p>Appropriate TTL: Manage tombstone creation</p> </li> <li> <p>Compression: Choose based on workload</p> </li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#performance-monitoring","title":"Performance Monitoring","text":"<p>Latency Percentiles:</p> <ul> <li>p50: Median performance</li> <li>p99: Tail latency</li> <li>Large p50-p99 gap indicates issues</li> </ul> <p>Throughput Balance:</p> <ul> <li>Even distribution across tables</li> <li>Identify heavy tables</li> <li>Plan capacity accordingly</li> </ul> <p>Resource Usage:</p> <ul> <li>Monitor memory per table</li> <li>Track GC impact</li> <li>Balance heap/off-heap usage</li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#troubleshooting","title":"Troubleshooting","text":"<p>High Latency:</p> <ul> <li>Check partition sizes</li> <li>Review SSTable counts</li> <li>Monitor tombstones</li> <li>Verify bloom filter efficiency</li> </ul> <p>Memory Issues:</p> <ul> <li>Check memtable sizes</li> <li>Monitor GC frequency</li> <li>Review flush thresholds</li> </ul> <p>Throughput Problems:</p> <ul> <li>Analyze coordinator distribution</li> <li>Check speculative retries</li> <li>Review consistency levels</li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#units-and-display","title":"Units and Display","text":"<ul> <li> <p>Latency: microseconds</p> </li> <li> <p>Throughput: ops/sec (rps/wps)</p> </li> <li> <p>Size: bytes (binary units)</p> </li> <li> <p>Ratio: decimal/percentage</p> </li> <li> <p>Count: short (absolute numbers)</p> </li> <li> <p>GC: milliseconds/count per sec</p> </li> </ul> <p>Legend Format:</p> <ul> <li>Overview: <code>$keyspace $scope</code></li> <li>Details: <code>$groupBy - $keyspace $scope</code></li> <li>Node-specific: <code>$dc - $host_id</code></li> </ul>"},{"location":"metrics/cassandra/table_metrics_mapping/#notes","title":"Notes","text":"<ul> <li>The <code>scope!=''</code> filter excludes empty table names</li> <li><code>function!='Min|Max'</code> excludes extreme values for percentiles</li> <li>Coordinator metrics show client-facing performance</li> <li>Replica metrics show storage-layer performance</li> <li>GC metrics help correlate latency with JVM behavior</li> <li>Some queries use special operations like <code>diff</code> or specific rack filtering</li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/","title":"Thread Pools Dashboard","text":""},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#axonops-thread-pools-dashboard-metrics-mapping","title":"AxonOps Thread Pools Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Thread Pools dashboard.</p>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Thread Pools dashboard monitors Cassandra's internal thread pools that handle various operations like reads, writes, compactions, and repairs. Understanding thread pool behavior is crucial for identifying performance bottlenecks and tuning Cassandra for optimal performance.</p>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#thread-pool-metrics","title":"Thread Pool Metrics","text":"Dashboard Metric Description Attributes <code>cas_ThreadPools_internal</code> Internal thread pool metrics <code>scope</code> (pool name), <code>key</code> (metric type), <code>dc</code>, <code>rack</code>, <code>host_id</code>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#metric-keys-types","title":"Metric Keys (Types)","text":"Key Description <code>ActiveTasks</code> Number of tasks currently being executed <code>PendingTasks</code> Number of tasks waiting in the queue <code>CompletedTasks</code> Total number of completed tasks (cumulative) <code>TotalBlockedTasks</code> Total number of tasks that were blocked (cumulative) <code>CurrentlyBlockedTasks</code> Number of tasks currently blocked"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#common-thread-pool-scopes","title":"Common Thread Pool Scopes","text":"Scope Purpose <code>MutationStage</code> Handles write operations <code>ReadStage</code> Handles read operations <code>RequestResponseStage</code> Handles request/response messaging <code>CompactionExecutor</code> Handles compaction tasks <code>ValidationExecutor</code> Handles validation tasks (repairs) <code>GossipStage</code> Handles gossip protocol <code>AntiEntropyStage</code> Handles anti-entropy repairs <code>MigrationStage</code> Handles schema migrations <code>MemtableFlushWriter</code> Handles memtable flush operations <code>MemtablePostFlush</code> Handles post-flush operations <code>HintsDispatcher</code> Handles hint delivery"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#active-tasks","title":"Active Tasks","text":"<pre><code>sum(cas_ThreadPools_internal{scope=~'$scope',key='ActiveTasks',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#pending-tasks","title":"Pending Tasks","text":"<pre><code>sum(cas_ThreadPools_internal{scope=~'$scope',key='PendingTasks',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#completed-tasks-rate","title":"Completed Tasks Rate","text":"<pre><code>sum(cas_ThreadPools_internal{axonfunction='rate',scope=~'$scope',key='CompletedTasks',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#total-blocked-tasks-rate","title":"Total Blocked Tasks Rate","text":"<pre><code>sum(cas_ThreadPools_internal{axonfunction='rate',scope=~'$scope',key='TotalBlockedTasks',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#currently-blocked-tasks","title":"Currently Blocked Tasks","text":"<pre><code>sum(cas_ThreadPools_internal{scope=~'$scope',key='CurrentlyBlockedTasks',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}) by ($groupBy)\n</code></pre>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>For each selected thread pool ($scope), the dashboard shows:</p> <ul> <li> <p>Active Tasks - Line chart showing currently executing tasks</p> </li> <li> <p>Pending Tasks - Line chart showing queued tasks waiting for execution</p> </li> <li> <p>Completed Tasks Rate by $groupBy - Line chart showing task completion rate</p> </li> <li> <p>Total Blocked Tasks Rate - Line chart showing rate of tasks being blocked</p> </li> <li> <p>Currently Blocked Tasks Rate - Line chart showing currently blocked tasks</p> </li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>data center (<code>dc</code>) - Filter by data center</p> </li> <li> <p>rack - Filter by rack</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific node</p> </li> <li> <p>Pool (scope) - Select specific thread pool(s) to monitor</p> </li> <li> <p>groupBy - Dynamic grouping (scope, dc, rack, host_id)</p> </li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#important-thread-pools-to-monitor","title":"Important Thread Pools to Monitor","text":""},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#mutationstage","title":"MutationStage","text":"<ul> <li>Handles all write operations</li> <li>High pending tasks indicate write bottleneck</li> <li>Blocked tasks suggest memtable pressure</li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#readstage","title":"ReadStage","text":"<ul> <li>Handles all read operations</li> <li>Pending tasks indicate read latency issues</li> <li>May need to tune concurrent_reads</li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#compactionexecutor","title":"CompactionExecutor","text":"<ul> <li>Manages compaction operations</li> <li>High pending tasks mean compactions falling behind</li> <li>Affects disk space and read performance</li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#memtableflushwriter","title":"MemtableFlushWriter","text":"<ul> <li>Flushes memtables to disk</li> <li>Blocked tasks indicate disk I/O issues</li> <li>Critical for write performance</li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#performance-indicators","title":"Performance Indicators","text":""},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#healthy-patterns","title":"Healthy Patterns","text":"<ul> <li>Low or zero pending tasks</li> <li>No currently blocked tasks</li> <li>Steady completed task rate</li> <li>Active tasks within thread pool size</li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#warning-signs","title":"Warning Signs","text":"<ul> <li>Consistently growing pending tasks</li> <li>Frequent blocked tasks</li> <li>Active tasks at maximum pool size</li> <li>Sudden drops in completion rate</li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#tuning-considerations","title":"Tuning Considerations","text":"<p>Thread Pool Sizing:</p> <ul> <li>Configured in cassandra.yaml</li> <li>Balance between concurrency and resource usage</li> <li>Consider CPU cores and workload type</li> </ul> <p>Common Adjustments:</p> <ul> <li><code>concurrent_reads</code>: For read-heavy workloads</li> <li><code>concurrent_writes</code>: For write-heavy workloads</li> <li><code>concurrent_compactors</code>: For compaction throughput</li> </ul> <p>Monitoring Strategy:</p> <ul> <li>Watch for sustained pending tasks</li> <li>Monitor blocked tasks for resource contention</li> <li>Compare completion rates across nodes</li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#grouping-and-aggregation","title":"Grouping and Aggregation","text":"<p>The <code>groupBy</code> variable allows flexible analysis:</p> <ul> <li>By <code>scope</code>: Compare different thread pools</li> <li>By <code>dc</code>: Data center level patterns</li> <li>By <code>rack</code>: Rack level distribution</li> <li>By <code>host_id</code>: Individual node behavior</li> </ul>"},{"location":"metrics/cassandra/thread_pools_metrics_mapping/#units-and-display","title":"Units and Display","text":"<ul> <li> <p>Task Counts: Displayed as short numbers</p> </li> <li> <p>Rates: Tasks per second</p> </li> <li> <p>Legend: Shows the groupBy dimension</p> </li> <li> <p>Time Series: Real-time and historical trends</p> </li> </ul>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/","title":"Metrics Reference","text":""},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#axonops-all-kafka-dashboards-metrics-reference","title":"AxonOps All Kafka Dashboards Metrics Reference","text":"<p>This document provides a comprehensive reference of all metrics used across AxonOps Kafka dashboards, organized by metric prefix and category.</p>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#table-of-contents","title":"Table of Contents","text":"<ol> <li>System Metrics (host_ and jvm_)</li> <li>Kafka Controller Metrics</li> <li>Kafka Server Metrics</li> <li>Kafka Network Metrics</li> <li>Kafka Log Metrics</li> <li>Kafka Connect Metrics</li> <li>ZooKeeper Metrics</li> <li>Special Functions and Attributes</li> </ol>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#system-metrics-host_-and-jvm_","title":"System Metrics (host_ and jvm_)","text":"<p>System-level metrics collected from the operating system and JVM, shared with Cassandra monitoring.</p>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#cpu-metrics","title":"CPU Metrics","text":"Metric Description Common Attributes Used In <code>host_CPU_Percent_Merge</code> Merged CPU usage percentage <code>time</code> (real/user/sys), <code>rack</code>, <code>host_id</code> System, Performance"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#memory-metrics","title":"Memory Metrics","text":"Metric Description Common Attributes Used In <code>host_Memory_Used</code> Used memory in bytes <code>rack</code>, <code>host_id</code> System <code>host_Memory_Free</code> Free memory in bytes <code>rack</code>, <code>host_id</code> System <code>host_Memory_Total</code> Total memory in bytes <code>rack</code>, <code>host_id</code> System <code>host_Memory_Buffers</code> Buffer memory <code>rack</code>, <code>host_id</code> System <code>host_Memory_Cached</code> Cached memory <code>rack</code>, <code>host_id</code> System"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#disk-metrics","title":"Disk Metrics","text":"Metric Description Common Attributes Used In <code>host_Disk_Free</code> Free disk space <code>partition</code>, <code>rack</code>, <code>host_id</code> System <code>host_Disk_SectorsRead</code> Disk sectors read <code>partition</code>, <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code> System <code>host_Disk_SectorsWrite</code> Disk sectors written <code>partition</code>, <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code> System"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#network-metrics","title":"Network Metrics","text":"Metric Description Common Attributes Used In <code>host_Network_ReceiveBytes</code> Network bytes received <code>interface</code>, <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code> System <code>host_Network_TransmitBytes</code> Network bytes transmitted <code>interface</code>, <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code> System"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#jvm-metrics","title":"JVM Metrics","text":"Metric Description Common Attributes Used In <code>jvm_Memory_Heap</code> Heap memory usage <code>type</code> (usage/max), <code>rack</code>, <code>host_id</code> System <code>jvm_GarbageCollector_*</code> GC metrics by collector <code>collector_name</code>, <code>function</code> (CollectionTime/CollectionCount), <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code> System"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#kafka-controller-metrics","title":"Kafka Controller Metrics","text":"<p>Metrics related to Kafka cluster control and coordination.</p> Metric Description Common Attributes Used In <code>kaf_KafkaController_ActiveControllerCount</code> Active controller count (should be 1) <code>rack</code>, <code>host_id</code> Overview, Controller <code>kaf_KafkaController_OfflinePartitionsCount</code> Partitions without leaders <code>dc</code>, <code>rack</code>, <code>host_id</code> Overview, Controller <code>kaf_KafkaController_PreferredReplicaImbalanceCount</code> Partitions with non-preferred leaders <code>dc</code>, <code>rack</code>, <code>host_id</code> Overview <code>kaf_KafkaController_GlobalTopicCount</code> Total topics in cluster <code>rack</code>, <code>host_id</code> Controller <code>kaf_KafkaController_GlobalPartitionCount</code> Total partitions in cluster <code>rack</code>, <code>host_id</code> Controller <code>kaf_KafkaController_FencedBrokerCount</code> Number of fenced brokers <code>rack</code>, <code>host_id</code> Controller <code>kaf_KafkaController_LastAppliedRecordTimestamp</code> Last applied record timestamp <code>rack</code>, <code>host_id</code> Controller <code>kaf_KafkaController_MetadataErrorCount</code> Metadata error count <code>rack</code>, <code>host_id</code> Controller <code>kaf_ControllerStats_UncleanLeaderElectionsPerSec</code> Unclean leader election rate <code>function</code> (MeanRate), <code>rack</code>, <code>host_id</code> Overview, Controller <code>kaf_ControllerStats_LeaderElectionRateAndTimeMs</code> Leader election rate and time <code>function</code>, <code>rack</code>, <code>host_id</code> Controller"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#kafka-server-metrics","title":"Kafka Server Metrics","text":"<p>Core Kafka broker server metrics.</p>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#replica-manager","title":"Replica Manager","text":"Metric Description Common Attributes Used In <code>kaf_ReplicaManager_LeaderCount</code> Partitions where broker is leader <code>rack</code>, <code>host_id</code> Overview, Replication <code>kaf_ReplicaManager_PartitionCount</code> Total partitions on broker <code>dc</code>, <code>rack</code>, <code>host_id</code> Overview, Replication <code>kaf_ReplicaManager_UnderReplicatedPartitions</code> Under-replicated partitions <code>dc</code>, <code>rack</code>, <code>host_id</code> Overview, Replication <code>kaf_ReplicaManager_UnderMinIsrPartitionCount</code> Partitions under min ISR <code>dc</code>, <code>rack</code>, <code>host_id</code> Overview, Replication <code>kaf_ReplicaManager_OfflineReplicaCount</code> Offline replica count <code>rack</code>, <code>host_id</code> Replication <code>kaf_ReplicaManager_IsrShrinksPerSec</code> ISR shrink rate <code>function</code> (MeanRate), <code>rack</code>, <code>host_id</code> Overview, Replication <code>kaf_ReplicaManager_IsrExpandsPerSec</code> ISR expansion rate <code>function</code> (MeanRate), <code>rack</code>, <code>host_id</code> Overview, Replication <code>kaf_ReplicaManager_ReassigningPartitions</code> Partitions being reassigned <code>rack</code>, <code>host_id</code> Replication <code>kaf_ReplicaManager_AtMinIsrPartitionCount</code> Partitions at min ISR <code>rack</code>, <code>host_id</code> Replication"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#broker-topic-metrics","title":"Broker Topic Metrics","text":"Metric Description Common Attributes Used In <code>kaf_BrokerTopicMetrics_BytesInPerSec</code> Incoming byte rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code> Overview, Topics, Requests <code>kaf_BrokerTopicMetrics_BytesOutPerSec</code> Outgoing byte rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code> Overview, Topics, Requests <code>kaf_BrokerTopicMetrics_MessagesInPerSec</code> Incoming message rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code> Overview, Topics, Requests <code>kaf_BrokerTopicMetrics_TotalFetchRequestsPerSec</code> Fetch request rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code> Topics, Requests <code>kaf_BrokerTopicMetrics_TotalProduceRequestsPerSec</code> Produce request rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code> Topics, Requests <code>kaf_BrokerTopicMetrics_FailedFetchRequestsPerSec</code> Failed fetch request rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code> Topics, Requests <code>kaf_BrokerTopicMetrics_FailedProduceRequestsPerSec</code> Failed produce request rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code> Topics, Requests <code>kaf_BrokerTopicMetrics_BytesRejectedPerSec</code> Rejected bytes rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code> Topics <code>kaf_BrokerTopicMetrics_FetchMessageConversionsPerSec</code> Fetch message conversion rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code> Requests <code>kaf_BrokerTopicMetrics_ProduceMessageConversionsPerSec</code> Produce message conversion rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code> Requests"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#request-handler-pool","title":"Request Handler Pool","text":"Metric Description Common Attributes Used In <code>kaf_KafkaRequestHandlerPool_RequestHandlerAvgIdlePercent</code> Request handler idle percentage <code>function</code> (OneMinuteRate), <code>rack</code>, <code>host_id</code> Overview, Performance"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#log-manager","title":"Log Manager","text":"Metric Description Common Attributes Used In <code>kaf_LogManager_LogDirectoryOffline</code> Offline log directories <code>logDirectory</code>, <code>rack</code>, <code>host_id</code> System"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#delayed-operation-purgatory","title":"Delayed Operation Purgatory","text":"Metric Description Common Attributes Used In <code>kaf_DelayedOperationPurgatory_PurgatorySize</code> Delayed operations in purgatory <code>delayedOperation</code> (Produce/Fetch/Heartbeat), <code>rack</code>, <code>host_id</code> Performance"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#raft-metrics","title":"Raft Metrics","text":"Metric Description Common Attributes Used In <code>kaf_RaftMetrics_CurrentLeader</code> Current Raft leader <code>rack</code>, <code>host_id</code> Controller <code>kaf_RaftMetrics_CurrentEpoch</code> Current Raft epoch <code>rack</code>, <code>host_id</code> Controller <code>kaf_RaftMetrics_HighWatermark</code> Raft high watermark <code>rack</code>, <code>host_id</code> Controller <code>kaf_RaftMetrics_CurrentState</code> Current Raft state <code>rack</code>, <code>host_id</code> Controller <code>kaf_RaftMetrics_CommitLatencyAvg</code> Average commit latency <code>rack</code>, <code>host_id</code> Controller <code>kaf_RaftMetrics_AppendRecordsRate</code> Record append rate <code>rack</code>, <code>host_id</code> Controller <code>kaf_RaftMetrics_PollIdleRatioAvg</code> Poll idle ratio <code>rack</code>, <code>host_id</code> Controller"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#kafka-network-metrics","title":"Kafka Network Metrics","text":"<p>Network and request handling metrics.</p>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#socket-server","title":"Socket Server","text":"Metric Description Common Attributes Used In <code>kaf_socket_server_metrics_</code> Socket server metrics <code>function</code> (connection_count), <code>rack</code>, <code>host_id</code> Overview, Connections <code>kaf_SocketServer_NetworkProcessorAvgIdlePercent</code> Network processor idle percentage <code>networkProcessor</code>, <code>rack</code>, <code>host_id</code> Performance <code>kaf_Acceptor_AcceptorBlockedPercent</code> Acceptor blocked percentage <code>listener</code>, <code>rack</code>, <code>host_id</code> Connections"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#request-metrics","title":"Request Metrics","text":"Metric Description Common Attributes Used In <code>kaf_RequestMetrics_RequestsPerSec</code> Request rate <code>axonfunction</code> (rate), <code>function</code> (Count), <code>request</code>, <code>rack</code>, <code>host_id</code> Overview, Performance, Requests <code>kaf_RequestMetrics_TotalTimeMs</code> Total request time <code>request</code>, <code>function</code> (percentiles/Mean), <code>rack</code>, <code>host_id</code> Performance <code>kaf_RequestMetrics_LocalTimeMs</code> Local processing time <code>request</code>, <code>function</code> (percentiles/Mean), <code>rack</code>, <code>host_id</code> Performance <code>kaf_RequestMetrics_RemoteTimeMs</code> Remote processing time <code>request</code>, <code>function</code> (percentiles/Mean), <code>rack</code>, <code>host_id</code> Performance <code>kaf_RequestMetrics_RequestQueueTimeMs</code> Time in request queue <code>request</code>, <code>function</code> (percentiles/Mean), <code>rack</code>, <code>host_id</code> Performance <code>kaf_RequestMetrics_ResponseQueueTimeMs</code> Time in response queue <code>request</code>, <code>function</code> (percentiles/Mean), <code>rack</code>, <code>host_id</code> Performance <code>kaf_RequestMetrics_ResponseSendTimeMs</code> Response send time <code>request</code>, <code>function</code> (percentiles/Mean), <code>rack</code>, <code>host_id</code> Performance"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#request-channel","title":"Request Channel","text":"Metric Description Common Attributes Used In <code>kaf_RequestChannel_RequestQueueSize</code> Request queue size <code>rack</code>, <code>host_id</code> Performance <code>kaf_RequestChannel_ResponseQueueSize</code> Response queue size <code>processor</code>, <code>rack</code>, <code>host_id</code> Performance"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#kafka-log-metrics","title":"Kafka Log Metrics","text":"<p>Log and partition-level metrics.</p>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#log-metrics","title":"Log Metrics","text":"Metric Description Common Attributes Used In <code>kaf_Log_NumLogSegments</code> Number of log segments <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Topics <code>kaf_Log_Size</code> Log size in bytes <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Topics <code>kaf_Log_LogEndOffset</code> Log end offset <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Topics <code>kaf_Log_LogStartOffset</code> Log start offset <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Topics"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#partition-metrics","title":"Partition Metrics","text":"Metric Description Common Attributes Used In <code>kaf_Partition_UnderReplicated</code> Under-replicated partition <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Replication <code>kaf_Partition_AtMinIsr</code> Partition at minimum ISR <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Replication <code>kaf_Partition_UnderMinIsr</code> Partition under minimum ISR <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Replication <code>kaf_Partition_InSyncReplicasCount</code> In-sync replicas count <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Replication <code>kaf_Partition_ReplicasCount</code> Total replicas count <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Replication <code>kaf_Partition_LastStableOffsetLag</code> Last stable offset lag <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Replication"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#kafka-connect-metrics","title":"Kafka Connect Metrics","text":"<p>Metrics for Kafka Connect distributed mode.</p>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#worker-metrics","title":"Worker Metrics","text":"Metric Description Common Attributes Used In <code>kaf_connect_worker_metrics_task_count</code> Number of tasks <code>status</code>, <code>rack</code>, <code>host_id</code> Connect Overview <code>kaf_connect_worker_metrics_connector_count</code> Number of connectors <code>status</code>, <code>rack</code>, <code>host_id</code> Connect Overview <code>kaf_connect_worker_metrics_connector_startup_attempts_total</code> Connector startup attempts <code>rack</code>, <code>host_id</code> Connect Workers <code>kaf_connect_worker_metrics_connector_startup_failure_total</code> Connector startup failures <code>rack</code>, <code>host_id</code> Connect Workers <code>kaf_connect_worker_metrics_connector_startup_success_total</code> Connector startup successes <code>rack</code>, <code>host_id</code> Connect Workers <code>kaf_connect_worker_metrics_task_startup_attempts_total</code> Task startup attempts <code>rack</code>, <code>host_id</code> Connect Workers <code>kaf_connect_worker_metrics_task_startup_failure_total</code> Task startup failures <code>rack</code>, <code>host_id</code> Connect Workers <code>kaf_connect_worker_metrics_task_startup_success_total</code> Task startup successes <code>rack</code>, <code>host_id</code> Connect Workers <code>kaf_connect_worker_rebalance_rebalance_completed_total</code> Rebalances completed <code>rack</code>, <code>host_id</code> Connect Workers <code>kaf_connect_worker_rebalance_rebalancing</code> Currently rebalancing <code>rack</code>, <code>host_id</code> Connect Workers <code>kaf_connect_worker_rebalance_connect_protocol</code> Connect protocol <code>rack</code>, <code>host_id</code> Connect Workers"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#connectortask-metrics","title":"Connector/Task Metrics","text":"Metric Description Common Attributes Used In <code>kaf_connector_task_batch_size_avg</code> Average batch size <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_connector_task_offset_commit_avg_time_ms</code> Offset commit time <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_connector_task_offset_commit_success_percentage</code> Offset commit success rate <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_source_task_source_record_poll_rate</code> Source record poll rate <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_source_task_source_record_write_rate</code> Source record write rate <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_sink_task_sink_record_read_rate</code> Sink record read rate <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_sink_task_sink_record_send_rate</code> Sink record send rate <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_sink_task_sink_record_lag_max</code> Maximum sink record lag <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#task-error-metrics","title":"Task Error Metrics","text":"Metric Description Common Attributes Used In <code>kaf_task_error_deadletterqueue_produce_failures</code> DLQ produce failures <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_task_error_deadletterqueue_produce_requests</code> DLQ produce requests <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_task_error_total_errors_logged</code> Total errors logged <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_task_error_total_record_errors</code> Total record errors <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_task_error_total_record_failures</code> Total record failures <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks <code>kaf_task_error_total_retries</code> Total retries <code>connector</code>, <code>task</code>, <code>rack</code>, <code>host_id</code> Connect Tasks"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#zookeeper-metrics","title":"ZooKeeper Metrics","text":"<p>Metrics for ZooKeeper connectivity and performance.</p>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#session-metrics","title":"Session Metrics","text":"Metric Description Common Attributes Used In <code>kaf_SessionExpireListener_ZooKeeperDisconnectsPerSec</code> ZooKeeper disconnect rate <code>function</code> (MeanRate), <code>rack</code>, <code>host_id</code> ZooKeeper <code>kaf_SessionExpireListener_ZooKeeperExpiresPerSec</code> ZooKeeper session expiry rate <code>function</code> (MeanRate), <code>rack</code>, <code>host_id</code> ZooKeeper <code>kaf_SessionExpireListener_ZooKeeperAuthFailuresPerSec</code> ZooKeeper auth failure rate <code>function</code> (MeanRate), <code>rack</code>, <code>host_id</code> ZooKeeper <code>kaf_SessionExpireListener_ZooKeeperSyncConnectsPerSec</code> ZooKeeper sync connect rate <code>function</code> (MeanRate), <code>rack</code>, <code>host_id</code> ZooKeeper"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#client-metrics","title":"Client Metrics","text":"Metric Description Common Attributes Used In <code>kaf_ZooKeeperClientMetrics_ZooKeeperRequestLatencyMs</code> ZooKeeper request latency <code>function</code> (percentiles/Max), <code>rack</code>, <code>host_id</code> ZooKeeper"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#consumer-group-metrics","title":"Consumer Group Metrics","text":"<p>Metrics for consumer group coordination and lag monitoring.</p>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#group-metadata-manager","title":"Group Metadata Manager","text":"Metric Description Common Attributes Used In <code>kaf_GroupMetadataManager_NumGroups</code> Total consumer groups <code>rack</code>, <code>host_id</code> Overview, Consumer Groups <code>kaf_GroupMetadataManager_NumGroupsStable</code> Stable consumer groups <code>rack</code>, <code>host_id</code> Overview, Consumer Groups <code>kaf_GroupMetadataManager_NumGroupsPreparingRebalance</code> Groups preparing rebalance <code>rack</code>, <code>host_id</code> Overview, Consumer Groups <code>kaf_GroupMetadataManager_NumGroupsDead</code> Dead consumer groups <code>rack</code>, <code>host_id</code> Overview, Consumer Groups <code>kaf_GroupMetadataManager_NumGroupsCompletingRebalance</code> Groups completing rebalance <code>rack</code>, <code>host_id</code> Overview, Consumer Groups <code>kaf_GroupMetadataManager_NumGroupsEmpty</code> Empty consumer groups <code>rack</code>, <code>host_id</code> Overview, Consumer Groups"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#consumer-lag-metrics","title":"Consumer Lag Metrics","text":"Metric Description Common Attributes Used In <code>kaf_kafka_consumer_lag_millis</code> Consumer lag in milliseconds <code>group_id</code>, <code>topic</code>, <code>partition</code>, <code>rack</code>, <code>host_id</code> Consumer Groups"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#special-functions-and-attributes","title":"Special Functions and Attributes","text":""},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#common-function-values","title":"Common Function Values","text":"<ul> <li> <p>Percentiles: <code>50thPercentile</code>, <code>75thPercentile</code>, <code>95thPercentile</code>, <code>98thPercentile</code>, <code>99thPercentile</code>, <code>999thPercentile</code></p> </li> <li> <p>Rates: <code>OneMinuteRate</code>, <code>FiveMinuteRate</code>, <code>FifteenMinuteRate</code>, <code>MeanRate</code></p> </li> <li> <p>Aggregations: <code>Count</code>, <code>Min</code>, <code>Max</code>, <code>Mean</code>, <code>Value</code></p> </li> <li> <p>Special: <code>axonfunction='rate'</code> - Converts counter to rate</p> </li> </ul>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#common-attributes","title":"Common Attributes","text":"<ul> <li> <p>Location: <code>dc</code> (datacenter), <code>rack</code>, <code>host_id</code> (node)</p> </li> <li> <p>Kafka Components: <code>topic</code>, <code>partition</code>, <code>group_id</code>, <code>connector</code>, <code>task</code></p> </li> <li> <p>Request Types: <code>request</code> (Produce, Fetch, Metadata, etc.)</p> </li> <li> <p>Filtering: <code>groupBy</code> - Dynamic aggregation dimension</p> </li> </ul>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#request-type-values","title":"Request Type Values","text":"<p>Common request types for RequestMetrics:</p> <ul> <li><code>Produce</code>, <code>Fetch</code>, <code>Metadata</code>, <code>ListOffsets</code>, <code>OffsetCommit</code>, <code>OffsetFetch</code></li> <li><code>FindCoordinator</code>, <code>JoinGroup</code>, <code>Heartbeat</code>, <code>LeaveGroup</code>, <code>SyncGroup</code></li> <li><code>DescribeGroups</code>, <code>ListGroups</code>, <code>ApiVersions</code>, <code>CreateTopics</code>, <code>DeleteTopics</code></li> </ul>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#metric-naming-conventions","title":"Metric Naming Conventions","text":"<p>Prefix indicates source:</p> <ul> <li><code>host_</code> - System metrics</li> <li><code>jvm_</code> - JVM metrics</li> <li><code>kaf_</code> - Kafka metrics</li> </ul> <p>Middle part indicates component:</p> <ul> <li>Examples: <code>KafkaController</code>, <code>ReplicaManager</code>, <code>BrokerTopicMetrics</code>, <code>RequestMetrics</code></li> </ul> <p>Suffix indicates measurement:</p> <ul> <li>Examples: <code>Count</code>, <code>PerSec</code>, <code>TimeMs</code>, <code>Percent</code></li> </ul>"},{"location":"metrics/kafka/all_kafka_dashboards_metrics_reference/#notes","title":"Notes","text":"<ul> <li>Kafka metrics use <code>kaf_</code> prefix consistently</li> <li>Many metrics use <code>axonfunction='rate'</code> for per-second calculations</li> <li>Connect metrics have their own sub-namespaces for different components</li> <li>Some metrics are topic-specific (with <code>topic</code> attribute) while others are cluster-wide</li> <li>Percentile functions are commonly available for latency metrics</li> <li>The <code>rack</code> and <code>host_id</code> attributes enable filtering by location and specific broker</li> </ul>"},{"location":"metrics/kafka/connect_overview_metrics_mapping/","title":"Connect Overview Dashboard","text":""},{"location":"metrics/kafka/connect_overview_metrics_mapping/#axonops-kafka-connect-overview-dashboard-metrics-mapping","title":"AxonOps Kafka Connect Overview Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/connect_overview_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka Connect Overview Dashboard provides comprehensive monitoring of Kafka Connect clusters, including worker health, connector status, task distribution, rebalancing activity, and network metrics. This dashboard helps monitor the overall health and performance of your Kafka Connect deployment.</p>"},{"location":"metrics/kafka/connect_overview_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes Worker Metrics <code>con_connect_worker_metrics_</code> (function='connectorfailedtaskcount') Number of failed tasks connector={connector} <code>con_connect_worker_metrics_</code> (function='task_count') Total number of tasks - <code>con_connect_worker_rebalance_metrics_</code> (function='rebalancing') Rebalancing status (0 or 1) - <code>con_connect_worker_rebalance_metrics_</code> (function='rebalance_avg_time_ms') Average rebalance time - Coordinator Metrics <code>con_connect_coordinator_metrics_</code> (function='assigned_connectors') Number of assigned connectors - <code>con_connect_coordinator_metrics_</code> (function='assigned_tasks') Number of assigned tasks - <code>con_connect_coordinator_metrics_</code> (function='failed_rebalance_total') Total failed rebalances - <code>con_connect_coordinator_metrics_</code> (function='last_heartbeat_seconds_ago') Seconds since last heartbeat - <code>con_connect_coordinator_metrics_</code> (function='join_total') Total join operations - <code>con_connect_coordinator_metrics_</code> (function='sync_rate') Group sync rate - <code>con_connect_coordinator_metrics_</code> (function='rebalance_total') Total rebalances - Connection Metrics <code>con_connect_metrics_</code> (function='connection_count') Active connection count - <code>con_connect_metrics_</code> (function='connection_close_total') Total connections closed - <code>con_connect_metrics_</code> (function='connection_creation_total') Total connections created - <code>con_connect_metrics_</code> (function='failed_authentication_total') Total authentication failures - Network Metrics <code>con_connect_metrics_</code> (function='request_total') Total requests - <code>con_connect_metrics_</code> (function='response_total') Total responses - <code>con_connect_metrics_</code> (function='incoming_byte_rate') Incoming bytes per second - <code>con_connect_metrics_</code> (function='outgoing_byte_rate') Outgoing bytes per second - <code>con_connect_metrics_</code> (function='network_io_rate') Network I/O rate - <code>con_connect_metrics_</code> (function='iotime_total') Total I/O time - <code>con_connect_metrics_</code> (function='io_waittime_total') Total I/O wait time -"},{"location":"metrics/kafka/connect_overview_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/connect_overview_metrics_mapping/#worker-health","title":"Worker Health","text":"<pre><code>// Failed task count\ncon_connect_worker_metrics_{function=\"connectorfailedtaskcount\",type='kafka', node_type='connect'}\n\n// Total task count\nsum(con_connect_worker_metrics_{function='task_count',type='kafka', node_type='connect'})\n\n// Rebalancing status\ncon_connect_worker_rebalance_metrics_{function=\"rebalancing\",type='kafka', node_type='connect'}\n</code></pre>"},{"location":"metrics/kafka/connect_overview_metrics_mapping/#coordinator-metrics","title":"Coordinator Metrics","text":"<pre><code>// Assigned connectors per worker\ncon_connect_coordinator_metrics_{function=\"assigned_connectors\",type='kafka', node_type='connect',client_id=~'$client_id'}\n\n// Assigned tasks per worker\ncon_connect_coordinator_metrics_{function=\"assigned_tasks\",type='kafka', node_type='connect',client_id=~'$client_id'}\n\n// Failed rebalances\ncon_connect_coordinator_metrics_{function=\"failed_rebalance_total\",type='kafka', node_type='connect',client_id=~'$client_id'}\n\n// Heartbeat monitoring\ncon_connect_coordinator_metrics_{function=\"last_heartbeat_seconds_ago\",type='kafka', node_type='connect',client_id=~'$client_id'}\n</code></pre>"},{"location":"metrics/kafka/connect_overview_metrics_mapping/#connection-management","title":"Connection Management","text":"<pre><code>// Active connections\ncon_connect_metrics_{function=\"connection_count\",type='kafka', node_type='connect',client_id=~'$client_id'}\n\n// Connection creation/close rates\ncon_connect_metrics_{function=\"connection_creation_total\",type='kafka', node_type='connect',client_id=~'$client_id'}\ncon_connect_metrics_{function=\"connection_close_total\",type='kafka', node_type='connect',client_id=~'$client_id'}\n\n// Authentication failures\ncon_connect_metrics_{function=\"failed_authentication_total\",type='kafka', node_type='connect'}\n</code></pre>"},{"location":"metrics/kafka/connect_overview_metrics_mapping/#network-performance","title":"Network Performance","text":"<pre><code>// Request/Response tracking\ncon_connect_metrics_{function=\"request_total\",type='kafka', node_type='connect'}\ncon_connect_metrics_{function=\"response_total\",type='kafka', node_type='connect'}\n\n// Byte rates\ncon_connect_metrics_{function=\"incoming_byte_rate\",type='kafka', node_type='connect'}\ncon_connect_metrics_{function=\"outgoing_byte_rate\",type='kafka', node_type='connect'}\n\n// I/O performance\ncon_connect_metrics_{axonfunction='rate',function=\"iotime_total\",type='kafka', node_type='connect'}\ncon_connect_metrics_{axonfunction='rate',function=\"io_waittime_total\",type='kafka', node_type='connect'} / 1000\n</code></pre>"},{"location":"metrics/kafka/connect_overview_metrics_mapping/#rebalancing-metrics","title":"Rebalancing Metrics","text":"<pre><code>// Average rebalance time\ncon_connect_worker_rebalance_metrics_{function=\"rebalance_avg_time_ms\",type='kafka', node_type='connect'}\n\n// Total rebalances\ncon_connect_coordinator_metrics_{function=\"rebalance_total\",type='kafka', node_type='connect',client_id=~'$client_id'}\n\n// Join operations\ncon_connect_coordinator_metrics_{function=\"join_total\",type='kafka', node_type='connect',client_id=~'$client_id'}\n\n// Sync rate\ncon_connect_coordinator_metrics_{function=\"sync_rate\",type='kafka', node_type='connect',client_id=~'$client_id'}\n</code></pre>"},{"location":"metrics/kafka/connect_overview_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>Overview</p> <ul> <li>Connector Workers (counter)</li> <li>Connectors Rebalancing (counter)</li> <li>Connector Tasks Failed (counter)</li> </ul> <p>Coordinator Metrics</p> <ul> <li>Assigned Connectors</li> <li>Assigned Tasks</li> <li>Failed Rebalances</li> <li>Last Heartbeat (Seconds ago)</li> <li>Rebalances</li> <li>Joins</li> <li>Sync Rate</li> </ul> <p>Connect Metrics</p> <ul> <li>Connections</li> <li>Connection Close</li> <li>Connection Creations</li> <li>Rebalance average time</li> <li>Requests vs Response</li> <li>Failed Authentication</li> <li>Incoming Byte Rate</li> <li>Outgoing Byte Rate</li> <li>Network IO Rate</li> <li>IO Time</li> <li>IO Wait Time</li> </ul>"},{"location":"metrics/kafka/connect_overview_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>host_id: Filter by specific Connect worker node</p> </li> <li> <p>client_id: Filter by specific client ID</p> </li> </ul>"},{"location":"metrics/kafka/connect_overview_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Worker Health Monitoring</p> <ul> <li>Monitor failed task count - should be 0</li> <li>Track total tasks for capacity planning</li> <li>Watch for frequent rebalancing</li> </ul> <p>Task Distribution</p> <ul> <li>Ensure even distribution of connectors/tasks</li> <li>Monitor for workers with no assignments</li> <li>Check for imbalanced workloads</li> </ul> <p>Rebalancing Analysis</p> <ul> <li>Frequent rebalances indicate instability</li> <li>High rebalance time impacts availability</li> <li>Monitor failed rebalances for issues</li> </ul> <p>Heartbeat Monitoring</p> <ul> <li>High heartbeat lag indicates worker issues</li> <li>Set alerts for heartbeat timeouts</li> <li>Correlate with worker failures</li> </ul> <p>Connection Management</p> <ul> <li>Monitor connection churn rate</li> <li>High authentication failures indicate security issues</li> <li>Track connection count for capacity</li> </ul> <p>Network Performance</p> <ul> <li>Monitor byte rates for throughput</li> <li>Check request/response balance</li> <li>High I/O wait time indicates bottlenecks</li> </ul> <p>Troubleshooting</p> <ul> <li>Failed tasks: Check connector logs</li> <li>Rebalancing issues: Review worker health</li> <li>Authentication failures: Verify credentials</li> <li>Network issues: Check Kafka broker connectivity</li> </ul>"},{"location":"metrics/kafka/connect_tasks_metrics_mapping/","title":"Connect Tasks Dashboard","text":""},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#axonops-kafka-connect-tasks-dashboard-metrics-mapping","title":"AxonOps Kafka Connect Tasks Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka Connect Tasks Dashboard provides detailed monitoring of individual connector tasks, including task performance, error tracking, and sink-specific metrics. This dashboard helps identify task-level issues and optimize connector performance.</p>"},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes Task Performance Metrics <code>con_connector_task_metrics_</code> (function='running_ratio') Ratio of time task is running vs paused connector={connector}, task={task} <code>con_connector_task_metrics_</code> (function='batch_size_avg') Average batch size processed connector={connector}, task={task} <code>con_connector_task_metrics_</code> (function='offset_commit_success_percentage') Percentage of successful offset commits connector={connector}, task={task} <code>con_connector_task_metrics_</code> (function='offset_commit_avg_time_ms') Average time for offset commits connector={connector}, task={task} <code>con_connector_task_metrics_</code> (function='offset_commit_max_time_ms') Maximum time for offset commits connector={connector}, task={task} Task Error Metrics <code>con_task_error_metrics_</code> (function='deadletterqueue_produce_failures') Failed attempts to produce to DLQ connector={connector}, task={task} <code>con_task_error_metrics_</code> (function='total_record_errors') Total number of record-level errors connector={connector}, task={task} <code>con_task_error_metrics_</code> (function='total_record_failures') Total number of record failures connector={connector}, task={task} <code>con_task_error_metrics_</code> (function='total_records_skipped') Total number of skipped records connector={connector}, task={task} <code>con_task_error_metrics_</code> (function='total_retries') Total number of retry attempts connector={connector}, task={task} Sink Task Metrics <code>con_sink_task_metrics_</code> (function='partition_count') Number of partitions assigned to task connector={connector}, task={task} <code>con_sink_task_metrics_</code> (function='sink_record_read_total') Total records read from Kafka connector={connector}, task={task} <code>con_sink_task_metrics_</code> (function='sink_record_active_count') Number of records being processed connector={connector}, task={task} <code>con_sink_task_metrics_</code> (function='sink_record_send_total') Total records sent to sink connector={connector}, task={task}"},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#task-performance","title":"Task Performance","text":"<pre><code>// Running ratio per task\nsum(con_connector_task_metrics_{function=\"running_ratio\",type='kafka', node_type='connect', connector='$connector', task='$task'}) by (connector,task)\n\n// Average batch size\nsum(con_connector_task_metrics_{function=\"batch_size_avg\",type='kafka', node_type='connect', connector='$connector', task='$task'}) by (connector,task)\n\n// Offset commit success rate\nsum(con_connector_task_metrics_{function=\"offset_commit_success_percentage\",type='kafka', node_type='connect', connector='$connector', task='$task'}) by (connector,task) * 100\n</code></pre>"},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#offset-commit-times","title":"Offset Commit Times","text":"<pre><code>// Average commit time\nsum(con_connector_task_metrics_{function=\"offset_commit_avg_time_ms\",type='kafka', node_type='connect', connector='$connector', task='$task'}) by (connector,task)\n\n// Maximum commit time\nsum(con_connector_task_metrics_{function=\"offset_commit_max_time_ms\",type='kafka', node_type='connect', connector='$connector', task='$task'}) by (connector,task)\n</code></pre>"},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#error-tracking","title":"Error Tracking","text":"<pre><code>// DLQ produce failures\nsum(con_task_error_metrics_{function=\"deadletterqueue_produce_failures\",type='kafka', node_type='connect', connector='$connector', task='$task'})\n\n// Total record errors\nsum(con_task_error_metrics_{function=\"total_record_errors\",type='kafka', node_type='connect'})\n\n// Total record failures\nsum(con_task_error_metrics_{function=\"total_record_failures\",type='kafka', node_type='connect'})\n\n// Records skipped\nsum(con_task_error_metrics_{function=\"total_records_skipped\",type='kafka', node_type='connect'})\n\n// Total retries\nsum(con_task_error_metrics_{function=\"total_retries\",type='kafka', node_type='connect'})\n</code></pre>"},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#sink-task-metrics","title":"Sink Task Metrics","text":"<pre><code>// Partition count per sink task\nsum(con_sink_task_metrics_{function=\"partition_count\",type='kafka', node_type='connect', connector='$connector', task='$task'}) by (connector,task)\n\n// Records read rate\nsum(con_sink_task_metrics_{axonfunction=\"rate\",function=\"sink_record_read_total\",type='kafka', node_type='connect', connector='$connector', task='$task'}) by (connector,task)\n\n// Active record count\nsum(con_sink_task_metrics_{function=\"sink_record_active_count\",type='kafka', node_type='connect', connector='$connector', task='$task'}) by (connector,task)\n\n// Records sent rate\nsum(con_sink_task_metrics_{axonfunction=\"rate\", function=\"sink_record_send_total\",type='kafka', node_type='connect', connector='$connector', task='$task'}) by (connector,task)\n</code></pre>"},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>Tasks Metrics</p> <ul> <li>Connector Tasks Batch Size</li> <li>Connector Task Running Ratio</li> <li>Connector Task Commit Success %</li> <li>Connector Task Commit Avg vs Max time</li> </ul> <p>Task Error Metrics</p> <ul> <li>Deadletter Produce Failures (duplicate panels)</li> <li>Record Errors</li> <li>Record Failures</li> <li>Record Skipped</li> <li>Total Retries</li> </ul> <p>Sink Task Metrics</p> <ul> <li>Sink Task Record Active Count</li> <li>Sink Task Record Read</li> <li>Sink Task Partition Count</li> <li>Sink Task Record Send</li> </ul>"},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>host_id: Filter by specific Connect worker node</p> </li> <li> <p>connector: Filter by specific connector name</p> </li> <li> <p>task: Filter by specific task ID</p> </li> </ul>"},{"location":"metrics/kafka/connect_tasks_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Task Performance Monitoring</p> <ul> <li>Running ratio should be close to 1.0 for active tasks</li> <li>Monitor batch sizes for throughput optimization</li> <li>Low commit success rate indicates processing issues</li> </ul> <p>Offset Commit Analysis</p> <ul> <li>High commit times indicate performance issues</li> <li>Compare average vs max times for outliers</li> <li>Frequent commit failures suggest configuration issues</li> </ul> <p>Error Management</p> <ul> <li>Monitor DLQ failures for error handling issues</li> <li>Track record errors vs failures vs skipped</li> <li>High retry counts indicate transient issues</li> </ul> <p>Sink Task Optimization</p> <ul> <li>Balance partition assignment across tasks</li> <li>Monitor active record count for backpressure</li> <li>Compare read vs send rates for processing lag</li> </ul> <p>Troubleshooting</p> <ul> <li>Low running ratio: Check for task pauses/failures</li> <li>High error rates: Review connector configuration</li> <li>DLQ failures: Check DLQ topic permissions</li> <li>Commit failures: Verify offset storage configuration</li> </ul> <p>Performance Tuning</p> <ul> <li>Adjust batch sizes for optimal throughput</li> <li>Tune commit intervals based on latency requirements</li> <li>Configure appropriate retry policies</li> <li>Monitor partition assignment balance</li> </ul> <p>Capacity Planning</p> <ul> <li>Track record processing rates</li> <li>Monitor active record counts for memory usage</li> <li>Plan task scaling based on partition count</li> </ul>"},{"location":"metrics/kafka/connect_workers_metrics_mapping/","title":"Connect Workers Dashboard","text":""},{"location":"metrics/kafka/connect_workers_metrics_mapping/#axonops-kafka-connect-workers-dashboard-metrics-mapping","title":"AxonOps Kafka Connect Workers Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/connect_workers_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka Connect Workers Dashboard provides comprehensive monitoring of individual Connect workers, tracking connector and task lifecycle, startup/shutdown events, and rebalancing activities. This dashboard helps monitor worker health and identify issues with connector deployment and task management.</p>"},{"location":"metrics/kafka/connect_workers_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes Worker Overview Metrics <code>con_connect_worker_metrics_</code> (function='task_count') Total number of tasks on worker - <code>con_connect_worker_metrics_</code> (function='connector_count') Total number of connectors on worker - Connector Lifecycle Metrics <code>con_connect_worker_metrics_</code> (function='connector_failed_task_count') Failed tasks per connector connector={connector} <code>con_connect_worker_metrics_</code> (function='connector_startup_attempts_total') Total connector startup attempts - <code>con_connect_worker_metrics_</code> (function='connector_startup_failure_total') Failed connector startup attempts - <code>con_connect_worker_metrics_</code> (function='connector_startup_success_total') Successful connector startup attempts - <code>con_connect_worker_metrics_</code> (function='connector_total_task_count') Total tasks per connector connector={connector} Task State Metrics <code>con_connect_worker_metrics_</code> (function='connector_paused_task_count') Paused tasks per connector connector={connector} <code>con_connect_worker_metrics_</code> (function='connector_destroyed_task_count') Destroyed tasks per connector connector={connector} <code>con_connect_worker_metrics_</code> (function='connector_running_task_count') Running tasks per connector connector={connector} Task Lifecycle Metrics <code>con_connect_worker_metrics_</code> (function='task_startup_attempts_total') Total task startup attempts - <code>con_connect_worker_metrics_</code> (function='task_startup_failure_total') Failed task startup attempts - <code>con_connect_worker_metrics_</code> (function='task_startup_success_total') Successful task startup attempts - Rebalance Metrics <code>con_connect_worker_rebalance_metrics_</code> (function='rebalance_avg_time_ms') Average rebalance time - <code>con_connect_worker_rebalance_metrics_</code> (function='completed_rebalances_total') Total completed rebalances -"},{"location":"metrics/kafka/connect_workers_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/connect_workers_metrics_mapping/#worker-overview","title":"Worker Overview","text":"<pre><code>// Total task count\ncon_connect_worker_metrics_{function=\"task_count\",type='kafka', node_type='connect'}\n\n// Total connector count\ncon_connect_worker_metrics_{function=\"connector_count\",type='kafka', node_type='connect'}\n</code></pre>"},{"location":"metrics/kafka/connect_workers_metrics_mapping/#connector-lifecycle","title":"Connector Lifecycle","text":"<pre><code>// Connector count by host\nsum(con_connect_worker_metrics_{function=\"connector_count\",type='kafka', node_type='connect'}) by (host_id)\n\n// Failed tasks by connector\ncon_connect_worker_metrics_{function=\"connector_failed_task_count\",type='kafka', node_type='connect'}\n\n// Connector startup attempts (total, failed, successful)\ncon_connect_worker_metrics_{function='connector_startup_attempts_total',type='kafka', node_type='connect'}\ncon_connect_worker_metrics_{function='connector_startup_failure_total',type='kafka', node_type='connect'}\ncon_connect_worker_metrics_{function='connector_startup_success_total',type='kafka', node_type='connect'}\n</code></pre>"},{"location":"metrics/kafka/connect_workers_metrics_mapping/#task-states","title":"Task States","text":"<pre><code>// Running tasks by connector\nsum(con_connect_worker_metrics_{function=\"connector_running_task_count\",type='kafka', node_type='connect', connector='$connector'}) by (connector)\n\n// Paused tasks by connector\nsum(con_connect_worker_metrics_{function=\"connector_paused_task_count\",type='kafka', node_type='connect', connector='$connector'}) by (connector)\n\n// Failed tasks by connector\nsum(con_connect_worker_metrics_{function=\"connector_failed_task_count\",type='kafka', node_type='connect', connector='$connector'}) by (connector)\n\n// Destroyed tasks by connector\nsum(con_connect_worker_metrics_{function=\"connector_destroyed_task_count\",type='kafka', node_type='connect', connector='$connector'}) by (connector)\n</code></pre>"},{"location":"metrics/kafka/connect_workers_metrics_mapping/#task-lifecycle","title":"Task Lifecycle","text":"<pre><code>// Task startup attempts (total, failed, successful)\ncon_connect_worker_metrics_{function='task_startup_attempts_total',type='kafka', node_type='connect'}\ncon_connect_worker_metrics_{function='task_startup_failure_total',type='kafka', node_type='connect'}\ncon_connect_worker_metrics_{function='task_startup_success_total',type='kafka', node_type='connect'}\n\n// Total tasks per connector\ncon_connect_worker_metrics_{function=\"connector_total_task_count\",type='kafka', node_type='connect', connector='$connector'}\n</code></pre>"},{"location":"metrics/kafka/connect_workers_metrics_mapping/#rebalancing","title":"Rebalancing","text":"<pre><code>// Average rebalance time\ncon_connect_worker_rebalance_metrics_{function=\"rebalance_avg_time_ms\",type='kafka', node_type='connect'}\n\n// Completed rebalances\ncon_connect_worker_rebalance_metrics_{function=\"completed_rebalances_total\",type='kafka', node_type='connect'}\n</code></pre>"},{"location":"metrics/kafka/connect_workers_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>Workers</p> <ul> <li>Connector Count (counter)</li> <li>Task Count (counter)</li> </ul> <p>Worker Metrics</p> <ul> <li>Connector Count (time series)</li> <li>Connector Startup</li> <li>Connector Failed</li> <li>Connector Task Count</li> <li>Connector Task Startup by Host</li> <li>Connector Paused Tasks</li> <li>Connector Destroyed</li> </ul> <p>Worker Tasks</p> <ul> <li>Connector Running Tasks</li> <li>Connector Failed Tasks</li> <li>Connector Destroyed Tasks</li> </ul> <p>Rebalance Metrics</p> <ul> <li>Connector Rebalances (duplicate panels)</li> <li>Connectors Avg Rebalance Time</li> </ul>"},{"location":"metrics/kafka/connect_workers_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>host_id: Filter by specific Connect worker node</p> </li> <li> <p>connector: Filter by specific connector name</p> </li> </ul>"},{"location":"metrics/kafka/connect_workers_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Worker Health Monitoring</p> <ul> <li>Monitor task and connector counts per worker</li> <li>Ensure balanced distribution across workers</li> <li>Track failed task counts for issues</li> </ul> <p>Connector Lifecycle</p> <ul> <li>Monitor startup success vs failure rates</li> <li>High failure rates indicate configuration issues</li> <li>Track connector count changes over time</li> </ul> <p>Task State Management</p> <ul> <li>Running tasks should match expected count</li> <li>Paused tasks may indicate manual intervention</li> <li>Failed tasks require investigation</li> <li>Destroyed tasks indicate connector removal</li> </ul> <p>Startup Monitoring</p> <ul> <li>Compare startup attempts vs successes</li> <li>High failure rates suggest configuration problems</li> <li>Monitor both connector and task startups</li> </ul> <p>Rebalancing Analysis</p> <ul> <li>Frequent rebalances impact availability</li> <li>High rebalance times affect task availability</li> <li>Monitor after adding/removing workers</li> </ul> <p>Troubleshooting</p> <ul> <li>Failed connectors: Check logs and configuration</li> <li>Paused tasks: Verify intentional vs error state</li> <li>Startup failures: Review connector configs</li> <li>Destroyed tasks: Confirm planned removals</li> </ul> <p>Capacity Planning</p> <ul> <li>Monitor task distribution across workers</li> <li>Plan worker scaling based on task counts</li> <li>Balance connectors for even resource usage</li> </ul>"},{"location":"metrics/kafka/connections_metrics_mapping/","title":"Connections Dashboard","text":""},{"location":"metrics/kafka/connections_metrics_mapping/#axonops-kafka-connections-dashboard-metrics-mapping","title":"AxonOps Kafka Connections Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/connections_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka Connections Dashboard provides comprehensive monitoring of client connections to Kafka brokers. It tracks connection counts, creation/close rates, client versions, and acceptor performance to help identify connection issues and optimize network resource usage.</p>"},{"location":"metrics/kafka/connections_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes Connection Metrics <code>kaf_socket_server_metrics_</code> (function='connection_count') Current number of active connections listener={listener}, networkProcessor={id} <code>kaf_socket_server_metrics_</code> (function='connection_creation_rate') Rate of new connections created per second listener={listener} <code>kaf_socket_server_metrics_</code> (function='connection_close_rate') Rate of connections closed per second listener={listener} <code>kaf_socket_server_metrics_</code> (function='connections') Connections by client software version listener={listener}, clientSoftwareName={name}, clientSoftwareVersion={version} Acceptor Metrics <code>kaf_Acceptor_AcceptorBlockedPercent</code> Percentage of time acceptor thread is blocked listener={listener}"},{"location":"metrics/kafka/connections_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/connections_metrics_mapping/#connection-count","title":"Connection Count","text":"<pre><code>// Total connections per broker\nsum(kaf_socket_server_metrics_{function='connection_count',rack=~'$rack',host_id=~'$host_id'}) by (host_id)\n\n// Total connections per listener\nsum(kaf_socket_server_metrics_{function='connection_count',rack=~'$rack',host_id=~'$host_id'}) by (listener)\n</code></pre>"},{"location":"metrics/kafka/connections_metrics_mapping/#connection-creation-rate","title":"Connection Creation Rate","text":"<pre><code>// Connection creation rate per broker\nsum(kaf_socket_server_metrics_{function='connection_creation_rate',rack=~'$rack',host_id=~'$host_id'}) by (host_id)\n\n// Connection creation rate per listener\nsum(kaf_socket_server_metrics_{function='connection_creation_rate',rack=~'$rack',host_id=~'$host_id'}) by (listener)\n</code></pre>"},{"location":"metrics/kafka/connections_metrics_mapping/#connection-close-rate","title":"Connection Close Rate","text":"<pre><code>// Connection close rate per broker\nsum(kaf_socket_server_metrics_{function='connection_close_rate',rack=~'$rack',host_id=~'$host_id'}) by (host_id)\n\n// Connection close rate per listener\nsum(kaf_socket_server_metrics_{function='connection_close_rate',rack=~'$rack',host_id=~'$host_id'}) by (listener)\n</code></pre>"},{"location":"metrics/kafka/connections_metrics_mapping/#client-version-distribution","title":"Client Version Distribution","text":"<pre><code>// Connections grouped by client software and version\nsum(kaf_socket_server_metrics_{function='connections',rack=~'$rack',host_id=~'$host_id'}) by (clientSoftwareVersion, clientSoftwareName)\n</code></pre>"},{"location":"metrics/kafka/connections_metrics_mapping/#acceptor-performance","title":"Acceptor Performance","text":"<pre><code>// Acceptor blocked percentage\nkaf_Acceptor_AcceptorBlockedPercent{function='MeanRate',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/connections_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>Connections</p> <ul> <li>Connections count per broker</li> <li>Connections count per listener</li> <li>Connections creation rate per broker</li> <li>Connections creation rate per listener</li> <li>Connections close rate per broker</li> <li>Connections close rate per listener</li> <li>Connections per client version</li> <li>Acceptor Blocked Percentage</li> </ul>"},{"location":"metrics/kafka/connections_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>rack: Filter by rack location</p> </li> <li> <p>host_id: Filter by specific host/broker</p> </li> </ul>"},{"location":"metrics/kafka/connections_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Connection Monitoring</p> <ul> <li>Monitor total connection count against broker limits</li> <li>Track connection creation/close rates for unusual patterns</li> <li>High connection churn may indicate client issues</li> </ul> <p>Listener Analysis</p> <ul> <li>Monitor connections per listener (PLAINTEXT, SSL, SASL)</li> <li>Different listeners may have different performance characteristics</li> <li>Ensure balanced connection distribution across listeners</li> </ul> <p>Client Version Tracking</p> <ul> <li>Track client software versions for compatibility</li> <li>Identify outdated clients that need upgrading</li> <li>Monitor for unauthorized or unexpected client versions</li> </ul> <p>Acceptor Performance</p> <ul> <li>High acceptor blocked percentage indicates connection bottlenecks</li> <li>May need to tune acceptor thread configuration</li> <li>Consider increasing network threads if consistently blocked</li> </ul> <p>Connection Limits</p> <ul> <li>Set appropriate connection limits per broker</li> <li>Monitor approaching connection limit thresholds</li> <li>Plan capacity based on connection growth trends</li> </ul> <p>Security Considerations</p> <ul> <li>Monitor for connection spikes (potential DoS)</li> <li>Track connections from unexpected sources</li> <li>Ensure proper authentication/authorization on all listeners</li> </ul> <p>Performance Tuning</p> <ul> <li>Adjust <code>max.connections.per.ip</code> for client fairness</li> <li>Tune <code>num.network.threads</code> based on connection load</li> <li>Monitor connection creation rate during peak times</li> </ul>"},{"location":"metrics/kafka/consumer_groups_metrics_mapping/","title":"Consumer Groups Dashboard","text":""},{"location":"metrics/kafka/consumer_groups_metrics_mapping/#axonops-kafka-consumer-groups-dashboard-metrics-mapping","title":"AxonOps Kafka Consumer Groups Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/consumer_groups_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka Consumer Groups Dashboard provides monitoring of consumer group lag across topics and partitions. This dashboard is essential for tracking consumer performance, identifying consumption bottlenecks, and ensuring consumers are keeping up with producers.</p>"},{"location":"metrics/kafka/consumer_groups_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes Consumer Group Metrics <code>kaf_consumer_group</code> Consumer group lag per partition client-id={client-id} <p>Note: Consumer group metrics are typically collected from Kafka's consumer group command-line tools or APIs rather than JMX, as they represent cluster-wide state rather than individual broker metrics.</p>"},{"location":"metrics/kafka/consumer_groups_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/consumer_groups_metrics_mapping/#consumer-group-lag","title":"Consumer Group Lag","text":"<pre><code>// Consumer group lag by group, topic, and partition\nsum(kaf_consumer_group{Topic='$topic',GroupID='$groupid'}) by (GroupID, Topic, Partition)\n\n// Total lag for a consumer group across all partitions\nsum(kaf_consumer_group{GroupID='$groupid'}) by (GroupID)\n\n// Lag for specific topic\nsum(kaf_consumer_group{Topic='$topic'}) by (GroupID, Partition)\n</code></pre>"},{"location":"metrics/kafka/consumer_groups_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>Consumer Groups</p> <ul> <li>Consumer Group Lag (detailed view by GroupID, Topic, and Partition)</li> </ul>"},{"location":"metrics/kafka/consumer_groups_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>groupid: Filter by specific consumer group ID(s)</p> </li> <li> <p>topic: Filter by specific topic(s)</p> </li> </ul>"},{"location":"metrics/kafka/consumer_groups_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Lag Monitoring</p> <ul> <li>Monitor lag trends over time, not just absolute values</li> <li>Set alerts for increasing lag trends</li> <li>Consider normal lag during consumer restarts</li> </ul> <p>Performance Analysis</p> <ul> <li>High lag indicates consumers can't keep up with producers</li> <li>Compare lag across partitions to identify imbalances</li> <li>Monitor lag spikes during peak traffic</li> </ul> <p>Consumer Group Health</p> <ul> <li>Zero lag doesn't always mean healthy consumption</li> <li>Check for stalled consumers (lag not changing)</li> <li>Monitor consumer group state (active, rebalancing, dead)</li> </ul> <p>Troubleshooting High Lag</p> <ul> <li>Check consumer processing time</li> <li>Verify consumer parallelism matches partition count</li> <li>Look for rebalancing issues</li> <li>Check for consumer errors or failures</li> </ul> <p>Capacity Planning</p> <ul> <li>Use lag trends for scaling decisions</li> <li>Add consumers when lag consistently increases</li> <li>Monitor lag during traffic peaks</li> </ul> <p>Partition Assignment</p> <ul> <li>Ensure even distribution of partitions to consumers</li> <li>Monitor for partition ownership changes</li> <li>Check for idle consumers (no partitions assigned)</li> </ul> <p>Alert Configuration</p> <ul> <li>Alert on lag threshold (e.g., &gt; 100k messages)</li> <li>Alert on lag growth rate</li> <li>Alert on consumer group state changes</li> <li>Different thresholds for different topics/groups</li> </ul>"},{"location":"metrics/kafka/controller_metrics_mapping/","title":"Controller Dashboard","text":""},{"location":"metrics/kafka/controller_metrics_mapping/#axonops-kafka-controller-dashboard-metrics-mapping","title":"AxonOps Kafka Controller Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/controller_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka Controller Dashboard monitors the health and performance of the Kafka controller, particularly in KRaft mode (Kafka without ZooKeeper). It tracks Raft consensus metrics, metadata operations, authentication rates, and controller state changes.</p>"},{"location":"metrics/kafka/controller_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes Controller State Metrics <code>kaf_KafkaController_FencedBrokerCount</code> Number of fenced (isolated) brokers - <code>kaf_KafkaController_LastAppliedRecordTimestamp</code> Timestamp of last applied metadata record - <code>kaf_KafkaController_MetadataErrorCount</code> Count of metadata errors - Raft Consensus Metrics <code>kaf_raft_metrics_</code> (function='current_leader') Current Raft leader node ID function='current_leader' <code>kaf_raft_metrics_</code> (function='log_end_offset') End offset of the Raft log function='log_end_offset' <code>kaf_raft_metrics_</code> (function='commit_latency_avg') Average commit latency function='commit_latency_avg' <code>kaf_raft_metrics_</code> (function='fetch_records_rate') Rate of fetching records function='fetch_records_rate' Raft Channel Metrics <code>kaf_raft_channel_metrics_</code> (function='request_rate') Raft request rate function='request_rate' <code>kaf_raft_channel_metrics_</code> (function='successful_authentication_rate') Successful authentication rate function='successful_authentication_rate' <code>kaf_raft_channel_metrics_</code> (function='failed_reauthentication_rate') Failed re-authentication rate function='failed_reauthentication_rate'"},{"location":"metrics/kafka/controller_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/controller_metrics_mapping/#controller-state","title":"Controller State","text":"<pre><code>// Fenced broker count\nkaf_KafkaController_FencedBrokerCount\n\n// Last applied record timestamp rate of change\nkaf_KafkaController_LastAppliedRecordTimestamp{axonfunction='rate'}\n\n// Metadata error rate\nkaf_KafkaController_MetadataErrorCount{axonfunction='rate'}\n</code></pre>"},{"location":"metrics/kafka/controller_metrics_mapping/#raft-leader-information","title":"Raft Leader Information","text":"<pre><code>// Current Raft leader\nkaf_raft_metrics_{function='current_leader'}\n\n// Raft log end offset changes\nsum(kaf_raft_metrics_{function='log_end_offset'}) by (host_id)\n</code></pre>"},{"location":"metrics/kafka/controller_metrics_mapping/#raft-performance","title":"Raft Performance","text":"<pre><code>// Commit latency average\nkaf_raft_metrics_{function='commit_latency_avg'}\n\n// Fetch records rate\nkaf_raft_metrics_{function='fetch_records_rate'}\n\n// Request rate\nkaf_raft_channel_metrics_{function='request_rate'}\n</code></pre>"},{"location":"metrics/kafka/controller_metrics_mapping/#authentication-metrics","title":"Authentication Metrics","text":"<pre><code>// Successful authentication rate\nkaf_raft_channel_metrics_{function='successful_authentication_rate'}\n\n// Failed re-authentication rate\nkaf_raft_channel_metrics_{function='failed_reauthentication_rate'}\n</code></pre>"},{"location":"metrics/kafka/controller_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>Controller</p> <ul> <li>Fenced Broker Count (counter)</li> <li>Current Raft Leader (counter)</li> <li>Last record offset timestamp</li> <li>Raft log offset change</li> <li>Commit Latency Avg</li> <li>Fetch Records Rate</li> <li>Raft Request Rate</li> <li>Metadata Error Rate</li> <li>New Active Controllers Count (placeholder)</li> </ul> <p>Authentication</p> <ul> <li>Successful Auth Rate</li> <li>Failed Auth Rate</li> </ul>"},{"location":"metrics/kafka/controller_metrics_mapping/#filters","title":"Filters","text":"<p>Note: The controller dashboard has no configurable filters, as controller metrics are cluster-wide.</p>"},{"location":"metrics/kafka/controller_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Controller Health Monitoring</p> <ul> <li>Fenced broker count should be 0 for healthy clusters</li> <li>Monitor metadata error rate for controller issues</li> <li>Track last applied record timestamp for activity</li> </ul> <p>Raft Consensus Monitoring</p> <ul> <li>Ensure stable Raft leader (minimal changes)</li> <li>Monitor commit latency for consensus performance</li> <li>High fetch records rate indicates active metadata changes</li> </ul> <p>Log Growth Monitoring</p> <ul> <li>Track Raft log offset growth rate</li> <li>Rapid growth may indicate frequent metadata changes</li> <li>Monitor for log compaction effectiveness</li> </ul> <p>Authentication Monitoring</p> <ul> <li>High failed authentication rates indicate security issues</li> <li>Monitor successful auth rate for normal operations</li> <li>Investigate spikes in failed re-authentication</li> </ul> <p>Performance Tuning</p> <ul> <li>Low commit latency ensures fast metadata propagation</li> <li>Monitor request rates for controller load</li> <li>Balance metadata operations across the cluster</li> </ul> <p>Troubleshooting</p> <ul> <li>Fenced brokers indicate network or configuration issues</li> <li>Metadata errors suggest controller processing problems</li> <li>Authentication failures may indicate credential issues</li> </ul> <p>KRaft Mode Considerations</p> <ul> <li>Controller metrics are specific to KRaft mode</li> <li>In ZooKeeper mode, different metrics apply</li> <li>Monitor for smooth leader elections and stable consensus</li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/","title":"Overview Dashboard","text":""},{"location":"metrics/kafka/overview_metrics_mapping/#axonops-kafka-overview-dashboard-metrics-mapping","title":"AxonOps Kafka Overview Dashboard Metrics Mapping","text":"<p>This document maps the metrics used in the AxonOps Kafka Overview dashboard.</p>"},{"location":"metrics/kafka/overview_metrics_mapping/#dashboard-overview","title":"Dashboard Overview","text":"<p>The Kafka Overview dashboard provides a comprehensive view of Kafka cluster health, including controller status, partition health, replication status, network throughput, and consumer group coordination. It serves as the primary dashboard for monitoring overall Kafka cluster performance and health.</p>"},{"location":"metrics/kafka/overview_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":""},{"location":"metrics/kafka/overview_metrics_mapping/#controller-metrics","title":"Controller Metrics","text":"Dashboard Metric Description Attributes <code>kaf_KafkaController_ActiveControllerCount</code> Number of active controllers in the cluster (should be 1) <code>rack</code>, <code>host_id</code> <code>kaf_KafkaController_OfflinePartitionsCount</code> Number of partitions without an active leader <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>kaf_KafkaController_PreferredReplicaImbalanceCount</code> Number of partitions where preferred replica is not the leader <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>kaf_ControllerStats_UncleanLeaderElectionsPerSec</code> Rate of unclean leader elections <code>function</code> (MeanRate), <code>rack</code>, <code>host_id</code>"},{"location":"metrics/kafka/overview_metrics_mapping/#replica-manager-metrics","title":"Replica Manager Metrics","text":"Dashboard Metric Description Attributes <code>kaf_ReplicaManager_UnderMinIsrPartitionCount</code> Partitions with fewer than minimum in-sync replicas <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>kaf_ReplicaManager_UnderReplicatedPartitions</code> Number of under-replicated partitions <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>kaf_ReplicaManager_PartitionCount</code> Total number of partitions on the broker <code>dc</code>, <code>rack</code>, <code>host_id</code> <code>kaf_ReplicaManager_LeaderCount</code> Number of partitions for which this broker is the leader <code>rack</code>, <code>host_id</code> <code>kaf_ReplicaManager_IsrShrinksPerSec</code> Rate of ISR shrinks <code>function</code> (MeanRate), <code>rack</code>, <code>host_id</code> <code>kaf_ReplicaManager_IsrExpandsPerSec</code> Rate of ISR expansions <code>function</code> (MeanRate), <code>rack</code>, <code>host_id</code>"},{"location":"metrics/kafka/overview_metrics_mapping/#broker-topic-metrics","title":"Broker Topic Metrics","text":"Dashboard Metric Description Attributes <code>kaf_BrokerTopicMetrics_BytesInPerSec</code> Incoming byte rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code>, <code>node_type</code> <code>kaf_BrokerTopicMetrics_BytesOutPerSec</code> Outgoing byte rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code>, <code>node_type</code> <code>kaf_BrokerTopicMetrics_MessagesInPerSec</code> Incoming message rate <code>axonfunction</code> (rate), <code>rack</code>, <code>host_id</code>, <code>topic</code>"},{"location":"metrics/kafka/overview_metrics_mapping/#network-metrics","title":"Network Metrics","text":"Dashboard Metric Description Attributes <code>kaf_socket_server_metrics_</code> Socket server connection metrics <code>function</code> (connection_count), <code>rack</code>, <code>host_id</code> <code>kaf_KafkaRequestHandlerPool_RequestHandlerAvgIdlePercent</code> Request handler idle percentage <code>function</code> (OneMinuteRate), <code>rack</code>, <code>host_id</code>"},{"location":"metrics/kafka/overview_metrics_mapping/#group-coordinator-metrics","title":"Group Coordinator Metrics","text":"Dashboard Metric Description Attributes <code>kaf_GroupMetadataManager_NumGroups</code> Total number of consumer groups <code>rack</code>, <code>host_id</code> <code>kaf_GroupMetadataManager_NumGroupsStable</code> Number of stable consumer groups <code>rack</code>, <code>host_id</code> <code>kaf_GroupMetadataManager_NumGroupsPreparingRebalance</code> Groups preparing to rebalance <code>rack</code>, <code>host_id</code> <code>kaf_GroupMetadataManager_NumGroupsDead</code> Number of dead consumer groups <code>rack</code>, <code>host_id</code> <code>kaf_GroupMetadataManager_NumGroupsCompletingRebalance</code> Groups completing rebalance <code>rack</code>, <code>host_id</code> <code>kaf_GroupMetadataManager_NumGroupsEmpty</code> Number of empty consumer groups <code>rack</code>, <code>host_id</code>"},{"location":"metrics/kafka/overview_metrics_mapping/#request-metrics","title":"Request Metrics","text":"Dashboard Metric Description Attributes <code>kaf_RequestMetrics_RequestsPerSec</code> Request rate per second <code>axonfunction</code> (rate), <code>function</code> (Count), <code>request</code>, <code>rack</code>, <code>host_id</code> <code>kaf_RequestMetrics_TotalTimeMs</code> Total request processing time <code>request</code> (Fetch), <code>function</code> (percentiles), <code>rack</code>, <code>host_id</code>"},{"location":"metrics/kafka/overview_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/overview_metrics_mapping/#healthcheck-queries","title":"Healthcheck Queries","text":"<pre><code>// Active Controllers (should be 1)\nsum(kaf_KafkaController_ActiveControllerCount{host_id!=\"\"})\n\n// Under min insync replicas partitions\nkaf_ReplicaManager_UnderMinIsrPartitionCount{dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n\n// Under Replicated Partitions\nkaf_ReplicaManager_UnderReplicatedPartitions{dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n\n// Offline Partitions\nkaf_KafkaController_OfflinePartitionsCount{dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/overview_metrics_mapping/#network-throughput","title":"Network Throughput","text":"<pre><code>// Cluster network throughput - Bytes in\nsum(kaf_BrokerTopicMetrics_BytesInPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id', topic!='',node_type='$node_type'})\n\n// Cluster network throughput - Bytes out\nsum(kaf_BrokerTopicMetrics_BytesOutPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id', topic!='',node_type='$node_type'})\n\n// Incoming Messages\nsum(kaf_BrokerTopicMetrics_MessagesInPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id', topic=''})\n</code></pre>"},{"location":"metrics/kafka/overview_metrics_mapping/#group-coordinator","title":"Group Coordinator","text":"<pre><code>// Consumer groups per coordinator\nkaf_GroupMetadataManager_NumGroups{rack=~'$rack',host_id=~'$host_id'}\n\n// Consumer groups by state\nsum(kaf_GroupMetadataManager_NumGroupsStable{rack=~'$rack',host_id=~'$host_id'})\nsum(kaf_GroupMetadataManager_NumGroupsPreparingRebalance{rack=~'$rack',host_id=~'$host_id'})\nsum(kaf_GroupMetadataManager_NumGroupsDead{rack=~'$rack',host_id=~'$host_id'})\n</code></pre>"},{"location":"metrics/kafka/overview_metrics_mapping/#request-rates","title":"Request Rates","text":"<pre><code>// Total Request Per Sec\nsum(kaf_RequestMetrics_RequestsPerSec{axonfunction='rate',function='Count',rack=~'$rack',host_id=~'$host_id'}) by (host_id)\n\n// Metadata Request Per Sec\nsum(kaf_RequestMetrics_RequestsPerSec{axonfunction='rate',function='Count',request='Metadata',rack=~'$rack',host_id=~'$host_id'}) by (host_id)\n</code></pre>"},{"location":"metrics/kafka/overview_metrics_mapping/#panel-organization","title":"Panel Organization","text":""},{"location":"metrics/kafka/overview_metrics_mapping/#healthcheck-section","title":"Healthcheck Section","text":"<ul> <li> <p>Active Controllers - Counter showing cluster controller status</p> </li> <li> <p>Brokers Online - Number of active brokers</p> </li> <li> <p>Online Partitions - Total partition count</p> </li> <li> <p>Offline Partitions - Partitions without leaders</p> </li> <li> <p>Preferred Replica Imbalance - Leader distribution health</p> </li> <li> <p>Under Replicated Partitions - Replication lag indicator</p> </li> <li> <p>Connections - Total client connections</p> </li> <li> <p>Under min insync replicas partitions - Critical replication status</p> </li> <li> <p>Unclean Leader Election Rate - Data loss risk indicator</p> </li> <li> <p>Cluster network throughput - Overall I/O performance</p> </li> <li> <p>Incoming Messages - Message ingestion rate</p> </li> <li> <p>Cluster Connections - Connection trend</p> </li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#general-section","title":"General Section","text":"<ul> <li> <p>Broker Count - Total brokers in cluster</p> </li> <li> <p>Active Controller - Controller assignment over time</p> </li> <li> <p>Request Handler Avg Idle Percent - Request handler capacity</p> </li> <li> <p>Under Replicated Partitions - Replication health trends</p> </li> <li> <p>Unclean Leader Elections Per Sec - Data integrity monitoring</p> </li> <li> <p>In-sync replicas Shrinks vs Expands - ISR stability</p> </li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#group-coordinator-section","title":"Group Coordinator Section","text":"<ul> <li> <p>Consumer groups number per coordinator - Group distribution</p> </li> <li> <p>No consumer groups per state - Group lifecycle monitoring</p> </li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#request-rate-section","title":"Request Rate Section","text":"<ul> <li> <p>Total Request Per Sec - Overall request load</p> </li> <li> <p>Metadata Request Per Sec - Metadata request patterns</p> </li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>rack - Filter by rack location</p> </li> <li> <p>node (<code>host_id</code>) - Filter by specific Kafka broker</p> </li> <li> <p>topic - Filter by Kafka topic</p> </li> <li> <p>node type - Filter by node type</p> </li> <li> <p>percentile - Select latency percentile (for request metrics)</p> </li> <li> <p>groupBy - Dynamic grouping (topic, host_id)</p> </li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#understanding-the-metrics","title":"Understanding the Metrics","text":""},{"location":"metrics/kafka/overview_metrics_mapping/#critical-health-indicators","title":"Critical Health Indicators","text":"<ul> <li> <p>Active Controllers: Must be exactly 1. More or less indicates cluster issues</p> </li> <li> <p>Offline Partitions: Should be 0. Any value &gt; 0 means data unavailability</p> </li> <li> <p>Under Replicated Partitions: Should be 0. Indicates replication lag</p> </li> <li> <p>Under Min ISR: Critical - indicates potential data loss risk</p> </li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#performance-indicators","title":"Performance Indicators","text":"<ul> <li> <p>Network Throughput: Monitor for capacity planning</p> </li> <li> <p>Request Handler Idle %: Lower values indicate high load</p> </li> <li> <p>ISR Shrinks/Expands: Frequent changes indicate instability</p> </li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#consumer-group-health","title":"Consumer Group Health","text":"<p>Group States:</p> <ul> <li>Stable: Normal operating state</li> <li>Rebalancing: Temporary during membership changes</li> <li>Dead: Groups that need cleanup</li> <li>Empty: Groups without active members</li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#best-practices","title":"Best Practices","text":""},{"location":"metrics/kafka/overview_metrics_mapping/#monitoring-guidelines","title":"Monitoring Guidelines","text":"<p>Set Alerts for:</p> <ul> <li>Active Controllers \u2260 1</li> <li>Offline Partitions &gt; 0</li> <li>Under Replicated Partitions &gt; 0</li> <li>Unclean Leader Elections &gt; 0</li> </ul> <p>Regular Checks:</p> <ul> <li>Network throughput trends</li> <li>Consumer group stability</li> <li>Request rate patterns</li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#troubleshooting","title":"Troubleshooting","text":"<p>No Active Controller:</p> <ul> <li>Check ZooKeeper connectivity</li> <li>Review controller logs</li> <li>Verify network partitions</li> </ul> <p>High Under-Replicated Partitions:</p> <ul> <li>Check broker health</li> <li>Verify network bandwidth</li> <li>Review replica lag settings</li> </ul> <p>Consumer Group Issues:</p> <ul> <li>Monitor rebalance frequency</li> <li>Check consumer lag</li> <li>Verify coordinator load</li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#data-resolution","title":"Data Resolution","text":"<ul> <li>Most metrics use <code>low</code> resolution for efficiency</li> <li>Rate metrics use <code>axonfunction='rate'</code> for accurate per-second calculations</li> <li>Percentile metrics available for latency measurements</li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#units","title":"Units","text":"<ul> <li> <p>Bytes: Network throughput (bytes/sec)</p> </li> <li> <p>short: Counts and rates</p> </li> <li> <p>percent: Utilization metrics (0-100)</p> </li> <li> <p>rps: Requests per second</p> </li> </ul>"},{"location":"metrics/kafka/overview_metrics_mapping/#notes","title":"Notes","text":"<ul> <li>Empty topic filter (<code>topic=''</code>) shows aggregate metrics</li> <li><code>host_id!=\"\"</code> ensures only active brokers are counted</li> <li>The <code>node_type</code> filter allows monitoring mixed clusters</li> <li>ISR metrics use <code>MeanRate</code> for smoothed values</li> </ul>"},{"location":"metrics/kafka/performance_metrics_mapping/","title":"Performance Dashboard","text":""},{"location":"metrics/kafka/performance_metrics_mapping/#axonops-kafka-performance-dashboard-metrics-mapping","title":"AxonOps Kafka Performance Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/performance_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka Performance Dashboard provides detailed insights into Kafka broker performance, including request processing times, throughput metrics, thread utilization, and queue sizes. This dashboard is essential for identifying performance bottlenecks and optimizing Kafka cluster performance.</p>"},{"location":"metrics/kafka/performance_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes Request Timing Metrics <code>kaf_RequestMetrics_TotalTimeMs</code> Total time to process requests (produce/fetch) request={Produce,Fetch,FetchFollower} <code>kaf_RequestMetrics_RequestQueueTimeMs</code> Time requests spend in request queue request={Fetch,FetchFollower} Throughput Metrics <code>kaf_BrokerTopicMetrics_MessagesInPerSec</code> Rate of messages received per second topic={topic} <code>kaf_BrokerTopicMetrics_BytesInPerSec</code> Rate of bytes received per second topic={topic} <code>kaf_BrokerTopicMetrics_BytesOutPerSec</code> Rate of bytes sent per second topic={topic} Queue Metrics <code>kaf_RequestChannel_RequestQueueSize</code> Current size of request queue - <code>kaf_RequestChannel_ResponseQueueSize</code> Current size of response queue processor={id} Thread Utilization Metrics <code>kaf_SocketServer_NetworkProcessorAvgIdlePercent</code> Average idle percentage of network threads - <code>kaf_KafkaRequestHandlerPool_RequestHandlerAvgIdlePercent</code> Average idle percentage of request handler threads - Purgatory Metrics <code>kaf_DelayedOperationPurgatory_PurgatorySize</code> Number of delayed operations in purgatory delayedOperation={Produce,Fetch}"},{"location":"metrics/kafka/performance_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/performance_metrics_mapping/#request-processing-time","title":"Request Processing Time","text":"<pre><code>// Total time for produce requests (selected percentile)\nkaf_RequestMetrics_TotalTimeMs{request='Produce',function='$percentile',rack=~'$rack',host_id=~'$host_id'}\n\n// Total time for fetch requests\nkaf_RequestMetrics_TotalTimeMs{request='Fetch',function='$percentile',rack=~'$rack',host_id=~'$host_id'}\n\n// Total time for follower fetch requests\nkaf_RequestMetrics_TotalTimeMs{request='FetchFollower',function='$percentile',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/performance_metrics_mapping/#message-throughput","title":"Message Throughput","text":"<pre><code>// Messages per second per broker\nsum(kaf_BrokerTopicMetrics_MessagesInPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id',topic=~'$topic'}) by (host_id)\n\n// Bytes in per second per broker\nsum(kaf_BrokerTopicMetrics_BytesInPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id',topic=~'$topic'}) by (host_id)\n\n// Bytes out per second per broker\nsum(kaf_BrokerTopicMetrics_BytesOutPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id',topic=~'$topic'}) by (host_id)\n</code></pre>"},{"location":"metrics/kafka/performance_metrics_mapping/#thread-utilization","title":"Thread Utilization","text":"<pre><code>// Network processor idle percentage\nkaf_SocketServer_NetworkProcessorAvgIdlePercent{rack=~'$rack',host_id=~'$host_id'} * 100\n\n// Request handler idle percentage\nkaf_KafkaRequestHandlerPool_RequestHandlerAvgIdlePercent{function='OneMinuteRate',rack=~'$rack',host_id=~'$host_id'} * 100\n</code></pre>"},{"location":"metrics/kafka/performance_metrics_mapping/#queue-sizes","title":"Queue Sizes","text":"<pre><code>// Request queue size\nkaf_RequestChannel_RequestQueueSize{rack=~'$rack',host_id=~'$host_id'}\n\n// Response queue size\nkaf_RequestChannel_ResponseQueueSize{processor='', rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/performance_metrics_mapping/#request-queue-time","title":"Request Queue Time","text":"<pre><code>// Fetch request queue time\nkaf_RequestMetrics_RequestQueueTimeMs{request='Fetch',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n\n// Follower fetch request queue time\nkaf_RequestMetrics_RequestQueueTimeMs{request='FetchFollower',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/performance_metrics_mapping/#purgatory-sizes","title":"Purgatory Sizes","text":"<pre><code>// Producer purgatory size\nkaf_DelayedOperationPurgatory_PurgatorySize{delayedOperation='Produce',rack=~'$rack',host_id=~'$host_id'}\n\n// Fetch purgatory size\nkaf_DelayedOperationPurgatory_PurgatorySize{delayedOperation='Fetch', rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/performance_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>Throughput</p> <ul> <li>Total time (produce/fetch) by percentile</li> <li>Messages In Per Broker</li> <li>Bytes In Per Broker</li> <li>Bytes Out Per Broker</li> </ul> <p>Purgatory</p> <ul> <li>Producer Purgatory Size</li> <li>Fetch Purgatory Size</li> </ul> <p>Request Queue</p> <ul> <li>Request Queue Fetch Follower Requests Time</li> <li>Request Queue Fetch Requests Time</li> </ul> <p>Thread Utilization</p> <ul> <li>Request Queue Size</li> <li>Response Queue Size</li> <li>Network Processor Avg Idle Percent</li> <li>Request Handler Avg Idle Percent</li> </ul>"},{"location":"metrics/kafka/performance_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>rack: Filter by rack location</p> </li> <li> <p>host_id: Filter by specific host/broker</p> </li> <li> <p>percentile: Select percentile for latency metrics (50th, 95th, 99th, etc.)</p> </li> <li> <p>topic: Filter metrics by specific topics</p> </li> </ul>"},{"location":"metrics/kafka/performance_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Request Latency Monitoring</p> <ul> <li>Monitor 99th percentile latencies to catch outliers</li> <li>High total time indicates performance issues</li> <li>Compare produce vs fetch latencies</li> </ul> <p>Throughput Monitoring</p> <ul> <li>Balance bytes in/out across brokers</li> <li>Monitor message rates for capacity planning</li> <li>Identify hot partitions or uneven load distribution</li> </ul> <p>Queue Monitoring</p> <ul> <li>Request queue size should remain low</li> <li>High queue sizes indicate thread pool saturation</li> <li>Monitor queue time to identify bottlenecks</li> </ul> <p>Thread Utilization</p> <ul> <li>Network processor idle % should be &gt; 30%</li> <li>Request handler idle % should be &gt; 30%  </li> <li>Low idle percentages indicate need for more threads</li> </ul> <p>Purgatory Monitoring</p> <ul> <li>High purgatory sizes indicate delayed operations</li> <li>Producer purgatory: waiting for replication</li> <li>Fetch purgatory: waiting for data availability</li> </ul> <p>Performance Tuning</p> <ul> <li>Adjust thread pools based on utilization</li> <li>Optimize batch sizes for better throughput</li> <li>Monitor and tune request timeouts</li> </ul>"},{"location":"metrics/kafka/replication_metrics_mapping/","title":"Replication Dashboard","text":""},{"location":"metrics/kafka/replication_metrics_mapping/#axonops-kafka-replication-dashboard-metrics-mapping","title":"AxonOps Kafka Replication Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/replication_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka Replication Dashboard provides comprehensive monitoring of Kafka's data replication health and performance. It tracks partition states, ISR (In-Sync Replica) changes, and request latencies for both leaders and followers to ensure data durability and availability.</p>"},{"location":"metrics/kafka/replication_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes Partition State Metrics <code>kaf_ReplicaManager_UnderReplicatedPartitions</code> Number of under-replicated partitions - <code>kaf_KafkaController_OfflinePartitionsCount</code> Number of offline partitions - <code>kaf_ReplicaManager_PartitionCount</code> Total number of partitions on the broker - <code>kaf_ReplicaManager_UnderMinIsrPartitionCount</code> Partitions with ISR count below min.insync.replicas - ISR Change Metrics <code>kaf_ReplicaManager_IsrShrinksPerSec</code> Rate of ISR shrinks per second - <code>kaf_ReplicaManager_IsrExpandsPerSec</code> Rate of ISR expansions per second - Leader Request Metrics <code>kaf_RequestMetrics_LocalTimeMs</code> (request='FetchFollower') Time leader spends processing follower fetch requests request=FetchFollower <code>kaf_RequestMetrics_LocalTimeMs</code> (request='Fetch') Time leader spends processing consumer fetch requests request=Fetch <code>kaf_RequestMetrics_LocalTimeMs</code> (request='FetchConsumer') Time leader spends processing consumer fetch requests request=FetchConsumer <code>kaf_RequestMetrics_LocalTimeMs</code> (request='Produce') Time leader spends processing produce requests request=Produce Follower Request Metrics <code>kaf_RequestMetrics_RemoteTimeMs</code> (request='Produce') Time follower waits for produce replication request=Produce <code>kaf_RequestMetrics_RemoteTimeMs</code> (request='Fetch') Time follower waits for fetch requests request=Fetch <code>kaf_RequestMetrics_RemoteTimeMs</code> (request='FetchConsumer') Time follower waits for consumer fetch request=FetchConsumer <code>kaf_RequestMetrics_RemoteTimeMs</code> (request='FetchFollower') Time follower waits for follower fetch request=FetchFollower"},{"location":"metrics/kafka/replication_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/replication_metrics_mapping/#partition-health","title":"Partition Health","text":"<pre><code>// Under-replicated partitions\nkaf_ReplicaManager_UnderReplicatedPartitions{rack=~'$rack',host_id=~'$host_id'}\n\n// Offline partitions\nkaf_KafkaController_OfflinePartitionsCount{rack=~'$rack',host_id=~'$host_id'}\n\n// Total partition count\nkaf_ReplicaManager_PartitionCount{rack=~'$rack',host_id=~'$host_id'}\n\n// Under min ISR partitions\nkaf_ReplicaManager_UnderMinIsrPartitionCount{rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/replication_metrics_mapping/#isr-changes","title":"ISR Changes","text":"<pre><code>// ISR shrink rate\nkaf_ReplicaManager_IsrShrinksPerSec{function='MeanRate',rack=~'$rack',host_id=~'$host_id'}\n\n// ISR expand rate\nkaf_ReplicaManager_IsrExpandsPerSec{function='MeanRate', rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/replication_metrics_mapping/#leader-performance","title":"Leader Performance","text":"<pre><code>// Leader processing time for follower fetch requests\nkaf_RequestMetrics_LocalTimeMs{request='FetchFollower',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n\n// Leader processing time for consumer fetch requests\nkaf_RequestMetrics_LocalTimeMs{request='Fetch',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n\n// Leader processing time for produce requests\nkaf_RequestMetrics_LocalTimeMs{request='Produce',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/replication_metrics_mapping/#follower-performance","title":"Follower Performance","text":"<pre><code>// Follower wait time for produce replication\nkaf_RequestMetrics_RemoteTimeMs{request='Produce', function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n\n// Follower wait time for fetch requests\nkaf_RequestMetrics_RemoteTimeMs{request='Fetch',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n\n// Follower wait time for follower fetch\nkaf_RequestMetrics_RemoteTimeMs{request='FetchFollower',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/replication_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>Replication</p> <ul> <li>Under Replicated Partitions</li> <li>Online Partitions</li> <li>Offline Partitions</li> <li>Under Min ISR Partitions</li> </ul> <p>Leader Performance</p> <ul> <li>Leader FetchFollower Requests</li> <li>Leader Fetch Requests</li> <li>Leader FetchConsumer Requests</li> <li>Leader Produce Requests</li> </ul> <p>Follower Performance</p> <ul> <li>Follower Produce Requests Time</li> <li>Follower Fetch Requests Time</li> <li>Follower FetchConsumer Request Time</li> <li>Follower FetchFollower Request Time</li> </ul> <p>ISR Shrinks / Expands</p> <ul> <li>IsrShrinks per Sec by Host</li> <li>IsrExpands per Sec By Host</li> </ul>"},{"location":"metrics/kafka/replication_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>rack: Filter by rack location</p> </li> <li> <p>host_id: Filter by specific host/broker</p> </li> <li> <p>percentile: Select percentile for latency metrics (50th, 95th, 99th, etc.)</p> </li> </ul>"},{"location":"metrics/kafka/replication_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Partition Health Monitoring</p> <ul> <li>Under-replicated partitions should be 0</li> <li>Offline partitions indicate serious issues</li> <li>Monitor under min ISR for potential data loss risk</li> </ul> <p>ISR Monitoring</p> <ul> <li>Frequent ISR shrinks indicate replication lag</li> <li>High ISR churn suggests network or performance issues</li> <li>ISR expansions should follow shrinks during recovery</li> </ul> <p>Leader Performance</p> <ul> <li>Monitor leader request processing times</li> <li>High FetchFollower times indicate replication bottlenecks</li> <li>Compare produce vs fetch latencies</li> </ul> <p>Follower Performance</p> <ul> <li>High RemoteTimeMs indicates replication delays</li> <li>Monitor follower fetch times for lag issues</li> <li>Ensure followers can keep up with leaders</li> </ul> <p>Replication Tuning</p> <ul> <li>Adjust <code>replica.lag.time.max.ms</code> for ISR membership</li> <li>Tune <code>num.replica.fetchers</code> for better throughput</li> <li>Monitor <code>min.insync.replicas</code> compliance</li> </ul> <p>Troubleshooting</p> <ul> <li>Under-replicated partitions: Check broker health and network</li> <li>ISR shrinks: Investigate disk I/O and network latency</li> <li>High follower lag: Check replication thread count</li> <li>Offline partitions: Critical issue requiring immediate attention</li> </ul>"},{"location":"metrics/kafka/requests_metrics_mapping/","title":"Requests Dashboard","text":""},{"location":"metrics/kafka/requests_metrics_mapping/#axonops-kafka-requests-dashboard-metrics-mapping","title":"AxonOps Kafka Requests Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/requests_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka Requests Dashboard provides comprehensive monitoring of request rates, processing times, and message conversions across your Kafka cluster. It helps identify performance bottlenecks, track request patterns, and monitor client compatibility issues.</p>"},{"location":"metrics/kafka/requests_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes Request Rate Metrics <code>kaf_RequestMetrics_RequestsPerSec</code> Rate of requests per second by type request={type} <code>kaf_BrokerTopicMetrics_TotalProduceRequestsPerSec</code> Produce requests per second per topic topic={topic} <code>kaf_BrokerTopicMetrics_TotalFetchRequestsPerSec</code> Fetch requests per second per topic topic={topic} Request Timing Metrics <code>kaf_RequestMetrics_TotalTimeMs</code> Total time to process requests request={type} <code>kaf_RequestMetrics_RequestQueueTimeMs</code> Time requests spend in queue request={type} Message Conversion Metrics <code>kaf_BrokerTopicMetrics_FetchMessageConversionsPerSec</code> Rate of message conversions during fetch - <code>kaf_BrokerTopicMetrics_ProduceMessageConversionsPerSec</code> Rate of message conversions during produce - Client Metrics <code>kaf_socket_server_metrics_</code> (function='connections') Client connections by version listener={listener}, clientSoftwareName={name}, clientSoftwareVersion={version}"},{"location":"metrics/kafka/requests_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/requests_metrics_mapping/#request-rates","title":"Request Rates","text":"<pre><code>// Total requests per second per broker\nsum(kaf_RequestMetrics_RequestsPerSec{axonfunction='rate',function='Count',rack=~'$rack',host_id=~'$host_id'}) by (host_id)\n\n// Produce requests per second\nsum(kaf_RequestMetrics_RequestsPerSec{axonfunction='rate',function='Count',request='Produce',rack=~'$rack',host_id=~'$host_id'}) by (host_id)\n\n// Fetch consumer requests per second\nsum(kaf_RequestMetrics_RequestsPerSec{axonfunction='rate',function='Count',request='FetchConsumer',rack=~'$rack',host_id=~'$host_id'}) by (host_id)\n\n// Metadata requests per second\nsum(kaf_RequestMetrics_RequestsPerSec{axonfunction='rate',function='Count',request='Metadata',rack=~'$rack',host_id=~'$host_id'}) by (host_id)\n</code></pre>"},{"location":"metrics/kafka/requests_metrics_mapping/#topic-level-request-rates","title":"Topic-Level Request Rates","text":"<pre><code>// Produce requests per topic\nsum(kaf_BrokerTopicMetrics_TotalProduceRequestsPerSec{axonfunction='rate',function='Count',rack=~'$rack',host_id=~'$host_id', topic!=''}) by (topic)\n\n// Fetch requests per topic\nsum(kaf_BrokerTopicMetrics_TotalFetchRequestsPerSec{axonfunction='rate',function='Count',rack=~'$rack',host_id=~'$host_id',topic=~'$topic', topic!=''}) by (topic)\n</code></pre>"},{"location":"metrics/kafka/requests_metrics_mapping/#request-processing-times","title":"Request Processing Times","text":"<pre><code>// Produce request total time\nkaf_RequestMetrics_TotalTimeMs{request='Produce',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n\n// Fetch request total time\nkaf_RequestMetrics_TotalTimeMs{request='Fetch',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n\n// Fetch follower request total time\nkaf_RequestMetrics_TotalTimeMs{request='FetchFollower',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/requests_metrics_mapping/#request-queue-times","title":"Request Queue Times","text":"<pre><code>// Fetch request queue time\nkaf_RequestMetrics_RequestQueueTimeMs{request='Fetch',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n\n// Fetch follower request queue time\nkaf_RequestMetrics_RequestQueueTimeMs{request='FetchFollower',function=~'$percentile',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/requests_metrics_mapping/#message-conversions","title":"Message Conversions","text":"<pre><code>// Fetch message conversions per second\nsum(kaf_BrokerTopicMetrics_FetchMessageConversionsPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id'})\n\n// Produce message conversions per second\nkaf_BrokerTopicMetrics_ProduceMessageConversionsPerSec{function='MeanRate',rack=~'$rack',host_id=~'$host_id'}\n\n// Client version distribution\nsum(kaf_socket_server_metrics_{function='connections',rack=~'$rack',host_id=~'$host_id'}) by (clientSoftwareVersion, clientSoftwareName)\n</code></pre>"},{"location":"metrics/kafka/requests_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>Requests</p> <ul> <li>Total Request Per Sec</li> <li>Metadata Request Per Sec</li> <li>Produce Request Per Sec</li> <li>Fetch Request Per Sec</li> <li>Produce request per sec per topic</li> <li>Fetch request per sec per topic</li> </ul> <p>Request Times</p> <ul> <li>Produce Time</li> <li>Fetch Time</li> <li>FetchFollower Time</li> </ul> <p>Request Queues</p> <ul> <li>Request Queue Fetch Follower Requests Time</li> <li>Request Queue Fetch Requests Time</li> </ul> <p>Message Conversion</p> <ul> <li>Number of produced message conversion</li> <li>Number of consumed message conversion</li> <li>Client version repartition</li> </ul>"},{"location":"metrics/kafka/requests_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>rack: Filter by rack location</p> </li> <li> <p>host_id: Filter by specific host/broker</p> </li> <li> <p>topic: Filter by specific topic(s)</p> </li> <li> <p>percentile: Select percentile for latency metrics (50th, 95th, 99th, etc.)</p> </li> </ul>"},{"location":"metrics/kafka/requests_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Request Rate Monitoring</p> <ul> <li>Monitor total request rates for capacity planning</li> <li>High metadata request rates may indicate client issues</li> <li>Balance request rates across brokers</li> </ul> <p>Request Timing Analysis</p> <ul> <li>Monitor 99th percentile for worst-case scenarios</li> <li>High total time indicates processing bottlenecks</li> <li>Compare request types to identify slow operations</li> </ul> <p>Queue Time Monitoring</p> <ul> <li>High queue times indicate thread pool saturation</li> <li>Consider increasing request handler threads</li> <li>Queue time should be minimal compared to total time</li> </ul> <p>Message Conversion Impact</p> <ul> <li>Message conversions impact performance significantly</li> <li>High conversion rates suggest client version mismatches</li> <li>Update clients to match broker message format version</li> </ul> <p>Client Version Management</p> <ul> <li>Monitor client version distribution</li> <li>Identify and upgrade outdated clients</li> <li>Ensure compatibility with broker version</li> </ul> <p>Performance Tuning</p> <ul> <li>Adjust <code>num.network.threads</code> for high request rates</li> <li>Tune <code>num.io.threads</code> for I/O operations</li> <li>Monitor and adjust <code>queued.max.requests</code></li> </ul> <p>Troubleshooting</p> <ul> <li>High produce times: Check replication settings</li> <li>High fetch times: Review consumer configurations</li> <li>Message conversions: Align client/broker versions</li> </ul>"},{"location":"metrics/kafka/system_metrics_mapping/","title":"System Dashboard","text":""},{"location":"metrics/kafka/system_metrics_mapping/#axonops-kafka-system-dashboard-metrics-mapping","title":"AxonOps Kafka System Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/system_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka System Dashboard provides comprehensive monitoring of system-level resources across your Kafka cluster. It tracks CPU utilization, disk I/O, memory usage, JVM performance, and network statistics to ensure optimal cluster health and performance.</p>"},{"location":"metrics/kafka/system_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes CPU Metrics <code>host_CPU_Percent_Merge</code> Overall CPU utilization percentage time='real' <code>host_CPU</code> (mode='iowait') CPU time waiting for I/O operations mode='iowait' <code>host_load15</code> 15-minute load average - Disk Metrics <code>host_Disk_UsedPercent</code> Percentage of disk space used - <code>host_Disk_Used</code> Absolute disk space used in bytes - <code>host_Disk_SectorsRead</code> Disk read throughput in bytes/sec - <code>host_Disk_SectorsWrite</code> Disk write throughput in bytes/sec - <code>host_Disk_IOCount</code> Input/output operations per second - <code>host_Disk_avgqsz</code> Average disk queue size - <code>host_Disk_WeightedIO</code> Weighted I/O time in milliseconds - <code>host_Disk_IoTime</code> Time spent on disk I/O operations - <code>host_filefd_allocated</code> Number of allocated file descriptors - <code>host_filefd_max</code> Maximum available file descriptors - Memory Metrics <code>host_Memory_Used</code> Used system memory in bytes - <code>host_Memory_Cached</code> Cached memory in bytes - <code>host_Memory_UsedPercent</code> Memory usage percentage - JVM Metrics <code>jvm_Threading_</code> JVM thread count type=Threading <code>jvm_GarbageCollector_G1_Young_Generation</code> G1 GC statistics name=G1 Young Generation <code>jvm_GarbageCollector_ZGC</code> ZGC statistics name=ZGC <code>jvm_GarbageCollector_Shenandoah_Cycles</code> Shenandoah GC statistics name=Shenandoah <code>jvm_GarbageCollector_ConcurrentMarkSweep</code> CMS GC statistics name=ConcurrentMarkSweep <code>jvm_GarbageCollector_ParNew</code> ParNew GC statistics name=ParNew <code>jvm_Memory_</code> JVM heap and non-heap memory usage type=Memory Network Metrics <code>host_netIOCounters_BytesRecv</code> Network bytes received per second - <code>host_netIOCounters_BytesSent</code> Network bytes sent per second - <code>host_ntp_offset_seconds</code> NTP time offset in seconds -"},{"location":"metrics/kafka/system_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/system_metrics_mapping/#cpu-usage-by-rack","title":"CPU Usage by Rack","text":"<pre><code>avg(host_CPU_Percent_Merge{time='real',rack=~'$rack',host_id=~'$host_id', node_type='$node_type', type='kafka'}) by (rack)\n</code></pre>"},{"location":"metrics/kafka/system_metrics_mapping/#io-wait-percentage","title":"I/O Wait Percentage","text":"<pre><code>avg(host_CPU{axonfunction='rate',mode='iowait',rack=~'$rack',host_id=~'$host_id',node_type='$node_type', type='kafka'}) by (host_id) * 100\n</code></pre>"},{"location":"metrics/kafka/system_metrics_mapping/#disk-io-throughput","title":"Disk I/O Throughput","text":"<pre><code>// Read throughput\nhost_Disk_SectorsRead{axonfunction='rate',rack=~'$rack',host_id=~'$host_id',partition=~'$partition',node_type='$node_type', type='kafka'}\n\n// Write throughput\nhost_Disk_SectorsWrite{axonfunction='rate',rack=~'$rack',host_id=~'$host_id',partition=~'$partition', node_type='$node_type', type='kafka'}\n</code></pre>"},{"location":"metrics/kafka/system_metrics_mapping/#file-descriptor-usage","title":"File Descriptor Usage","text":"<pre><code>(host_filefd_allocated{rack=~'$rack',host_id=~'$host_id'} / host_filefd_max{rack=~'$rack',host_id=~'$host_id', node_type='$node_type', type='kafka'})*100\n</code></pre>"},{"location":"metrics/kafka/system_metrics_mapping/#jvm-heap-memory-usage","title":"JVM Heap Memory Usage","text":"<pre><code>jvm_Memory_{function='used',scope='HeapMemoryUsage',rack=~'$rack',host_id=~'$host_id', node_type='$node_type', type='kafka'}\n</code></pre>"},{"location":"metrics/kafka/system_metrics_mapping/#gc-rate","title":"GC Rate","text":"<pre><code>jvm_GarbageCollector_G1_Young_Generation{axonfunction='rate',function='CollectionCount',rack=~'$rack',host_id=~'$host_id', node_type='$node_type', type='kafka'}\n</code></pre>"},{"location":"metrics/kafka/system_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Average CPU Usage per Rack</li> </ul> <p>CPU and Load</p> <ul> <li>CPU usage per host</li> <li>Load Average (15m)</li> <li>Avg IO wait CPU per Host</li> </ul> <p>Disk Statistics</p> <ul> <li>Disk % Usage by mount point</li> <li>Used Disk Space Per Node</li> <li>Bytes Read/Write Per Second</li> <li>IOPS</li> <li>Disk avgqsz</li> <li>Disk WeightedIO time</li> <li>% File Descriptors Allocated</li> <li>Time Spent on Disk IO</li> </ul> <p>Memory Statistics</p> <ul> <li>Used memory</li> <li>Cached memory</li> <li>Used Memory Percentage</li> <li>JVM Thread Count</li> <li>GC Count per sec</li> <li>GC Duration</li> <li>JVM Utilization (Heap/Non-Heap)</li> <li>JVM Heap Utilization</li> </ul> <p>Network Statistics</p> <ul> <li>Network Received (bytes)</li> <li>Network Transmitted (bytes)</li> <li>NTP offset (milliseconds)</li> </ul>"},{"location":"metrics/kafka/system_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>node_type: Filter by node type (broker, controller, etc.)</p> </li> <li> <p>rack: Filter by rack location</p> </li> <li> <p>host_id: Filter by specific host/node</p> </li> <li> <p>mountpoint: Filter by disk mount point</p> </li> <li> <p>partition: Filter by disk partition</p> </li> <li> <p>Interface: Filter by network interface</p> </li> </ul>"},{"location":"metrics/kafka/system_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>CPU Monitoring</p> <ul> <li>Monitor CPU usage to ensure it stays below 80% for production workloads</li> <li>High I/O wait indicates disk bottlenecks</li> <li>Monitor load average relative to CPU core count</li> </ul> <p>Disk Monitoring</p> <ul> <li>Keep disk usage below 85% to prevent performance degradation</li> <li>Monitor IOPS and queue size for disk saturation</li> <li>Track weighted I/O time for disk latency issues</li> </ul> <p>Memory Monitoring</p> <ul> <li>Monitor both system and JVM memory usage</li> <li>Ensure adequate memory for page cache (cached memory)</li> <li>Track JVM heap usage to prevent OutOfMemory errors</li> </ul> <p>GC Monitoring</p> <ul> <li>Monitor GC frequency and duration</li> <li>Excessive GC activity indicates memory pressure</li> <li>Different GC algorithms (G1, ZGC, Shenandoah) have different characteristics</li> </ul> <p>Network Monitoring</p> <ul> <li>Track network throughput for replication and client traffic</li> <li>Monitor NTP offset to ensure time synchronization</li> <li>High network usage may indicate replication storms</li> </ul> <p>File Descriptors</p> <ul> <li>Monitor file descriptor usage to prevent \"too many open files\" errors</li> <li>Kafka requires many file descriptors for log segments and network connections</li> </ul>"},{"location":"metrics/kafka/topics_metrics_mapping/","title":"Topics Dashboard","text":""},{"location":"metrics/kafka/topics_metrics_mapping/#axonops-kafka-topics-dashboard-metrics-mapping","title":"AxonOps Kafka Topics Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/topics_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka Topics Dashboard provides detailed monitoring of individual topic performance and health. It tracks message throughput, byte rates, log sizes, segment counts, and offset progression to help manage and optimize topic performance.</p>"},{"location":"metrics/kafka/topics_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes Topic Throughput Metrics <code>kaf_BrokerTopicMetrics_MessagesInPerSec</code> Rate of messages produced to topic topic={topic} <code>kaf_BrokerTopicMetrics_BytesInPerSec</code> Rate of bytes produced to topic topic={topic} <code>kaf_BrokerTopicMetrics_BytesOutPerSec</code> Rate of bytes consumed from topic topic={topic} Log Metrics <code>kaf_Log_LogEndOffset</code> End offset of the log topic={topic}, partition={partition} <code>kaf_Log_NumLogSegments</code> Number of log segments topic={topic}, partition={partition} <code>kaf_Log_Size</code> Size of the log in bytes topic={topic}, partition={partition} Log Manager Metrics <code>kaf_LogManager_LogDirectoryOffline</code> Number of offline log directories logDirectory={path}"},{"location":"metrics/kafka/topics_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/topics_metrics_mapping/#topic-throughput-general-view","title":"Topic Throughput - General View","text":"<pre><code>// Messages in per topic\nsum(kaf_BrokerTopicMetrics_MessagesInPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id',topic!='',topic='$topic'}) by (topic)\n\n// Bytes in per topic\nsum(kaf_BrokerTopicMetrics_BytesInPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id', topic!='', topic='$topic'}) by(topic)\n\n// Bytes out per topic\nsum(kaf_BrokerTopicMetrics_BytesOutPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id', topic!='',topic='$topic'}) by(topic)\n</code></pre>"},{"location":"metrics/kafka/topics_metrics_mapping/#topic-throughput-detailed-view","title":"Topic Throughput - Detailed View","text":"<pre><code>// Messages in per topic (all topics)\nsum(kaf_BrokerTopicMetrics_MessagesInPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id',topic=~'$topic',topic!=''}) by (topic)\n\n// Bytes in per topic (all topics)\nsum(kaf_BrokerTopicMetrics_BytesInPerSec{axonfunction='rate', topic='$topic',rack=~'$rack',host_id=~'$host_id',topic!=''}) by (topic)\n\n// Bytes out per topic (all topics)\nsum(kaf_BrokerTopicMetrics_BytesOutPerSec{axonfunction='rate', topic='$topic',rack=~'$rack',host_id=~'$host_id',topic!=''}) by (topic)\n</code></pre>"},{"location":"metrics/kafka/topics_metrics_mapping/#log-offset-and-segments","title":"Log Offset and Segments","text":"<pre><code>// End offset increase rate per topic\nsum(rate(kaf_Log_LogEndOffset{rack=~'$rack',host_id=~'$host_id',topic!='',topic='$topic'}[5m])) by (topic)\n\n// Number of log segments per topic\nsum(kaf_Log_NumLogSegments{rack=~'$rack',host_id=~'$host_id',topic='$topic'}) by (topic)\n</code></pre>"},{"location":"metrics/kafka/topics_metrics_mapping/#log-size-metrics","title":"Log Size Metrics","text":"<pre><code>// Log size per topic\nsum(kaf_Log_Size{rack=~'$rack',host_id=~'$host_id', topic='$topic'}) by (topic)\n\n// Log size per broker\nsum(kaf_Log_Size{rack=~'$rack',host_id=~'$host_id', topic='$topic'}) by (host_id)\n\n// Offline log directories\nkaf_LogManager_LogDirectoryOffline{rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/topics_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>General</p> <ul> <li>Messages In</li> <li>Bytes In</li> <li>Bytes Out</li> <li>End Offset Increase Per Topic</li> <li>No. Log Segments per topic</li> </ul> <p>Log Size</p> <ul> <li>Log size per Topic</li> <li>Log size per Broker</li> <li>Log Directories Offline</li> </ul> <p>Throughput</p> <ul> <li>Messages In Per Topic</li> <li>Bytes In Per Topic</li> <li>Bytes Out Per Topic</li> </ul>"},{"location":"metrics/kafka/topics_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>rack: Filter by rack location</p> </li> <li> <p>host_id: Filter by specific host/broker</p> </li> <li> <p>topic: Filter by specific topic(s)</p> </li> <li> <p>percentile: Select percentile for latency metrics</p> </li> <li> <p>groupBy: Group results by rack or host_id</p> </li> </ul>"},{"location":"metrics/kafka/topics_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Topic Throughput Monitoring</p> <ul> <li>Monitor message and byte rates for capacity planning</li> <li>Identify hot topics with disproportionate traffic</li> <li>Compare bytes in vs bytes out for consumption patterns</li> </ul> <p>Log Management</p> <ul> <li>Monitor log sizes to prevent disk space issues</li> <li>Track segment counts for retention policy effectiveness</li> <li>Watch for rapid offset increases indicating high activity</li> </ul> <p>Performance Analysis</p> <ul> <li>High bytes in with low messages indicates large messages</li> <li>Compare throughput across brokers for load distribution</li> <li>Monitor topic growth trends for capacity planning</li> </ul> <p>Log Directory Health</p> <ul> <li>Offline log directories indicate disk failures</li> <li>Requires immediate attention to prevent data loss</li> <li>May trigger under-replicated partitions</li> </ul> <p>Segment Management</p> <ul> <li>High segment counts may impact performance</li> <li>Consider adjusting segment.ms or segment.bytes</li> <li>Monitor segment creation rate for tuning</li> </ul> <p>Topic-Specific Tuning</p> <ul> <li>Different topics may need different configurations</li> <li>High-throughput topics may need more partitions</li> <li>Consider compression for high-volume topics</li> </ul> <p>Retention Monitoring</p> <ul> <li>Log size indicates retention effectiveness</li> <li>Monitor growth rate vs retention settings</li> <li>Ensure cleanup policies are working correctly</li> </ul>"},{"location":"metrics/kafka/zookeeper_metrics_mapping/","title":"ZooKeeper Dashboard","text":""},{"location":"metrics/kafka/zookeeper_metrics_mapping/#axonops-kafka-zookeeper-dashboard-metrics-mapping","title":"AxonOps Kafka ZooKeeper Dashboard Metrics Mapping","text":""},{"location":"metrics/kafka/zookeeper_metrics_mapping/#overview","title":"Overview","text":"<p>The Kafka ZooKeeper Dashboard monitors the health and performance of ZooKeeper ensemble used by Kafka for cluster coordination (in non-KRaft mode). It tracks connections, request latency, node statistics, and session management to ensure ZooKeeper is functioning properly.</p>"},{"location":"metrics/kafka/zookeeper_metrics_mapping/#metrics-mapping","title":"Metrics Mapping","text":"Dashboard Metric Description Attributes ZooKeeper Health Metrics <code>zk_NumAliveConnections</code> Number of active client connections port={port} <code>zk_NodeCount</code> Total number of znodes port={port} <code>zk_WatchCount</code> Total number of watches port={port} <code>zk_OutstandingRequests</code> Number of queued requests port={port} Request Latency Metrics <code>zk_MinRequestLatency</code> Minimum request latency port={port} <code>zk_AvgRequestLatency</code> Average request latency port={port} <code>zk_MaxRequestLatency</code> Maximum request latency port={port} Packet Metrics <code>zk_PacketsSent</code> Number of packets sent port={port} <code>zk_PacketsReceived</code> Number of packets received port={port} Kafka-Reported ZooKeeper Metrics <code>kaf_ZooKeeperClientMetrics_ZooKeeperRequestLatencyMs</code> ZooKeeper request latency from Kafka perspective - <code>kaf_SessionExpireListener_ZooKeeperExpiresPerSec</code> Rate of ZooKeeper session expirations - <code>kaf_SessionExpireListener_ZooKeeperAuthFailuresPerSec</code> Rate of ZooKeeper authentication failures - <code>kaf_SessionExpireListener_ZooKeeperSyncConnectsPerSec</code> Rate of ZooKeeper connections - <code>kaf_SessionExpireListener_ZooKeeperDisconnectsPerSec</code> Rate of ZooKeeper disconnections -"},{"location":"metrics/kafka/zookeeper_metrics_mapping/#query-examples","title":"Query Examples","text":""},{"location":"metrics/kafka/zookeeper_metrics_mapping/#health-check-metrics","title":"Health Check Metrics","text":"<pre><code>// Alive connections\nzk_NumAliveConnections{rack='$rack',host_id=~'$host_id'}\n\n// Total znode count\nsum(zk_NodeCount{host_id=~'$host_id',type='kafka',node_type='zookeeper'})\n\n// Total watch count\nsum(zk_WatchCount{host_id=~'$host_id',type='kafka',node_type='zookeeper'})\n\n// Outstanding requests\nsum(zk_OutstandingRequests{host_id=~'$host_id',type='kafka',node_type='zookeeper'})\n</code></pre>"},{"location":"metrics/kafka/zookeeper_metrics_mapping/#request-latency","title":"Request Latency","text":"<pre><code>// Minimum request latency\nzk_MinRequestLatency{host_id=~'$host_id',type='kafka',node_type='zookeeper'}\n\n// Average request latency\nzk_AvgRequestLatency{host_id=~'$host_id',node_type='zookeeper',type='kafka'}\n\n// Maximum request latency\nzk_MaxRequestLatency{host_id=~'$host_id',node_type='zookeeper',type='kafka'}\n\n// Kafka-reported ZooKeeper latency\nkaf_ZooKeeperClientMetrics_ZooKeeperRequestLatencyMs{rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/zookeeper_metrics_mapping/#traffic-metrics","title":"Traffic Metrics","text":"<pre><code>// Packets sent rate\nsum(zk_PacketsSent{host_id=~'$host_id', axonfunction='rate', type='kafka',node_type='zookeeper'})\n\n// Packets received rate\nsum(zk_PacketsReceived{host_id=~'$host_id', axonfunction='rate', type='kafka',node_type='zookeeper'})\n\n// Znode creation rate\navg(zk_NodeCount{host_id=~'$host_id', axonfunction='rate',type='kafka',node_type='zookeeper'})\n</code></pre>"},{"location":"metrics/kafka/zookeeper_metrics_mapping/#connection-management","title":"Connection Management","text":"<pre><code>// Session expiration rate\nkaf_SessionExpireListener_ZooKeeperExpiresPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id'}\n\n// Authentication failure rate\nkaf_SessionExpireListener_ZooKeeperAuthFailuresPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id'}\n\n// Connection rate\nkaf_SessionExpireListener_ZooKeeperSyncConnectsPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id'}\n\n// Disconnection rate\nkaf_SessionExpireListener_ZooKeeperDisconnectsPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"metrics/kafka/zookeeper_metrics_mapping/#panel-organization","title":"Panel Organization","text":"<p>Overview Section</p> <ul> <li>Empty row for spacing/organization</li> </ul> <p>Health Check</p> <ul> <li>Alive Connections</li> <li>Outstanding Requests</li> <li>Number of Watchers</li> <li>Number of ZNodes</li> </ul> <p>Request Latency</p> <ul> <li>Packets (sent/received rates)</li> <li>Znode Creation Rate</li> <li>Request Latency - Minimum</li> <li>Request Latency - Average</li> <li>Request Latency - Maximum</li> <li>Kafka Reported Request Latency</li> </ul> <p>Connections</p> <ul> <li>Zookeeper expired connections per sec</li> <li>Zookeeper auth failures per sec</li> <li>Zookeeper disconnect per sec</li> <li>Zookeeper connections per sec</li> </ul>"},{"location":"metrics/kafka/zookeeper_metrics_mapping/#filters","title":"Filters","text":"<ul> <li> <p>host_id: Filter by specific ZooKeeper node</p> </li> <li> <p>rack: Filter by rack location</p> </li> </ul>"},{"location":"metrics/kafka/zookeeper_metrics_mapping/#best-practices","title":"Best Practices","text":"<p>Health Monitoring</p> <ul> <li>Monitor alive connections for capacity planning</li> <li>Outstanding requests should remain low</li> <li>High watch count may impact performance</li> <li>Monitor znode count growth</li> </ul> <p>Latency Analysis</p> <ul> <li>Average latency should be below tickTime</li> <li>High max latency indicates potential issues</li> <li>Compare ZK-reported vs Kafka-reported latency</li> </ul> <p>Connection Management</p> <ul> <li>Monitor session expirations for client issues</li> <li>Auth failures indicate security problems</li> <li>High disconnect rate suggests network issues</li> </ul> <p>Performance Tuning</p> <ul> <li>Adjust tickTime based on latency requirements</li> <li>Monitor packet rates for network saturation</li> <li>Balance connections across ensemble members</li> </ul> <p>Troubleshooting</p> <ul> <li>High outstanding requests: Check ZK performance</li> <li>Session expirations: Review session timeout settings</li> <li>Auth failures: Check SASL/ACL configurations</li> </ul> <p>Capacity Planning</p> <ul> <li>Monitor znode growth rate</li> <li>Track connection count trends</li> <li>Plan for watch count scaling</li> </ul> <p>ZooKeeper Ensemble Health</p> <ul> <li>Ensure all ensemble members are responsive</li> <li>Monitor for leader elections</li> <li>Check fsync latency on ZK data directory</li> </ul>"},{"location":"monitoring/overview/","title":"Monitoring Overview","text":"<p>When monitoring enterprise service there are 3 categories of how the service is performing that we generally capture and monitor. These are;</p> <ul> <li>Performance metrics</li> <li>Events (logs)</li> <li>Service availability</li> </ul>"},{"location":"monitoring/overview/#performance-metrics","title":"Performance Metrics","text":"<p>Performance metrics in Cassandra is highly extensive and there is a large number that can be captured to understand how Cassandra is performing. Another key metrics that also must be captured in order to effectively understand the performance of a database is the system resource utilisation.</p> <p>AxonOps agent captures both Cassandra and OS metrics and pushes them to the AxonOps server.</p>"},{"location":"monitoring/overview/#events","title":"Events","text":"<p>Cassandra event logs are, by default, written to log files. There are important information in the log files that allows SREs and DevOps engineers to identify issues when they occur. AxonOps agent captures the logs and pushes them to the AxonOps server. These logs are visible within AxonOps dashboard allowing quick access to them without having to log in to the individual servers.</p>"},{"location":"monitoring/overview/#service-availability","title":"Service Availability","text":"<p>Checking the momentary service availability and dashboards gives confidence that all services are running correctly as expected. Example service checks that allow engineers to gain confidence in the service availability are:</p> <ul> <li>System process</li> <li>Network open ports - e.g. CQL and storage ports</li> <li>Database availability - e.g. can execute CQL query</li> </ul>"},{"location":"monitoring/overview/#axonops-monitoring","title":"AxonOps Monitoring","text":"<p>AxonOps implements all three types of monitoring described above. AxonOps agent captures the information, sends them securely to AxonOps server, and the information is stored in the backend data store.</p> <p>AxonOps GUI provides comprehensive set of metrics dashboards combined with the event log view. It also provides separate service check status view showing the health of the cluster.</p> <p>This section describes how the AxonOps GUI organises the dashboards of all three types of monitoring.</p>"},{"location":"monitoring/grafana/grafana/","title":"Metrics in Grafana","text":""},{"location":"monitoring/grafana/grafana/#accessing-axonops-metrics-with-grafana","title":"Accessing AxonOps Metrics with Grafana","text":""},{"location":"monitoring/grafana/grafana/#generate-api-token","title":"Generate API Token","text":"<p>Generate an API token with read-only permission to the clusters you wish to access.</p> <ul> <li>Login to (https://console.axonops.com)[https://console.axonops.com]</li> <li> <p>Navigate in the left menu to API Tokens.</p> <p></p> </li> <li> <p>Click on Create New API Token button and complete the details.     </p> </li> </ul>"},{"location":"monitoring/grafana/grafana/#configure-grafana","title":"Configure Grafana","text":"<ul> <li>Configure a new Prometheus data source in Grafana</li> <li>Set the URL to https://dash.axonops.cloud/$ORGNAME </li> <li>Enable Basic auth. </li> <li>Paste the API key in the User field </li> <li>Click Save &amp; Test</li> </ul> <p>Now you should be able to browse and query the metrics from the Explore interface.</p> <p>See the video below: </p>"},{"location":"monitoring/logsandevents/logsandevents/","title":"Logs & Events","text":""},{"location":"monitoring/logsandevents/logsandevents/#logs-and-events","title":"Logs and Events","text":"<p>AxonOps provides a powerful logging feature that allows you to search and filter logs based on different parameters such as:</p> <ul> <li>DC/Rack/Node</li> <li>Log Level</li> <li>Event Type</li> <li>Source</li> <li>Log Content</li> </ul> <p>The logs and events are visible in two locations allowing quick access to them without having to login to the individual servers:</p> <ol> <li> <p>Within the Logs &amp; Events tab:</p> <p></p> </li> <li> <p>Within the AxonOps Dashboard by dragging the bottom handle icon up:</p> <p></p> </li> </ol>"},{"location":"monitoring/logsandevents/logsandevents/#search-by-log-level","title":"Search by Log Level","text":"<p>Filter logs based on their log levels to focus on specific severity levels. The log level indicates the importance or severity of a message from the most critical (ERROR) to less severe (DEBUG).</p> <p></p>"},{"location":"monitoring/logsandevents/logsandevents/#setting-up-the-debug-level","title":"Setting up the Debug Level","text":"<p>To search logs by DEBUG level you have to enable DEBUG logs in Cassandra by editing the <code>logback.xml</code> file:</p> <pre><code>&lt;appender name=\"SYSTEMLOG\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;\n    &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt;\n        &lt;level&gt;DEBUG&lt;/level&gt;\n</code></pre> <p>Note: Enabling DEBUG logs within Cassandra is not advised during normal operations and should only be activated for short periods of time on select nodes when debugging issues where INFO logs do not provide enough visibility.</p> <p>Leaving DEBUG logs on indefinitely can cause immense strain on the Cassandra process due to its high CPU usage.</p>"},{"location":"monitoring/logsandevents/logsandevents/#search-by-logs-source-and-event-type","title":"Search by Logs Source and Event Type","text":"<p>You can filter logs based on the log Source (<code>cassandra</code>, <code>axon-server</code>, and <code>axon-agent</code> logs) and Event Type to narrow down search results.</p> <p> </p>"},{"location":"monitoring/logsandevents/logsandevents/#search-by-content","title":"Search by Content","text":"<p>For free text search, enter a keyword in the Message field or use the <code>/&lt;expression&gt;/</code> syntax to search by regex expressions.</p>"},{"location":"monitoring/logsandevents/logsandevents/#example-search-terms","title":"Example Search Terms","text":"<p>Currently the following keyword syntax is supported:</p> <ul> <li><code>hello</code><ul> <li>matches <code>hello</code></li> </ul> </li> <li><code>hello world</code><ul> <li>matches <code>hello</code> or <code>world</code></li> </ul> </li> <li><code>\"hello world\"</code><ul> <li>matches exact <code>hello world</code></li> </ul> </li> <li><code>+-hello</code><ul> <li>matches excluding <code>hello</code></li> </ul> </li> <li><code>+-\"hello world\"</code><ul> <li>matches excluding <code>hello world</code></li> </ul> </li> <li><code>+-hello +-world</code><ul> <li>matches excluding <code>hello</code> or <code>world</code></li> </ul> </li> <li><code>/.*repair.*/</code><ul> <li>display logs that contain a specific word or phrase</li> </ul> </li> <li><code>/(Validated|Compacted)/</code><ul> <li>display logs that matches either what is before or after the <code>|</code>, in this case <code>Validated</code> or <code>Compacted</code></li> </ul> </li> <li><code>/Segment.*deleted/</code><ul> <li>display logs that contain both patterns in a line, in this case <code>Segment</code> and <code>deleted</code></li> </ul> </li> </ul>"},{"location":"monitoring/metricsdashboards/cassandra/","title":"Cassandra","text":"<p>AxonOps dashboards provides a comprehensive set of charts with an embedded view for logs and events. </p> <p>You can correlate metrics with logs/events as you can zoom in the logs histogram or metrics charts to drill down both results. </p> <p>Alert rules can be defined graphically in each chart and Log collection is  defined in the bottom part of that page.</p> <p>Infomy</p> <p></p>"},{"location":"monitoring/metricsdashboards/kafka/","title":"Kafka","text":"<p>AxonOps dashboards provides a comprehensive set of charts with an embedded view for logs and events. </p> <p>You can correlate metrics with logs/events as you can zoom in the logs histogram or metrics charts to drill down both results. </p> <p>Alert rules can be defined graphically in each chart and Log collection is  defined in the bottom part of that page.</p> <p>Infomy</p> <p></p>"},{"location":"monitoring/metricsdashboards/querysyntax/","title":"Query Syntax","text":""},{"location":"monitoring/metricsdashboards/querysyntax/#axonops-query-language-documentation","title":"AxonOps Query Language Documentation","text":"<p>AxonOps uses a powerful query language for dashboarding performance metrics collected from the AxonOps agent. This language is largely based on the Prometheus query language, allowing users familiar with Prometheus to quickly adapt to AxonOps. For a comprehensive guide on the Prometheus query language, please refer to the Prometheus Query Language documentation</p>"},{"location":"monitoring/metricsdashboards/querysyntax/#key-difference-in-axonops-query-language","title":"Key Difference in AxonOps Query Language","text":"<p>While most of the AxonOps query language is identical to Prometheus, there is a notable difference in the handling of the <code>rate</code> function, specifically for metrics of the \"Count\" type. AxonOps has implemented an optimized method for generating rate graphs for these metrics at the source in the agent. This method ensures accurate rated metrics, as well as faster query time for the rated metrics when compared to dynamically calculating at query time.</p>"},{"location":"monitoring/metricsdashboards/querysyntax/#querying-rated-metrics","title":"Querying Rated Metrics","text":"<p>To query rated metrics in AxonOps, you need to use a specific syntax that includes embedding the <code>axonfunction='rate'</code> label within the query. This informs the AxonOps agent to generate the rated values for the Count metrics data at source. The following is an example of how to structure such a query:</p>"},{"location":"monitoring/metricsdashboards/querysyntax/#example-query","title":"Example Query","text":"<pre><code>cas_ClientRequest_Latency{axonfunction='rate',scope='Write_*$consistency',function='Count',dc=~'$dc',rack=~'$rack',host_id=~'$host_id'}\n</code></pre>"},{"location":"monitoring/metricsdashboards/querysyntax/#explanation-of-the-query","title":"Explanation of the Query","text":"<ul> <li><code>cas_ClientRequest_Latency</code>: The specific metric being queried.</li> <li><code>{axonfunction='rate', ...}</code>: The label set that includes <code>axonfunction='rate'</code>, which instructs the AxonOps agent to generate the rated values.</li> <li><code>axonfunction='rate'</code>: This label indicates that the agent should compute rate values.</li> <li><code>scope='Write_*$consistency'</code>: A scope pattern that matches the relevant metrics.</li> <li><code>function='Count'</code>: Specifies that the metric type is Count.</li> <li><code>dc=~'$dc'</code>, <code>rack=~'$rack'</code>, <code>host_id=~'$host_id'</code>: Additional labels that allow filtering by data center, rack, and host ID using regular expressions.</li> </ul>"},{"location":"monitoring/metricsdashboards/querysyntax/#parameters","title":"Parameters","text":"<ul> <li><code>axonfunction='rate'</code>: Tells the AxonOps agent to generate rated values for Count metrics.</li> <li><code>scope</code>: A pattern for filtering the scope of the query.</li> <li><code>function</code>: Specifies the metric type, which should be \"Count\" for rated metrics.</li> <li><code>dc</code>: Filters metrics by data center.</li> <li><code>rack</code>: Filters metrics by rack.</li> <li><code>host_id</code>: Filters metrics by host ID.</li> </ul>"},{"location":"monitoring/metricsdashboards/querysyntax_kafka/","title":"Query Syntax","text":""},{"location":"monitoring/metricsdashboards/querysyntax_kafka/#axonops-query-language-documentation","title":"AxonOps Query Language Documentation","text":"<p>AxonOps uses a powerful query language for dashboarding performance metrics collected from the AxonOps agent. This language is largely based on the Prometheus query language, allowing users familiar with Prometheus to quickly adapt to AxonOps. For a comprehensive guide on the Prometheus query language, please refer to the Prometheus Query Language documentation</p>"},{"location":"monitoring/metricsdashboards/querysyntax_kafka/#key-difference-in-axonops-query-language","title":"Key Difference in AxonOps Query Language","text":"<p>While most of the AxonOps query language is identical to Prometheus, there is a notable difference in the handling of the <code>rate</code> function, specifically for metrics of the \"Count\" type. AxonOps has implemented an optimized method for generating rate graphs for these metrics at the source in the agent. This method ensures accurate rated metrics, as well as faster query time for the rated metrics when compared to dynamically calculating at query time.</p>"},{"location":"monitoring/metricsdashboards/querysyntax_kafka/#querying-rated-metrics","title":"Querying Rated Metrics","text":"<p>To query rated metrics in AxonOps, you need to use a specific syntax that includes embedding the <code>axonfunction='rate'</code> label within the query. This informs the AxonOps agent to generate the rated values for the Count metrics data at source. The following is an example of how to structure such a query:</p>"},{"location":"monitoring/metricsdashboards/querysyntax_kafka/#example-query","title":"Example Query","text":"<pre><code>sum(kaf_BrokerTopicMetrics_MessagesInPerSec{axonfunction='rate',rack=~'$rack',host_id=~'$host_id',topic=~'$topic'}) by (host_id)\n</code></pre>"},{"location":"monitoring/metricsdashboards/querysyntax_kafka/#explanation-of-the-query","title":"Explanation of the Query","text":"<ul> <li><code>sum()</code>: adds up the values returned by the metric </li> <li><code>kaf_BrokerTopicMetrics_MessagesInPerSec</code>: The specific metric being queried.</li> <li><code>{axonfunction='rate', ...}</code>: The curly braces set the includes for e.g. <code>axonfunction='rate'</code>, which instructs the AxonOps agent to generate the rated values.<ul> <li><code>axonfunction='rate'</code>: This label indicates that the agent should compute rate values.</li> <li><code>dc=~'$dc'</code>, <code>rack=~'$rack'</code>, <code>host_id=~'$host_id'</code>, <code>topic=~'$topic'</code>: Additional labels that allow filtering by data center, rack, host ID and topic using regular expressions.</li> </ul> </li> <li><code>by (host_id)</code>: groups the metric query by host_id. can be grouped by host\u2013id,topic,rack or dc.</li> </ul>"},{"location":"monitoring/metricsdashboards/querysyntax_kafka/#parameters","title":"Parameters","text":"<ul> <li><code>axonfunction='rate'</code>: Tells the AxonOps agent to generate rated values for Count metrics.</li> <li><code>dc</code>: Filters metrics by data center.</li> <li><code>rack</code>: Filters metrics by rack.</li> <li><code>host_id</code>: Filters metrics by host ID.</li> <li><code>topic</code>: A Topic Name</li> </ul>"},{"location":"monitoring/servicechecks/notifications/","title":"Notifications","text":"<p>Service checks will notify with one of the three statuses:</p> <p>Service Statuses.</p> <p>  Success</p> <p>  Warning</p> <p>  Error</p> <p>Depending on the status of the service an appropriate alert will be sent. The <code>alert</code> will be sent based on the <code>Default Routing</code> that has been setup via the integrations menu.</p> <p>Noticed: If the <code>Default Routing</code> has not been set up <code>no alerts</code> will be sent.</p> <p>Service Alerts will be sent using the following rules.</p>"},{"location":"monitoring/servicechecks/notifications/#info","title":"Info","text":"<p>Default routing rules will be used to send  success  alerts</p>"},{"location":"monitoring/servicechecks/notifications/#warning","title":"Warning","text":"<p>Default routing rules will be used to send   warning  alerts</p>"},{"location":"monitoring/servicechecks/notifications/#error","title":"Error","text":"<p>Default routing rules will be used to send  error  alerts</p>"},{"location":"monitoring/servicechecks/overview/","title":"Service Checks","text":""},{"location":"monitoring/servicechecks/overview/#overview","title":"Overview","text":"<p>Service Checks in AxonOps allows you to configure custom checks using three types of checks:</p> <ol> <li>Shell Scripts</li> <li>HTTP endpoint checks</li> <li>TCP endpoint checks</li> </ol> <p>The functionality is accessible via the Service Checks menu</p> <p>You can list the service checks by node: </p> <p>Or by services: </p> <p>You can click on a row within the node view to see all the <code>services</code> for that given Node. </p> <p>The following shows a successful check:</p> <p></p> <p>And a failing check:</p> <p></p>"},{"location":"monitoring/servicechecks/overview/#configure-service-checks","title":"Configure service checks","text":"<p>To set up the checks, go to Settings &gt; Service Checks and click one of the <code>+</code> buttons</p> <p></p> <p>Any changes made and saved are automatically pushed down to the agents. There is no need to deploy the check scripts to individual servers like you may do for instance with Nagios. The status will show once the check has been executed on the agent, so it might take some time depending on the interval you have specified within the Service Checks. Although the first execution of the checks will be spread across 30 seconds to prevent running all the checks at the same time.</p>"},{"location":"monitoring/servicechecks/overview/#service-checks-templating","title":"Service checks templating","text":"<p>You can provide templated checks with the following pattern: <code>{{.variable_name}}</code></p> <p></p> <p><code>{{.comp_listen_address}}</code> will be replace with Cassandra listen address.</p> <p>For instance, port <code>7000</code> in the previous example for check storage port could be replaced with {{.comp_storage_port}} on a Cassandra cluster:</p> <p>endpoint: <code>{{.comp_listen_address}}:{{.comp_storage_port}}</code> </p>"},{"location":"monitoring/servicechecks/overview/#cassandra-variables","title":"Cassandra variables","text":"<p>Here is the full list of variables that can be specified in any service check: </p><pre><code>agent_version\ncomp_PROPERTY_PREFIX\ncomp_SENSITIVE_KEYS\ncomp_allocate_tokens_for_keyspace\ncomp_authenticator\ncomp_authorizer\ncomp_auto_bootstrap\ncomp_auto_snapshot\ncomp_back_pressure_enabled\ncomp_back_pressure_strategy\ncomp_batch_size_fail_threshold_in_kb\ncomp_batch_size_warn_threshold_in_kb\ncomp_batchlog_replay_throttle_in_kb\ncomp_broadcast_address\ncomp_broadcast_rpc_address\ncomp_buffer_pool_use_heap_if_exhausted\ncomp_cas_contention_timeout_in_ms\ncomp_cdc_enabled\ncomp_cdc_free_space_check_interval_ms\ncomp_cdc_raw_directory\ncomp_cdc_total_space_in_mb\ncomp_client_encryption_options\ncomp_cluster_name\ncomp_column_index_cache_size_in_kb\ncomp_column_index_size_in_kb\ncomp_commit_failure_policy\ncomp_commitlog_compression\ncomp_commitlog_directory\ncomp_commitlog_max_compression_buffers_in_pool\ncomp_commitlog_periodic_queue_size\ncomp_commitlog_segment_size_in_mb\ncomp_commitlog_sync\ncomp_commitlog_sync_batch_window_in_ms\ncomp_commitlog_sync_period_in_ms\ncomp_commitlog_total_space_in_mb\ncomp_compaction_large_partition_warning_threshold_mb\ncomp_compaction_throughput_mb_per_sec\ncomp_concurrent_compactors\ncomp_concurrent_counter_writes\ncomp_concurrent_materialized_view_writes\ncomp_concurrent_reads\ncomp_concurrent_replicates\ncomp_concurrent_writes\ncomp_counter_cache_keys_to_save\ncomp_counter_cache_save_period\ncomp_counter_cache_size_in_mb\ncomp_counter_write_request_timeout_in_ms\ncomp_credentials_cache_max_entries\ncomp_credentials_update_interval_in_ms\ncomp_credentials_validity_in_ms\ncomp_cross_node_timeout\ncomp_data_file_directories\ncomp_dc\ncomp_disk_access_mode\ncomp_disk_failure_policy\ncomp_disk_optimization_estimate_percentile\ncomp_disk_optimization_page_cross_chance\ncomp_disk_optimization_strategy\ncomp_dynamic_snitch\ncomp_dynamic_snitch_badness_threshold\ncomp_dynamic_snitch_reset_interval_in_ms\ncomp_dynamic_snitch_update_interval_in_ms\ncomp_enable_materialized_views\ncomp_enable_scripted_user_defined_functions\ncomp_enable_user_defined_functions\ncomp_enable_user_defined_functions_threads\ncomp_encryption_options\ncomp_endpoint_snitch\ncomp_file_cache_round_up\ncomp_file_cache_size_in_mb\ncomp_gc_log_threshold_in_ms\ncomp_gc_warn_threshold_in_ms\ncomp_hinted_handoff_disabled_datacenters\ncomp_hinted_handoff_enabled\ncomp_hinted_handoff_throttle_in_kb\ncomp_hints_compression\ncomp_hints_directory\ncomp_hints_flush_period_in_ms\ncomp_hostId\ncomp_incremental_backups\ncomp_index_interval\ncomp_index_summary_capacity_in_mb\ncomp_index_summary_resize_interval_in_minutes\ncomp_initial_token\ncomp_inter_dc_stream_throughput_outbound_megabits_per_sec\ncomp_inter_dc_tcp_nodelay\ncomp_internode_authenticator\ncomp_internode_compression\ncomp_internode_recv_buff_size_in_bytes\ncomp_internode_send_buff_size_in_bytes\ncomp_isClientMode\ncomp_jvm_VM name\ncomp_jvm_VM vendor\ncomp_jvm_VM version\ncomp_jvm_awt.toolkit\ncomp_jvm_boot classpath\ncomp_jvm_cassandra-foreground\ncomp_jvm_cassandra.config\ncomp_jvm_cassandra.jmx.local.port\ncomp_jvm_cassandra.native.epoll.enabled\ncomp_jvm_com.sun.management.jmxremote.ssl\ncomp_jvm_file.encoding\ncomp_jvm_file.encoding.pkg\ncomp_jvm_file.separator\ncomp_jvm_gc_G1 Old Generation_collection count\ncomp_jvm_gc_G1 Old Generation_collection time\ncomp_jvm_gc_G1 Old Generation_memory pool names\ncomp_jvm_gc_G1 Young Generation_collection count\ncomp_jvm_gc_G1 Young Generation_collection time\ncomp_jvm_gc_G1 Young Generation_memory pool names\ncomp_jvm_heap_heapFreeSize\ncomp_jvm_heap_heapMaxSize\ncomp_jvm_heap_heapSize\ncomp_jvm_input arguments\ncomp_jvm_io.netty.native.workdir\ncomp_jvm_java.awt.graphicsenv\ncomp_jvm_java.awt.printerjob\ncomp_jvm_java.class.path\ncomp_jvm_java.class.version\ncomp_jvm_java.endorsed.dirs\ncomp_jvm_java.ext.dirs\ncomp_jvm_java.home\ncomp_jvm_java.io.tmpdir\ncomp_jvm_java.library.path\ncomp_jvm_java.rmi.server.hostname\ncomp_jvm_java.rmi.server.randomIDs\ncomp_jvm_java.runtime.name\ncomp_jvm_java.runtime.version\ncomp_jvm_java.specification.name\ncomp_jvm_java.specification.vendor\ncomp_jvm_java.specification.version\ncomp_jvm_java.util.logging.SimpleFormatter.format\ncomp_jvm_java.vendor\ncomp_jvm_java.vendor.url\ncomp_jvm_java.vendor.url.bug\ncomp_jvm_java.version\ncomp_jvm_java.vm.info\ncomp_jvm_java.vm.name\ncomp_jvm_java.vm.specification.name\ncomp_jvm_java.vm.specification.vendor\ncomp_jvm_java.vm.specification.version\ncomp_jvm_java.vm.vendor\ncomp_jvm_java.vm.version\ncomp_jvm_jna.loaded\ncomp_jvm_jna.platform.library.path\ncomp_jvm_jnidispatch.path\ncomp_jvm_library classpath\ncomp_jvm_line.separator\ncomp_jvm_log4j.configuration\ncomp_jvm_management spec version\ncomp_jvm_name\ncomp_jvm_os.arch\ncomp_jvm_os.name\ncomp_jvm_os.version\ncomp_jvm_path.separator\ncomp_jvm_spec name\ncomp_jvm_spec vendor\ncomp_jvm_start time\ncomp_jvm_sun.arch.data.model\ncomp_jvm_sun.boot.class.path\ncomp_jvm_sun.boot.library.path\ncomp_jvm_sun.cpu.endian\ncomp_jvm_sun.cpu.isalist\ncomp_jvm_sun.io.unicode.encoding\ncomp_jvm_sun.java.command\ncomp_jvm_sun.java.launcher\ncomp_jvm_sun.jnu.encoding\ncomp_jvm_sun.management.compiler\ncomp_jvm_sun.nio.ch.bugLevel\ncomp_jvm_sun.os.patch.level\ncomp_jvm_up time\ncomp_jvm_user.country\ncomp_jvm_user.dir\ncomp_jvm_user.home\ncomp_jvm_user.language\ncomp_jvm_user.name\ncomp_jvm_user.timezone\ncomp_jvm_user.variant\ncomp_key_cache_keys_to_save\ncomp_key_cache_save_period\ncomp_key_cache_size_in_mb\ncomp_listen_address\ncomp_listen_interface\ncomp_listen_interface_prefer_ipv6\ncomp_listen_on_broadcast_address\ncomp_logger\ncomp_max_file_descriptors\ncomp_max_hint_window_in_ms\ncomp_max_hints_delivery_threads\ncomp_max_hints_file_size_in_mb\ncomp_max_mutation_size_in_kb\ncomp_max_streaming_retries\ncomp_max_value_size_in_mb\ncomp_memtable_allocation_type\ncomp_memtable_cleanup_threshold\ncomp_memtable_flush_writers\ncomp_memtable_heap_space_in_mb\ncomp_memtable_offheap_space_in_mb\ncomp_min_free_space_per_drive_in_mb\ncomp_mode\ncomp_native_transport_max_concurrent_connections\ncomp_native_transport_max_concurrent_connections_per_ip\ncomp_native_transport_max_frame_size_in_mb\ncomp_native_transport_max_threads\ncomp_native_transport_port\ncomp_native_transport_port_ssl\ncomp_num_tokens\ncomp_open_file_descriptors\ncomp_otc_backlog_expiration_interval_ms\ncomp_otc_backlog_expiration_interval_ms_default\ncomp_otc_coalescing_enough_coalesced_messages\ncomp_otc_coalescing_strategy\ncomp_otc_coalescing_window_us\ncomp_otc_coalescing_window_us_default\ncomp_ownership\ncomp_partitioner\ncomp_permissions_cache_max_entries\ncomp_permissions_update_interval_in_ms\ncomp_permissions_validity_in_ms\ncomp_phi_convict_threshold\ncomp_prepared_statements_cache_size_mb\ncomp_rack\ncomp_range_request_timeout_in_ms\ncomp_read_request_timeout_in_ms\ncomp_releaseVersion\ncomp_request_scheduler\ncomp_request_scheduler_id\ncomp_request_scheduler_options\ncomp_request_timeout_in_ms\ncomp_role_manager\ncomp_roles_cache_max_entries\ncomp_roles_update_interval_in_ms\ncomp_roles_validity_in_ms\ncomp_row_cache_class_name\ncomp_row_cache_keys_to_save\ncomp_row_cache_save_period\ncomp_row_cache_size_in_mb\ncomp_rpc_address\ncomp_rpc_interface\ncomp_rpc_interface_prefer_ipv6\ncomp_rpc_keepalive\ncomp_rpc_listen_backlog\ncomp_rpc_max_threads\ncomp_rpc_min_threads\ncomp_rpc_port\ncomp_rpc_recv_buff_size_in_bytes\ncomp_rpc_send_buff_size_in_bytes\ncomp_rpc_server_type\ncomp_saved_caches_directory\ncomp_schemaVersion\ncomp_seed_provider\ncomp_server_encryption_options\ncomp_slow_query_log_timeout_in_ms\ncomp_snapshot_before_compaction\ncomp_ssl_storage_port\ncomp_sstable_preemptive_open_interval_in_mb\ncomp_start_native_transport\ncomp_start_rpc\ncomp_storage_port\ncomp_stream_throughput_outbound_megabits_per_sec\ncomp_streaming_keep_alive_period_in_secs\ncomp_streaming_socket_timeout_in_ms\ncomp_thrift_framed_transport_size_in_mb\ncomp_thrift_max_message_length_in_mb\ncomp_thrift_prepared_statements_cache_size_mb\ncomp_tombstone_failure_threshold\ncomp_tombstone_warn_threshold\ncomp_tracetype_query_ttl\ncomp_tracetype_repair_ttl\ncomp_transparent_data_encryption_options\ncomp_trickle_fsync\ncomp_trickle_fsync_interval_in_kb\ncomp_truncate_request_timeout_in_ms\ncomp_unlogged_batch_across_partitions_warn_threshold\ncomp_user_defined_function_fail_timeout\ncomp_user_defined_function_warn_timeout\ncomp_user_function_timeout_policy\ncomp_windows_timer_interval\ncomp_write_request_timeout_in_ms\nhost_BootTime\nhost_Ctxt\nhost_HostID\nhost_Hostname\nhost_KernelArch\nhost_KernelVersion\nhost_OS\nhost_Platform\nhost_PlatformFamily\nhost_PlatformVersion\nhost_Procs\nhost_ProcsBlocked\nhost_ProcsRunning\nhost_ProcsTotal\nhost_Uptime\nhost_VirtualizationRole\nhost_VirtualizationSystem\nhost_cpu_CPU\nhost_cpu_CacheSize\nhost_cpu_CoreID\nhost_cpu_Cores\nhost_cpu_Family\nhost_cpu_Flags\nhost_cpu_Mhz\nhost_cpu_Microcode\nhost_cpu_Model\nhost_cpu_ModelName\nhost_cpu_PhysicalID\nhost_cpu_Stepping\nhost_cpu_VendorID\nhost_disk_/_Free\nhost_disk_/_Total\nhost_disk_/_Used\nhost_disk_/_fstype\nhost_swapmem_Free\nhost_swapmem_PgFault\nhost_swapmem_PgIn\nhost_swapmem_PgMajFault\nhost_swapmem_PgOut\nhost_swapmem_Sin\nhost_swapmem_Sout\nhost_swapmem_Total\nhost_swapmem_Used\nhost_swapmem_UsedPercent\nhost_virtualmem_Active\nhost_virtualmem_Available\nhost_virtualmem_Buffers\nhost_virtualmem_Cached\nhost_virtualmem_CommitLimit\nhost_virtualmem_CommittedAS\nhost_virtualmem_Dirty\nhost_virtualmem_Free\nhost_virtualmem_HighFree\nhost_virtualmem_HighTotal\nhost_virtualmem_HugePageSize\nhost_virtualmem_HugePagesFree\nhost_virtualmem_HugePagesTotal\nhost_virtualmem_Inactive\nhost_virtualmem_Laundry\nhost_virtualmem_LowFree\nhost_virtualmem_LowTotal\nhost_virtualmem_Mapped\nhost_virtualmem_PageTables\nhost_virtualmem_SReclaimable\nhost_virtualmem_SUnreclaim\nhost_virtualmem_Shared\nhost_virtualmem_Slab\nhost_virtualmem_SwapCached\nhost_virtualmem_SwapFree\nhost_virtualmem_SwapTotal\nhost_virtualmem_Total\nhost_virtualmem_Used\nhost_virtualmem_UsedPercent\nhost_virtualmem_VMallocChunk\nhost_virtualmem_VMallocTotal\nhost_virtualmem_VMallocUsed\nhost_virtualmem_Wired\nhost_virtualmem_Writeback\nhost_virtualmem_WritebackTmp\nhuman_readable_identifier\nhuman_readable_identifier_field\n</code></pre>"},{"location":"operations/cassandra/backup/aws_s3/","title":"AWS S3","text":""},{"location":"operations/cassandra/backup/aws_s3/#what-is-s3","title":"What is S3","text":"<p>Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance. Read more at Amazon S3</p> <p>When selecting AWS S3 as a remote option there are a few fields that are mandatory the rest are optional.</p> <p>S3 allows any valid UTF-8 string as a key.</p> <p></p>"},{"location":"operations/cassandra/backup/aws_s3/#remote-backup-retention","title":"Remote Backup Retention","text":"<p>The amount of days that backup files will be kept in the remote storage provider location.  After this amount of days the file that are older will be removed.</p>"},{"location":"operations/cassandra/backup/aws_s3/#base-remote-path","title":"Base Remote Path","text":"<p>This is the name of the storage buckets, you can also add subfolders if using shared storage buckets or saving multiple clusters to the same bucket. by default AxonOps will save the backups to /bucket/folder/org/clustertype/clustername/host-id/</p> <p>The org/clustertype/clustername/host-id/ will match the top breadcrump navigation in your AxonOps Dashboard.</p>"},{"location":"operations/cassandra/backup/aws_s3/#region","title":"Region","text":"<p>This is a drop down selection of all the AWS regions that are available for your AWS account.</p>"},{"location":"operations/cassandra/backup/aws_s3/#authentication-methods","title":"Authentication Methods","text":"<p>IAM Role (Recommended)</p> <p>The recommended approach is to use IAM roles attached to your EC2 instances. This method is more secure as it doesn't require storing credentials:</p> <ol> <li>Create an IAM role with the necessary S3 permissions (see policy below)</li> <li>Attach the role to your EC2 instances running Cassandra</li> <li>Leave the Access Key ID and Secret Access Key fields empty in AxonOps</li> <li>AxonOps will automatically use the instance's IAM role credentials</li> </ol> <p>This approach provides: * No credential management or rotation needed * More secure - no long-lived access keys * Automatic credential refresh * Follows AWS security best practices</p> <p>Access Key ID and Secret Access Key (Alternative)</p> <p>If IAM roles are not available (e.g., on-premises installations), you can use explicit credentials: * This is the standard AWS Access and Secret key that are associated with an IAM user * These credentials should be protected and rotated regularly * Only use this method when IAM roles are not an option</p>"},{"location":"operations/cassandra/backup/aws_s3/#required-iam-permissions","title":"Required IAM Permissions","text":"<p>Whether using IAM roles or user credentials, the following permissions are needed for accessing the S3 buckets:</p> <p>For IAM roles, use this policy (attach to the role, not the bucket):</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"AxonOpsBackupPermissions\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:ListBucket\",\n        \"s3:GetBucketLocation\",\n        \"s3:DeleteObject\",\n        \"s3:GetObject\",\n        \"s3:PutObject\",\n        \"s3:PutObjectAcl\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::&lt;BUCKETNAME&gt;\",\n        \"arn:aws:s3:::&lt;BUCKETNAME&gt;/*\"\n      ]\n    }\n  ]\n}\n</code></pre> <p>Replace <code>&lt;BUCKETNAME&gt;</code> with your actual bucket name. For bucket naming rules, see AWS documentation.</p> <p>For cross-account access or when using IAM users, you may need to configure a bucket policy as well.</p>"},{"location":"operations/cassandra/backup/aws_s3/#storage-class","title":"Storage Class","text":"<p>Amazon S3 offers a range of storage classes that you can choose from based on the performance, data access, resiliency, and cost requirements of your workloads. S3 storage classes are purpose-built to provide the lowest cost storage for different access patterns.</p> <p>Please pick from the available AWS Storage classes:</p> <ul> <li>Glacier</li> <li>Glacier Deep Archive</li> <li>Intelligent-Tiering</li> <li>One Zone Infrequent Access</li> <li>Reduced Redundancy</li> <li>Standard</li> <li>Stadard Infrequent Access</li> </ul> <p>For more inforamtion on S3 Storage classes please go here</p>"},{"location":"operations/cassandra/backup/aws_s3/#acl","title":"ACL","text":"<p>Amazon S3 access control lists (ACLs) enable you to manage access to buckets and objects. Each bucket and object has an ACL attached to it as a subresource. It defines which AWS accounts or groups are granted access and the type of access. When a request is received against a resource, Amazon S3 checks the corresponding ACL to verify that the requester has the necessary access permissions.</p> <p>Please pick from the available AWS ACL's:</p> <ul> <li>Private</li> <li>Public Read</li> <li>Public Read-Write</li> <li>Authenticated Read</li> <li>Bucket Owner Read</li> <li>Bucket Owner Full Control</li> </ul> <p>For more inforamtion on S3 ACL's please go here</p>"},{"location":"operations/cassandra/backup/aws_s3/#server-side-encryption","title":"Server Side Encryption","text":"<p>The server-side encryption algorithm used when storing this object in S3.</p>"},{"location":"operations/cassandra/backup/aws_s3/#disable-checksum","title":"Disable Checksum","text":"<p>Normally AxonOps Backups will check that the checksums of transferred files match, and give an error \"corrupted on transfer\" if they don't. If you disable this then the checksum will be ignored if there are differences. This is not advised. </p>"},{"location":"operations/cassandra/backup/azure_blob/","title":"Azure Blob Storage","text":""},{"location":"operations/cassandra/backup/azure_blob/#what-is-azure-blob-storage","title":"What is Azure Blob Storage","text":"<p>Azure Blob Storage is Microsoft's object storage solution for the cloud. Blob storage is optimized for storing massive amounts of unstructured data, such as text or binary data. Azure Blob Storage is ideal for serving images or documents, storing files for distributed access, streaming video and audio, storing data for backup and restore, disaster recovery, and archiving. Read more at Azure Blob Storage documentation</p> <p>When selecting Azure Blob Storage as a remote option there are several fields that need to be configured.</p> <p></p>"},{"location":"operations/cassandra/backup/azure_blob/#remote-backup-retention","title":"Remote Backup Retention","text":"<p>The amount of days that backup files will be kept in the remote storage provider location.  After this amount of days the files that are older will be removed.</p>"},{"location":"operations/cassandra/backup/azure_blob/#base-remote-path","title":"Base Remote Path","text":"<p>This is the name of the container, you can also add subfolders if using shared containers or saving multiple clusters to the same container. By default AxonOps will save the backups to <code>/container/folder/org/clustertype/clustername/host-id/</code></p> <p>The org/clustertype/clustername/host-id/ will match the top breadcrumb navigation in your AxonOps Dashboard.</p> <p>Note: Azure container names must be lowercase and follow specific naming rules. See Azure naming conventions</p>"},{"location":"operations/cassandra/backup/azure_blob/#storage-account-name","title":"Storage Account Name","text":"<p>The name of your Azure Storage account. This is a globally unique name that identifies your storage account. It must be between 3 and 24 characters, containing only lowercase letters and numbers.</p>"},{"location":"operations/cassandra/backup/azure_blob/#authentication-method","title":"Authentication Method","text":"<p>AxonOps supports multiple authentication methods for Azure Blob Storage:</p> <p>Managed Identity (Recommended)</p> <p>The recommended approach is to use Azure Managed Identities for your Azure VMs. This method is more secure as it doesn't require storing credentials:</p> <ol> <li>Enable system-assigned or user-assigned managed identity on your Azure VMs</li> <li>Grant the managed identity appropriate permissions on the storage account (see RBAC section below)</li> <li>Leave all authentication fields empty in AxonOps</li> <li>AxonOps will automatically use the VM's managed identity</li> </ol> <p>This approach provides: * No credential management or rotation needed * More secure - no keys or secrets to protect * Automatic token refresh * Follows Azure security best practices * Works with both system and user-assigned identities</p> <p>Storage Account Key (Alternative) * Uses the primary or secondary key from your storage account * Only use when managed identities are not available (e.g., on-premises) * Found in Azure Portal &gt; Storage Account &gt; Access Keys * Full access to the storage account</p> <p>Shared Access Signature (SAS) * Provides limited access with specific permissions * Time-bound access tokens * Good for temporary or restricted access</p> <p>Azure Active Directory (OAuth) * Uses Azure AD service principals * Suitable when managed identities cannot be used * Requires app registration and secret management</p>"},{"location":"operations/cassandra/backup/azure_blob/#required-permissions-rbac","title":"Required Permissions (RBAC)","text":"<p>When using Managed Identity, assign one of these roles to the identity: * Storage Blob Data Contributor - Recommended for backup operations * Storage Blob Data Owner - If you need full control * Or create a custom role with these permissions:   - <code>Microsoft.Storage/storageAccounts/blobServices/containers/read</code>   - <code>Microsoft.Storage/storageAccounts/blobServices/containers/write</code>   - <code>Microsoft.Storage/storageAccounts/blobServices/containers/blobs/read</code>   - <code>Microsoft.Storage/storageAccounts/blobServices/containers/blobs/write</code>   - <code>Microsoft.Storage/storageAccounts/blobServices/containers/blobs/delete</code></p> <p>To assign the role: 1. Go to your Storage Account in Azure Portal 2. Select \"Access Control (IAM)\" 3. Click \"Add role assignment\" 4. Select the appropriate role 5. Assign to your VM's managed identity</p>"},{"location":"operations/cassandra/backup/azure_blob/#storage-account-key","title":"Storage Account Key","text":"<p>When using key authentication (not recommended), provide either the primary or secondary key from your storage account. These keys provide full access to your storage account and should be protected accordingly.</p> <p>To find your keys: 1. Navigate to your storage account in the Azure Portal 2. Select \"Access keys\" under Security + networking 3. Copy either key1 or key2</p>"},{"location":"operations/cassandra/backup/azure_blob/#sas-token","title":"SAS Token","text":"<p>When using SAS authentication, provide a SAS token with appropriate permissions. The token should have at least: * Read permission * Write permission * Delete permission * List permission</p> <p>Example SAS token format: </p><pre><code>?sv=2020-08-04&amp;ss=b&amp;srt=sco&amp;sp=rwdlacx&amp;se=2024-12-31T23:59:59Z&amp;st=2023-01-01T00:00:00Z&amp;spr=https&amp;sig=...\n</code></pre>"},{"location":"operations/cassandra/backup/azure_blob/#access-tier","title":"Access Tier","text":"<p>Azure Blob Storage offers different access tiers optimized for different data access patterns:</p> <ul> <li>Hot: For frequently accessed data</li> <li>Highest storage costs, lowest access costs</li> <li> <p>Best for active backups</p> </li> <li> <p>Cool: For infrequently accessed data (30+ days)</p> </li> <li>Lower storage costs, higher access costs</li> <li> <p>Good for recent backups</p> </li> <li> <p>Archive: For rarely accessed data (180+ days)</p> </li> <li>Lowest storage costs, highest access costs</li> <li>Requires rehydration before access</li> <li>Best for compliance/long-term storage</li> </ul> <p>For backup scenarios: * Use Hot tier for the most recent backups * Use Cool tier for backups older than 30 days * Use Archive tier for long-term retention</p>"},{"location":"operations/cassandra/backup/azure_blob/#blob-type","title":"Blob Type","text":"<p>Azure supports different blob types: * Block Blobs: Optimized for upload of large amounts of data (recommended for backups) * Page Blobs: Optimized for random read/write operations * Append Blobs: Optimized for append operations</p> <p>For Cassandra backups, Block Blobs are recommended.</p>"},{"location":"operations/cassandra/backup/azure_blob/#redundancy-options","title":"Redundancy Options","text":"<p>While not directly configured in AxonOps, your storage account's redundancy affects availability: * LRS (Locally Redundant Storage): 3 copies in one region * ZRS (Zone Redundant Storage): 3 copies across availability zones * GRS (Geo-Redundant Storage): 6 copies across two regions * GZRS (Geo-Zone Redundant Storage): Combines ZRS and GRS</p>"},{"location":"operations/cassandra/backup/azure_blob/#encryption","title":"Encryption","text":"<p>Azure provides several encryption options: * Microsoft-managed keys: Default encryption (automatic) * Customer-managed keys: Use your own keys via Azure Key Vault * Infrastructure encryption: Double encryption at rest</p>"},{"location":"operations/cassandra/backup/azure_blob/#network-configuration","title":"Network Configuration","text":"<p>Ensure your Azure Storage account allows connections from AxonOps: * Public endpoint: Accessible from anywhere (check firewall rules) * Private endpoint: Requires VNet connectivity * Service endpoints: Restricts access to specific VNets</p>"},{"location":"operations/cassandra/backup/azure_blob/#disable-checksum","title":"Disable Checksum","text":"<p>Normally AxonOps Backups will check that the checksums of transferred files match, and give an error \"corrupted on transfer\" if they don't. If you disable this then the checksum will be ignored if there are differences. This is not advised.</p>"},{"location":"operations/cassandra/backup/azure_blob/#best-practices","title":"Best Practices","text":"<ol> <li>Use SAS Tokens: Prefer SAS tokens over account keys for better security</li> <li>Enable Soft Delete: Protect against accidental deletion</li> <li>Set Lifecycle Policies: Automatically move old backups to cooler tiers</li> <li>Monitor Costs: Use Azure Cost Management to track storage expenses</li> <li>Enable Logging: Use Azure Storage Analytics for audit trails</li> </ol>"},{"location":"operations/cassandra/backup/azure_blob/#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Use Premium Storage: For performance-critical restore operations</li> <li>Enable Large File Shares: For better throughput</li> <li>Optimize Block Size: Larger blocks for large files</li> <li>Parallel Uploads: Configure appropriate parallelism</li> <li>CDN Integration: For geo-distributed restore needs</li> </ol>"},{"location":"operations/cassandra/backup/azure_blob/#cost-management","title":"Cost Management","text":"<ol> <li>Reserved Capacity: Purchase reserved storage for predictable workloads</li> <li>Lifecycle Management: Auto-transition to cheaper tiers</li> <li>Regional Selection: Choose regions with lower costs</li> <li>Monitor Transactions: Each operation incurs a small cost</li> <li>Cleanup Old Backups: Remove unnecessary backups</li> </ol>"},{"location":"operations/cassandra/backup/azure_blob/#troubleshooting","title":"Troubleshooting","text":"<ol> <li>Authentication Failed: Verify account name and key/SAS token</li> <li>Container Not Found: Check container name (must be lowercase)</li> <li>Access Denied: Verify SAS permissions or firewall rules</li> <li>Throttling: Check storage account limits and scale if needed</li> <li>Network Errors: Verify connectivity and firewall settings</li> </ol>"},{"location":"operations/cassandra/backup/azure_blob_storage/","title":"Azure Blob Storage","text":""},{"location":"operations/cassandra/backup/gcs/","title":"Google Cloud Storage","text":""},{"location":"operations/cassandra/backup/gcs/#what-is-google-cloud-storage","title":"What is Google Cloud Storage","text":"<p>Google Cloud Storage (GCS) is a RESTful online file storage web service for storing and accessing data on Google Cloud Platform infrastructure. It provides unified object storage for developers and enterprises, from live data serving to data analytics/ML to data archiving. Read more at Google Cloud Storage documentation</p> <p>When selecting Google Cloud Storage as a remote option there are several fields that need to be configured.</p> <p></p>"},{"location":"operations/cassandra/backup/gcs/#remote-backup-retention","title":"Remote Backup Retention","text":"<p>The amount of days that backup files will be kept in the remote storage provider location.  After this amount of days the files that are older will be removed.</p>"},{"location":"operations/cassandra/backup/gcs/#base-remote-path","title":"Base Remote Path","text":"<p>This is the name of the GCS bucket, you can also add subfolders if using shared storage buckets or saving multiple clusters to the same bucket. By default AxonOps will save the backups to <code>/bucket/folder/org/clustertype/clustername/host-id/</code></p> <p>The org/clustertype/clustername/host-id/ will match the top breadcrumb navigation in your AxonOps Dashboard.</p>"},{"location":"operations/cassandra/backup/gcs/#project-id","title":"Project ID","text":"<p>Your Google Cloud Project ID. This is a unique identifier for your GCP project and can be found in the GCP Console. It typically looks like <code>my-project-123456</code>.</p>"},{"location":"operations/cassandra/backup/gcs/#authentication","title":"Authentication","text":"<p>AxonOps supports multiple authentication methods for Google Cloud Storage:</p> <p>VM Instance Service Account (Recommended)</p> <p>The recommended approach is to use the service account attached to your GCE instances. This method is more secure as it doesn't require storing credentials:</p> <ol> <li>Create a service account with the necessary GCS permissions (see IAM section below)</li> <li>Attach the service account to your GCE instances running Cassandra</li> <li>Leave the Service Account Key field empty in AxonOps</li> <li>AxonOps will automatically use the instance's service account credentials</li> </ol> <p>This approach provides: * No credential management or key rotation needed * More secure - no long-lived keys to protect * Automatic credential refresh * Follows GCP security best practices * Works with Workload Identity for GKE deployments</p> <p>Service Account Key (Alternative) * Uses a JSON key file for authentication * Only use when instance service accounts are not available (e.g., on-premises) * Requires secure key storage and rotation * Allows fine-grained permissions through IAM</p> <p>OAuth2 Token * Uses OAuth2 access tokens * Suitable for development or temporary access * Requires token refresh management</p>"},{"location":"operations/cassandra/backup/gcs/#service-account-configuration","title":"Service Account Configuration","text":"<p>When using explicit service account keys (not recommended), provide the JSON key file contents. </p> <p>Required Permissions</p> <p>Whether using instance service accounts or explicit keys, the service account needs these permissions: * <code>storage.buckets.get</code> * <code>storage.objects.create</code> * <code>storage.objects.delete</code> * <code>storage.objects.get</code> * <code>storage.objects.list</code></p> <p>You can grant these permissions by: 1. Using the predefined role <code>roles/storage.objectAdmin</code> on the specific bucket 2. Creating a custom role with only these permissions 3. Using <code>roles/storage.legacyBucketWriter</code> and <code>roles/storage.objectViewer</code> combined</p> <p>Example service account key structure: </p><pre><code>{\n  \"type\": \"service_account\",\n  \"project_id\": \"your-project-id\",\n  \"private_key_id\": \"key-id\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n...\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"service-account@project.iam.gserviceaccount.com\",\n  \"client_id\": \"123456789\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/...\"\n}\n</code></pre>"},{"location":"operations/cassandra/backup/gcs/#location","title":"Location","text":"<p>The location where your bucket is stored. Google Cloud Storage offers several location types: * Regional: Data stored in a specific region (e.g., <code>us-central1</code>, <code>europe-west1</code>) * Multi-regional: Data replicated across regions (e.g., <code>us</code>, <code>eu</code>, <code>asia</code>) * Dual-regional: Data replicated across two specific regions</p> <p>Choose based on your latency, availability, and compliance requirements.</p>"},{"location":"operations/cassandra/backup/gcs/#storage-class","title":"Storage Class","text":"<p>Google Cloud Storage offers different storage classes optimized for different use cases:</p> <ul> <li>Standard: Best for frequently accessed data (\"hot\" data)</li> <li>Nearline: For data accessed once per month</li> <li>Coldline: For data accessed once per quarter</li> <li>Archive: For data accessed less than once per year</li> </ul> <p>For backups, consider: * Use Standard for recent backups that might need quick access * Use Nearline or Coldline for older backups * Use Archive for long-term compliance storage</p>"},{"location":"operations/cassandra/backup/gcs/#encryption","title":"Encryption","text":"<p>GCS provides several encryption options: * Google-managed keys: Default encryption (no configuration needed) * Customer-managed keys (CMEK): Use your own keys via Cloud KMS * Customer-supplied keys (CSEK): Provide your own encryption keys</p>"},{"location":"operations/cassandra/backup/gcs/#object-lifecycle-management","title":"Object Lifecycle Management","text":"<p>While not directly configured in AxonOps, you can set up lifecycle rules in GCS to: * Automatically transition objects to cheaper storage classes * Delete objects older than the retention period * Manage versions of objects</p>"},{"location":"operations/cassandra/backup/gcs/#uniform-bucket-level-access","title":"Uniform Bucket-Level Access","text":"<p>Recommended security setting that disables object ACLs and uses only IAM for access control. Enable this in your GCS bucket settings for better security.</p>"},{"location":"operations/cassandra/backup/gcs/#versioning","title":"Versioning","text":"<p>Object versioning can be enabled on the bucket to: * Protect against accidental deletion * Maintain backup history * Support point-in-time recovery</p>"},{"location":"operations/cassandra/backup/gcs/#disable-checksum","title":"Disable Checksum","text":"<p>Normally AxonOps Backups will check that the checksums of transferred files match, and give an error \"corrupted on transfer\" if they don't. If you disable this then the checksum will be ignored if there are differences. This is not advised.</p>"},{"location":"operations/cassandra/backup/gcs/#iam-best-practices","title":"IAM Best Practices","text":"<ol> <li>Use Service Accounts: Create a dedicated service account for AxonOps</li> <li>Principle of Least Privilege: Grant only the minimum required permissions</li> <li>Bucket-Level Permissions: Apply IAM policies at the bucket level when possible</li> <li>Audit Logging: Enable Cloud Audit Logs for backup operations</li> <li>Key Rotation: Regularly rotate service account keys</li> </ol>"},{"location":"operations/cassandra/backup/gcs/#cost-optimization","title":"Cost Optimization","text":"<ol> <li>Choose Appropriate Storage Class: Match storage class to access patterns</li> <li>Set Lifecycle Policies: Automatically transition to cheaper storage</li> <li>Regional Selection: Choose regions close to your Cassandra clusters</li> <li>Monitor Egress Costs: Be aware of cross-region transfer costs</li> <li>Enable Bucket Lock: For compliance requirements, preventing early deletion</li> </ol>"},{"location":"operations/cassandra/backup/gcs/#troubleshooting","title":"Troubleshooting","text":"<ol> <li>Permission Denied: Check IAM permissions and service account key</li> <li>Bucket Not Found: Verify project ID and bucket name</li> <li>Invalid Key: Ensure the JSON key is properly formatted</li> <li>Network Timeouts: Check firewall rules and GCP connectivity</li> <li>Storage Class Errors: Verify the storage class is available in your region</li> </ol>"},{"location":"operations/cassandra/backup/generic_s3/","title":"Generic S3","text":""},{"location":"operations/cassandra/backup/generic_s3/#what-is-generic-s3","title":"What is Generic S3","text":"<p>Generic S3 (S3 Compatible) storage refers to object storage services that implement the Amazon S3 API but are not provided by AWS. Many cloud providers and storage solutions offer S3-compatible APIs, including MinIO, Ceph, DigitalOcean Spaces, Wasabi, Backblaze B2, and many others. This allows you to use the same S3 protocol with different storage providers.</p> <p>When selecting Generic S3 as a remote option there are several fields that need to be configured.</p> <p></p>"},{"location":"operations/cassandra/backup/generic_s3/#remote-backup-retention","title":"Remote Backup Retention","text":"<p>The amount of days that backup files will be kept in the remote storage provider location.  After this amount of days the files that are older will be removed.</p>"},{"location":"operations/cassandra/backup/generic_s3/#base-remote-path","title":"Base Remote Path","text":"<p>This is the name of the storage bucket, you can also add subfolders if using shared storage buckets or saving multiple clusters to the same bucket. By default AxonOps will save the backups to <code>/bucket/folder/org/clustertype/clustername/host-id/</code></p> <p>The org/clustertype/clustername/host-id/ will match the top breadcrumb navigation in your AxonOps Dashboard.</p>"},{"location":"operations/cassandra/backup/generic_s3/#endpoint-url","title":"Endpoint URL","text":"<p>The endpoint URL for your S3-compatible storage service. This varies by provider: * MinIO: <code>https://play.min.io</code> or your self-hosted URL * DigitalOcean Spaces: <code>https://{region}.digitaloceanspaces.com</code> * Wasabi: <code>https://s3.{region}.wasabisys.com</code> * Backblaze B2: <code>https://s3.{region}.backblazeb2.com</code> * Ceph: Your Ceph RadosGW endpoint</p>"},{"location":"operations/cassandra/backup/generic_s3/#region","title":"Region","text":"<p>The region where your S3-compatible storage is located. Some providers use AWS-style regions (us-east-1, eu-west-1), while others may use their own region naming conventions. Check your provider's documentation for the correct region identifier.</p>"},{"location":"operations/cassandra/backup/generic_s3/#access-key-id-and-secret-access-key","title":"Access Key ID and Secret Access Key","text":"<p>These are the credentials provided by your S3-compatible storage provider: * Access Key ID: The public identifier for your storage account * Secret Access Key: The private key used to sign requests</p> <p>These credentials should have the following permissions on the bucket: * ListBucket * GetObject * PutObject * DeleteObject * GetBucketLocation</p>"},{"location":"operations/cassandra/backup/generic_s3/#path-style-access","title":"Path Style Access","text":"<p>S3-compatible storage services support two URL styles: * Virtual-hosted style: <code>https://bucket.endpoint.com/object</code> (default for AWS S3) * Path style: <code>https://endpoint.com/bucket/object</code></p> <p>Enable path style access if your provider requires it. Many S3-compatible services like MinIO require path style access.</p>"},{"location":"operations/cassandra/backup/generic_s3/#ssltls-settings","title":"SSL/TLS Settings","text":"<p>Configure the SSL/TLS settings for secure connections: * Use SSL: Enable HTTPS connections (recommended) * Verify SSL Certificate: Validate the server's SSL certificate * Skip SSL Verification: Only use for testing or self-signed certificates (not recommended for production)</p>"},{"location":"operations/cassandra/backup/generic_s3/#storage-class","title":"Storage Class","text":"<p>While S3-compatible services may support storage classes, the available options vary by provider: * Standard (most common) * Provider-specific classes (check your provider's documentation)</p> <p>If unsure, leave this as \"Standard\" or consult your storage provider's documentation.</p>"},{"location":"operations/cassandra/backup/generic_s3/#acl-access-control-list","title":"ACL (Access Control List)","text":"<p>The access control settings for uploaded objects. Common options include: * Private: Only the bucket owner can access (recommended) * Public Read: Anyone can read the objects * Authenticated Read: Authenticated users can read</p> <p>Most S3-compatible services support standard S3 ACLs, but check your provider's documentation for specifics.</p>"},{"location":"operations/cassandra/backup/generic_s3/#chunk-size","title":"Chunk Size","text":"<p>The size of chunks used for multipart uploads (in MB). Larger chunks can improve performance for large files but use more memory. Typical values: * Minimum: 5 MB * Default: 8 MB * Maximum: Varies by provider (often 5 GB)</p>"},{"location":"operations/cassandra/backup/generic_s3/#connection-settings","title":"Connection Settings","text":"<ul> <li>Connection Timeout: Time to wait for initial connection (seconds)</li> <li>Read Timeout: Time to wait for data during transfers (seconds)</li> <li>Max Retries: Number of retry attempts for failed operations</li> </ul>"},{"location":"operations/cassandra/backup/generic_s3/#disable-checksum","title":"Disable Checksum","text":"<p>Normally AxonOps Backups will check that the checksums of transferred files match, and give an error \"corrupted on transfer\" if they don't. If you disable this then the checksum will be ignored if there are differences. This is not advised.</p>"},{"location":"operations/cassandra/backup/generic_s3/#provider-specific-notes","title":"Provider-Specific Notes","text":"<p>MinIO * Requires path style access * Default port is 9000 for self-hosted instances * Supports all standard S3 operations</p> <p>DigitalOcean Spaces * Uses virtual-hosted style URLs * Regions: nyc3, sfo2, sfo3, ams3, sgp1, fra1 * Supports most S3 operations</p> <p>Wasabi * No egress fees * Supports virtual-hosted style * Minimum storage duration of 90 days</p> <p>Backblaze B2 * Requires application keys (not master keys) * Limited to 1000 buckets per account * Supports S3 API through specific endpoints</p>"},{"location":"operations/cassandra/backup/generic_s3/#troubleshooting","title":"Troubleshooting","text":"<ol> <li>Connection Refused: Check endpoint URL and port</li> <li>Access Denied: Verify access keys and bucket permissions</li> <li>Invalid Region: Confirm the region matches your provider's requirements</li> <li>SSL Errors: May need to disable certificate verification for self-signed certs</li> <li>Signature Errors: Ensure clock synchronization between AxonOps and storage service</li> </ol>"},{"location":"operations/cassandra/backup/google_cloud_storage/","title":"Google Cloud Storage","text":""},{"location":"operations/cassandra/backup/local_filesystem/","title":"Local File System","text":""},{"location":"operations/cassandra/backup/local_storage/","title":"Local Storage","text":""},{"location":"operations/cassandra/backup/local_storage/#what-is-local-storage","title":"What is Local Storage","text":"<p>Local Storage in the context of AxonOps remote backups refers to any file system path that is accessible from the Cassandra nodes. This could be a locally attached disk, a network-attached storage (NAS) mount, a SAN volume, or any other file system that appears as a local path to the operating system. This option is useful when you have dedicated backup infrastructure that is mounted on your Cassandra nodes.</p> <p>When selecting Local Storage as a remote option, configuration is straightforward with minimal fields required.</p> <p></p>"},{"location":"operations/cassandra/backup/local_storage/#remote-backup-retention","title":"Remote Backup Retention","text":"<p>The amount of days that backup files will be kept in the remote storage provider location.  After this amount of days the files that are older will be removed.</p>"},{"location":"operations/cassandra/backup/local_storage/#base-remote-path","title":"Base Remote Path","text":"<p>This is the absolute file system path where backups will be stored. The path must: * Be an absolute path (starting with <code>/</code> on Linux/Unix or drive letter on Windows) * Be accessible and writable by the AxonOps agent user * Have sufficient disk space for storing backups * Be a valid mounted file system</p> <p>Examples: * <code>/mnt/backups/cassandra</code> * <code>/backup/nfs/cassandra-cluster</code> * <code>/data/backup/production</code> * <code>D:\\Backups\\Cassandra</code> (Windows)</p> <p>By default, AxonOps will create subdirectories under this path following the pattern: <code>/base/path/org/clustertype/clustername/host-id/</code></p> <p>The org/clustertype/clustername/host-id/ will match the top breadcrumb navigation in your AxonOps Dashboard.</p>"},{"location":"operations/cassandra/backup/local_storage/#common-use-cases","title":"Common Use Cases","text":"<p>Network Attached Storage (NAS) * Mount NFS, SMB/CIFS, or other network shares * Centralized backup storage across multiple nodes * Example: <code>/mnt/nas/cassandra-backups</code></p> <p>Storage Area Network (SAN) * High-performance block storage * Often used in enterprise environments * Example: <code>/san/backup/cassandra</code></p> <p>Dedicated Backup Volumes * Separate disk or volume for backups * Isolates backup I/O from database operations * Example: <code>/backup/cassandra</code></p> <p>Shared File Systems * GlusterFS, CephFS, or other distributed file systems * Provides redundancy at the storage layer * Example: <code>/gluster/backups/cassandra</code></p>"},{"location":"operations/cassandra/backup/local_storage/#permissions-and-ownership","title":"Permissions and Ownership","text":"<p>Ensure the AxonOps agent user has appropriate permissions: </p><pre><code># Check current permissions\nls -la /path/to/backup/directory\n\n# Grant permissions if needed (example)\nsudo chown -R axonops:axonops /path/to/backup/directory\nsudo chmod -R 750 /path/to/backup/directory\n</code></pre>"},{"location":"operations/cassandra/backup/local_storage/#mount-options","title":"Mount Options","text":"<p>For network-mounted file systems, consider these mount options: * NFS: <code>rw,hard,intr,rsize=1048576,wsize=1048576</code> * SMB/CIFS: <code>rw,uid=axonops,gid=axonops,file_mode=0750,dir_mode=0750</code> * Auto-mount: Configure in <code>/etc/fstab</code> for persistence</p>"},{"location":"operations/cassandra/backup/local_storage/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>I/O Impact: Local storage backups can impact disk I/O on the node</li> <li>Network Bandwidth: For network mounts, ensure adequate bandwidth</li> <li>Disk Space: Monitor available space to prevent backup failures</li> <li>File System Choice: ext4, XFS, or ZFS are recommended for Linux</li> <li>Mount Options: Use appropriate options for your storage type</li> </ol>"},{"location":"operations/cassandra/backup/local_storage/#monitoring-and-maintenance","title":"Monitoring and Maintenance","text":"<ol> <li>Disk Space Monitoring: Set up alerts for low disk space</li> <li>Mount Health: Monitor that network mounts remain accessible</li> <li>Backup Verification: Regularly verify backup integrity</li> <li>Cleanup: Ensure retention policies are working correctly</li> <li>Performance Metrics: Track backup duration and throughput</li> </ol>"},{"location":"operations/cassandra/backup/local_storage/#best-practices","title":"Best Practices","text":"<ol> <li>Dedicated Storage: Use dedicated backup storage separate from Cassandra data</li> <li>Redundancy: Ensure the storage itself has redundancy (RAID, replication)</li> <li>Regular Testing: Periodically test restore procedures</li> <li>Documentation: Document mount points and dependencies</li> <li>Automation: Automate mount checks and space monitoring</li> </ol>"},{"location":"operations/cassandra/backup/local_storage/#advantages","title":"Advantages","text":"<ul> <li>Simple Configuration: No cloud credentials or complex setup</li> <li>Fast Transfers: No network latency for local disks</li> <li>Cost Effective: No cloud storage fees</li> <li>Full Control: Complete control over storage infrastructure</li> <li>Predictable Performance: Consistent I/O characteristics</li> </ul>"},{"location":"operations/cassandra/backup/local_storage/#limitations","title":"Limitations","text":"<ul> <li>Single Point of Failure: Unless using redundant storage</li> <li>Manual Management: Requires managing disk space and mounts</li> <li>No Geographic Distribution: Backups in same location as cluster</li> <li>Scaling Challenges: Must provision sufficient storage upfront</li> </ul>"},{"location":"operations/cassandra/backup/local_storage/#troubleshooting","title":"Troubleshooting","text":"<ol> <li>Permission Denied: Check file system permissions and ownership</li> <li>No Space Left: Monitor and manage disk space usage</li> <li>Mount Not Found: Verify mount points are active and accessible</li> <li>Slow Performance: Check disk I/O metrics and mount options</li> <li>Stale Mounts: For network mounts, check connectivity and remount if needed</li> </ol>"},{"location":"operations/cassandra/backup/local_storage/#disable-checksum","title":"Disable Checksum","text":"<p>Normally AxonOps Backups will check that the checksums of transferred files match, and give an error \"corrupted on transfer\" if they don't. If you disable this then the checksum will be ignored if there are differences. This is not advised, especially for network-mounted storage where corruption is more likely.</p>"},{"location":"operations/cassandra/backup/overview/","title":"Overview","text":"<p>AxonOps provides scheduled backup funtionality for your Cassandra data to local and remote storage options.</p> <p>The Backup feature is accessible via Operations &gt; Backups.</p> <p>Infomy</p> <p></p>"},{"location":"operations/cassandra/backup/overview/#scheduled-backups","title":"Scheduled Backups","text":"<p>You can initiate three types of scheduled backup:</p> <ul> <li> <p>Immediate scheduled backup: will trigger backup immediately once.</p> </li> <li> <p>Cron schedule backup: triggered based on the selected schedule and based on a Cron expression.</p> </li> </ul> <p>Infomy</p> <p></p>"},{"location":"operations/cassandra/backup/overview/#remote-backups","title":"Remote Backups","text":"<p>Backups can be created and stored locally and/or remotely.</p> <p>Infomy</p> <p></p> <p>Backups can be stored to:</p> <ul> <li>AWS S3</li> <li>Google Cloud Storage</li> <li>Local filesystem</li> <li>Microsoft Azure Blog Storage</li> <li>S3 Compatible storage systems</li> <li>SFTP/SSH servers</li> </ul> <p>Infomy</p> <p></p>"},{"location":"operations/cassandra/backup/remote/","title":"Overview","text":""},{"location":"operations/cassandra/backup/remote/#remote-backups","title":"Remote backups","text":"<p>Note that axonops user will need read access on Cassandra data folders to be able to perform a remote backup.</p> <p>When selecting Remote backups there is some basic config presets.</p> <p></p>"},{"location":"operations/cassandra/backup/remote/#transfers-file-transfer-parallelism","title":"Transfers (File Transfer Parallelism)","text":"<p>The number of file transfers to run in parallel. It can be beneficial to set this to a smaller number if the remote is giving timeouts. You can set this to a bigger number or leave it at 0  if you have lots of bandwidth and a fast remote.</p>"},{"location":"operations/cassandra/backup/remote/#tps-limit","title":"TPS Limit","text":"<p>If you are getting errors from the cloud storage provider then you need to start adjusting this limit.</p> <p>The default is 0</p> <p>Storage provider errors consist of getting you banned or imposing rate limits.</p> <p>A transaction is any of but not limited to, PUT/GET/POST calls to the Storage backend. </p> <p>Different Storage providers have different limits. </p> <ul> <li>Amazon S3 has a limit of 5,500 GET requests per second per partitioned prefix.More here</li> <li>Google Cloud Storage has an approximate limit of 1,000 READ and 5,000 WRITE requests per second.More here</li> <li>Azure Blob Storage has a limit of 20,000 requests per second per storage account. More here</li> </ul>"},{"location":"operations/cassandra/backup/remote/#bandwidth-limit","title":"Bandwidth Limit","text":"<p>This will allow you to set a limit on how much data you want to transfer to your Storage provider during backups.  Note that the units are Byte/s, not bit/s. Typically connections are measured in bit/s - to convert divide by 8. For example, let's say you have a 10 Mbit/s connection and you wish AxonOps to use half of it - 5 Mbit/s.  You will calculate the limit value as 5MB/8 = 0.625 MiB/s. The value you would set it 0.625</p> <p>In most modern storage systems the value is not normally this low but if you have a VPN Gateway connection setup between an on-premise cluster and a storage provider that has a 100MB connection you could potentially limit how much of the pipe gets used by backups. </p>"},{"location":"operations/cassandra/backup/remote/#the-available-remote-options-are","title":"The available remote options are:","text":"<ul> <li>AWS S3</li> <li>Google Cloud Storage</li> <li>local filesystem</li> <li>Microsoft Azure Blob Storage</li> <li>S3 Compatible</li> <li>SFTP/SSH</li> </ul>"},{"location":"operations/cassandra/backup/s3_compatible/","title":"S3 Compatible Storage","text":""},{"location":"operations/cassandra/backup/sftp_ssh/","title":"SFTP/SSH Storage","text":""},{"location":"operations/cassandra/backup/ssh_sftp/","title":"SSH/SFTP","text":""},{"location":"operations/cassandra/backup/ssh_sftp/#what-is-sshsftp","title":"What is SSH/SFTP","text":"<p>SSH File Transfer Protocol (SFTP) is a network protocol that provides file access, file transfer, and file management over any reliable data stream. It is typically used with SSH protocol to provide secure file transfer capabilities. Read more at SSH.com SFTP</p> <p>When selecting SSH/SFTP as a remote option there are several fields that need to be configured.</p> <p></p>"},{"location":"operations/cassandra/backup/ssh_sftp/#remote-backup-retention","title":"Remote Backup Retention","text":"<p>The amount of days that backup files will be kept in the remote storage provider location.  After this amount of days the files that are older will be removed.</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#base-remote-path","title":"Base Remote Path","text":"<p>This is the path on the remote SSH/SFTP server where backups will be stored. You can specify an absolute path like <code>/backups/cassandra</code> or a relative path from the user's home directory. By default AxonOps will save the backups to <code>/path/org/clustertype/clustername/host-id/</code></p> <p>The org/clustertype/clustername/host-id/ will match the top breadcrumb navigation in your AxonOps Dashboard.</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#host","title":"Host","text":"<p>The hostname or IP address of the SSH/SFTP server. This can be: * A fully qualified domain name (e.g., <code>backup.example.com</code>) * An IP address (e.g., <code>192.168.1.100</code>) * A hostname resolvable via DNS</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#port","title":"Port","text":"<p>The port number for the SSH/SFTP connection. The default SSH port is 22, but your server may be configured to use a different port for security reasons.</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#username","title":"Username","text":"<p>The username for authenticating to the SSH/SFTP server. This user must have: * SSH access to the server * Write permissions to the base remote path * Sufficient disk quota for storing backups</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#authentication-method","title":"Authentication Method","text":"<p>AxonOps supports two authentication methods for SSH/SFTP:</p> <p>Password Authentication * Enter the password for the specified username * Less secure but simpler to configure * May be disabled on some SSH servers for security reasons</p> <p>Key-Based Authentication * Uses SSH private key for authentication * More secure than password authentication * Requires the private key to be in PEM format</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#private-key-for-key-based-authentication","title":"Private Key (for Key-Based Authentication)","text":"<p>When using key-based authentication, provide the SSH private key in PEM format. The key should: * Be in standard PEM format (begins with <code>-----BEGIN RSA PRIVATE KEY-----</code> or similar) * Have appropriate permissions (readable only by the AxonOps user) * Correspond to a public key that has been added to the <code>~/.ssh/authorized_keys</code> file on the remote server</p> <p>Example key format: </p><pre><code>-----BEGIN RSA PRIVATE KEY-----\nMIIEpAIBAAKCAQEA...\n...\n-----END RSA PRIVATE KEY-----\n</code></pre>"},{"location":"operations/cassandra/backup/ssh_sftp/#key-passphrase","title":"Key Passphrase","text":"<p>If your private key is encrypted with a passphrase, enter it here. Leave blank if the key is not encrypted.</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#host-key-verification","title":"Host Key Verification","text":"<p>For security, AxonOps can verify the SSH server's host key to prevent man-in-the-middle attacks. Options include: * Strict: Always verify the host key against known hosts * Accept New: Accept new host keys but verify known ones * No Verification: Skip host key verification (not recommended for production)</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#compression","title":"Compression","text":"<p>Enable compression for the SSH connection to reduce bandwidth usage. This is especially useful for: * Slow network connections * Large backup files * Metered or limited bandwidth connections</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#connection-timeout","title":"Connection Timeout","text":"<p>The maximum time (in seconds) to wait for the SSH connection to be established. Increase this value if connecting to servers over slow or unreliable networks.</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#disable-checksum","title":"Disable Checksum","text":"<p>Normally AxonOps Backups will check that the checksums of transferred files match, and give an error \"corrupted on transfer\" if they don't. If you disable this then the checksum will be ignored if there are differences. This is not advised.</p>"},{"location":"operations/cassandra/backup/ssh_sftp/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Use Key-Based Authentication: Always prefer SSH keys over passwords for better security</li> <li>Restrict User Permissions: Create a dedicated user for AxonOps with minimal required permissions</li> <li>Use Non-Standard Ports: Consider using a non-standard SSH port to reduce automated attacks</li> <li>Enable Host Key Verification: Always verify host keys in production environments</li> <li>Secure Key Storage: Ensure private keys are stored securely with appropriate file permissions</li> <li>Regular Key Rotation: Implement a key rotation policy for enhanced security</li> </ol>"},{"location":"operations/cassandra/repair/","title":"Repairs","text":"<p>Repairs must be completed regularly to maintain Cassandra nodes.</p> <p>AxonOps provides two mechanisms to ease management of repairs in Cassandra:</p> <ul> <li>Adaptive Repair Service</li> <li>Scheduled Repairs</li> </ul>"},{"location":"operations/cassandra/repair/#adaptive-repair-service","title":"Adaptive Repair Service","text":"<p>Since AxonOps collects performance metrics and logs, we built an \"Adaptive\" repair system which regulates the velocity (parallelism and pauses between each subrange repair) based on performance trending data. The regulation of repair velocity takes input from various metrics including:</p> <ul> <li>CPU utilization</li> <li>Query latencies</li> <li>Cassandra thread pools pending statistics</li> <li>I/O wait percentage</li> <li>Tracking of the repair schedule based on <code>gc_grace_seconds</code> for each table</li> </ul> <p>The idea of this is to achieve the following:</p> <ul> <li>Completion of repair within <code>gc_grace_seconds</code> of each table.</li> <li>Repair process does not affect query performance.</li> <li>In essence, the adaptive repair regulator slows down the repair velocity when it detects an increase in load and speeds up to catch up with the repair schedule when resources are more readily available.</li> <li>This mechanism does not require JMX access. The adaptive repair service running on AxonOps server orchestrates and issues commands to the agents over the existing connection.</li> </ul> <p>Infomy</p> <p></p> <p>From a user's point of view there is only a single switch to enable this service. Keep this enabled and AxonOps will take care of the repair of all tables for you. </p> <p>You can, however, customize the following:</p> <ul> <li> <p>Exclude tables</p> <p>Skip specific tables from automatic repair</p> </li> <li> <p>Parallel processing</p> <p>Set how many tables to repair simultaneously</p> </li> <li> <p>Segment size</p> <p>Splits each table into segments of up to this size and repairs each segment in turn.</p> </li> <li> <p>GC grace threshold</p> <p>If a table has a gc grace lesser than the specified value, the table will be ignored by the adaptive repair service.</p> </li> </ul>"},{"location":"operations/cassandra/repair/#increasing-data-consistency","title":"Increasing Data Consistency","text":"<p>To keep tables as up-to-date as possible we recommend both:</p> <ul> <li>Increasing the <code>Concurrent Repair Processes</code> to be greater than the total number of tables in the cluster.</li> <li>Reducing the <code>Target Segment Size</code> to generate fewer repair requests.</li> </ul>"},{"location":"operations/cassandra/repair/#scheduled-repairs","title":"Scheduled Repairs","text":"<p>You can initiate two types of scheduled repairs with AxonOps.</p> <p>Infomy</p> <p></p> <p>The above screenshot showcases a running repair that has been initiated immediately and a scheduled repair that is scheduled for 12:00 AM UTC.</p>"},{"location":"operations/cassandra/repair/#immediate-repairs","title":"Immediate Repairs","text":"<p>These will trigger immediately once.</p> <p>Infomy</p> <p></p>"},{"location":"operations/cassandra/repair/#cron-scheduled-repairs","title":"Cron Scheduled Repairs","text":"<p>These will trigger based on the selected schedule repeatedly.</p> <p>Infomy</p> <p></p>"},{"location":"operations/cassandra/restore/overview/","title":"Overview","text":"<p>AxonOps provides the ability to restore from local snapshots and remote backups.</p> <p>The Restore feature is accessible via Operations &gt; Restore</p> <p>Infomy</p> <p></p> <p>Note that axonops user will need temporary write access on Cassandra data folders to be able to perform the restoration.</p> <p>To restore Cassandra, click on the backup you wish to restore.</p> <p>This will provide the details of that backup and the ability to start the restoration by clicking the <code>LOCAL RESTORE</code> or <code>REMOTE RESTORE</code>  button depending on if you prefer to restore from the local snapshot or the remote backup (if remote backups were configured). Here you can also select a subset of nodes to restore via the checkboxes in the Nodes list.</p> <p>Infomy</p> <p></p> <p>Follow the links below for some more detailed backup restore scenarios</p> <p>Restore a single node - same IP address</p> <p>Replace a node - different IP address</p> <p>Restore whole cluster - same IP addresses</p>"},{"location":"operations/cassandra/restore/restore-cluster-different-ips/","title":"Whole cluster with changed IP addresses","text":""},{"location":"operations/cassandra/restore/restore-cluster-different-ips/#restore-a-whole-cluster-from-a-remote-backup-with-different-ip-addresses","title":"Restore a whole cluster from a remote backup with different IP addresses","text":"<p>Follow this procedure when you have lost all nodes in a cluster and they have been recreated in the same topology (Cluster, DC and rack names are all the same and the same number of nodes in each) but the replacement nodes have different IP addresses from the original cluster.</p> <p>NOTE: This process is for disaster recovery and cannot be used to clone a backup to a different cluster</p>"},{"location":"operations/cassandra/restore/restore-cluster-different-ips/#prepare-the-cluster-for-restoring-a-backup","title":"Prepare the cluster for restoring a backup","text":"<p>Before you start, ensure that Cassandra is stopped on all replacement nodes and that their data directories are empty </p><pre><code>sudo systemctl stop cassandra\nsudo rm -rf /var/lib/cassandra/commitlog/* /var/lib/cassandra/data/* /var/lib/cassandra/hints/* /var/lib/cassandra/saved_caches/*\n</code></pre> <p>Allow the AxonOps user to write to the Cassandra data directory on all nodes </p><pre><code>sudo chmod -R g+w /var/lib/cassandra/data\n</code></pre> <p>The commands above assume you are storing the Cassandra data in the default location <code>/var/lib/cassandra</code>, you will need to change the paths shown if your data is stored at a different location</p> <p>As the IP addresses of the replacement Cassandra nodes are different to the old cluster you will need to update the seeds list in <code>cassandra.yaml</code> to point to the IPs of the nodes that are replacing the old seeds. For package-based  installations (RPM or DEB) you can find this in <code>/etc/cassandra/cassandra.yaml</code> or for tarball installations it should be in <code>&lt;install_path&gt;/conf/cassandra.yaml</code>.</p>"},{"location":"operations/cassandra/restore/restore-cluster-different-ips/#manually-configure-the-axonops-agent-host-ids","title":"Manually configure the AxonOps Agent host IDs","text":"<p>AxonOps identifies nodes by a unique host ID which is assigned when the agent starts up. In order to restore a backup to a node with a different IP address you must manually assign the AxonOps host ID of the old node to its new replacement.</p> <p>In order to restore the whole cluster from a backup you will need to apply the old AxonOps host ID to all nodes in the replacement cluster.</p> <p>The host ID of the old node can be found on the Cluster Overview page of the AxonOps dashboard</p> <p>Infomy</p> <p></p> <p>If you still have access to the old server or its data then its host ID can also be found in the file <code>/var/lib/axonops/hostId</code></p>"},{"location":"operations/cassandra/restore/restore-cluster-different-ips/#apply-the-old-nodes-host-id-to-its-replacement","title":"Apply the old node's host ID to its replacement","text":"<p>Ensure the AxonOps Agent is stopped and clear any data that it may have created on startup</p> <pre><code>sudo systemctl stop axon-agent\nsudo rm -rf /var/lib/axonops/*\n</code></pre> <p>Manually apply the old node's host ID on the replacement (replace the host ID shown with your host ID from the previous steps)</p> <pre><code>echo '24d0cbf9-3b5a-11ed-8433-16b3c6a7bcc5' | sudo tee /var/lib/axonops/hostId\nsudo chown axonops.axonops /var/lib/axonops/hostId\n</code></pre> <p>Start the AxonOps agent</p> <pre><code>sudo systemctl start axon-agent\n</code></pre> <p>In the AxonOps dashboard you should see the replacement nodes start up and take over from the old nodes after a few minutes.</p>"},{"location":"operations/cassandra/restore/restore-cluster-different-ips/#restore-the-backup","title":"Restore the backup","text":"<p>Open the Restore page in the AxonOps Dashboard by going to Operations &gt; Restore</p> <p>Infomy</p> <p></p> <p>Choose the backup you wish to restore from the list and click the <code>RESTORE</code> button</p> <p>This will show the details of the backup and allow you to restore to all nodes or a subset using the checkboxes in the Nodes list.</p> <p>Infomy</p> <p></p> <p>Select all nodes in the checkbox list then start the restore by clicking the <code>REMOTE RESTORE</code> button.</p> <p>The restore progress will be displayed in the Backup Restorations in Progress list</p> <p>Infomy</p> <p></p> <p>After the restore operation has completed successfully, fix the ownership and permissions on the Cassandra data directories on all nodes in the cluster </p><pre><code>sudo chown -R cassandra.cassandra /var/lib/cassandra/data\nsudo chmod -R g-w /var/lib/cassandra/data\n</code></pre> <p>Start cassandra on the restored nodes one at a time, starting with the seeds first </p><pre><code>sudo systemctl start cassandra\n</code></pre> <p>After the whole cluster is started up you should be able to see the replaced nodes with their new IP addresses in the output of <code>nodetool status</code>. You may still see the IP addresses of the old cluster nodes in the output of <code>nodetool gossipinfo</code>, these should clear out automatically after a few days or they can be manually tidied up by performing a rolling restart of the cluster.</p>"},{"location":"operations/cassandra/restore/restore-cluster-same-ip/","title":"Whole cluster","text":""},{"location":"operations/cassandra/restore/restore-cluster-same-ip/#restore-a-whole-cluster-from-a-remote-backup","title":"Restore a whole cluster from a remote backup","text":"<p>Follow this procedure when you have lost all nodes in a cluster but they have been recreated in the same cluster  topology (Cluster, DC and rack names are all the same and the same number of nodes in each) and the replacement nodes have the same IP addresses as the original cluster.</p> <p>Ensure that Cassandra is stopped on all nodes and that its data directories are empty</p> <pre><code>sudo systemctl stop cassandra\nsudo rm -rf /var/lib/cassandra/commitlog/* /var/lib/cassandra/data/* /var/lib/cassandra/hints/* /var/lib/cassandra/saved_caches/*\n</code></pre> <p>Allow the AxonOps user to write to the Cassandra data directory </p><pre><code>sudo chmod -R g+w /var/lib/cassandra/data\n</code></pre> <p>These commands assume you are storing the Cassandra data in the default location <code>/var/lib/cassandra/</code>, you will need to change the paths shown if your data is stored at a different location</p> <p>Start the AxonOps agent on all nodes </p><pre><code>sudo systemctl start axon-agent\n</code></pre> <p>Now open the Restore page in the AxonOps Dashboard by going to Operations &gt; Restore</p> <p>Infomy</p> <p></p> <p>Choose the backup you wish to restore from the list and click the <code>RESTORE</code> button</p> <p>This will show the details of the backup and allow you to restore to all nodes or a subset using the checkboxes in the Nodes list.</p> <p>Infomy</p> <p></p> <p>Select all nodes in the checkbox list then start the restore by clicking the <code>REMOTE RESTORE</code> button.</p> <p>The restore progress will be displayed in the Backup Restorations in Progress list</p> <p>Infomy</p> <p></p> <p>After the restore operation has completed successfully, fix the ownership and permissions on the Cassandra data  directories on all nodes in the cluster </p><pre><code>sudo chown -R cassandra.cassandra /var/lib/cassandra/data\nsudo chmod -R g-w /var/lib/cassandra/data\n</code></pre> <p>Start cassandra on the restored nodes, starting with the seeds first </p><pre><code>sudo systemctl start cassandra\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/","title":"Restore to a different cluster","text":""},{"location":"operations/cassandra/restore/restore-different-cluster/#restore-a-backup-to-a-different-cluster","title":"Restore a backup to a different cluster","text":"<p>Follow this procedure to restore an AxonOps backup from remote storage onto a different cluster</p> <p>NOTE: This facility is only available for backups created using AxonOps Agent version 1.0.60 or later</p> <p>AxonOps Agent version 1.0.60 and later includes a command-line tool which can be used to restore a backup created by AxonOps from remote storage (e.g. S3, GCS). This tool connects directly to your remote storage and does not require an AxonOps server or an active AxonOps Cloud account in order to function.</p>"},{"location":"operations/cassandra/restore/restore-different-cluster/#installing-the-cassandra-restore-tool","title":"Installing the Cassandra Restore Tool","text":"<p>The AxonOps Cassandra Restore tool is included in the AxonOps Agent package.</p>"},{"location":"operations/cassandra/restore/restore-different-cluster/#installing-on-debian-ubuntu","title":"Installing on Debian / Ubuntu","text":"<pre><code>sudo apt-get update\nsudo apt-get install -y curl gnupg ca-certificates\ncurl -L https://packages.axonops.com/apt/repo-signing-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/axonops.gpg\necho \"deb [arch=arm64,amd64 signed-by=/usr/share/keyrings/axonops.gpg] https://packages.axonops.com/apt axonops-apt main\" | sudo tee /etc/apt/sources.list.d/axonops-apt.list\nsudo apt-get update\nsudo apt-get install axon-agent\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#installing-on-centos-redhat","title":"Installing on CentOS / RedHat","text":"<pre><code>sudo tee /etc/yum.repos.d/axonops-yum.repo &lt;&lt; EOL\n[axonops-yum]\nname=axonops-yum\nbaseurl=https://packages.axonops.com/yum/\nenabled=1\nrepo_gpgcheck=0\ngpgcheck=0\nEOL\nsudo yum install axon-agent\n</code></pre> <p>After the package has been installed you can find the Cassandra Restore Tool at <code>/usr/share/axonops/axon-cassandra-restore</code>.</p> <p>Run the tool with <code>--help</code> to see the available options: </p><pre><code>~# /usr/share/axonops/axon-cassandra-restore --help\nUsage of /usr/share/axonops/axon-cassandra-restore:\n  -i, --backup-id string                UUID of the backup to restore\n      --cassandra-bin-dir string        Where the Cassandra binary files are stored (e.g. /opt/cassandra/bin)\n      --cqlsh-options string            Options to pass to cqlsh when restoring a table schema\n      --dest-table string               The name of the destination table for the restore in keyspace.table format. Requires --tables with a single source table. (Added in v1.0.61)\n  -h, --help                            Show command-line help\n  -l, --list                            List backups available in remote storage\n  -d, --local-sstable-dir string        A local directory in which to store sstables downloaded from backup storage\n      --org-id string                   ID of the AxonOps organisation from which the backup was created\n  -r, --restore                         Restore a backup from remote storage\n      --restore-schema                  Set this when using --use-sstable-loader to restore the CQL schema for each table. Keyspaces must already exist.\n  -e, --skip-existing-files             Don't download files that already exist in the local destination path (Added in v1.0.61)\n  -c, --source-cluster string           The name of the cluster from which to restore\n  -s, --source-hosts string             Comma-separated list containing host IDs for which to restore backups\n      --sstable-loader-options string   Options to pass to sstableloader when restoring a backup\n      --storage-config string           JSON-formatted remote storage configuration\n      --storage-config-file string      Path to a file containing JSON-formatted remote storage configuration (Added in v1.0.95)\n  -t, --tables string                   Comma-separated list of keyspace.table to restore. Defaults to all tables if omitted.\n      --use-sstable-loader              Use sstableloader to restore the backup. Requires --sstable-loader-options and --cassandra-bin-dir.\n  -v, --verbose                         Show verbose output when listing backups\n      --version                         Show version information and exit\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#storage-config-and-storage-config-file-options","title":"Storage Config and Storage Config File options","text":"<p>The <code>--storage-config-file</code> option was added to v1.0.95 and later of AxonOps Agent</p> <p>The <code>axonops-cassandra-restore</code> tool has two options when passing the remote storage configuration. The fist option is to pass a JSON formatted string to --storage-config or pre-populated JSON file to --storage-config-file</p> <p>NOTE: You can only use one of the options when doing a restore. </p> <p>For examples of both please see: </p> <ul> <li> <p>Storage Config Examples</p> </li> <li> <p>Storage Config File Examples</p> </li> </ul>"},{"location":"operations/cassandra/restore/restore-different-cluster/#listing-the-available-backups","title":"Listing the available backups","text":"<p>NOTE: The host IDs used in this tool are the ID given to each host by AxonOps and do not relate to the Cassandra host ID. You can find the AxonOps host ID by selecting the node on the Cluster Overview page of the AxonOps dashboard and looking at the Agent ID field.</p> <p>To list the backups available in the remote storage bucket you can run the tool with the <code>--list</code> option. For example to list the backups in an Amazon S3 bucket you could use a command similar to this:</p> <p><code>--storage-config</code></p> <pre><code>/usr/share/axonops/axon-cassandra-restore --list \\\n  --org-id myaxonopsorg \\\n  --storage-config '{\"type\":\"s3\",\"path\":\"/axonops-cassandra-backups\",\"access_key_id\":\"MY_AWS_ACCESS_KEY\",\"secret_access_key\":\"MY_AWS_SECRET_ACCESS_KEY\",\"region\":\"eu-west-3\"}'\n</code></pre> <p><code>--storage-config-file</code></p> <pre><code>/usr/share/axonops/axon-cassandra-restore --list \\\n  --org-id myaxonopsorg \\\n  --storage-config-file /full/path/to/remote_storage_config_file.json\n</code></pre> <p>The restore tool will then scan the specified S3 bucket for AxonOps backups and it will display the date and backup ID for any backups it finds: </p><pre><code>Org ID:    myaxonopsorg\nCluster:   testcluster\nTime                   Backup ID\n2023-09-14 14:30 UTC   c67cea2a-5310-11ee-b686-bed50b9335ec\n2023-09-15 14:31 UTC   2c1d9aca-5312-11ee-b686-bed50b9335ec\n2023-09-16 14:30 UTC   91be5007-5313-11ee-b686-bed50b9335ec\n2023-09-17 14:31 UTC   f75f13d9-5314-11ee-b686-bed50b9335ec\n2023-09-18 14:30 UTC   5cffc1e6-5316-11ee-b686-bed50b9335ec\n</code></pre> If you pass the <code>--verbose</code> option when listing backups it will show the list of nodes and tables in each backup, for example: <pre><code>Org ID:    myaxonopsorg\nCluster:   testcluster\nTime:      2023-09-14 14:30 UTC\nBackup ID: c67cea2a-5310-11ee-b686-bed50b9335ec\n\nHost:   026346a0-dc89-4235-ae34-552fcd453b42\nTables: system.prepared_statements, system.transferred_ranges_v2, system_distributed.repair_history, system_schema.types, system_traces.sessions, system.compaction_history, system.available_ranges_v2, system.batches, system.size_estimates, system_schema.aggregates, system.IndexInfo, system_auth.resource_role_permissons_index, system_schema.views, test.test, system.paxos, system.local, system.peers, system.peers_v2, system.table_estimates, system_auth.network_permissions, system_auth.roles, system_distributed.view_build_status, system.built_views, system_schema.triggers, system.peer_events, system.repairs, keyspace1.table1, system.sstable_activity, keyspace1.table2, system.transferred_ranges, system_auth.role_permissions, system_distributed.parent_repair_history, system.available_ranges, system_schema.dropped_columns, system_schema.columns, system_schema.keyspaces, system.view_builds_in_progress, system_auth.role_members, system_schema.functions, system_schema.indexes, system_schema.tables, system_traces.events, system.peer_events_v2\n\nHost:   84759df0-8a19-497e-965f-200bdb4c1c9b\nTables: system_traces.events, system.available_ranges_v2, system.peer_events, system_auth.resource_role_permissons_index, system_auth.role_members, system_schema.types, system.IndexInfo, system.sstable_activity, system_distributed.view_build_status, system_schema.indexes, system.batches, system.transferred_ranges, system_schema.keyspaces, system_schema.tables, system_traces.sessions, system_distributed.repair_history, system_schema.aggregates, system.available_ranges, system.compaction_history, system.paxos, system.peers_v2, system.view_builds_in_progress, system.size_estimates, keyspace1.table1, system_auth.roles, system_schema.dropped_columns, test.test, system_auth.role_permissions, system_distributed.parent_repair_history, system.local, system.peer_events_v2, system.repairs, system.table_estimates, system_auth.network_permissions, system.peers, system_schema.triggers, system_schema.views, system.built_views, system.prepared_statements, system.transferred_ranges_v2, system_schema.columns, system_schema.functions, keyspace1.table2\n\nHost:   94ed3811-12ce-487f-ac49-ae31299efa31\nTables: system.peers_v2, system.view_builds_in_progress, system_auth.resource_role_permissons_index, system_auth.role_permissions, system_schema.aggregates, system_schema.indexes, test.test, system.available_ranges_v2, system_distributed.parent_repair_history, system_schema.keyspaces, system_traces.sessions, system_auth.role_members, system_auth.network_permissions, system_schema.dropped_columns, system_schema.types, system.repairs, system.size_estimates, system_auth.roles, system_schema.tables, system_schema.views, system.paxos, system.table_estimates, system.transferred_ranges, system.peers, system.prepared_statements, system.sstable_activity, system.peer_events_v2, system.batches, system.built_views, system.compaction_history, system_traces.events, system.IndexInfo, system.local, keyspace1.table2, system.peer_events, system.transferred_ranges_v2, system_distributed.repair_history, system_distributed.view_build_status, system_schema.columns, system_schema.functions, system.available_ranges, system_schema.triggers, keyspace1.table1\n</code></pre> <p>Scanning for backups can take a long time depending on the storage type and the amount of data, so you can use command-line options to restrict the search. For example this will restrict the search to a specific backup,  cluster, hosts and tables:</p> <p><code>--storage-config</code> </p><pre><code>/usr/share/axonops/axon-cassandra-restore --list \\\n  --verbose \\\n  --org-id myaxonopsorg \\\n  --storage-config '{\"type\":\"s3\",\"path\":\"/axonops-cassandra-backups\",\"access_key_id\":\"MY_AWS_ACCESS_KEY\",\"secret_access_key\":\"MY_AWS_SECRET_ACCESS_KEY\",\"region\":\"eu-west-3\"}' \\\n  --backup-id 2c1d9aca-5312-11ee-b686-bed50b9335ec \\\n  --source-cluster testcluster \\\n  --source-hosts 026346a0-dc89-4235-ae34-552fcd453b42,84759df0-8a19-497e-965f-200bdb4c1c9b\n  --tables keyspace1.table1,keyspace1.table2\n</code></pre> <p><code>--storage-config-file</code> </p><pre><code>/usr/share/axonops/axon-cassandra-restore --list \\\n  --verbose \\\n  --org-id myaxonopsorg \\\n  --storage-config-file /full/path/to/remote_storage_config_file.json \\\n  --backup-id 2c1d9aca-5312-11ee-b686-bed50b9335ec \\\n  --source-cluster testcluster \\\n  --source-hosts 026346a0-dc89-4235-ae34-552fcd453b42,84759df0-8a19-497e-965f-200bdb4c1c9b\n  --tables keyspace1.table1,keyspace1.table2\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#restoring-a-backup","title":"Restoring a Backup","text":"<p>The <code>axon-cassandra-restore</code> tool can perform the following operations to restore a backup from remote storage:</p> <ol> <li>Download the sstable files from the bucket</li> <li>Create table schemas in the target cluster.</li> <li>Import the downloaded sstable files into the target cluster using <code>sstableloader</code></li> </ol> <p>The default behaviour is to only download the sstable files to a local directory.</p>"},{"location":"operations/cassandra/restore/restore-different-cluster/#downloading-a-backup-to-a-local-directory","title":"Downloading a backup to a local directory","text":"<p>This command will download the backup with ID <code>2c1d9aca-5312-11ee-b686-bed50b9335ec</code> for the 3 hosts listed in the <code>--list</code> output above into the local directory <code>/opt/cassandra/axonops-restore</code></p> <p><code>--storage-config</code></p> <pre><code>/usr/share/axonops/axon-cassandra-restore \\\n  --restore \\\n  --org-id myaxonopsorg \\\n  --storage-config '{\"type\":\"s3\",\"path\":\"/axonops-cassandra-backups\",\"access_key_id\":\"MY_AWS_ACCESS_KEY\",\"secret_access_key\":\"MY_AWS_SECRET_ACCESS_KEY\",\"region\":\"eu-west-3\"}' \\\n  --source-cluster testcluster \\\n  --backup-id 2c1d9aca-5312-11ee-b686-bed50b9335ec \\\n  --source-hosts 026346a0-dc89-4235-ae34-552fcd453b42,84759df0-8a19-497e-965f-200bdb4c1c9b,94ed3811-12ce-487f-ac49-ae31299efa31 \\\n  --local-sstable-dir /opt/cassandra/axonops-restore\n</code></pre> <p><code>--storage-config-file</code></p> <pre><code>/usr/share/axonops/axon-cassandra-restore \\\n  --restore \\\n  --org-id myaxonopsorg \\\n  --storage-config-file /full/path/to/remote_storage_config_file.json \\\n  --source-cluster testcluster \\\n  --backup-id 2c1d9aca-5312-11ee-b686-bed50b9335ec \\\n  --source-hosts 026346a0-dc89-4235-ae34-552fcd453b42,84759df0-8a19-497e-965f-200bdb4c1c9b,94ed3811-12ce-487f-ac49-ae31299efa31 \\\n  --local-sstable-dir /opt/cassandra/axonops-restore\n</code></pre> <p>The sstable files will be restored into directories named <code>{local-sstable-dir}/{host-id}/keyspace/table/</code> and from here you can copy/move the files to another location or import them into a cluster using <code>sstableloader</code>.</p> <p>NOTE: At least the <code>keyspaces</code> must exist in the target cluster. If you did not create the tables remember to add the option <code>--restore-schema</code> to the command line. See Importing CQL schemas during the restore</p>"},{"location":"operations/cassandra/restore/restore-different-cluster/#download-and-import-a-backup-in-a-single-operation","title":"Download and import a backup in a single operation","text":"<p>The above example shows how to download the backed up files into a local directory but it does not import them into a new cluster. You can make the <code>axon-cassandra-restore</code> tool do this for you after it downloads the files by passing the <code>--use-sstable-loader</code>, <code>--cassandra-bin-dir</code> and <code>--sstable-loader-options</code> command-line arguments.</p> <p>For example this command will download the same backup files as the previous example but it will also run <code>sstableloader</code> to import the downloaded files into a new cluster with contact points 10.0.0.1, 10.0.0.2 and 10.0.0.3:</p> <p><code>--storage-config</code></p> <pre><code>/usr/share/axonops/axon-cassandra-restore \\\n  --restore \\\n  --org-id myaxonopsorg \\\n  --storage-config '{\"type\":\"s3\",\"path\":\"/axonops-cassandra-backups\",\"access_key_id\":\"MY_AWS_ACCESS_KEY\",\"secret_access_key\":\"MY_AWS_SECRET_ACCESS_KEY\",\"region\":\"eu-west-3\"}' \\\n  --source-cluster testcluster \\\n  --backup-id 2c1d9aca-5312-11ee-b686-bed50b9335ec \\\n  --source-hosts 026346a0-dc89-4235-ae34-552fcd453b42,84759df0-8a19-497e-965f-200bdb4c1c9b,94ed3811-12ce-487f-ac49-ae31299efa31 \\\n  --local-sstable-dir /opt/cassandra/axonops-restore \\\n  --use-sstable-loader \\\n  --cassandra-bin-dir /opt/cassandra/bin \\\n  --sstable-loader-options \"-d 10.0.0.1,10.0.0.2,10.0.0.3 -u cassandra -pw cassandra\"\n</code></pre> <p><code>--storage-config-file</code></p> <pre><code>/usr/share/axonops/axon-cassandra-restore \\\n  --restore \\\n  --org-id myaxonopsorg \\\n  --storage-config-file /full/path/to/remote_storage_config_file.json \\\n  --source-cluster testcluster \\\n  --backup-id 2c1d9aca-5312-11ee-b686-bed50b9335ec \\\n  --source-hosts 026346a0-dc89-4235-ae34-552fcd453b42,84759df0-8a19-497e-965f-200bdb4c1c9b,94ed3811-12ce-487f-ac49-ae31299efa31 \\\n  --local-sstable-dir /opt/cassandra/axonops-restore \\\n  --use-sstable-loader \\\n  --cassandra-bin-dir /opt/cassandra/bin \\\n  --sstable-loader-options \"-d 10.0.0.1,10.0.0.2,10.0.0.3 -u cassandra -pw cassandra\"\n</code></pre> <p>NOTE: if you are using an Apache Cassandra version installed using either the Debian or RedHat package manager use <code>--cassandra-bin-dir /usr/bin</code> when specifying the bin directory.</p>"},{"location":"operations/cassandra/restore/restore-different-cluster/#importing-cql-schemas-during-the-restore","title":"Importing CQL schemas during the restore","text":"<p>When a backup is imported to a cluster using <code>sstableloader</code> it assumes that the destination tables already exist and will skip the import for any that are missing. AxonOps stores the current table schema with each backup, so it is possible to create any missing tables as part of the restore operation. This can be enabled with the <code>--restore-schema</code> and <code>--cqlsh-options</code> arguments to <code>axon-cassandra-restore</code>.</p> <p>Building on the example above this command will download the files from the backup, create the schema for any missing tables, and import the downloaded data with <code>sstableloader</code>:</p> <p><code>--storage-config</code></p> <pre><code>/usr/share/axonops/axon-cassandra-restore \\\n  --restore \\\n  --org-id myaxonopsorg \\\n  --storage-config '{\"type\":\"s3\",\"path\":\"/axonops-cassandra-backups\",\"access_key_id\":\"MY_AWS_ACCESS_KEY\",\"secret_access_key\":\"MY_AWS_SECRET_ACCESS_KEY\",\"region\":\"eu-west-3\"}' \\\n  --source-cluster testcluster \\\n  --backup-id 2c1d9aca-5312-11ee-b686-bed50b9335ec \\\n  --source-hosts 026346a0-dc89-4235-ae34-552fcd453b42,84759df0-8a19-497e-965f-200bdb4c1c9b,94ed3811-12ce-487f-ac49-ae31299efa31 \\\n  --local-sstable-dir /opt/cassandra/axonops-restore \\\n  --use-sstable-loader \\\n  --cassandra-bin-dir /opt/cassandra/bin \\\n  --sstable-loader-options \"-d 10.0.0.1,10.0.0.2,10.0.0.3 -u cassandra -pw cassandra\" \\\n  --restore-schema \\\n  --cqlsh-options \"-u cassandra -p cassandra 10.0.0.1\"\n</code></pre> <p><code>--storage-config-file</code></p> <pre><code>/usr/share/axonops/axon-cassandra-restore \\\n  --restore \\\n  --org-id myaxonopsorg \\\n  --storage-config-file /full/path/to/remote_storage_config_file.json \\\n  --source-cluster testcluster \\\n  --backup-id 2c1d9aca-5312-11ee-b686-bed50b9335ec \\\n  --source-hosts 026346a0-dc89-4235-ae34-552fcd453b42,84759df0-8a19-497e-965f-200bdb4c1c9b,94ed3811-12ce-487f-ac49-ae31299efa31 \\\n  --local-sstable-dir /opt/cassandra/axonops-restore \\\n  --use-sstable-loader \\\n  --cassandra-bin-dir /opt/cassandra/bin \\\n  --sstable-loader-options \"-d 10.0.0.1,10.0.0.2,10.0.0.3 -u cassandra -pw cassandra\" \\\n  --restore-schema \\\n  --cqlsh-options \"-u cassandra -p cassandra 10.0.0.1\"\n</code></pre> <p>NOTE: This will not create missing keyspaces. You must ensure that the target keyspaces already exist in the destination cluster before running the restore command.</p>"},{"location":"operations/cassandra/restore/restore-different-cluster/#storage-config-examples","title":"Storage Config Examples","text":"<p>The AxonOps Cassandra restore tool can restore backups from any remote storage supported by AxonOps for backups. The <code>--storage-config</code> command-line option configures the type of remote storage and the credentials required for access.</p> <p>Here are some examples of the most common storage types:</p>"},{"location":"operations/cassandra/restore/restore-different-cluster/#local-filesystem","title":"Local filesystem","text":"<pre><code>--storage-config '{\"type\":\"local\",\"path\":\"/backups/cassandra\"}'\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#amazon-s3","title":"Amazon S3","text":"<pre><code>--storage-config '{\"type\":\"s3\",\"path\":\"/axonops-cassandra-backups\",\"access_key_id\":\"MY_AWS_ACCESS_KEY\",\"secret_access_key\":\"MY_AWS_SECRET_ACCESS_KEY\",\"region\":\"eu-west-3\"}'\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#azure-blob-storage","title":"Azure Blob Storage","text":"<pre><code>--storage-config '{\"type\":\"azureblob\",\"account\":\"MY_AZURE_ACCOUNT_NAME\",\"key\":\"MY_AZURE_STORAGE_KEY\"}'\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#google-cloud-storage","title":"Google Cloud Storage","text":"<pre><code>--storage-config '{\"type\":\"googlecloudstorage\",\"location\":\"us\",\"service_account_credentials\":\"ESCAPED_JSON_PRIVATE_KEY\"}'\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#sshsftp","title":"SSH/SFTP","text":"<pre><code>--storage-config '{\"type\":\"sftp\",\"host\":\"&lt;sftp_server_hostname&gt;\",\"port\":\"22\",\"path\":\"/backup/path\",\"user\":\"&lt;sftp_username&gt;\",\"key_file\":\"~/private/key/file\"}'\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#sshsftp-with-password","title":"SSH/SFTP with password","text":"<pre><code>--storage-config '{\"type\":\"sftp\",\"host\":\"&lt;sftp_server_hostname&gt;\",\"port\":\"22\",\"path\":\"/backup/path\",\"user\":\"&lt;sftp_username&gt;\",\"pass\":\"&lt;sftp_password&gt;\"}'\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#storage-config-file-examples","title":"Storage Config File Examples","text":""},{"location":"operations/cassandra/restore/restore-different-cluster/#local-filesystem_1","title":"Local filesystem","text":"<pre><code>{\n  \"type\": \"local\",\n  \"path\": \"/backups/cassandra\"\n}\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#amazon-s3_1","title":"Amazon S3","text":"<pre><code>{\n  \"type\": \"s3\",\n  \"path\": \"/axonops-cassandra-backups\",\n  \"access_key_id\": \"MY_AWS_ACCESS_KEY\",\n  \"secret_access_key\": \"MY_AWS_SECRET_ACCESS_KEY\",\n  \"region\": \"eu-west-3\"\n}\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#azure-blob-storage_1","title":"Azure Blob Storage","text":"<pre><code>{\n  \"type\": \"azureblob\",\n  \"account\": \"MY_AZURE_ACCOUNT_NAME\",\n  \"key\": \"MY_AZURE_STORAGE_KEY\"\n}\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#google-cloud-storage_1","title":"Google Cloud Storage","text":"<pre><code>{\n  \"type\": \"googlecloudstorage\",\n  \"location\": \"us\",\n  \"service_account_credentials\": \"ESCAPED_JSON_PRIVATE_KEY\"\n}\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#sshsftp_1","title":"SSH/SFTP","text":"<pre><code>{\n  \"type\": \"sftp\",\n  \"host\": \"&lt;sftp_server_hostname&gt;\",\n  \"port\": \"22\",\n  \"path\": \"/backup/path\",\n  \"user\": \"&lt;sftp_username&gt;\",\n  \"key_file\": \"~/private/key/file\"\n}\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#sshsftp-with-password_1","title":"SSH/SFTP with password","text":"<pre><code>{\n  \"type\": \"sftp\",\n  \"host\": \"&lt;sftp_server_hostname&gt;\",\n  \"port\": \"22\",\n  \"path\": \"/backup/path\",\n  \"user\": \"&lt;sftp_username&gt;\",\n  \"pass\": \"&lt;sftp_password&gt;\"\n}\n</code></pre>"},{"location":"operations/cassandra/restore/restore-different-cluster/#restore-to-a-different-table","title":"Restore to a different table","text":"<p>This feature is available in AxonOps Agent v1.0.61 or later</p> <p>When restoring a single table from a backup it is possible to use the <code>--dest-table</code> option on the command-line to load the restored data into table with a different name and/or keyspace to the original table. If you also supply the  <code>--restore-schema</code> option then the new table will be created as part of the restore process.</p> <p>NOTE: The destination keyspace must already exist before running the restore command.</p> <p>This example shows restoring the table <code>keyspace1.table1</code> into a table named <code>table1_restored</code> in keysace <code>restoreks</code>:</p> <p><code>--storage-config</code></p> <pre><code>/usr/share/axonops/axon-cassandra-restore \\\n  --restore \\\n  --org-id myaxonopsorg \\\n  --storage-config '{\"type\":\"s3\",\"path\":\"/axonops-cassandra-backups\",\"access_key_id\":\"MY_AWS_ACCESS_KEY\",\"secret_access_key\":\"MY_AWS_SECRET_ACCESS_KEY\",\"region\":\"eu-west-3\"}' \\\n  --source-cluster testcluster \\\n  --backup-id 2c1d9aca-5312-11ee-b686-bed50b9335ec \\\n  --source-hosts 026346a0-dc89-4235-ae34-552fcd453b42,84759df0-8a19-497e-965f-200bdb4c1c9b,94ed3811-12ce-487f-ac49-ae31299efa31 \\\n  --local-sstable-dir /opt/cassandra/axonops-restore \\\n  --use-sstable-loader \\\n  --cassandra-bin-dir /opt/cassandra/bin \\\n  --sstable-loader-options \"-d 10.0.0.1,10.0.0.2,10.0.0.3 -u cassandra -pw cassandra\" \\\n  --restore-schema \\\n  --cqlsh-options \"-u cassandra -p cassandra 10.0.0.1\" \\\n  --tables keyspace1.table1 \\\n  --dest-table restoreks.table1_restored\n</code></pre> <p><code>--storage-config-file</code> </p><pre><code>/usr/share/axonops/axon-cassandra-restore \\\n  --restore \\\n  --org-id myaxonopsorg \\\n  --storage-config-file /full/path/to/remote_storage_config_file.json \\\n  --source-cluster testcluster \\\n  --backup-id 2c1d9aca-5312-11ee-b686-bed50b9335ec \\\n  --source-hosts 026346a0-dc89-4235-ae34-552fcd453b42,84759df0-8a19-497e-965f-200bdb4c1c9b,94ed3811-12ce-487f-ac49-ae31299efa31 \\\n  --local-sstable-dir /opt/cassandra/axonops-restore \\\n  --use-sstable-loader \\\n  --cassandra-bin-dir /opt/cassandra/bin \\\n  --sstable-loader-options \"-d 10.0.0.1,10.0.0.2,10.0.0.3 -u cassandra -pw cassandra\" \\\n  --restore-schema \\\n  --cqlsh-options \"-u cassandra -p cassandra 10.0.0.1\" \\\n  --tables keyspace1.table1 \\\n  --dest-table restoreks.table1_restored\n</code></pre>"},{"location":"operations/cassandra/restore/restore-node-different-ip/","title":"Single node with a different IP address","text":""},{"location":"operations/cassandra/restore/restore-node-different-ip/#replace-a-node-from-a-remote-backup","title":"Replace a node from a remote backup","text":"<p>Follow this procedure to restore a single Cassandra node from a total loss of all data where the replacement node has a different IP address from the original.</p> <p>NOTE: Restoring a node from a total loss can only be performed from a remote backup</p> <p>AxonOps identifies nodes by a unique host ID which is assigned when the agent starts up. In order to restore a backup to a node with a different IP address you must manually assign the AxonOps host ID of the old node to its new replacement.</p> <p>You can find the host ID of the old node on the Cluster Overview page of the AxonOps dashboard</p> <p>Infomy</p> <p></p> <p>If you still have access to the old server or its data then its host ID can also be found in the file <code>/var/lib/axonops/hostId</code></p>"},{"location":"operations/cassandra/restore/restore-node-different-ip/#manually-configure-the-axonops-agent-host-id","title":"Manually configure the AxonOps Agent host ID","text":"<p>Ensure the AxonOps Agent is stopped and clear any data that it may have created on startup</p> <pre><code>sudo systemctl stop axon-agent\nsudo rm -rf /var/lib/axonops/*\n</code></pre> <p>Manually apply the old node's host ID on the replacement (replace the host ID shown with your host ID from the previous steps)</p> <pre><code>echo '24d0cbf9-3b5a-11ed-8433-16b3c6a7bcc5' | sudo tee /var/lib/axonops/hostId\nsudo chown axonops.axonops /var/lib/axonops/hostId\n</code></pre> <p>Start the AxonOps agent</p> <pre><code>sudo systemctl start axon-agent\n</code></pre>"},{"location":"operations/cassandra/restore/restore-node-different-ip/#restore-a-backup-to-the-replacement-node","title":"Restore a backup to the replacement node","text":"<p>Ensure Cassandra is stopped on the new node and that its data directories are all empty </p><pre><code>sudo systemctl stop cassandra\nsudo rm -rf /var/lib/cassandra/commitlog/* /var/lib/cassandra/data/* /var/lib/cassandra/hints/* /var/lib/cassandra/saved_caches/*\n</code></pre> <p>Allow the AxonOps user to write to the Cassandra data directory </p><pre><code>sudo chmod -R g+w /var/lib/cassandra/data\n</code></pre> <p>These commands assume you are storing the Cassandra data in the default location <code>/var/lib/cassandra/</code>, you will need to change the paths shown if your data is stored at a different location</p> <p>Now open the Restore page in the AxonOps Dashboard by going to Operations &gt; Restore</p> <p>Infomy</p> <p></p> <p>Choose the backup you wish to restore from the list and click the <code>RESTORE</code> button</p> <p>This will show the details of the backup and allow you to restore to all nodes or a subset using the checkboxes in the Nodes list.</p> <p>Infomy</p> <p></p> <p>Ensure only the node you wish to restore is selected in the checkbox list and start the restore by clicking the <code>REMOTE RESTORE</code> button.</p> <p>The restore progress will be displayed in the Backup Restorations in Progress list</p> <p>Infomy</p> <p></p> <p>After the restore has completed successfully, fix the ownership and permissions on the Cassandra data directories </p><pre><code>sudo chown -R cassandra.cassandra /var/lib/cassandra/data\nsudo chmod -R g-w /var/lib/cassandra/data\n</code></pre> <p>Now you can start cassandra on the restored node </p><pre><code>sudo systemctl start cassandra\n</code></pre> <p>After the replacement node has started up the old IP address may still be visible in Gossip. It should clear out automatically after a day or two, or you can perform a rolling restart of the cluster to make sure everything is up-to-date.</p>"},{"location":"operations/cassandra/restore/restore-node-same-ip/","title":"Single node","text":""},{"location":"operations/cassandra/restore/restore-node-same-ip/#restore-a-single-node-from-a-remote-backup","title":"Restore a single node from a remote backup","text":"<p>Follow this procedure to restore a single Cassandra node from a total loss of all data where the replacement node has the same IP address as the original.</p> <p>NOTE: Restoring a node from a total loss can only be performed from a remote backup</p> <p>Ensure Cassandra is stopped on the new node and that its data directories are all empty </p><pre><code>sudo systemctl stop cassandra\nsudo rm -rf /var/lib/cassandra/commitlog/* /var/lib/cassandra/data/* /var/lib/cassandra/hints/* /var/lib/cassandra/saved_caches/*\n</code></pre> <p>Allow the AxonOps user to write to the Cassandra data directory </p><pre><code>sudo chmod -R g+w /var/lib/cassandra/data\n</code></pre> <p>These commands assume you are storing the Cassandra data in the default location <code>/var/lib/cassandra/</code>, you will need to change the paths shown if your data is stored at a different location</p> <p>Start axon-agent if it is not already running </p><pre><code>sudo systemctl start axon-agent\n</code></pre> <p>Now open the Restore page in the AxonOps Dashboard by going to Operations &gt; Restore</p> <p>Infomy</p> <p></p> <p>Choose the backup you wish to restore from the list and click the <code>RESTORE</code> button</p> <p>This will show the details of the backup and allow you to restore to all nodes or a subset using the checkboxes in the Nodes list.</p> <p>Infomy</p> <p></p> <p>Ensure only the node you wish to restore is selected in the checkbox list and start the restore by clicking the <code>REMOTE RESTORE</code> button.</p> <p>The restore progress will be displayed in the Backup Restorations in Progress list</p> <p>Infomy</p> <p></p> <p>After the restore has completed successfully, fix the ownership and permissions on the Cassandra data directories </p><pre><code>sudo chown -R cassandra.cassandra /var/lib/cassandra/data\nsudo chmod -R g-w /var/lib/cassandra/data\n</code></pre> <p>Start cassandra on the restored node </p><pre><code>sudo systemctl start cassandra\n</code></pre>"},{"location":"operations/cassandra/rollingrestart/overview/","title":"Rolling Restarts","text":"<p>AxonOps provides a rolling restart functionality for Cassandra.</p> <p>The feature is accessible via Operations &gt; Rolling Restart</p> <p>Infomy</p> <p></p> <p>axonops user will require permissions to be able to stop and start Cassandra service. To do so you will add axonops user in the sudoers with for instance the following permissions: </p><pre><code>#/etc/sudoers.d/axonops\naxonops ALL=NOPASSWD: /sbin/service cassandra *, /usr/bin/systemctl * cassandra*\n</code></pre> <p>You can start an immediate rolling restart or schedule it.</p> <p>The script field let you able to tweak the predefined script executed by axon-agents during the restart process.</p> <p>You can also specify different degree of parallelism for the restart: DC, Rack and Node.</p> <p>For instance, to restart one entire rack at once across the cluster, you can set a large Node parallelism (greater than the number of nodes the rack has, ie 999). </p><pre><code>DC parallelism: 1\nRack parallelism: 1\nNode parallelism: 999\n</code></pre> <p>To restart one entire rack across each DC: </p><pre><code>DC parallelism: 999\nRack parallelism: 1\nNode parallelism: 999\n</code></pre>"},{"location":"operations/kafka/rollingrestart/overview/","title":"Overview","text":"<p>AxonOps provides a rolling restart functionality for Kafka.</p> <p>The feature is accessible via Operations &gt; Rolling Restart</p> <p>Infomy</p> <p></p> <p>axonops user will require permissions to be able to stop and start Kafka service. To do so you will add axonops user in the sudoers with for instance the following permissions: </p><pre><code>#/etc/sudoers.d/axonops\naxonops ALL=NOPASSWD: /sbin/service kafka *, /usr/bin/systemctl * kafka*\n</code></pre> <p>You can start an immediate rolling restart or schedule it.</p> <p>The script field let you able to tweak the predefined script executed by axon-agents during the restart process.</p> <p>You can also specify different degree of parallelism for the restart: DC, Rack and Node.</p> <p>For instance, to restart one entire rack at once across the cluster, you can set a large Node parallelism (greater than the number of nodes the rack has, ie 999). </p><pre><code>DC parallelism: 1\nRack parallelism: 1\nNode parallelism: 999\n</code></pre> <p>To restart one entire rack across each DC: </p><pre><code>DC parallelism: 999\nRack parallelism: 1\nNode parallelism: 999\n</code></pre>"},{"location":"overview/architecture/","title":"Architecture","text":""},{"location":"overview/architecture/#architecture","title":"Architecture","text":""},{"location":"overview/architecture/#before","title":"Before","text":"<p>Our deployment model with the use of open source tools </p> <p>Infomy</p> <p></p>"},{"location":"overview/architecture/#axonops-deployment-model","title":"AxonOps Deployment Model","text":"<p>As you can see from the diagram below, we have massively simplified the stack with AxonOps.</p> <p>Infomy</p> <p></p> <p>You can also use a CQL datastore such as Cassandra, Elassandra, or Scylla to store the metrics. We recommend storing metrics on a CQL store on 100+ nodes clusters to improve your experience navigating the metrics dashboards.</p>"},{"location":"overview/axonops-cloud/","title":"AxonOps Cloud","text":""},{"location":"overview/axonops-enterprise/","title":"AxonOps Enterprise","text":""},{"location":"overview/motivation/","title":"What is AxonOps?","text":""},{"location":"overview/motivation/#what-is-axonops","title":"What is AxonOps?","text":"<p>AxonOps is a One-Stop Operations Platform for Apache Cassandra\u00ae</p> <p>Built by Cassandra experts, the only cloud native solution to monitor, maintain and backup any Cassandra cluster anywhere</p>"},{"location":"overview/motivation/#why","title":"Why ?","text":"<p>Frustrated by the lack of tooling available to manage the next generation open source data platforms, AxonOps engineers decided to build a one-stop monitoring and operations platform to ensure they could provide the highest quality of services. Proven in some of the most demanding environments, AxonOps is now available as a standalone platform supporting Apache Cassandra today with Apache Kafka coming soon.</p>"},{"location":"overview/motivation/#features","title":"Features","text":"<ul> <li>Metric Dashboard - The AxonOps dashboard is pre-configured and well laid out in order for you to easily visualise the performance of your multiple Cassandra clusters across all of your data centres,</li> <li>Logs and Events - AxonOps agents collect logs from log files, as well as internal Cassandra events such as \u201crepair\u201d and JMX calls.</li> <li>Service Checks - As a site reliability engineer, service checks and the RAG status dashboard gives you great confidence in how your platform is operating. Regular checks against your processes, open ports, service health can be quickly implemented and deployed with minimum setup.</li> <li>Alert Integrations - Alerts can be configured for multiple services including Slack, Pagerduty, SMTP, and generic webhooks.</li> <li>Cassandra Repairs - Cassandra repairs are essential for maintaining the data integrity across all replicas.</li> <li>Backup and Restore - There are very few Cassandra tools that allow to setup Cassandra data backups as easily as AxonOps.</li> </ul>"},{"location":"overview/motivation/#company-timeline","title":"Company Timeline","text":"<p>To view the journey we have embarked on since 2017 have a look here</p>"},{"location":"overview/motivation/#motivation","title":"Motivation","text":"<p>AxonOps has been developed and actively maintained by AxonOps Limited, a company providing managed services for Apache Cassandra\u2122 and other modern distributed data technologies.</p> <p>AxonOps used a variety of modern and popular open source tools to manage its customer's data platforms to gain quick insight into how the clusters are working, and be alerted when there are issues.</p> <p>The open source tools we used are:</p> <ul> <li>Grafana - metrics dashboarding</li> <li>Prometheus - time series database for metrics</li> <li>Prometheus Alertmanager - metrics alerting</li> <li>ELK - Log capture and visualisation</li> <li>elastalert - Alerting on logs</li> <li>Consul - Service Discovery and Health Checks</li> <li>consul-alerts - Alerting on service health check failures</li> <li>Rundeck - Job Scheduler</li> <li>Ansible - Provisioning automation</li> </ul>"},{"location":"overview/motivation/#problems","title":"Problems","text":"<p>The tools listed above served us well. They gave us the confidence to manage enterprise deployment of distributed data platforms \u2013 alerting us when there are problems, ability to diagnose issues quickly, automatically performing routine scheduled tasks etc.</p> <p>However, using these tools and their problems were realised over time.</p> <ol> <li>Too many components - There are many components including the agents that need to be installed. Takes a lot of effort to integrate all components for each customer's on-premises environment, even with fully automated implementation using Ansible.</li> <li>Steep learning curve - The learning curve of deploying and configuring all the components is high.</li> <li>Patching hell - Patching schedule became a nightmare because of the sheer number of components. Imagine having to raise change requests for patching all above components!</li> <li>Enterprise hell - Firewall configurations became big for enterprise on-premises customers, often required many hours of tracing which change requests were unsuccessfully executed.</li> <li>Multiple dashboards - Multiple dashboards for metrics, logs and service availability.</li> <li>Complex alerting configurations - Alert notification configurations were all over the place. Fine-tuning alerts and updating them takes a lot of work.</li> </ol>"},{"location":"overview/motivation/#wish-list","title":"Wish List","text":"<p>With the above problems in mind, we needed to become more efficient as a company deploying the tools we need to manage our customers. After promoting the above tools to our customers, we ate the humble pie, and went back to the drawing board with the aim of reducing the efforts needed to on-board new customers.</p> <ul> <li>On-premises / cloud deployment</li> <li>Single dashboard for metrics / logs / service health</li> <li>Simple alert rules configurations</li> <li>Capture all metrics at high resolution (with Cassandra there are well over 20,000 metrics!)</li> <li>Capture logs and internal events like authentication, DDL, DML etc</li> <li>Scheduled backup / restore feature</li> <li>Performs domain specific administrative tasks, including Cassandra repair</li> <li>Manages the following products;<ul> <li>Apache Cassandra</li> <li>Apache Kafka</li> <li>DataStax Enterprise</li> <li>Confluent Enterprise</li> <li>Elasticsearch</li> <li>Apache Spark</li> <li>etc</li> </ul> </li> <li>Simplified deployment model</li> <li>Single agent for collecting metrics, logs, event, configs</li> <li>The same agent performs execution of health checks, backup, restore</li> <li>No JMX to capture the metrics, and must be push from the JVM and not pull</li> <li>Single socket connection initiated by agent to management server requiring only simple firewall rules</li> <li>Bidirectional communication between agent and management server over the single socket</li> <li>Modern snappy GUI</li> </ul>"},{"location":"pitr/configuration/","title":"Configure Commitlog Archiving","text":""},{"location":"pitr/configuration/#prerequisites","title":"Prerequisites","text":"<p>Backups are enabled and setup. For more on how to setup backups please follow the guide here.</p>"},{"location":"pitr/configuration/#steps","title":"Steps:","text":"<p>In the AxonOps Dashboard on the left hand menu navigate to Operations --&gt; Backups</p> <p></p> <p>On the top tab select Commitlog Archiving.</p> <p></p>"},{"location":"pitr/configuration/#configuration","title":"Configuration","text":"<p>Complete the fields with the required value and click </p>"},{"location":"pitr/configuration/#fields","title":"Fields","text":"<ul> <li> <p><code>Data Centers (Mandatory)</code></p> <p>The Cassandra Cluster DC that you want to enable Commitlog Archiving.</p> </li> <li> <p><code>Retention (Mandatory)</code></p> <p>The amount of time in hours(h), days(d), weeks(w), month(M) or year(y) that you want to archive the commit logs for.</p> </li> <li> <p><code>Remote Storage</code></p> <p>The following options are available for Remote storage locations.</p> <ul> <li>AWS S3</li> <li>Google Cloud Storage</li> <li>local filesystem</li> <li>Microsoft Azure Blob Storage</li> <li>S3 Compatible</li> <li>SFTP/SSH</li> </ul> </li> <li> <p><code>Base Remote Path</code></p> <p>This is the name of the storage buckets, you can also add subfolders if using shared storage buckets or saving multiple clusters to the same bucket. By default AxonOps will save the backups to /bucket/folder/org/clustertype/clustername/host-id/</p> <p>The org/clustertype/clustername/host-id/ will match the top breadcrump navigation in your AxonOps Dashboard.</p> </li> </ul>"},{"location":"pitr/overview/","title":"Overview","text":""},{"location":"pitr/overview/#point-in-time-recovery","title":"Point in Time Recovery","text":"<p>The aim of the AxonOps Cassandra Commitlog Archiving(PITR) feature is to provide an easy to use graphical user interface instead of users having to configure it manually on every Cassandra node in a cluster.</p>"},{"location":"pitr/overview/#features","title":"Features","text":"<ul> <li>UI to configure Commitlog archiving per Data Center(DC) in your cluster.</li> <li>UI that uses backups and commitlogs to specify the Point-in-Time to restore your cluster state too. </li> <li>UI for for viewing current commitlog archiving status.</li> <li>Local or Remote Storage locations to store your commitlog archives.</li> <li>Retention periods for how long to keep your commitlog archives.</li> </ul>"},{"location":"pitr/overview/#understanding-commitlog-archiving","title":"Understanding Commitlog Archiving","text":"<p>In Apache Cassandra, the commitlog is a vital component of the database that records every write operation before it is applied to the data files (SSTables).  This mechanism ensures durability and helps recover data in case of a node failure.</p> <p>Commitlog Archiving takes this a step further by continuously saving these logs to a secure location. This process involves:</p> <ul> <li> <p><code>Capturing Every Change</code></p> <p>Every modification to the database, including inserts, updates, and deletions, is recorded in the commitlog.</p> </li> <li> <p><code>Archiving Logs</code></p> <p>These logs are periodically copied to an external storage location, creating a history of all database operations.</p> </li> <li> <p><code>Ensuring Data Durability</code></p> <p>In the event of a hardware failure or data corruption, the archived commitlogs can be used to reconstruct the state of the database.</p> </li> </ul> <p>This archiving process is essential for maintaining data integrity, enabling disaster recovery, and supporting compliance with data retention policies.</p>"},{"location":"pitr/overview/#point-in-time-restore-pitr","title":"Point-in-Time Restore (PITR)","text":"<p>Point-in-Time Restore (PITR) is a powerful feature that allows you to restore your database to a specific moment in time. This is particularly useful for recovering from data corruption, accidental deletions, or other operational errors.</p> <p>Here\u2019s how PITR works in Apache Cassandra:</p> <ul> <li> <p><code>Continuous Archiving</code></p> <p>As mentioned, commitlogs are continuously archived, creating a comprehensive record of all database operations.</p> </li> <li> <p><code>Restore Process</code></p> <p>When a restore is needed, the archived commitlogs are replayed from the last known good snapshot up to the desired point in time. This involves:</p> <ul> <li><code>Stopping the Database:</code> Halting operations to ensure data consistency.</li> <li><code>Applying Logs:</code> Reapplying the archived commitlogs to reconstruct the database state up to the specified timestamp.</li> <li><code>Restarting Operations:</code> Bringing the database back online, now restored to the desired point in time.</li> </ul> </li> </ul> <p>PITR is invaluable for maintaining business continuity and minimizing data loss in critical situations. It provides a granular level of control over data recovery, allowing enterprises to revert their databases to any precise moment before an issue occurred.</p>"},{"location":"pitr/overview/#why-commitlog-archiving-and-pitr-matter","title":"Why Commitlog Archiving and PITR Matter","text":"<p>Commitlog archiving and PITR are not just advanced database features; they are essential tools for enterprise-grade data management. They ensure that:   - <code>Data Integrity</code></p> <pre><code>Your data remains accurate and consistent, even in the face of failures.\n</code></pre> <ul> <li> <p><code>Disaster Recovery</code></p> <p>You can recover quickly from unforeseen disasters with minimal data loss.</p> </li> <li> <p><code>Regulatory Compliance</code></p> <p>You meet stringent data retention and auditing requirements.</p> </li> <li> <p><code>Operational Resilience</code></p> <p>You can handle accidental data modifications or deletions without significant downtime.</p> </li> </ul>"},{"location":"pitr/overview/#the-traditional-challenges-of-cassandra-commitlog-archiving-and-point-in-time-restore","title":"The Traditional Challenges of Cassandra Commitlog Archiving and Point-in-Time Restore","text":"<p>Typically, setting up Commitlog Archiving and Point-in-Time Restore in Cassandra is a complex and time-consuming process.  It involves configuring various components, ensuring compatibility between different systems, and maintaining an intricate setup that can often be fragile and prone to errors. These configurations require in-depth knowledge and continuous monitoring to ensure everything runs smoothly.</p> <p>Setup Commitlog (PITR) in a couple easy steps here.</p>"},{"location":"pitr/restore/","title":"Restore from Point-in-Time","text":""},{"location":"pitr/restore/#requirements","title":"Requirements","text":"<ul> <li>Make sure Cassandra service is stopped on every node in the Cluster/Data Center(DC)</li> <li>Make sure Cassandra commitlog directory is emptied for every node you want to restore too.</li> <li>Check Cassandra Application Keyspace table directories are emptied for every node and keyspace/table you want to restore. </li> </ul>"},{"location":"pitr/restore/#steps","title":"Steps:","text":"<p>In the AxonOps Dashboard on the left hand menu navigate to Operations --&gt; Restore</p> <p></p> <p>On the top tab select Point-In-Time Recovery</p> <p></p> <p>You will be presented with the Point-In-Time restore screen. There are several steps that need to be done to complete a Point-in-time restore. </p> <p></p>"},{"location":"pitr/restore/#step-1-select-restore-point-in-time","title":"Step 1: Select Restore Point-in-time.","text":"<p>Select the Point-In-Time you want to restore your cluster too. </p> <p>Please complete the Date/Time selection and fields of the keyspace and table/s that you would like to restore.</p> <ul> <li> <p><code>Wide Time Range</code></p> <p>The wide time range is always a calendar month from the 1st to the last day of the selected month.</p> <p>To select a different month please use the  and  arrows on either side of the slider.</p> <p>At the beginning and end of the Wide Time Range slider there is a black bar that you can slide left and right to narrow the Date/Time of when you want to restore to.</p> </li> <li> <p><code>Zoomed Section</code></p> <p>This is a narrower view of the wide selection in the above slider.</p> <p>By default if the Wide Time Range slider is 30 days the Zoomed Section will be 30 days. </p> <p>The narrower the time range in the Wide Time Range slider the more precise the available date/time selection will be in the Zoomed section.</p> <p>Example of what the Zoomed section will look like when snapshots are available to select for PITR.</p> <p> </p><pre><code>The Camera Icon represents a snapshot at a point-in-time where a commitlog is archived.\n</code></pre> </li> <li> <p><code>Point in time</code></p> <p>A text based representation of the selection made in the Zoomed section slider. This is an altenative if you want to manually input a specific time. </p> </li> <li> <p><code>Keyspace(optional)</code></p> <p>The Application or System Keyspaces that were included as part of the commitlog archive process. If you don't specify a Keyspace all Keyspaces will be included in the restore process.</p> </li> <li> <p><code>Tables(optional)</code></p> <p>The Application or System Tables that were included as part of the commitlog archive process. If you don't specify a Table all Tables will be included in the restore process.</p> </li> </ul>"},{"location":"pitr/restore/#step-2-overview-of-point-in-time-nodeskeyspaces-and-tables","title":"Step 2: Overview of Point-in-time nodes,keyspaces and tables.","text":"<p>Confirm by clicking show details that all the tables and keyspaces you want to restore will be part of the restoration. You will be presented with the following screen. </p> <p></p> <ul> <li> <p><code>Tables</code></p> <p>Tables to be restored will be highlighted in Green, those to be excluded will be Greyed out.  The search box will allow you to search for and confirm specific tables or keyspaces will be restored.</p> </li> <li> <p><code>Commit Logs</code></p> <p>The last timestamp and file name of the commit log that will be used to recover to the specified point-in-time.</p> </li> <li> <p><code>Snapshots</code></p> <p>The Snapshot/s that will be used to recover to the specified point-in-time</p> </li> </ul>"},{"location":"pitr/restore/#step-3-confirmation-of-point-in-time-restoration-to-proceed","title":"Step 3: Confirmation of Point-in-time restoration to proceed.","text":"<p>Confirm you are ready to start the Point-in-time restore.</p> <p></p> <ul> <li>Stop Cassandra on the nodes that need to be restored. </li> <li>Delete the SStable files in the target table directories</li> <li>Delete commitlog files in the commitlog directory</li> </ul>"},{"location":"pitr/restore/#step-4-final-checks-and-last-steps-before-point-in-time-restore-starts","title":"Step 4: Final checks and last steps before Point-in-time restore starts.","text":"<p>The Axon-Agent service confirm the Cassandra nodes are stopped. Checks to ensure the clstuer is ready for the Point-in-time restore.</p> <p></p> <p>Once you have clicked Check PITR Readiness it will confirm that the Cluster is in the correct state for recovery to proceed.</p> <p>If any of the data directories still contain sstables a warning may be displayed. </p> <p>Click on show details button to view the tables affected and any errors/warnings.</p> <p></p>"},{"location":"pitr/restore/#step-5-start-the-point-in-time-restore","title":"Step 5: Start the Point-in-time restore.","text":"<p>Start the restore process</p> <p></p>"},{"location":"pitr/restore/#step-6-wait-for-completion-and-start-cassandra-nodes","title":"Step 6: Wait for completion and start Cassandra nodes.","text":"<p>The Status page of the Point-in-time restore process.  Once the restore has been completed the status will remain in a progressing state until the Cassandra nodes are restarted.</p> <p></p>"},{"location":"pitr/restore/#step-7-check-data-in-cassandra-has-been-recovered-to-specified-point-in-time","title":"Step 7: Check data in Cassandra has been recovered to specified Point-in-time.","text":"<p>Successful Point-in-time restore.  Please confirm the details and data in the tables that have been restored are present as expected.</p> <p></p>"},{"location":"quickstart/docker/","title":"Docker","text":""},{"location":"quickstart/saas/","title":"SaaS Quickstart","text":""},{"location":"release_notes/releases/","title":"Release Notes","text":""},{"location":"server/api/overview/","title":"API Overview","text":""},{"location":"system-requirements/","title":"System Requirements","text":""},{"location":"system-requirements/#system-requirements","title":"System requirements","text":"<p>Minimum system requirements for installing AxonOps Server and AxonOps Dashboard on a Self-Hosted Server to Monitor and Manage the 6 nodes that are part of the Starter Tier</p> <p>Please note this is not a system requirements spec for your Cassandra nodes where the AxonOps Agent will be installed. </p> System Requirements AxonOps Server and AxonOps Dashboard Processor 1 gigahertz (GHz)\u202for\u202ffaster with 4 or more cores on a\u202fcompatible 64-bit processor. RAM 8 gigabytes (GB) Storage 20 GB or larger storage device. Elasticsearch Metrics Store Processor 1 gigahertz (GHz)\u202for\u202ffaster with 4, ideally 8 or more cores on a\u202fcompatible 64-bit processor. RAM 16 gigabytes (GB) Storage 120 GB or larger storage device. <p>If you need to increase the amount of nodes to be monitored, you can get in touch with us</p> <p>Contact Us</p>"},{"location":"workbench/cassandra/cassandra/","title":"Cassandra Workbench","text":""},{"location":"workbench/cassandra/license/","title":"License","text":"<p>These licenses apply to the AxonOps\u2122 Workbench source code and product. </p>"},{"location":"workbench/cassandra/license/#end-user-license-agreement-eula-for-axonopstm-workbench-product","title":"End-User License Agreement (EULA) for AxonOps\u2122 Workbench product","text":"<p>AxonOps Workbench releases are made available under the Apache License 2.0 licence agreement.</p>"},{"location":"workbench/cassandra/license/#source-code-licence-for-axonopstm-workbench-product","title":"Source Code Licence for AxonOps\u2122 Workbench product","text":"<p>Source Code for AxonOps Workbench is available at https://github.com/axonops/axonops-workbench-cassandra under the Apache License 2.0 licence agreement.</p>"}]}